Évaluer réseaux bayésiens échantillonnage hypothèses simplifiées Saaid Baraty Simovici Université Massachusetts Boston Computer Science Department Boston Massachusetts 02125 sbaraty Résumé plupart évaluations remise forme commune réseaux bayésiens présence données critère Cooper Herskovitz Cette technique implique énormes quantités données conséquent calculs expansives proposons méthode évaluation alternative moins coûteuse utilisant hypothèses simplifiées évaluations duces fortement corrélés Cooper Herskovitz Introduction étudions problème construction réseau bayésien nomène composite nomène discrètes variables aléatoires représentant affectation attributs faire partons multiset données tuple instance événement appelons cette multiset comme ensemble données preuve ensemble données faire court certain nombre hypothèses nécessaires obtenir mesure évaluation aptitude structure réseau bayésien ensemble données apprentissage hypothèses fortes evaluationmoremanageable autre modèle obtenu selon hypothèses faibles mieux mesure conforme véritable distribution jacente problème graphe orienté acyclique ayant comme ensemble sommets ensemble bords capture dépendances probabilistes directes entre variables ensemble paramètres permet quantifier distribution probabilité conjointe spécifié ensemble affectations possibles variable aléatoire notion domaine étendu ensembles variables produit cartésien ensemble nœuds parents ensemble descendants ensemble noeuds excluent descendants Quand clair contexte laissons tomber indice paire satisfait condition Markov local distribution probabilité défini modèle réseau bayésien satisfait condition Markov locale règle chaîne conséquent laissons θijri distribution probabilité conjointe spécifiée évaluation réseaux bayésiens échantillonnage postéro Score ensemble réduit Hypothèses Cooper Herskovitz introduit probabil mesure évaluer aptitude comme modèle probabiliste Puisque constante travers différents réseaux pouvons travailler espace distributions toute probabilité thetav structure Alors Rappelons ensemble distributions vecteurs doivent satisfaire outre collecte variables vecteurs aléatoires considéré comme variable aléatoire fonction probabilité conditionnelle données donné fonction densité conditionnelle structure donnée fonction probabilité priori Structure évaluer nombre intégrale hypothèses introduites Cooper Herskovits indépendance données suppose tuples indépendants compte structure réseau hypothèse indépendance locale mondiale exige conditionnellement indépendante compte structure hypothèse espace collections possibles écrit comme raison hypothèse Cooper Herskovits remplacer produit dessus égalité outre prennent distribution chaque uniforme appelons cette hypothèse comme deuxième probabilité uniforme commande SOUPE Heckerman introduisent métrique mesure basée postérieur similaire métrique utilisent hypothèse trois autres hypothèses second ordre probabilité Dirichlet suggéré utilisé Cooper Herskovits modularité paramètres hypothèse échantillon multinomial généralisation hypothèse SOUPE stipule distribution Dirichlet hypothèse échantillon multinomial affirme définissons ensemble ordonné désigne restriction tuple avons Assign compatible hypothèse remplacé autres hypothèses lence probabilité possibilité structure implique prise charge Notez toutes fonctions proba distribution Dirichlet nécessite paramètres Ainsi chaque devons spécifier paramètres cette pratique approche surmonter cette difficulté Heckerman connais sances avant réseau bayésien dénommé réseau antérieur Ensuite Dirichlet paramètre correspondant composante distribution probabilité ParGpr paramètre donné utilisateur auquel Baraty Simovici considèrent comme étant taille équivalente échantillon choix valeurs collection observer données arbitraire utilisons échantillonnage permettent laisser données façonner répartition probabilité posteriori vecteurs évaluation avant Cooper Herskovits suppose distribution priori uniforme autres hypothèses basées paramètres doivent spécifiés arbitrairement échantillonnage permet utiliser données substitut hypothèses fortes connaissance domaine détermination paramètres deuxième répartition probabilité ordre probabilité priori Laissez échantillons disjoints évaluons comme mesure remise forme structure Puisque dépend spécifique pouvons laisser tomber place calcul Notez règle chaîne prélevons régulièrement différentes structures alors constante supprimée conséquent adoptons mesure relative aptitude structures ensemble données répète processus échantillonnage pouvons étendre notre mesure échantillons FROMD chaque référons cette mesure validation échantillon structure données désignons SAMPk échantillons disjoints premier terme SAMPk écrit forme ordre topologique noeuds représente connaissance préalable expert domaine Notons nombre occurrences tuple laisser Étant donné attributs discrètes λlijr première égalité règle chaîne seconde égalité supposant hypothèse λlijr λlijr sinon Depuis λlijr avons Ensuite second terme droite égalité Évaluation réseaux bayésiens échantillonnage suppose theSOUP hypothèse chaque probabilité postérieure conditionnée présence échantillon comme montre égalité Cette approche différente celle utilisée Cooper Herskovits hypothèse SOUPE appliquée directement intervention données échantillon Ensuite avons égalité SOUPE résultat Jeffreys Jeffreys pages cette référence Ainsi partir égalités précédentes fonction Euler combinaison égalités obtient rapprocher quantité utilisons légère variation mesure appelée distorsion distribution introduite Baraty Simovici voulons évaluer indépendance conditionnelle capturé condition Markov locale selon données voulons évaluer quelle mesure conditions détient fonction fréquence rapport échantillon parvenir mesure divergence ensemble distributions probabilité ensemble distributions probabilité Définition divergence Markov locale structure fourche niveau noeud fonction échantillon notée LMDGS nombre somme étend divergence Kullbach Leibler entre distributions probabilité Laissez entropie Shannon ensemble partitionné fonction valeurs entropie Shannon conditionnelle ensemble partitionnées fonction valeurs conditionnée partition conformément affectation ensemble attributesW Baraty Simovici Théorème avons LMDGS Théorème seulement théorème implique LMDGS après théorème valeur structure fourche niveau noeud satisfaire condition Markov locale selon conséquent condition Markov proche satisfaite selon échantillon autre divergente Baraty Simovici distributions probabilité chaque Lorsque LMDGS haveHS signifie ensemble aucune capacité prédiction niveau noeud ensemble capacité parfaite predication Laissez ensemble toutes structures possibles bayésienne ensemble attributs Define LMDGS utilisant évaluations précédentes SAMPk écrit LMDGS2q échantillonne systématiquement données travers structures différentes pouvons laisser tomber entités constantes rapport supposant LMDGS2q avons SAMPk Résultats expérimentaux conclusions avons expériences trois structures connues domaines alarme Voiture Diagnosis2 Cancer napolitain nœuds respec tivement premières structures avons généré hasard tables probabilités correspondantes Ensuite fonction distributions probabilité introduites avons produit ensembles données tailles 80000 100000 respectivement avons utilisé ensemble données correspondant littérature valeurs manquantes chaque ensemble données avons généré hasard certain nombre structures différentes complexités nombre bords structures varie ensembles données respectivement figures montrent corrélations fortes entre score score diverses valeurs mesure dérivée moins calculer fonctionne échantillons beaucoup petits ensemble données avons introduit mesure basée probabilité posteriori mesurer aptitude structure réseau bayésien partir données conclusion travail notre notation alternative échantillonnage viable beaucoup moins utilisons échantillonnage réduire ensemble hypothèses obtenons forte corrélation entre mesures confirme SOUPE distribution uniforme hypothèses sûres faussent recherche Évaluation réseaux bayésiens échantillonnage données alarme Données voitures Diagnosis2 données cancer napolitain diagramme comparaison temps Corrélations entre SAMPk temps nécessaires ouvrir session calcul SAMP1 marque Références Baraty Simovici Use_edge structures réseau bayésien Actes Conférence Mining Australie Melbourne Cooper Herskovits Procédé bayésien induction réseaux données probabilistes Rapport technique Université Stanford laboratoire Knowledge System Heckerman Geiger Chickering Apprentissage réseaux bayésiens combinaison connaissances données statistiques InMachine apprentissage Jeffreys Jeffreys Dirichlet Intégrales Cambridge Royaume Cambridge versité Press évaluation qualitative résumé Connue Bayesiens réseaux présence Données Cooper Herskovitz critère Technique implique Quantités massives Données conséquent Nombreux Calculs proposons méthode évaluation suppositions Efficace Simplifiées Utilisant produit EVALUATIONS FORTEMENT corrélées Cooper Herskovitz critère