E33Approche préventive gestion élastique traitement parallèle distribué données Roland Kotto Kombi Nicolas Lumineau Philippe Lamarre LIRIS UMR5205 69621 Villeurbanne France affil2 Université Claude Bernard LIRIS UMR5205 69622 Villeurbanne France liris prénom liris Résumé contexte traitement données important garantir utilisateur propriétés performance qualité résultats passage échelle Mettre adéquation ressources besoins allouer ressources nécessaires traitement efficace tualité majeur croisement problématiques Green approche suggérons permet adapter dynamiquement automati quement degré parallélisme différents opérateurs composant quête continue selon évolution débit traités proposons métrique permettant estimer activité future opérateurs selon évolution entrée approche AUTOSCALE évaluant priori intérêt modification degré parallélisme opérateurs prenant compte traitement données globalité grâce intégration notre proposition Apache Storm exposons tests performance comparant notre approche rapport solution native outil Introduction multiplication sources données capteurs objets connectés méthodes acquisition stockage traitement données évolué gérer masse vélocité séquences uplets débit distribution valeurs peuvent varier cours temps interrogation requêtes dites continues Sattler Beier soulèvent défis majeurs terme performance passage échelle terme performance systèmes gestion données doivent pouvoir traiter volée données issues capacité systèmes absorber traiter dépend également qualité résultats seront produits concerne passage échelle systèmes doivent mesure absorber débits données potentiellement variables élevés Travaux partiellement financés projet Socioplug socioplug nantes index SocioPlug_Project AUTOSCALE Traitement adaptatif données répondre enjeux systèmes gestion données Gedik Neumeyer Schneider Zaharia développés concentrerons systèmes représentant quêtes continues comme graphe opérateurs workflow gérant support exécu distribué solutions répondent mieux défis ciblés plaçons cadre techniques celles réécriture permis identifier différentes factorisations possibles entre ensemble requêtes continues workflows Notre problème traiter mieux workflows évolutions entrée accord ressources disponibles contexte parallèle distribué aspects distincts jouent rôles majeurs usage ressources gestion degré parallélisme opérateurs stratégie location ressources dispersion globale traitements dépend degré parallélisme chaque opérateur Modifier dynamiquement degré parallélisme opérateur permet adapter capacité absorption fonction variations données entrée stratégie adoptée mécanisme allocation impact évident ressources utilisées exemple stratégie répartition charge utilisera maximum ensemble sources disponibles contrario stratégie centrée diminution trafic réseau effet concentrer davantage opérateurs ensemble ressources qualité adaptation dynamique point qualité résultats usage ressources résultat solutions apportées aspects ainsi interaction article focaliserons adaptation degré parallélisme chaque opérateur débits variants effet augmentation débit entrée opérateur conduire congestion Gedik traduit augmentation rédhibitoire latence pouvant conduire défaillance système éviter problème mécanisme allocation déplacer opérateurs ressources ayant puissance disponible Lorsque possible changement degré parallélisme constitue solution travaux récents Gedik intéressent notion élasticité optimiser performances usage ressources sources entendons machines ainsi bande passante réseau notre connaissance solutions adaptant dynamiquement degré parallélisme opéra teurs Gedik Schneider permettent anticiper activité opérateurs autre solutions Neumeyer nécessitent intervention utilisateur avons choisi intégrer notre système gestion dynamique degré parallélisme chaque opérateur Apache Storm nombre répliques opérateur calculé partir métrique permettant anticiper activité court terme Cette métrique évolution entrée activité récente opérateur reconfigurations passant augmentation scale diminution scale degré parallélisme évaluées notre approche AUTOSCALE individuellement globalement identifier celles cohérentes favorables performance stabilité système suite présentons limites solutions existantes Section triques caractérisant activité opérateur introduites Section approche AUTOSCALE adaptant dynamiquement degré parallélisme opérateurs décrit Apache Storm storm apache Kotto Kombi Lumineau Lamarre Section Enfin exposons résultats évaluation expérimentale approche proposons Section Motivation Contexte exécution préciser problème traitons positionner rapport considérons trois requêtes continues Comme illustré Figure requêtes représentées topologies correspondent leurs plans exécution logiques respectifs Principe traitement parallèle distribué multi requêtes données Chaque requête porte entrée topologie séquentielle organisée diamant étoile Chacune topologies représente motif élémentaire toute topologie considérée comme composition topologies chaque opérateur associé ensemble tâches nombre tâches associées opérateur correspond degré parallélisme opérateur exemple associé tâches degré parallélisme tâches allouées selon allocation unités traitement machines disponibles exécutées Figure quatre tâches topologie distribuées machinesM1 distinguons trois types machines trois types ressources machines ressources actives elles traitent tâches leurs affectées machines ressources configurées actives aucune leurs unités traitement traitent tâches Enfin machines AUTOSCALE Traitement adaptatif données ressources disponibles configurées utilisable mécanisme allocation posons hypothèses suivantes contexte exécution Premièrement sources latences réseaux homogènes ressources suffisantes traiter entrée plaçons plusieurs requêtes continues peuvent traitées simultanément Ensuite stratégie allocation gérée gestion données Enfin considérons ensemble débits variant distribution valeurs écart faible problématique adaptation dynamique distribution variante valeurs abordée Rivetti scope article Approches existantes performance solution traitement qualité résultats produits fortement dépendants réactivité système variations environnement exécu problème cependant complexe réagissant variations contexte exécution éviter instabilité système affecterait performance qualité résultats Certaines solutions Aniello basent sources trafic réseau déterminer ensemble quasi optimal affectations tâches unités traitement permet réduire latence globale topologie évitant échanges réseaux coûteux entre machines Toutefois solutions impact limité capacité traitement chaque opérateur effet toutes tâches associées opérateur réparties maximum ressources capacité traitement augmentée solutions basant systématiquement usage maximal ensemble sources Neumeyer Zaharia permettent garantir selon thèse traitement requête continue dégradation qualité résultats exemple support exécution donné revient paralléliser maximum opéra teurs placer unités traitement selon stratégie répartition charge heureusement cette solution avère inappropriée contexte exécution multi requêtes point énergétique économique souhaitable auteurs présentent algorithme permettant faire scale scale demande Cette approche repose utilisateur nition script règles métier elles existent Enfin cette approche uniquement curative augmente degré parallélisme opérateurs congestionnés possibilité anticipation solutions Gedik Schneider permettent adapter dynami quement automatiquement degré parallélisme opérateurs toutefois elles reposent détection congestions effectives solutions puissent réduire durée congestion opérateurs elles peuvent prévenir Heinze auteurs proposent solution basée algorithme apprentissage cette nière système adapter degré parallélisme opérateurs apprenant mesure gains réalisés fonction reconfigurations effectuées Toutefois cette détection consommation ressources congestions système Kotto Kombi Lumineau Lamarre différentes approches toutes curatives puisqu elles interviennent soudre problème congestion produit conséquences qualité résultats plupart nécessite présence expertise utilisateur lution anticipant congestions limiter voire éviter naturellement souhaitable Anticipation activité opérateur proposons formalisation différentes notions manipulons caractériser exécution topologie requête continue introduisons métriques nécessaires estimation adéquation entre degré parallélisme niveau tivité opérateurs topologie requête continue représentée graphe orienté ensemble nœuds représente opérateurs ensemble représente transmission données considérons chaque opérateurOi comme opérateur physique pouvant exécuté parallèle ensemble tâches nombre tâches degree définit degré parallélisme opérateur ensemble fenêtres analyse chacune composée ensemble itérations Chaque fenêtre analyse associée opérateur Chaque définit durée regroupe mesures effectuées durant intervalle temps mesures effectuées selon ensemble prédéfini timestampsMi chaque opérateurOi effectuons chaque timestampm mesures prenant compte uplets reçus traités intervalle important préciser mesures effectuées opérateurs appartenant topologie synchrones ensemble potentiellement infini uplets entrée opérateur définissons ensemble uplets reçus opérateur durant fenêtre ensemble uplets reçus durant intervalle Estimation charge traiter opérateur proposons estimer itération nombre uplets système devra traiter durant itération suivante estimer capacité traitement compatible cette charge opérateur considéré comme source potentielle congestion système charge traiter opérateur durant itération correspond nombre uplets nouvellement reçus ajoutent uplets traités itération précé dente charge effective itération correspond valeur Chargeij nbEnAttenteF nbEnAttente correspond nombre uplets attente traitement durant ration traitement achevé durant itération ultérieure valeur formule calcul cette charge effective faire AUTOSCALE Traitement adaptatif données pouvoir anticiper congestion avons besoin estimer cette charge estimons nombre nouveaux uplets reçus durant itération régres linéaire basant nombre uplets observés durant itération fonction affine calculée régression linéaire partir couples estimation nombre total uplets attendus durant itération itération définie EstimRi estimation charge attendue durant itération définie EstimChargeF EstimRi nbEnAttenteF Estimation capacité traitement opérateur Maintenant avons estimation quantité uplets devrait avoir traiter opérateur itération reste estimer capacité traitement opérateur cette itération définissons capacité traitement opérateur comme étant nombre moyen uplets opérateur capable traiter durant itération CapaciteF degree correspond latence intra opérateur attente moyenne observée uplets traités durant itération hypothèse portant caractère uniforme distribution données entrée opérateurs utilisons simplement covariance estimer capacité moyenne traitement opérateur durant fenêtre EstimCapaciteF CapaciteF correspond covariance entre capacité traitement estimée itération capacités traitement observées itérations précédentes Estimation niveau activité congestion opérateur différentes observations estimations permettent présent définir trique contrôle activité opérateur notion Niveau Activité représente intuitivement adéquation entre degré parallélisme débit entrée définie EstimChargeF EstimCapaciteF Choix arbitraire auteurs technique régression remise cause résultats expérimentaux Kotto Kombi Lumineau Lamarre seuils paramétrables définissant respectivement niveau faible niveau activité interprétation opérateur suivante SiNdAF activité opérateur faible capacité opérateur considérée comme importante rapport nombre uplets attente traitement durant itération activité opérateur normale opérateur capacité traiter uplets attente traitement durant itération activité opérateur forte opérateur arrive limite capacité traiter uplets attente traitement durant itération activité opérateur critique opérateur mesure traiter uplets attente traitement durant itération Approche AUTOSCALE approche AUTOSCALE détermine chaque opérateur modification degré parallélisme augmentation scale diminution scale conservation nothing Notre approche prend compte estimation activité chaque opérateur aussi contexte global effet reconfigurations effets cascade prévisibles exemple augmentation capacité opéra activité forte critique augmenter débit sortie avoir impact débit entrée opérateurs Initialisation Graphe Actions Possibles premier temps allons définir ensemble reconfigurations effectuer chaque opérateur fonction activité ensemble représenté forme graphe disposant structure topologie sommets étiquetés proposition action opérateur correspondant actions possibles scale scale nothing graphe actions possibles fenêtre rappel fonction affine calculée régression linéaire estimer charge opérateur formule Cette fonction permet estimer tendance évolution charge dérivée cette dérivée strictement positive charge considérée comme croissante sinon considérée comme décroissante constante opérateurs topologie parcourus après autres fenêtre courante opérateur courant selon niveau activité opérateur faible normal critique tendance évolution charge possible proposer action modification degré parallélisme selon matrice décision locale définie Tableau AUTOSCALE Traitement adaptatif données Tendance évolution charge Activité opérateur activité faible activité normale activité forte activité critique Décroissante constante scale nothing nothing scale Croissante nothing nothing scale scale Matrice décision locale construction graphe actions possibles Prise compte contexte global graphe actions possibles construit approche AUTOSCALE vérifie hérence globale graphe actions possibles ainsi obtenu introduisons relation ordre ensemble actions possibles Ainsi action scale prédomine action scale prédomine action nothing déterminer action prise localement cohérente globalement définissons matrice décision globale Tableau déclenchement actions reconfiguration parcourons graphe tions possibles partir opérateurs entrée utilisant matrice décision globale identifions ensemble reconfigurations cohérentes effectuer opérateurs pologie action prédominante amont opérateur décision locale opérateur nothing scale scale nothing nothing scale scale scale nothing scale scale scale scale nothing scale Matrice décision globale Grâce ordre ensemble actions possibles pouvons déterminer action prédominante observée nœuds précédant courant topologie Ainsi après Tableau scale validé amont courant action prédominante scale contraire scale remplacé action nulle éviter contradiction court terme Quantification reconfigurations étapes précédentes permettent savoir reconfigurer opérateur ainsi reconfiguration reste quantifier degré parallélisme chaque opérateur reconfigurer degreej nombre tâches associées opérateur Kotto Kombi Lumineau Lamarre durant itération SoitmaxPOi nombre maximal tâches pouvant initialisées opérateur action scale scale validée alors degré parallélisme degreej défini degreej maxPOi degreej particulier scale préconisé cause activité forte critique degré parallélisme courant opérateur incrémenté Expérimentations Apache Storm permet définir requête continue forme topologie rateurs langage programmation niveau Python Clojure outil permet utilisateur configurer parallélisation opérateurs contrairement Neumeyer Zaharia Storm impose paradigme représenta données comme modèle valeur fondement approches MapReduce Zaharia offre grande flexibilité définition opérateurs Apache Storm garantit chaque uplet suivi individuellement jusqu sortie topologie avons développé notre approche intégrant Apache Storm présentons protocoles résultats expérimentaux Protocole expérimental Notre cluster compose machines virtuelles disposant chacune Intel cadencés 00GHz mémoire disque machine coordination autres dédiées exécution tâches leurs affectées Chacune machines supervisors unités traitement workers Notre module gestion dynamique degré parallélisme implémente interface ISchedu Storm coordinateur Nimbus avons également déployé données MySQL stocker historique différentes mesures détaillées Section valider notre approche avons choisi mettre avant impact topologies caractéristiques topologie linéaire topologie étoile diamant Chaque topologie caractéristique composée types opérateurs opérateurs intermediate ayant faible latence intra opérateur opérateurs possédant forte latence intra opérateur avons construit synthétique possédant plusieurs caractéristiques tribution uniforme valeurs variations caractéristiques effet comme présenté figure entrée stable émettant uplets augmente exponentiel lement stabilisant débit important Enfin débit synthétique diminue paliers jusqu stabiliser débit faible avons également sorte irrégulier approcher permet observer adaptation automatique Storm approche AUTOSCALE comparons solution native configurations Storm lesquelles paramétrons nombre tâches opérateur notre support exécution AUTOSCALE Traitement adaptatif données entrée topologies workers peuvent alloués topologie configuration ConfMin nombre initial tâches opérateur équivalent nombre minimal tâches Intuitivement configuration ConfMin adaptée faibles débits entrée absorber débits maximaux configuration ConfExpt nombre initial tâches opérateur intermediate opérateur nombre initial tâches topolo étoile topologies linéaire diamant choix faits configuration ConfExpt justifie expertise entrée effet paramètres confi guration ConfExpt permettent absorber débits maximaux entrée gaspillage ressources chaque configuration avons mesuré latence globale topologie perfor mance calcul nombre uplets déphasés qualité résultats concerne réactivité système consommation ressources sommes intéressés nombre tâches affectées chaque opérateur Résultats Comparatif entre Storm Default AUTOSCALE ConfMin avons choisi exposer uniquement résultats topologie linéaire représentatifs résultats autres topologies élémentaires intégralité résultats expérimentations peuvent consultés annexe respecter pratiques programmation Apache Storm avons implémenté rejeu uplets lorsque Annexe disponible liris rkottoko autoscale Kotto Kombi Lumineau Lamarre déphasés ConfMin observons absorbé conduit congestion totale topologie effet topologie mesure émettre uplets uplets source finissent déphasés rejoués indéfiniment source jusqu intervention utilisateur inverse notre proche AUTOSCALE augmente dynamiquement automatiquement degré parallélisme opérateur critique absorber variations entrée Lorsque degré parallélisme diminué conséquence éviter surconsommation ressources Comparatif entre Storm Default AUTOSCALE ConfExpt ConfExpt Figure partons configuration capable absorber maximal entrée cependant cette configuration surévaluée début notre synthétique Notre approche AUTOSCALE diminue degré parallélisme lorsque opérateurs nécessitent telle capacité traitement charge instar ConfMin degré parallélisme adapté progressivement AUTOS parvient ainsi diminuer dynamiquement automatiquement quantité ressources allouées maintenir latence équivalente Conclusion avons proposé approche permettant adapter dynamiquement automatique degré parallélisme opérateurs topologie Apache Storm fonction évolution entrée expérimentations montré cette proche permet limiter risques congestion opérateurs également converge configuration utilisant uniquement ressources nécessaires Cette proche offre traitement élastique hypothèse support exécution fournisse fisamment ressources travaux cours portent expérimentation large échelle ainsi problématiques liées configurations ressources insuffisantes Références Aniello Baldoni Querzoni Adaptive online scheduling storm International Conference Distributed Event Based Systems Arlington AUTOSCALE Traitement adaptatif données Gedik Schneider Hirzel Elastic scaling stream proces Trans Parallel Distrib Heinze Pappalardo Jerzak Fetzer scaling techniques stream processing Proceedings International Conference Distributed Event Based Systems Neumeyer Robbins Kesari Distributed stream computing platform Mining Workshops ICDMW International Conference Hosseini Farivar Campbell storm Resource aware scheduling storm Proceedings Annual Middleware Conference Vancouver Canada December Rivetti Querzoni Anceaume Busnel Sericola Efficient optimal balancing stream processing systems Proceedings International Conference Distributed Event Based Systems Norway Sattler Beier Towards elastic stream processing Patterns infrastruc Cormode Deligiannakis Garofalakis Volume Workshop Proceedings Schneider Andrade Gedik Elastic scaling parallel operators stream processing Parallel Distributed Processing IPDPS International Symposium Stela Enabling stream processing systems scale scale demand International Conference Cloud Engineering storm Traffic aware online scheduling storm Distributed Computing Systems ICDCS International Conference Zaharia Hunter Shenker Stoica Discretized streams fault tolerant model scalable stream processing Technical Report Department University California Berkeley Summary context stream processing important guarantee properties perfor mance quality results scalability final users Adjusting resource usage processing requirements order consume necessary resources major challenge dealing Green approach suggested article adapts dynamically matically parallelism degree operators belonging continuous query takes account evolution input stream rates suggest metric estimating activ level operators future approach AUTOSCALE which evaluates brought parallelism degree modifications local global scope thanks integration solution Apache Storm performance tests comparing approach native solution stream processing engine