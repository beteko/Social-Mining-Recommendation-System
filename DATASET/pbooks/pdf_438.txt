Apprentissage ensemble opérateurs projection orthogonale détection nouveauté Fatma Hamdi Younès Bennani Université Paris Clément 93430 Villetaneuse France Prénom paris13 Résumé papier proposons approche détection veauté fondée opérateurs projection orthogonale double bootstrap bootstrap Notre approche appelée Random Subspace Novelty Detection Filter combine technique rééchantillonnage apprentissage ensemble ensemble filtres Novelty Detection Filter induits partir échantillons bootstrap données apprentissage utilisant sélection aléatoire variables appren tissage filtres utilise double bootstrap rééchantillonnage remise observations rééchantillonnage remise variables prédiction faite agrégation prédictions ensemble filtres présente généralement importante lioration performances rapport modèle unique Grâce algorithme apprentissage ligne approche également mesure suivre changements données temps Plusieurs métriques performance montrent approche proposée efficace robuste offre meilleures performances détection nouveauté parée autres techniques existantes Introduction Plusieurs travaux recherche proposées problème détection veauté Markou Singh 2003a Markou Singh 2003c grande variété plications méthodes essentiel détection nouveauté conciste apprendre modèle ensemble modèles données disponibles utiliser aprés identifier données nouvelles nouveauté applications typiques problème détection fraudes maintenance préventive détection intrusions réseau diagnostic maladies rares nombreux autres domaines détection nouveauté particulièment utile quand classe importante représentée données exemple typique problème détection fraudes avoir intervalle plusieurs heures entre transactions frauduleuses distingue trois grandes familles approches détection nouveauté méthodes déterminent nouveauté aucune connaissance préalable données essentiellement approches apprentissage analogues classifica Détection nouveauté supervisée approches traitent données comme distribution statique cherchent identifier points éloignés points concidérés comme valeurs potentiellement aberrantes deuxième méthodes consiste modéliser données normales nouveauté approches analogues classification supervisée nécessitent données étiquetées finalement méthodes détection nouveauté analogues tâche classi fication supervisée essentiel repérer nouveauté apportée données encore inconnues exploitant connaissance extraite partir ensemble données référence données apprentissage données référence limitent exemples positifs données normales familières difficulté voire impossibilité certains identifier priori constituerait nouveauté rapport données connues amène problème classification partir seule classe article proposons nouvelle technique détection nouveauté fondée opérateurs projection orthogonale utilisées Kohonen modèle honen bootstrap ainsi paradigme apprentissage ensembliste Notre approche appelée Random subspace novelty detection filter semble induit partir échantillons bootstrap données apprentissage lisant sélection aléatoire niveau variables prédiction faite agrégeant prévisions ensemble caractéristique intéressante modèle simple œuvre architecture réseau neurones Kohonen ainsi prentissage adaptatif robustesse bruit article organisé comme section introduit concepts notre modèle Random Subspace Novelty Detection Filter section décrit bases données validation protocole expérimental ainsi résultats obtenus conclusion présentée section principe notre approche filtre détecteur nouveauté Kohonen Kohonen Kohonen proposé filtre détecteur veauté système linéaire adaptatif après apprentissage données référence comme opérateur projection espace vectoriel orthogonal espace vectoriel engendré données référence modèle laisse passer seulement propriétés nouvelles donnée rapport ensemble données rence apprises propriétés dites nouvelles elles représentées données référence autre description filtre donnée Kohonen filtre détecteur nouveauté implémenté réseau récurrent neurones élémentaires étroitement connectés forme boucles rétroactives feedback Figure sortie chaque neurone calculée comme combinaison linéaire entrée feedback reçoit sortie opérateur transfert décrit équation suivante Hamdi architecture neuronale modèle filtre détecteur nouveauté equation précedente écrire forme matricielle comme poids connexions rétroactives caractérisent interne réseau initialisés ensuite après présentation chaque donnée entrée réseau selon règle apprentissage Hebbian coefficient positif modifié manière adaptative cours apprentissage fonction transfert réseau définie représente matrice identité équation différentiel obtenue manière suivante αΦ2xxT théorème Greville Greville permet donner expression récursive estimer fonction transfert réseau manière suivante Détection nouveauté vecteur matrice données référence chaque vecteur diensions Pendant phase apprentissage modèle habitue données présentées entrée apprentissage terminé donnée férences leurs combinaisons linéaires présentée entrée modèle sortie correspondante nulle autre donnée appartenant espace formé données référence choisie comme entrée sortie correspondante nulle comme représentative variables nouvelles extraites partir donnée entrée données référence apprises extension modèle proposée Kassab Kassab deric modèle apprentissage incrémental ILoNDF Cette extension guidée réflexions problème modèle adaptation envisagée rectement apprentissage modèle guidé uniquement nouveauté adaptation interne modèle décrite formule prcécedente considère variables représentant nouveauté apportent données entrée faire participer toutes variables données entrée processus apprentissage stratégie adaptée consiste introduire matrice identité chaque étape apprentissage proje données entrée matrice identité matrice filtre nouvelle règle apprentissage écrit forme suivante matrice nulle notre travail avons utilisé cette nouvelle règle apprentissage problème détection nouveauté proportions peuvent calculées proportion nouveauté mesure permet quantifier nouveauté apportée donnée rapport ensemble données apprises filtre nombre exemples utilisés apprentissage proportion habituation indicateur similarité exemple données précédemment apprises Cette proportion pourrait considérée comme score classification exemple indique probabilité appartient nouvelle classe également possible calculer vecteur représente exemples utilisés apprentissage Ainsi score classification données entrée calculé façon suivante Hamdi vecteur unité associé chaque variable ensemble variables proportion habituation variable calculée comme vecteur défini comme vecteur poids composantes représentent proportion habituation chaque variable espace données algorithme Notre approche basée coopération ensemble calculés plusieurs échantillons derniers obtenus double bootstrap tirage aléatoire remise données tirage aléatoire remise variables prédiction faite agrégeant prévisions ensemble notre algorithme opérateurs projection orthogonale utilisées Kohonen modèle Kohonen technique bootstrap principe apprentissage semble architecture neuronale modèle déterminer seuil détection chaque filtre avons appliqué règles vantes Kassab Kassab Frederic scores sorties filtre attribués données apprentissage peuvent utilisés comme indicateur scores données peuvent positives faciles détecter elles fortement similaires données apprentissage Détection nouveauté conséquent moyenne scores admise comme limite supérieure seuil détection scores attribués données disponibles apprentissage avant utilisation peuvent utilisés comme indicateur scores données positives moins faciles détecter conséquent moyenne scores admise comme limite inférieure seuil détection algorithme apprentissage suivant Algorithme Random Subspace Novelty Detection Filter Entrées ensemble données apprentissage ensemble données ensemble variales nombre filtres matrice initial Sorties filtres vecteurs représentent classes cibles matrice détection nouveauté Begin jusqu tirage aléatoire remise données apprentissage tirage aléatoire remise variables Appliquer variables choisies aléatoirement formule jusqu jusqu Calculer proportion habituation formule utilisant filtre Agréger prédictions ensemble filtres mettre prédiction finale Validation Description données démontrer efficacité méthode proposée avons testé données utilisant validation croisée description données résumée tableau différents données Asuncion Newman disponibles archive datasets Hamdi notre expérimentation avons adapté différentes bases données utilisées contexte détection nouveauté apprentissage partir seule classe classe choisie aléatoirement chaque données Cette classe considérée comme étant classe nouveauté autres classes restantes fusionnées obtenir classe normale apprentissage Description bases données Dimension Taille Taille classe nouvelle Glass Ionosphere Spectf Waveform Yeast mesures performances protocole expérimental évaluer notre approche avons calculé plusieurs métriques performance plupart dernières concentrent capacité classifieurs identifier correctement observations chaque classes différentes métriques obtenues partir trice confusion suivantes Prcision Fmesure tableau présente matrice confusion classification binaire vrais positifs positifs négatifs vrais négatifs Matrice confusion classification binaire Classe Positive Prédite Classe Negative Prédite Classe Positive Réelle Class Negative Réelle TauxdeV raisNgative TauxdeV raispositive Rappel Precision Fmesure Precision Rappel Precision Rappel avons aussi utilisé courbe Peterson courbe représentation graphique compromis entre négatifs Détection nouveauté positifs existe plusieurs méthodes estimer courbe classification binaire définie comme avons utilisé toutes mesures comparer notre méthode approches couramment utilisées problème apprentissage partir seule classe détection nouveauté résultats différents indicateurs performance obtenus suite validation croisée algorithmes sélectionnés analyse composantes principales Jolliffe Séparateurs Vastes Marges Scholkopf Perceptron Multi couches associatif Rumelhart modèle Résultats chaque données approches testées leurs résultats évalués termes différentes mesures performances citées tableau montre performances différents algorithmes Comparaison Performances données Rappel measure partir résultats obtenus notre approche montre fonctionnement meilleur rapport toutes autres méthodes Cette amélioration touché différents critères évaluation tableaux montrent respectivement performances férents algorithmes utilisés Ionosphere Glass résultats montrent encore notre approche dépasse toutes mesures performances utilisées seulement notre approche donne résultat légèrement inférieur celui ionosphere Glass Comparaison Performances données Ionosphere Rappel measure Hamdi Comparaison Performances données Glass Rappel measure tableaux avons montré amélioration apportée notre approche rapport méthodes utilisées résultats également confirmés pection visuelle effet figures représentent performances obtenues critères évaluation bases données testées regardant graphiques quatre radars figure certaines conclusions peuvent tirées général donne meilleurs résultats rapport autres méthodes critères performances utilisés résultats obtenus parNDF légèrement supérieurs résultats notre approche données Waveform dépasse autres algorithmes utilisant Precision mesure precision définie comme pourcentage exemples correctement étiquetés comme positif pouvons conclure notre approche classe exemples positifs mieux autres méthodes Aussi critèresG etAUC donne meilleurs résultats comparé ailleurs graphiques radars bases données Spectf figure confirment bonnes performances notre approche effet valeurs montrent notre approche mesure donner résul intéressants Cette mesure performance représentation quantitative courbe courbe largement utilisée évaluation classifieurs outil visualisation organisation sélection algorithmes basant compromis entre vrais positifs négatifs figure montre radar mesure représente capacité modèles détecter classe nouveauté avons choisi cette métriques montrer bonne capacité détecter classe nouveauté Ainsi pouvons clairement notre approche donne meilleurs résultats comparé autres méthodes Conclusion article avons proposé nouvelle approche adaptée problème prentissage partir seule classe applications détection nouveauté proche basée opérateurs projection orthogonale technique bootstrap princie apprentissage ensemble approche proposée ensemble induit partir échantillons bootstrap sélection aléatoire variables processus induction modèle prédiction faite agrégeant prévisions ensemble mesures performance telles écision rappel positifs négatifs mesure calculées travers validation croisée basesr données accessibles public amélio Détection nouveauté Radars bases Waveform Glass Ionosphère mesure différentes données Hamdi Radars bases Yeast Spectf rations significatives précision obtenues utilisant notre méthode approche présente généralement amélioration substantielle performances rapport algorithmes existants Grâce algorithme apprentissage ligne approche également mesure suivre changements données temps Références Asuncion Newman Machine learning repository Greville applications pseudoinverse matrix Jolliffe Principal Component Analysis Springer Verlag Kassab Frederic Incremental driven learning novelty detection model class classification problem application dimensional noisy Machine Learning Détection nouveauté Kassab Charle Emmanuel Novelty detection modeling users profile International FLAIRS Conference Kohonen adaptative formation orthogonalizing filters associa memory reccurent networks neuron elements Biological Cybernetics Kohonen organization associative memory Springer Berlin Markou Singh 2003a Novelty detection review statistical approaches Signal Processing Markou Singh 2003b Novelty detection review neural network based approaches Signal Processing Markou Singh 2003c Novelty detection learning systems Neural Computing Peterson under curve evaluation machine learning algorithms Pattern Recogn Rumelhart Hinton Williams Learning internal representation error propagation Parallel Distributed Processing Explorations microstructures cognition Scholkopf Platt Shawe Taylor Smola Williamson Estimating support dimensional distribution Neural Computation Summary paper propose novelty detection framework based orthogonal projection operators bootstrap approach called Random Subspace Novelty Detection Filter combines sampling technique ensemble ensemble induced bootstrap samples training using random feature selection induction process Prediction aggregating predictions ensemble generally exhibits substantial performance improvement single Thanks online learning algorithm approach track changes method compared single other novelty detection methods tenfold cross validation experiments publicly available datasets where method superiority demonstrated Performance metrics precision recall false positive false negative measure computed proposed approach shown improve prediction accuracy novelty detection favorable performance compared existing algorithms