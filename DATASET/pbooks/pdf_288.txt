plateforme parallèle distribuée intégration données massives mahfoud oussama mokeddem boussaid alimazighi lrdsi université dahleb blida algérie mahfoud mokeddem gmail université lumière france boussaid lyon2 usthb alger algérie zalimazighi usthb résumé intéressons papier impact données sives environnement décisionnel particulièrement phase intégration données contexte avons développé plate forme baptisée parallel destinée entreposage données sives selon paradigme mapreduce permet paramétrage proces workflow paramétrage avancé relatif environnement parallèle distribué papier décrit plateforme démonstration données allant tuples expéri mentations menées montré amélioration significative performances lorsque taille cluster nombre tâches parallèles augmentent introduction données massives appelées communément impactent directement cessus extracting transforming loading celui premier composant système décisionnel confronté données travaux traité problématique données massives processus proposé approche parallèle distribuée appelée etlmr consistant améliorer performances phase transformation chargement adoptant chacune phases stratégies distribution appropriées expérimentations misra montré paradigme mapreduce prometteur solutions basées frameworks source apache hadoop performantes moins teuses rapport solutions commercialisées contrairement travaux misra considèrent phase extraction teuse celle traitée environnement parallèle distribué selon paradigme preduce démonstration prototype etlmr auteurs proposent plateforme cloudetl basée apache hadoop apache performances nettement améliorées rapport celles etlmr plateforme parallèle distribuée plateformes etlmr cloudetl basées python conséquent celles destinées informaticiens dévelop peurs solutions parallèles distribuées vulgariser plateformes rendre accessibles utilisateurs finaux proposons papier plate forme baptisée parallel développée environnement apache hadoop paramétrage processus interface unique structurée trois onglets chacun concerne phase processus paramétrage effectuer fichier traitement batch avons adapté schéma classique environnement mapreduce ainsi procède phases xtracting artitioning ransforming educing oading parle plutôt eptrl bases présentons cette section bases principes fondamentaux exposant techniques partitionnement supportées adaptation phases reduce spécificités terminons architecture globale partitionnement données distribuer paralléliser processus données sources doivent elles aussi distribuées permettre plusieurs tâches exécuter façon parallèle chacune traite propre partition données offre trois types partitionnement assurer charge moins équitable entre différentes tâches parallèles choix partitionnement important présence élevé partition données tuples valeurs creuses implique charge faible termes traitement tâche effet tuples question seront rejetés filtre simple étant donné volume données source partitionnement simple génère partitions égales selon équation nb_part étant nombre partitions taille partition taille nb_part round robin technique round robin affectation tuple depuis volume source partition données basée équation tuple étant tuple volume nb_part étant nombre partitions tuple nb_part round robin cette technique similaire round robin accélérer partitionnement tuples affecté partition plutôt affec tation tuple tuple hadoop apache mappers reducers plateforme primitives reduce adaptées spécificités assigné mapper normalisation données nettoyage filtrage conversion mapper traite chaque tunnel transformations chaque chargé opération particulière telles nettoyage filtrage projection conversion concaténation figure montre tunnel transformation constitué trois fonctions projection filtre fonction extraction année tuple format valeur transformé après passage tunnel mapper tunnel transformation reducer quant chargé fusion agrégation données préparées union count figure montre résultats partiels obtenus mappers triés selon destination reducer niveau reduceri primitive shuffle consiste capturer tuples destination celui stocker locale seront ensuite agrégés chargés entrepôt données architecture reducer architecture plateforme organisée modules xtracting artitioning ransf orming educing oading figure après extraction données sources chargées système fichier distribué hadoop ensuite partitionnement logique données effectue selon choix utilisateur final simple partitions données ainsi générées seront soumises processus mapreduce chaque charge transformer données partition nettoyage filtrage conversion fonctions fusion agrégation données différées exécutées phase reduce niveau données deviennent pertinentes peuvent alors chargées entrepôt données plateforme parallèle distribuée architecture paramétrage processus paramétrage processus interface unique organisée trois onglets extract transform dédiés processus workflow partie vanced parameters réservée configuration environnement parallèle distribué apache hadoop figure configuration processus utilisateur commencer onglet extract paramètres disponibles autres onglets transform dépendent premier principalement format source structure placement revanche partie advanced parameters utilisée indépendamment trois onglets interface configuration onglet extract utilisateur premier localiser données sources format pivot données fichier adopté toutes plateformes mapre légèreté absence données accélérer chargement données sources système utilisateur pourra activer compression celles ensuite utilisateur choisir partitionnement données sources simple round round robin block ainsi nombre partitions nombre mappers enfin paramétrer lecture mapreader partir partitions données ligne ligne nombre lignes taille figure montre onglet transform fournit utilisateur liste fonctions transformation agrégation chaque fonction insérée paramétrée entrées conditions expressions tunnel transforma ainsi constitué exécutera ordre insertion fonctions enfin onglet permet configuration chargement données préparées entrepôt données comporte destination données entrepôt données magasin données compression données avant chargement système ainsi caractère séparateur fichier cible concernant paramétrage environnement paral distribué apache hadoop taille nombre noeuds impliqué processus taille mémoire réservée noeud tâche compression résultats mappers avant soumettre reducers celui partie advanced parameters expérimentation évaluer avons installé cluster machines chacune possède processeur intel processor disque réseau local ethernet selon configuration matérielle présentée dessus environnement hadoop permet affecter maximum tâches rallèles noeud ainsi tâches parallèles équivalentes noeud données avons développé programme génère données synthé tiques relatives renseignements étudiants expérimentations réalisées données allant tuples exposons expérimentation réalisée fichier etudiant lignes chacune taille octets fichier contient attributs suivants matricule inscription cycle licence master doctorat spécialité bourse sport processus paramétré expérimentation présente quatre fonctions première tâche projection consiste exclure attributs bourse sport deuxième tâche processus restric filtre tuples rejette présentant valeur attributs inscription cycle spécialité troisième tâche extrait année inscription enfin quatrième tâche fonction agrégation count compte nombre étudiants inscrits durant année cycle spécialité noter durant exécution processus lorsque rencontre agrégation comme count celle différée exécutée phase reduce résultats comme montre tableau augmentation tâches parallèles améliore manière significative performances processus remarquons temps entre tâches intéressant revanche constatons régression plateforme parallèle distribuée entre tâches pourrons conclure certain seuil termes tâches parallèles amélioration performances processus devient significative nombre tâches temps trait temps traitement données conclusion processus considéré aujourd comme étant coeur système décisionnel puisque toutes données destinées analyse transitent celui faire données massives avons adapté selon paradigme mapreduce permettre exécution environnement parallèle distribué interface paramétrage conviviale rendre plateforme accessible utilisateurs finaux résultats expérimentations montrent meilleure scalabilité volumes données importants lorsque taille cluster augmente références thomsen pedersen etlmr highly scalable dimensional framework based mapreduce warehousing knowledge discovery springer thomsen pedersen mapreduce based dimensional proceedings endowment thomsen pedersen cloudetl scalable dimensional proceedings international database engineering applications symposium misra mazumdar performance comparison hadoop based tools commercial tools study analytics springer summary focus paper impact decision making environment partic ularly integration phase context developed under apache hadoop framework platform called parallel intented large warehousing according mapreduce paradigm allows setting processes workflow template provides advanced setting consists configuring parallel distributed processing apache hadoop paper demonstrates platform facing until tuples conducted experiment shows increasing cluster parallel tasks speed process démonstrations plateforme parallèle distribuée intégration données massives mahfoud boussaid alimazighi