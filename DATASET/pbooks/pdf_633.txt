articles assemblage pdfComparaison critères pureté intégration connaissances clustering supervisé Germain Forestier Cédric Wemmert Pierre Gançarski Université Strasbourg LSIIT Sébastien Brant 67412 Illkirch France forestier wemmert gancarski unistra Résumé utilisation connaissances améliorer processus fouille données mobilisé important effort recherche dernières années cependant souvent difficile formaliser connaissances comme celles souvent dépendantes domaine article téressons intégration connaissances forme objets étiquetés algorithmes clustering Plusieurs critères permettant évaluer pureté clusters présentés comportement comparé données artificiels avantages inconvénients chaque critère analysés aider utilisateur faire choix Introduction intégration connaissances algorithmes clustering connu intérêt dernières années connaissances dites domaine background knowledge étant disponibles Celles peuvent présenter formes différentes diffi ciles formaliser manière générique elles dépendent souvent domaine application Plusieurs travaux Wagstaff Bilenko intéressés utilisation connaissances forme contraintes entre paires objets instar algorithme supervisé apprendre fonction classification cette information utilisée pendant processus clustering guider algorithme solution accord connaissances concept récurrent méthodes utilisant connaissances pureté clusters consiste évaluer qualité clusters rapport objets étiquetés cluster cluster lequel objets classe connue appartiennent seule classe cluster impur présentera objets classes différentes objectif article présenter comparer différentes méthodes évaluation pureté clusters section présentons utilisation connaissances clustering section différentes mesures pureté présentées comparées Enfin section présente conclusions futures pistes recherche travaux Comparaison critères pureté intégration connaissances Évaluation clustering considérons connaissance ensemble objets étiquetés nombre objets étiquetés clusters trouvés algorithme tering classes objets étiquetés objets appartenant cluster ensemble objets classe nombre objets cluster objets cluster classe Calcul pureté façon simple calculer pureté chercher classe majoritaire chacun clusters sommer nombre objets cette classe chacun clusters Manning pureté clustering définit comme Πsimple autre façon calculer pureté clusters proposée Solomonoff formulent comme probabilité étant donné cluster objets tirés hasard remise soient classe Πprob πprob πprob Cette mesure avantage rapport pureté simple prendre compte distribution classes minoritaires cluster classes autres classe majori taire favorise clusters présentant nombre limité classes différentes mesures pureté cependant inconvénient majeur surévaluer qualité clustering nombre important clusters Différentes propositions faites résoudre problème exemple Ajmera proposé calculer pureté clusters terme classes ainsi pureté classes terme clusters chaque classe répartition différents clusters valeurs ensuite combinées donner évaluation globale clustering Considérer également pureté classes permet pénaliser nombre important clusters pureté classes calcule manière similaire pureté clusters observant distribution clusters objets chaque classe Πgprob πgprob πgprob pureté clusters pureté classes ensuite combinées Πoverall Πprob Πgprob autre approche consiste considérer également mesure qualité clustering partir données Demiriz utilisent algorithme optimiser pureté Forestier clusters appelé similaire éviter algorithme génère solution nombre important clusters fonction objective moyenne arithmétique pureté clusters qualité clustering combinaison critères permet éviter solutions extrêmes Enfin également proposé introduire notion pénalité rapport nombre clusters solution proposée résoudre problème Cette méthode permet pénaliser solution ayant nombre clusters important rapport nombre classes penalty sinon nombre clusters nombre classes nombre objets Cette pénalité retranchée indice pureté choisi pondérée paramètre comme Πpenalty Πsimple βpenalty autre solution utiliser cadre théorie information évaluer infor mation mutuelle normalisée entre connaissances clustering information mutuelle entropie Comparaison partitions autre indice couramment utilisé indice permet parer partitions notre consiste vérifier couples objets classe après connaissances disponibles placés cluster couple objets positif objets classe placés cluster négatif quand objets classes différentes placés clusters différents positif correspond objets Comparaison critères pureté intégration connaissances données utilisés classes différentes placés cluster négatif correspond objets classe clusters différents défini manière suivante Πrand représentant couples possibles objets couples objets correctement classés indice donne cependant poids positifs négatifs Mesure Rijsbergen quant permet pondérer valeurs tenant compte précision rappel Πfmesure valeur retenue article précision rappel alors portance avantage indices Πrand Πfmesure intègrent implicitement nombre clusters défavorisant naturellement solutions nombre clusters important Évaluation différents critères qualité cette section allons évaluer critères présentés section précédente différents données figure présente trois données artificiels représentant chacun quatre clusters espace dimensions algorithme KMEANS utilisé données nombres clusters variant étant nombre clusters attendu chaque clustering mesures présentées sections précédentes calculées Trois configurations différentes évaluées première données étiquetées seconde données étiquetées enfin dernière données étiquetées Chaque expérience effectuée initialisations aléatoires algorithme résultats moyennés figures représentent résultats respectivement données figures Forestier Evolution critères fonction nombre clusters donné Evolution critères fonction nombre clusters donné Quand nombre objets étiquetés disponibles faible majorité critères comportement aléatoire effet garanti avoir objets chacune classes données pourquoi critères difficilement utilis ables quand vraiment connaissances disponibles Quand nombre objets étiquetés augmente probable avoir objets étiquetés chaque classe conséquent courbes deviennent caractéristiques problème présenté précédem mesures pureté simples surévaluent qualité clustering quand nombre objets augmente observé effet pureté simple Πsimple ainsi pureté cluster Πprob augmenter nombre clusters autres indices Πrand Πfmesure Πoverall Πpenalty tendance diminuer augmentation clusters caractérisques étant Πfmesure Πoverall critères Πrand Πpenalty diminuent façon moins caractéristique intéressant noter différence importante entre résultats obtenus objets étiquetés objets étiquetés Conclusion intégration connaissances algorithmes classification supervisée repré sente enjeu important connaissances implicites explicites disponibles convient développer approches permettant tirer parti article avons abordé utilisation objets étiquetés évaluer pureté résultat clustering Plusieurs critères présentés formalisés comparés ressort critères Comparaison critères pureté intégration connaissances pureté prendre compte nombre clusters peuvent rapidement surévaluer qualité résultats résoudre problème possible prendre compte mesure pénaliser résultats nombre clusters important autres types critères comparent regroupement couples objets prennent compte implicite nombre clusters notamment Mesure donné résultats particulièrement expériences Références Ajmera Bourlard Lapidot McCowan Unknown multiple speaker cluster using International Conference Spoken Language Processing Bilenko Mooney Integrating constraints metric learning supervised clustering International Conference Machine Learning Demiriz Bennett Embrechts supervised clustering using genetic algorithms Intelligent Engineering Systems Through Artificial Neural Networks Zeidat Supervised clustering algorithms benefits International Conference Tools Artificial Intelligence Manning Raghavan Schütze Introduction Information Retrieval Cambridge University Press Objective criteria evaluation clustering methods Journal American Statistical Association Solomonoff Mielke Schmidt Clustering speakers their voices Acoustics Speech Signal Processing Proceedings International Conference Volume Rijsbergen Information Retrieval London Butterworths Wagstaff Cardie Rogers Schroedl Constrained means clustering background knowledge International Conference Machine Learning Summary recent years background knowledge improve mining process intensively studied Indeed background knowledge along knowledge directly indirectly provided often available However often difficult formalize knowledge often dependent domain article studied integration knowledge labeled objects clustering algorithm Several criteria allowing evaluation purity clustering presented their behavior compared using artificial datasets Advantages drawbacks criteria analyzed order choice among