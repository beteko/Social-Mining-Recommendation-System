ordonnancement apprentissage transformations documents guillaume wisniewski patrick gallinari capitaine scott 75015 paris prénom connex résumé notre objectif transformer documents schéma médiateur défini priori étape nécessaire nombreuses tâches recherche information concernant sémantique ments structurés traitement sources hétérogènes permet associer structure sémantiquement riche documents formats contient informations présentation proposons traiter problème comme problème apprentissage structuré formalisant comme transformation arbre arbre notre méthode transformation comporte étapes première étape grammaire contexte probabiliste permet générer ensemble solutions candidates deuxième étape solutaions candidates ordonnées grâce algorithme ordonnancement percep noyau cette étape ordonnancement permet utiliser manière efficace caractéristiques complexes définies partir document entrée solution candidate introduction objectif faciliter accès information représentant documents structure sémantiquement riche traditionnel cette structure généralement définie représentation documents forme arbres éléments contenu identifiés séquence étiquetée feuilles arbre organi selon structure prédéfinie ensemble nœuds internes représentant relations entre éléments cette structure traduit relations sémantiques logiques entre éléments contenu comparateurs sémantique exemples services fournis plupart documents utilisent formats structurés comme encore wikitext formats permettent enrichir texte balises interprétation directe celles permet décrire documents arbre arbre appellerons structure syntaxique cette structure directement manière information codée applications peuvent toutefois ordonnancement transformation documents tirer directement profit cette structure elles toutes besoin connaître priori struc utilisée capables traiter documents respectant strictement schéma spécifique schéma définit structures peuvent avoir cuments probable documents respectent schéma donné priori général proviennent plusieurs sources hétérogènes utilisant chacune structures différentes format contient informations informatif applications utilisation directe structure syntaxique application impossible rendre utilisables transformer sources hétérogènes format médiateur spécifique application objet travail présentons intéressons spécifiquement conversion matique documents format prédéfini cette problématique spécifique intéret masse information présente format moins riche celle nombreux formats structurés information présente fournit information exploitée quotidiennement nombreux utilisateurs notamment faciliter navigation recherche informa effet développement sites basés systèmes gestion contenu blogs nouvelles pages générées automatiquement partir bases données leurs régularités documents reflète structure logique permet identifier éléments titre commentaire ainsi relations entre exemple préciser auteur partie document information directement présentation documents exemple utilisé organiser commentaires visiteurs threads figure ordre chronologique extrait thread commentaires slashdot permet identifier facilement chaque commentaire ainsi relations entre commentaires informations comme auteur commentaire également immédiatement accessibles wisniewski gallinari exploiter cette information additionnelle proposons transformer ments format médiateur cette structure spécifiée schéma cible dépen application considérée écriture manuelle convertisseurs spécifiques chaque source documents chaque application travail présentant grand risque adapté richesse nature dynamique plusieurs solutions chung utilisant apprentissage artificiel proposées automatiser transformation documents structurés structure définie schéma arbitraire objectif associer document entrée document contenant mêmes informations exprimées schéma cible après avoir observé semble documents exprimés structure origine structure cible approches prometteuses chidlovskii fuselier cette tâche comme généralisation analyse syntaxique document entrée représenté séquence observations correspondant feuilles document structure document sortie reconstruite partir cette représentation grâce grammaire contexte décrivant schéma sortie cette approche structure document entrée cependant ignorée comme montrerons fournit information indispensable déterminer bonne structure sortie travail proposons approche générale permet considérer caractéristiques arbitraires décrivant structure sortie structure entrée documents commencerons décrire cadre général transformation documents fondé techniques apprentissage structuré paragraphe détaillerons notre modèle paragraphe présentons enfin ensemble expériences prospectives plusieurs corpus documents réels paragraphe problématique restructuration transformer automatiquement document considérons tâche générale restructuration étant donné schéma arbitraire souhaitons transformer document entrée document sortie conforme schéma cette transformation arbres inclure différents types opérations réorganisation éléments bibliographie présentée thématique année regroupement éléments prénom auteur peuvent stockés élément tâche restructuration revient identifier document éléments pertinents déterminer récursivement relations entre éléments exemple figure objectif ainsi identifier acteurs personnages déterminer chaque acteur éléments relations extraire définis schéma cible automatiser cette transformation revient apprendre fonction correspondance documents problème généralement déterminé puisque plusieurs documents sortie peuvent compatibles document entrée ainsi exemple casting importe acteur priori jouer importe déterminer unique restructuration correspondant définissons paramétrée permettant évaluer qualité solution candidate cette fonction permet ordonner éléments ensemble restructu rations potentielles constitué documents respectant schéma cible contenant informations tâche restructuration correspond alors recherche ordonnancement transformation documents structuration potentielle grand score argmax équation argmax traduit parcours espace toutes restructurations tentielles rechercher meilleure solution ensemble inclure ensemble segmentations réorganisations nœuds contenu notamment permutations fusions séparations nœuds arbres compatibles cette nouvelle organisa taille espace recherche exponentielle rapport nombre nœuds contenu limitant permutations nœuds espace recherche contient éléments trouver meilleure solution temps raisonnable plusieurs sources informa tions doivent considérées élaguer espace recherche contenu document source structure définition schéma cible ainsi exemple figure restructuration guidée structure document entrée premières feuilles décrivent personnage puisqu parent contrainte structure cible chaque personnage composé acteur information apportée structures entrée sortie essentielles tâche restructuration table korben dallas bruce willis leelo milla jovovitch casting personnage acteur personnage acteur exemple transformation fragment objectif identifier acteur personnages déterminer chaque acteur pourquoi choisissons faire dépendre représentation jointe document entrée restructuration potentielle cette représentation jointe comporte toutes caractéristiques permettant sélectionner meilleure solution inclut notam wisniewski gallinari caractéristiques globales peuvent déterminées considérant ensemble comme nombre occurrences étiquette dépendances longue distance suite supposerons linéaire rapport cette hypothèse tâche restructuration comme problème apprentissage structuré tsochantaridis apprentissage structuré généralisation apprentissage multi classe permettant traiter problèmes lesquels entrées sorties peuvent décomposées ensemble parties inter dépendantes utiliser techniques apprentissage structuré intéressant puisque formalisme fournit plusieurs méthodes apprendre partir caractéristiques arbitraires décrivant structures entrée sortie algorithmes apprentissage structuré souffrent général complexité élevée prohibe utilisation tâches complexes comme tâche restructuration traiter corpus grande taille allons maintenant présenter méthode apprentissage structuré présente avoir complexité suffisamment faible pouvoir appliquée problème restructuration corpus grande taille modèle apprentissage méthode proposons repose observation suivante apprentissage struc décrit équation nécessite construire ensemble grand structures combinatoires retrouver celle grand score proposons consi dérer étapes séquentiellement précisément algorithme proposé enchaîne étapes étape génération construire ensemble solutions candi dates processus repose hypothèses indépendance fortes entre éléments documents utilisation ensemble restreint caractéristiques mettre construction efficace solutions candidates algorithme programmation dynamique étape ordonnancement trouver meilleure restructuration parmi solutions candidates générées étape précédente considérant caractéristiques arbitraires aussi document entrée solution candidate particulier puisqu travaille univers restreint pourra considérer caractéris tiques globales arbres entrée sortie permet programmation dynamique traiter étapes manière séquentielle permet conserver avantages grammation dynamique construction efficace sortie structurée considére caractéristiques locales considérant caractéristiques globales seconde étape sélectionner meilleure restructuration cette approche fournit solution approchée équation puisque seules solutions prometteuses première étape évaluées toutefois montré efficacité plusieurs tâches langue naturelle collins allons maintenant détailler étapes ordonnancement transformation documents génération solutions candidates première étape notre modèle objectif construire structure document sortie partir séquence nœuds contenu cette construction faire facilement algorithmes analyse syntaxique jurafsky martin utilisation algorithmes autant intéressante structures arbores centes documents structurés modélisent naturellement grammaires contexte chidlovskii fuselier effet celles permettent décrire simplement structures récursives horizontale section comporte plusieurs sections verticale possible faire listes listes elles permettent aussi maliser observation suivante identifier élément contenu taille définie nombre unité éléments constituent composée année représentation ordre éléments peuvent varier utilisation version probabilisée cette grammaire permet outre caractériser régularités variabilité schéma cible possible exemple modéliser section regroupe ensemble sections nombre sections distribution donnée formellement décrivant document structuré définie quintuplet ensemble terminaux décrivant étiquettes nœuds internes correspondent relations ensemble terminaux définissant étiquettes feuilles correspondent nœuds contenu élément symbole initial décrivant racine arbre ensemble productions chaque élément associé probabilité chaque production relation décrit règles composition règle indique élément regroupe ordre élément élément modèle contenu défini distribution probabilité chaque contenu intuitivement cette distribution permet rajouter ensemble productions éléments éléments contenu productions permettent déterminer étiquette feuilles figure montre exemple schéma cible associée permet associer probabilité chaque structure sortie cette probabi mesure compatibilité entre structure arborescente séquence observations définie ensemble productions utilisées construire arbre séquence nœuds contenu document estimation probabilités détaillée chain paragraphe figure donne exemple calcul cette probabilité algorithme analyse syntaxique permet reconstruire efficacement meilleures restructuration associées séquence nœuds contenu avons utilisé exten wisniewski gallinari element header element header element header header author title header author title author title exemple partie schéma décrivant structure nouvelle associée schéma spécifie étiquettes nœuds contenu étiquettes relations indique aussi élément composé éléments observation probabilités associées productions montre dernier moins fréquent table donne exemple distribution probabilité suite quatre nœuds contenu algorithme jimnez marzal construire meilleures solutions complexité généralement expériences cette complexité ordre grandeur celle algorithme reconstruisant meilleure solution apprentissage paramètres apprentissage partir ensemble documents exprimés schéma cible paramètres décrivant éléments estimés maximum vraisemblance jurafsky martin probabilité production donnée correspond nombre apparition cette production corpus prentissage élément probabilités contenu estimées notre modèle classifieur maximisant entropie classifieur permet prendre compte facilement toutes ractéristiques jugeons pertinentes nécessiter hypothèses indépendance entre celles caractéristiques peuvent dépendre contenu étiquette pouvons définir aussi caractéristiques décrivant contenu nœuds nombre majuscules présence chiffre contexte nombre frères profon arbre données spécifié schéma table détaille partie caractéristiques utilisées précisément algorithme permet retrouver efficacement meilleure solution utilisant programmation mique ordonnancement transformation documents header author title header author title exemple restructurations potentielles arbres arbre figure score document author title score document vecteur caractéristiques décrit paragraphe précédent étiquette coefficient normalisation vecteur paramètres estimer produit scalaire canonique vecteur paramètres estimé utilisant principe maximisation tropie algorithme apprentissage détermine parmi toutes distributions compatibles observations celle moins hypothèse valeurs observées caractéristiques contenu caractéristiques contexte caractéristiques données contains child xs_string begins capitals siblings xs_duration contains number descendant title xs_time contains spaces exemples caractéristiques utilisées décrire nœuds contenu représente trois types caractéristiques contenu séquence contient contexte frère données string selon définition norme schema étape ordonnancement objectif cette étape apprendre fonction permet ordonner ensemble solutions candidates score notamment permettre prendre compte caractéristiques globales vecteur paramètres estimé partir ensemble apprentissage constitué ensemble documents chaque document étant exprimé structure origine structure cible noterons ensemble wisniewski gallinari chaque élément solutions candidates construites première étape supposerons perte généralité meilleure restructuration apprentissage effectué perceptron noyaux collins duffy collins méthode simple efficace permet grâce utilisation noyau considérer espaces grandes dimensions score calculé perceptron noyau solution candidate associée document entrée fonction noyau explicitée paragraphe suivant paramètres appris exemple apprentissage meilleure restructuration associée exemple parmi éléments autres solutions candidates caractéristiques utilisées types caractéristiques envisageables discriminer meilleure solution candidate premier caractéristiques décrit dépendances longue distance entre nœuds arbre décrire chaque contexte riche celui étape génération deuxième caractéristiques permet mesurer similarité entre document entrée solution candidate effet ments majoritairement textuel certains groupes éléments doivent conservés transformation garder pourquoi allons utiliser combinaison noyaux ktree kfeatures dinij addition noyaux traduit concaténation espaces caractéristiques premier noyau ktree noyau arbre collins duffy capture dépendances terme entre nœuds arbre contrairement consi dépendances entre noyau arbre considère ensemble arbre modéliser contexte arbre représenté ensemble arbres nombre arbres arbre exponentiel rapport taille arbre solution basée programmation dynamique permet réaliser avoir énumérer arbres second noyau utilisé kfeatures noyau radial basis function utilise caractéristiques globales document entrée solution candidate caractéristiques incluent comparaison entre nombre nœuds document entrée document sortie couvertures communes document entrée document sortie couverture définie chaque arbre paire constituée position séquence feuilles première dernière feuille arbre ayant comme racine manière intuitive couvertures permettent résoudre problème comme présentés figure ordonnancement transformation documents contraintes imposées schéma cible exemple avoir titre plusieurs réalisateurs contraintes déduites automatiquement schéma cible score première étape valeurs caractéristiques combinées noyau incorporées noyau global expériences avons testé notre modèle corpus différents premier corpus semble nouvelles publiées traitant actualité informatique linuxfr linuxfr pages téléchargées converties schéma prédéfini chaque correspond nouvelle comporte regroupant informations auteur titre corps nouvelle plusieurs threads commentaires visiteurs corps nouvelle comme commen taires peuvent utiliser plupart partie décrivant commentaires utilisateurs fortement structurée présente transformation document structure logique commentaires commentaire commentaire donné réponse reconstruite partir structure document entrée corpus porte nouvelles chaque nouvelle ayant moyenne nœuds contenu nœuds internes grand document nœuds contenu nœuds internes schéma cible définit étiquettes possibles nœuds contenu nœuds internes second corpus données descrip tions films téléchargées converties manuellement suivant schéma donné chaque description comporte moyenne nœuds contenu nœuds internes grande respectivement corpus données comme bases données relationnelles descriptions structure attribut valeur seuls quelques nœuds données textuelles généralement mentaires utilisateurs résumés conséquence structure documents régulières premier corpus chaque corpus séparé aléatoirement ensemble apprentissage ensemble comportent documents entrée documents cible respondant toutefois seuls documents entrée utilisés ensembles taille notre modèle alors utilisé retrouver structure cible documents corpus différentes valeurs nombre solutions candidates générées première étape testées notre modèle correspond seule étape génération entre reconstruction alors tenir compte structure document entrée proche modèle proposé chidlovskii fuselier proposons évaluer qualité restructuration mesurant similitude entre document reconstruit document convertit comme mesure similarité avons utilisé pourcentage constituants correctement recons truit constituant correspond paire tiquette couverture permet décrire étiquette position arbre reconstruit avons mesuré rément résultats reconstruction feuilles arbre nœuds internes wisniewski gallinari celui pouvoir évaluer capacité notre modèle identifier éléments identifier relations entre éléments table rassemble résultats expériences utilisation formation document entrée étape ordonnancement améliore résultats modèle complexité globale sensiblement identique cette amélioration significative lorsque considère petit nombre solutions candidates cependant augmenter nombre solutions candidates certain seuil étape ordonnancement diminue performances cette baisse certainement limites algorithme apprentissage notamment rapport petit nombre données fournies apprentissage analyse détaillée résultats montre performances proche bonnes parties régulières documents qualité reconstruction chute parties récursives documents résultats étape ordonnancement dépendent qualité solutions candidates linuxfr movie feuilles nœuds internes arbre feuilles nœuds internes arbre résultat reconstruction corpus problèmes semblables schema matching intégration données traités plusieurs années communauté données apparus récemment recherche documentaire conversion chidlovskii fuselier intégration documents chung alignement ontologies plusieurs techniques prentissage employées classifieur multi classes spectre graphe plusieurs récents abordent problématique transformation documents notamment grammaires formelles chidlovskii fuselier wisniewski comparaison différentes approches proposées données faite halevy présente approches abouties travailler différents types données ontologies tâche présentée comme problème classification supervisée multi étiquettes toutefois corpus consi dérés différents corpus auxquels intéressons évaluation méthodes développées généralement faite corpus petite taille ayant structure stricte présentant récursion contenant rarement données textuelles conclusion avons proposé cadre général transformation document structuré schéma arbitraire cadre permet considérer caractéristiques cument entrée structure sortie améliorant ainsi plusieurs approches existantes ordonnancement transformation documents plusieurs expériences prospectives réalisées résultats encourageants nouvelles caractéristiques doivent définies améliorer performances plusieurs améliorations envisageables pensons notamment réduire complexité étape génération utilisant méthodes inférence approchée autre piste consiste étudier comment informations apprises corpus peuvent utilisées faciliter apprentissage transformation corpus similaire références chidlovskii fuselier probabilistic learning method annotation documents ijcai chung gertz sundaresan reverse engineering visual semantic structures collins duffy convolution kernels natural language collins duffy ranking algorithms parsing tagging kernels discrete structures voted perceptron collins discriminative reranking natural language parsing compu tational linguistics domingos halevy learning match schemas sources multistrategy approach learn halevy semantic integration research database community brief survey magazine special issue semantic integration jimnez marzal computation parse trees weighted chastic context grammars jurafsky martin speech language processing introduction natural language processing computational linguistics speech recognition tsochantaridis hofmann joachims altun support vector machine learning interdependent structured output spaces wisniewski denoyer gallinari modèle probabiliste traction structures documents structurés coria summary documents formated weakly structured format exploitation these documents systems difficult heterogeneity their structure their semantic consider conversion documents predefined structured format which amenable automatic processing document content develop machine learning approach conversion problem based parsing algorithm kernel perceptron