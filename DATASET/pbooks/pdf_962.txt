régression floue crédibiliste classification images sonar hicham laanaya arnaud martin driss aboutajdine khenchaf université mohammed agdal faculté sciences rabat maroc aboutaj ensieta ea3876 françois verny 29806 brest cedex laanayhi arnaud martin khenchaf ensieta ensieta résumé classification images sonar grande importance exemple navigation marine cartographie fonds effet sonar offre capacités imagerie performantes capteurs optiques milieu marin classification données rencontre plusieurs difficultés raison imprécisions incertitudes liées capteur milieu nombreuses approches proposées donner résultats celles tenant compte imperfections données modéliser données judicieux utiliser théories certain comme théorie ensembles flous théorie fonctions croyance machines vecteurs supports utilisées classification automatique simplicité leurs capacités généralisation ainsi possible proposer approche tient compte imprécisions incertitudes algorithme classification approche régression avons introduite permet cette modélisation imperfections proposons application cette nouvelle approche données réelles particulièrement complexes cadre classification images sonar introduction images sonar utilisées rapidité imager grandes zones optique faire retrouve ainsi nombreuses applications telles navigation marine cartographie marine images sonar entachées plusieurs imprécisions incertitudes instru mentation utilisée capteur sonar milieu marin paramètres entrent reconstruction images géométrie dispositif coordonnées bateau mouvements sonar aussi entachés bruits mesure ajoute interférences trajets multiples signaux utilisés bruits chatoiement encore faune régression floue crédibiliste classification images sonar flore imperfections rendent tache difficile caractérisation fonds marins partir données nécessaire proposer algorithmes robustes imperfections classification automatiques images sonar plusieurs choix envisageable remédier problèmes imperfections tentons supprimer imperfections nécessite compréhension souvent diffi physique conduit imperfections cherchons développer processus traitement robustes imperfections cherchons modéliser cadre théorique théories incertain offre possibilité modéliser finement imperfections parmi elles théorie ensembles flous théorie fonctions croyance permettent tenir compte incertitudes imprécisions nombreuses approches proposées classification images sonar exemple laanaya 2005b leblond approches tiennent compte incertitude expert segmentation images adopterons papier approche avons proposée laanaya solution problème optimisation adaptée classification automatique images sonar cette approche donné résultats intéressants données générées montrerons intérêt données complexes images sonar ainsi présenterons description rapide fonctions appartenance tions croyance utilisées approche régression rappelons ensuite approche régression après brève introduction principe cette approche comparée classique discutée dernière partie partir images sonar théories incertain avons martin théories incertain telles théorie ensembles flous introduite zadeh théorie possibilités dubois prade encore théorie fonctions croyance dempster shafer permettent modélisation données incertaines imprécises cadre classification images sonar théories fondées fonctions appartenance premières fonctions croyance dernière intégrer directement contraintes liées fonctions algorithme classification rappelons caractéristiques tions appartenance théorie ensembles flous fonctions croyance dempster shafer fonctions appartenance fonctions appartenance permettent décrire appartenance floue classe ainsi appartenance observation classe parmi classes donnée fonction telle laanaya considérons classes floues classes nettes possible considérer distributions possibilité typiquement représenter partie marin sédiment présent image verrons paragraphe comment fonctions peuvent choisie notre application fonctions croyance théorie fonctions croyance fondée manipulation fonctions masse fonctions masse définies ensemble toutes disjonctions cadre cernement valeurs représente hypothèse servation appartient classe contrainte normalité couramment employée donnée représente fonction masse première difficulté définir tions masse selon problème verrons comment possible faire notre application section partir fonctions masse autres fonctions croyance peuvent définies telles fonctions crédibilité représentant intensité toutes sources croient élément telles fonctions plausibilité repré sentant intensité laquelle doute élément conserver maximum informations préférable rester niveau manipuler fonctions croyance pendant étape manipulation infor mations prendre décision fonctions croyance issue manipulation fonctions décision prise maximum crédibilité pessimiste décision issue maximum plausibilité souvent optimiste maximum probabilité pignistique introduite smets reste compromis employé probabilité pignistique donnée similitudes ainsi fonctions appartenance fonctions masse permettent modélisation incertitude imprécision partir points différents fonctions toutes particularité valeurs avoir contrainte normalité équivalente allons section suivante comment intégrer contraintes régression linéaire multiple régression floue crédibiliste avons proposée laanaya nouvelle approche classifi cation automatique fondée régression effectuée partir cette approche régression floue crédibiliste classification images sonar montré performances remarquables données générées assoir notations utiles suite rappelons principe laquelle appuie régression floue crédibiliste présentée ensuite principe classifieur machines vecteurs support initiées vapnik avant proche classification linéaire classes elles tentent séparer individus issus classes cherchant hyperplan optimal sépare ensembles garantissant grande marge entre classes nombre réduit exemples recherche hyperplan suffisant description hyperplan exemples linéairement séparables cherche hyperplan maximise marge entre ensembles produit scalaire ainsi solution problème optimisation convexe contraintes représentent données apprentissage classe problème optimisation résout méthode lagrangien données linéairement séparables contraintes relachées introduction termes positifs cherchons alors minimiser contraintes données constante choisie utilisateur problème résout alors manière laire linéairement séparable classer nouvel élément suffit étudier fonction décision donnée séparable séparable ensemble vecteurs support multiplicateurs lagrange linéaire principe projeter fonction noyau données départ espace grande dimension éventuellement infinie ainsi classification nouvel élément donnée fonction décision laanaya fonction noyau utilisées noyau polynomial noyau gaussien choix noyau optimisation paramètres celui reste délicat selon application régression floue crédibiliste avons situé cette approche littérature laanaya ainsi novatrice prise compte contraintes similaires normalisation fonctions croyance appartenance problème régression multiple proposons employer résolution problème optimisation pouvant gérer grande quantité données soient vecteurs apprentissage fonctions associées nombre classes fonctions appartenance fonctions masse ainsi régression multiple linéaire cherchons fonctionnelle linéaires forme cherchons déterminer cette fonctionnelle telle apprentissage dépasse certain supposons ainsi points intérieur cylindre défini généraliser associons facteur points extérieur cylindre défini problème optimisation convexe revient celui exposé section critère minimiser contraintes données lagrangien donné ηtnξtn régression floue crédibiliste classification images sonar multiplicateurs lagrange positifs point selle lagrangien ainsi σtnxt intégrant équations lagrangien équation problème revient maximiser σtnσt contraintes enfin prédire sortie nouvel élément calcule σtnxt déduite conditions karush tucker laanaya alors ainsi raisonnement identique donne résolution système optimisation régression problèmes grande dimension nécessite mémoires stockage grande taille ainsi application algorithmes optimisation classiques difficile limites constatées laanaya solution utiliser méthodes optimisation itératives essaye résoudre problèmes problème principale avons adapté résolution sequential minimal optimization développée platt machines vecteurs support notre problème optimisation résout problèmes dimension manière analytique pouvons ainsi résoudre problèmes grande taille vitesse remarquable suppose relation entre sorties linéaire pouvons présenter données départ utilisant noyau ainsi produit scalaire entre données apprentissage substitué noyau produit scalaire vient régression linéaire alors appliquer espace représentation observation sortie prédit considérant valeurs partir cette approche régression fonctions appartenance fonctions croyance obtenons classifieur prenant décision maximum fonctions appartenance maximum probabilité pignistique expérimentations présentons application notre approche classification images sonar effet environnement marin incertain systèmes mesure complexes imprécis particulièrement important classifier marins nombreuses applications telles navigation cartographie marine verons plusieurs études classification images sonar citons exemple martin laanaya 2005a laanaya 2005b leblond données classifier ainsi entachées nombreuses imperfections bruits mesure interférences signaux utilisés acquisition bruits chatoiement faune flore données données constituée images sonar fournies gesma groupe etudes marines atlantique obtenues partir sonar klein large côtes finistériennes images labellisées partir logiciel loppé spécialement spécifiant sédiment présent sable roche caillou ombre figure degré certitude expert moyennement parmi sédiments avons considéré trois classes distinctes particulièrement régression floue crédibiliste classification images sonar sable roche cailloutis roche sable exemple image sonar fournit gesma imagettes étiquetées importantes navigation marine sédimentologues ainsi première classe regroupe roche cailloutis deuxième classe rides troisième sable vases unité classification retenue imagette taille pixels environ extraction paramètres réduire problèmes représentativité imagettes comportent sédiment problèmes évaluation martin considérons imagettes homogènes imagettes sédiment avons ainsi 31957 imagettes avons calculé imagettes paramètres extraits partir matrices occurrence calculés imagettes martin matrices cooccurrence calculées comptant occurrences identiques niveaux entre pixels contigus direction donnée quatre directions considérées degrés quatre directions paramètres haralick calculés homogénéité contraste entropie corrélation uniformité homogénéité valeur élevée images uniformes possédant texture périodique direction donnée niveau imagettes estimation contrast donnée laanaya entropie faibles valeurs probabilités transition élevées définie corrélation entre lignes colonnes matrice donnée représentent respectivement moyennes écart types distributions marginales éléments matrice cooccurrence directivité définie existence direction privilégiée texture calculée uniformité caractérise proportion niveau donnée avons moyenné paramètres selon quatre directions ainsi chaque imagette représentée uniquement parammètres modélisation fonctions floues crédibilistes avons utilisé approche keller calculer fonction apparte nance vecteurs apprentissage utiliserons apprentissage approche denœux estimer fonctions masses utiliserons apprentissage crédibiliste approche keller celle proches voisins fonctions appartenance vecteur apprentissage estimées premier temps nombre proches voisins choisi voisinage second temps calculons fonction appartenance vecteur classifier régression floue crédibiliste classification images sonar norme employée norme euclidienne classe appartenance ensuite décidée manière classique comme classe donnant maximum fonctions appartenance prédites notre régression approche denœux calcule estimation fonctions masses partir modèle distance αieγid αieγid classe associée vecteurs apprentissage proches valeur distance employée distance euclidienne coefficients affaiblissement normalisation fonctions masse ainsi calculées chaque combinées règle orthogonale normalisée dempster shafer cette règle donnée experts décision ensuite prise maximum fonctions masse prédites notre régression équivalent maximum probabilité pignistique seuls éléments focaux singletons ignorance résultats avons effectué tirage aléatoire imagettes homogènes toute données 31957 imagettes ainsi apprentissage contient effectifs différents trois classes imagettes contiennent roche cailloutis imagettes rides restants sable constituée imagettes choisies façon aléatoire avons répété cette opération obtenir estimations fiables classification avons comparé classification fondée machines vecteurs support donnée logiciel libsvm chang version modifiée dernier développée intégrer notre approche matrices confusion normalisées obtenues classique paramètres défaut libsvm noyau gaussien crédibiliste noyau gaussien données dessous classique crédibiliste avons ainsi obtenu classique crédibiliste laanaya classique avons obtenu vecteur bonne classification régression crédibiliste régression floue vecteurs reurs donnés classique crédibiliste comparaison approche classique avons ainsi amélioration significative classification trois classes régression floue issue amélioration significative régression crédibiliste issue premières classes classe roches cailloutis classe rides dernières classes particulièrement difficiles classifier faible représentativité notons approche crédibiliste donne meilleurs résultats classes ainsi nouvelle approche apporté amélioration classification différentes classes images sonar particuliè rement difficile caractérisées conclusion avons proposé papier nouvelle résolution approche régression floue crédibiliste partir machines vecteurs support classification précé dement introduite résultats obtenus images sonar montré intérêt cette approche particulier approche crédibiliste donne résultats données faiblement apprises alors approche floue permet avoir meilleure classification chaque classe considérée avons donné résultats utilisant valeurs empiriques ramètres réglage paramètres faire utilisant algorithmes génétiques exemple possible aussi intégrer optimisation constantes problème optimisation générale régression références chang libsvm library support vector machines software available cjlin libsvm dempster upper lower probabilities induced multivalued mapping annals mathematical statistics denœux nearest neighbor classification based dempster shafer theory transactions systems cybernetics systems humans dubois prade théorie possibilités masson keller givens fuzzy neighbor algorithm transac tions systems cybernetics laanaya martin aboutajdine khenchaf 2005a dimen sionality reduction method seabed characterization supervised curvilinear component analysis oceans europe brest france régression floue crédibiliste classification images sonar laanaya martin khenchaf aboutajdine march 2005b feature selec using genetic algorithm sonar images classification support vector machines european conference propagation systems brest france laanaya martin khenchaf aboutajdine octobre classification règression floue crèdibiliste machines vecteurs support toulouse france leblond legris solaiman classification segmen tation sidescan sonar images registration oceans europe brest france martin novembre fusion classifieurs classification images sonar extraction connaissances perspectives martin laanaya arnold evaluation uncertain image classification segmentation pattern recognition martin sevellec leblond october characteristics decision fusion bottom characterization colloque caractérisation fonds marins brest france platt sequential minimal optimization algorithm training support vector machines microsoft research technical report shafer mathematical theory evidence princeton university press smets constructing pignistic probability function context uncertainty uncertainty artificial intelligence vapnik statistical learning theory wesley zadeh fuzzy information control summary sonar image classification great importance underwater navigation seabed cartography indeed sonar suitable optical captors seabed imagery classification encounters several difficulties imprecisions uncertainties present these approaches proposed without giving results account imperfections model judicious uncertain theories fuzzy subsets theory belief function theory support vector machines automatic classification their simplicity their generalization capacities possible propose approach account these imprecisions uncertainties regression approach proposed model these imperfections propose application approach particularly complex framework sonar image classification introduction théories incertain fonctions appartenance fonctions croyance similitudes régression floue crédibiliste principe classifieur régression floue crédibiliste expérimentations données extraction paramètres modélisation fonctions floues crédibilistes résultats conclusion