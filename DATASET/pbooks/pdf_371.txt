heuristique paramétrage automatique algorithme clustering spectral Pierrick Bruneau Olivier Parisot Philippe Pinheiro Centre Recherche Public Gabriel Lippmann Brill Belvaux bruneau parisot pinheiro lippmann Résumé Trouver nombre optimal groupes contexte rithme clustering problème notoirement difficile article décrivons évaluons solution approchée rithme spectral Notre méthode présente avantage déterministe coûteuse montrons fonctionne manière satisfaisante quelques limites amènent perspectives travail Introduction clustering ensemble objets nombre groupes déterminé blème souvent difficile suivant critère optimisation modèle choisi choix optimal nombre groupes identifié manière univoque variable reste article probablement davantage principe généralement accepté rasoir Occam favorisant nombre minimal clusters oppose exhaustivité compromis satisfai possible priori pratique paramètre souvent laissé discrétion praticien logiciels analyse données récents approche exploratoire inconnu heuristique souhaitable article limitons algorithme clustering spectral proposons nouvelle manière extrêmement simple coûteuse fondée estimer partir spectre laplacien propre algorithme Bartlett égalité variances utilisé depuis longtemps déterminer nombre facteurs retenir contexte Analyse Composantes Principales James montrons possible adapter assez facilement estimer contexte algorithme clustering spectral premier temps rappelons clustering spectral ainsi méthodes estimation automatiques existantes décrivons ensuite notre méthode matérialisée algorithme simple efficacité méthode illustrée expériences données synthétiques réelles littérature analyse critique résultats permet formuler quelques perspectives données conclusion heuristique clustering spectral Fondamentaux clustering spectral bases clustering spectral remontent théorie graphes popularisé Malik Considérant collection éléments présentée matrice symétrique similarités entre couples éléments algorithme clustering spectral groupes résumé comme Calcul matrice diagonale Calcul laplacien Décomposition valeurs propres Extraction vecteurs propres mineurs vecteurs propres associés petites valeurs propres formant vecteurs colonnes Exécution algorithme means lignes produit étiquettes éléments respectifs Algorithme algorithme clustering spectral variantes algorithme diffèrent souvent laplacien utilisé laplacien défaut normalisé induit difficultés pratiques dépendance domaine distribution données Luxburg normalisations suivantes introduites littérature version symétrique version random Malik matrice identité taille Remarquons multiplicité valeur propre décomposition spectrale laplaciens interprétée comme nombre composantes connexes graphe jacent Luxburg nombre clusters forment noeuds autre variante notable normalisation Zelnik Manor Perona implémentation récente ailleurs basée cette dernière Karatzoglou inspectant équation remarquons Conséquemment adaptation algorithme utilisant considère vecteurs propres majeurs relie multiplicité valeur propre détermination nombre clusters entre paramètre algorithme multiplicité valeur propre spectre laplacien normalisé strictement valable composantes connexes graphes considérés peuvent cependant contenir composantes faiblement connectées entre elles totalement disjointes exemple similarités calculées Basis Function égalent jamais exactement induisant nécessairement seule composante connexe algorithme alors précisément identifier cette structure similarités peuvent également interprétées comme poids arêtes valeurs fonction kernel nuire généralité propos diagonale cette matrice conventionnellement nulle Bruneau Profil petites valeurs propres synth2 synth1 section description reste document gérer variabilité données termes domaine distribution utilisons variante proposée Karatzoglou Cette dernière adapte rayon fonction chaque élément selon médiane proches voisins Comme préconisé auteurs avons retenu expériences ainsi calcul spectres présentés figure figure montre profil petites valeurs propres renseigner probable valeur optimale Intuitivement seule valeur propre égale exactement autres approximativement égales reste significativement supérieur meilleure valeur ainsi marquée différence absolue entre valeur propre nommée eigengap Luxburg plupart travaux littérature détermine eigengap vraisemblable manière empirique comparant candidats seuil arbitraire analysant croissance profil valeurs propres scree Cattell Cattell figure illustre néanmoins relativement simples priori application problématique procédure optimisation itérative également proposée demeure complexe point conceptuel computationnel Zelnik Manor Perona proposons alternative simple efficace adaptant Bartlett égalité variances clustering spectral instar scree était originellement employé déterminer nombre facteurs extraire contexte James Description méthode Considérant échantillon individus définis variables calcule facteurs représentatifs matrice covariance échantillon faisant hypothèse plicite échantillons dimensionnels générés importe lequel facteurs restants doivent avoir variance identiquement faible conditions tistique après James heuristique clustering spectral valeur propre ordre décroissant conventionnel moyen valeurs propres mineures algorithme permet ainsi trouver simplement petite valeur acceptable algorithme quadra tique selon Comme décomposition spectrale cubique surcoût calculatoire modeste Entrée vecteur valeurs propres niveau risque Résultat petite valeur acceptable répéter statistique équation contraint équation définie jusqu obtient minimum menant rejet hypothèse nulle Algorithme algorithme simple déterminer nombre facteurs détermination algorithme clustering spectral analogue problème nombre facteurs rechercher grandes valeurs propres matrice covariance intéressons alors petites valeurs spectre laplacien section suffit alors adapter algorithme recherche grande valeur acceptable effet laplacien contexte clustering efficace faire démarrer recherche initialiser algorithme décrémenter chaque itération condition arrêt adaptée autre avons constaté empiriquement ensemble valeurs propres laplacien normalisé proche moyenne permet appro équation menant critère dépendant valeurs propres mineures entrelaçant algorithmes extraction incré mentale valeurs propres depuis petites alors arrêtée précocément Comme obtenons ainsi algorithme clustering spectral quadratique selon cluant détermination automatique Résultats expérimentaux avons implémenté notre méthode forme package speccalt alternative fonction specc package kernlab interface simple requiert matrice similarité paramètre optionnel estimé automatiquement absence avons utilisé normalisation laplacien suggérée Zelnik Manor Perona Karatzoglou stable pratique réaliser clustering Toutefois algorithme repose toujours laplaciens ainsi leurs décompo sitions respectives doivent calculés complexités annoncées section project packages speccalt index indifféremment laplaciens ayant spectre Bruneau données Notre indice vérité terrain méthode corrigé synth1 synth2 synth3 synth4 synth5 synth6 isolet données synthétiques Zelnik Manor Perona loration glyphes indique vérité terrain Synthèse résultats expérimentaux moyennes écarts types indices calculés indépendamment indiqués procédé appliqué méthode Zelnik Manor Perona restent cependant valides changent facteur constant évaluation avons récupéré échantillons synthétiques introduits Zelnik Manor Perona figure utilisé échantillons éléments variables voyelles échantillon isolet éléments variables échantillons synthétiques synth1 synth6 suivant position gauche droite figure expériences avons utilisé notre implémentation algorithme clustering spectral estimation automatique Cette estimation ainsi indice corrigé section enregistrés chaque données titre comparaison avons également indiqué estimations respectives obtenues méthode Zelnik Manor Perona Comme algorithme sensible minima locaux travers dépendance means indice corrigé estimé exécutions dépendantes chaque données procédé appliqué méthode Zelnik Manor Perona égard nature itérative revanche estimation algorithme déterministe résultats résumés figure constatons abord notre heuristique obtient meilleurs résultats thode référence satisfaisante premiers moins isolet synth6 clusters découverts contre respectivement après vérité terrain ailleurs reflété nette dégradation indices respectifs vérité terrain isolet caractérisée frontières décision tranchées induit notre thode identifier nombre minimal clusters synth6 subtils suivant exactement algorithme aurions identifié respectivement clusters avons utilisé implémentation Matlab disponible vision caltech Demos SelfTuningClustering heuristique clustering spectral effet notre méthode pénalise nombre excessif clusters existence clusters chaque point cercle dense synth6 ainsi identifié comme cluster nature quasiment discrète toutes valeurs décimale semble également problématique pallier notre implémentation algorithme borne plicitement atteint aucune valeurs autorisées seuil abaissé grand quantile mesuré souci équité bornes valeurs identiques imposées méthode Zelnik Manor Perona Conclusion article avons proposé méthode simple coûteuse performante estimer automatiquement contexte clustering spectral ainsi attestent résultats expérimentaux Toutefois avons également identifié limites proche focalisation exclusive caractérisation variétés données algorithme spectral utilise means étape intermédiaire dernier équivalent algorithme mélange gaussiennes isotropes ouvre possible combinaison notre méthode estimation bayésienne exemple utilisant notre heuristique comme priori Références Cattell scree number factors Multivariate Behavioral search Gordon Classification Chapman James equality latent roots covariance matrix Multivariate Analysis Volume Karatzoglou Smola Hornik kernlab package Jordan Weiss spectral clustering Analysis algorithm Malik Normalized image segmentation Transactions Pattern Analysis Machine Intelligence Luxburg tutorial spectral clustering Technical report Planck Institute Biological Cybernetics Zelnik Manor Perona tuning spectral clustering Summary Finding optimal number groups context clustering algorithm known difficult problem article describe evaluate heuristic thereof spectral clustering algorithm method deterministic remarkable computational burden effectiveness cases limits identified though serve formulation perspectives