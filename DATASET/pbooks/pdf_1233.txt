microsoft docmesurer qualité règles leurs contraposées informationnel julien blanchard fabrice guillet régis henri briand ecole polytechnique université nantes chantrerie 50609 44306 nantes cedex julien blanchard fabrice guillet regis henri briand polytech nantes résumé validation connaissances étapes problématiques processus découverte règles association décideur expert données puisse trouver connaissances intéressantes grandes quantités règles produites algorithmes fouille données nécessaire mesurer qualité règles insérant cadre analyse statistique implicative proposons article évaluer règles considérant contenu informationnel travers nouvel indice qualité fondé entropie shannon informationnel modulé contraposée indice avantage adapté sémantique règles puisque respecte caractère asymétrique autre profit leurs contraposées ailleurs notre connaissance seule mesure qualité règles intègre indépendance déséquilibre permette rejeter simultanément règles entre variables corrélées négativement règles possèdent contre exemples exemples comparaisons mesure information mutuelle indice confiance réalisées simulations numériques introduction parmi modèles connaissances utilisés extraction connaissances données règles association agrawal devenues concept majeur donné nombreux travaux recherche règles tendances implicatives forme entre attributs données variables booléennes dénommées items telle règle signifie plupart enregistrements vérifient prémisse données vérifient aussi conclusion étapes problématiques processus découverte règles association validation règles après extraction algorithmes mining peuvent effet produire énormes quantités règles empêche décideur expert données étudiées pouvoir exploiter résultats directement sortie algorithmes problème nature supervisée découverte règles décideur explicite spécifie aucune variable endogène nombre conjonctions items manipulées algorithmes devient alors prohibitif assister décideur recherche connaissances intéressantes prise décision nécessaire mesurer qualité règles extraites importante littérature consacrée évaluation cette notion complexe qualité mesures souvent classées catégories subjectives orientées décideur objectives mesurer qualité règles leurs contraposées informationnel orientées données mesures subjectives prennent compte objectifs décideur connaissances priori domaine étudié padmanabhan tuzhilin ensemble tandis seules cardinalités liées contingence données interviennent calcul mesures objectives exemple bayardo agrawal hilderman hamilton dernières mesures nombreuses natures diverses trouve mesures fréquentielles mesures dérivées théorie information mesures fondées tests statistiques selon elles symétriques invariantes permutation prémisse conclusion elles évaluent similarités règles article intéressons mesures objectives travail insère cadre analyse statistique implicative proposé prolongement intensité implication entropique selon qualité objective règle réside trois notions généralité mesurée support agrawal support causal kodratoff puissance implicative validité inclusion jacente règle mesurée confiance agrawal indice loevinger loevinger measure smyth goodman citer elles parmi mesures symétriques significativité statistique mesurée 1997a intensité implication version entropique blanchard 2003a intègre significativité puissance implicative trois critères décideur privilégier différents ensembles règles exemple décideur désire exploiter pépites données telles niches comportementales rechercher règles spécifiques significatives contrepartie tolérera puissance implicative faible contre exemples contre décideur intéresse connaissances connues exemple conforter théorie mettre confiance expert données pédagogiques alors recherchera plutôt règles générales significatives puissances implicatives élevées extrême décideur recherche éventuels effets causalité désire description données appliquera trouver règles fortement implicatives forcément significatives proposons article évaluer puissance implicative règles indice fondé entropie shannon shannon weaver informationnel avantage posséder sémantique claire puisqu mesure quantité information entropie apportée règle cette propriété sémantique primordiale indice qualité décideur puisse sélectionner mesures lesquelles confiance existe autres mesures issues théorie information communément utilisées évaluer qualité règles information mutuelle jaroszewicz simovici mesure smyth goodman indice bayardo agrawal mesure surprise freitas freitas règle information mutuelle entropie shannon mesure information notations définies partie blanchard moyenne partagée entre variables mesure information mutuelle relative règle précisément évènements indice quant entropie quadratique enfin mesure freitas indicateur effet surprise provoqué règle repose paradigme différent mesures précédentes puisqu cherche minimiser information apportée conclusion chaque attribut prémisse maximiser effet règle évaluée autres mesures autant étonnante attributs constituent indépendamment autres informatifs conclusion plupart mesures qualité règles prennent compte règles contraposées2 pourtant utilité contraposée découverte règles explicitée kodratoff sémantique relation recherchée données descriptive alors contraposée considérée comme suggère paradoxe hempel contre sémantique relation recherchée causale alors contraposée prise compte paradoxe cours considérant décideur recherche intuitivement règles nature causale modèle référence implication logique avons choisi article faire valoir contraposée confirmer infirmer puissance implicative règles approche avions adoptée intensité implication entropique introduisons partie notion couple implicatif article présentons nouvelle mesure objective qualité évalue puissance implicative règles cette mesure appelée fondée entropie permet repérer indépendance corrélation nulle entre variables prémisse conclusion déséquilibre autant exemples contre exemples règles introduisons partie suivante notion informationnel règle définissons mesure prend compte conjointement règle contraposée partie étudions propriétés indices réalisons comparaisons mesure information mutuelle indice confiance simulations numériques informationnel règle considérons ensemble sujets décrits ensemble variables booléennes vocabulaire règles association sujets transactions stockées données variables appelées items conjonctions variables itemsets etant donnée itemset notons ensemble transactions vérifient complémentaire cardinalité ensemble notée règle association couple itemsets possèdent commun définissons couple implicatif comme étant paire règles suite appelons variables itemsets souvent mesures évaluent simple règle prennent compte réciproque règle considérant ainsi règles comme similarités mesurer qualité règles leurs contraposées informationnel fonction entropique symétrique approche couramment adoptée indices qualité évaluer puissance implicative règles quantifier déséquilibre entre exemples contre exemples mesurer déséquilibre considérons expérience aléatoire consiste vérifier réalisé quand observé incertitude moyenne expérience mesurée entropie conditionnelle variable sachant réalisation cette entropie fondé indice inclusion mesure puissance implicative règles intervient calcul intensité implication entropique blanchard 2003a cependant instar information mutuelle théorie information avérer judicieux mesurer entropie apporté règle écart entre entropie posteriori précédente entropie priori variable entropie quantité moyenne information apportée réalisation prémisse sujet conclusion autres termes quantité information contenue règle règle entropie informationnel écrit eebag bbbbb symétrie entropie autant relative façon entropie évalue façon déséquilibre faveur déséquilibre faveur cependant déséquilibre faveur exemples respecte règle apporte information escomptée tandis déséquilibre faveur contre exemples traduit règle considérant règle signification implicative lorsque contre exemples nombreux exemples introduisons version modifiée entropie incertitude maximale lorsque déséquilibre orienté convenablement cette fonction entropique symétrique notée représentée figure entropie shannon variable binaire entropie réduite xxxxxe représentations entropie shannon entropie réduite blanchard définition entropie réduite définie alors alors xxxxxe alors définition informationnel normalisé informationnel respecter caractère asymétrique règles utilisons entropie réduite mesurer gains informationnels informationnel règle écrit maintenant eebag important réalisation apporte information puissance implicative règle garantie négatif signifie règle apporte aucune information connaissance retire autres termes incertitude moindre prédire connaissance priori hasard prédire utilisant règle informationnel maximal lorsque règle admet aucun contre exemple faciliter filtrage règles informatives normalisons informationnel associant score maximal règles meilleures revient calculer réduction entropie définition définissons informationnel règle ebati mesure définie règles évidemment rejeter informationnel ailleurs prise compte contraposée mesure règles contraposées jouent évaluation puissance implicative règles associons informationnel règle celui contraposée indice synthétique solution naturelle agréger quantités information consiste utiliser moyenne arithmétique comme information mutuelle moyenne entre variables cependant semble important indice puissance implicative règle contraposée existe avons choisi utiliser moyenne géométrique combiner informationnels règle contraposée rejetant informationnels négatifs mesurer qualité règles leurs contraposées informationnel définition informationnel modulé contraposée couple implicatif moyenne géométrique informationnels règles défini abtibatibatic batic sinon évalue simple règle couple implicatif cependant suite employer vocabulaire commun celui autres mesures qualité évoquons indifféremment couple implicatif règle valeurs élevées indice mettent évidence couples implicatifs règle directe contraposée forte puissance implicative toutefois cadre évaluation règles fortement sélective judicieux plutôt calculer moyenne retenir minimum informationnels valeurs élevées alors attribuées couples implicatifs forts règles jacentes possèdent toutes forte puissance implicative permet particulier écarter règles décideur pourraient confirmées fortement contraposée faiblement règle directe propriétés mesures informationnel prend valeurs associe mêmes valeurs règle contraposée réciproque règle contraire fonction décroissante convexe nombre contre exemples partie indices qualité exigeants diminuent rapidement premiers contre exemples précisément implication logique correspond cardinalités attendues hypothèse indépendance entre déséquilibre exemple contre exemples lorsque distinguer comportements différents informationnel selon indépendance atteinte avant après déséquilibre quand contre exemples augmentent alors indépendance atteinte avant déséquilibre annule admet valeurs négatives figure alors déséquilibre atteint avant indépendance annule admet valeurs négatives figure effet impossible règle retire information puisque incertitude maximale permet repérer situations indépendance règles significatives situations déséquilibre règles implicatif escompté effet retenant informationnels strictement positifs règles informatives décideur rejette indépendance ainsi écarte règles entre variables blanchard corrélées négativement rejette aussi déséquilibre ainsi écarte règles possèdent contre exemples exemples parmi mesures qualité règles certaines prennent valeur indépendante données déséquilibre permettent rejeter indépendance seuil confiance agrawal mesure sebag schoenauer sebag schoenauer surprise kodratoff indice inclusion blanchard 2003a tandis autres prennent valeur indépendance permettent rejeter déséquilibre seuil 1997a indice loevinger loevinger conviction 1997b indice piatetsky shapiro piatestsky shapiro notre connaissance indice intègre indépendance déséquilibre evolution informationnel fonction contre exemples désigne indépendance déséquilibre informationnel modulé contraposée prend valeurs associe mêmes valeurs règle réciproque règle contraire aussi mesure décroît rapidement premiers contre exemples informationnel couple implicatif règles constituent apporte information ainsi mesure permet aussi repérer situations déséquilibre règle contraposée situations indépendance figures permettent comparer différentes configurations données informationnel mesures issues théorie information habituellement utilisées évaluer règles information mutuelle mesure indice formules tableau figures intègrent également confiance comme indice référence figures mesures représentées fonction nombre contre exemples figures concernent configurations données déséquilibre premier déséquilibre parmi celui règle directe celui règle contraposée avant indépendance tandis figures concernent configurations données déséquilibre après indépendance quatre figures montrent quelle configuration mesure rejette déséquilibre indépendance information mutuelle mesurer qualité règles leurs contraposées informationnel mesure indice annulent indépendance repèrent déséquilibre elles peuvent prendre valeurs élevées confiance quant déséquilibre règle directe repère indépendance prendre valeurs élevées noter seules confiance permettent fixer seuil filtrage règles manière absolue maximum toujours information mutuelle apapapap mesure indice bpbpabpabpapabpabpap mesures qualité règles issues théorie information formules données evolution mesures fonction nombre contre exemples désigne indépendance déséquilibre blanchard figures illustrent aussi caractère symétrique information mutuelle mesure indice information mutuelle invariante permutation négation variables prémisse conclusion puisqu calculée totalité distribution jointe variables indice invariant négation mesure invariante négation conclusion indices informationnels respectent caractère asymétrique règles justifie introduction mesure informationnelle mieux adaptée sémantique règles comme figures relatives configurations données nombre total individus grand elles illustrent sensibilité mesures pépites connaissance règles spécifiques pouvons mesure indice deviennent discriminants lorsque grand quasi tandis confiance moindre mesure information mutuelle occultent rares capacité repérer règles spécifiques comportements aussi visibles simulation figure laquelle augmente partir configuration initiale information mutuelle règle contredite autant meilleure grand explique contraposée confirmée evolution mesures figures mesures représentées fonction respectivement figures illustrent comportements indices lorsque grandit extérieur tandis figures ensemble grandit extérieur comme précédemment figures concernent configurations données déséquilibre avant indépendance figures concernent configurations données déséquilibre après indépendance quatre simulations illustrent comportement satisfaisant décroît lorsque augmente trois propriétés caractérisant bonne mesure qualité règles énoncées piatetsky shapiro piatestsky shapiro vérifiées figures montrent aussi rejette déséquilibre indépendance mesurer qualité règles leurs contraposées informationnel evolution mesures quand grandit désigne indépendance déséquilibre conclusion avons présenté article nouvelle mesure objective qualité règles informationnel modulé contraposée appuie théorie information cette mesure adaptée sémantique causale règles puisque contrairement autres indices entropiques qualité règles respecte caractère asymétrique autre prend compte contraposée notre connaissance seule mesure qualité règles intègre indépendance déséquilibre suffit effet retenir règles informatives rejeter simultanément celles établies entre variables corrélées négativement celles possèdent contre exemples exemples simulations numériques encouragent utiliser recherche pépites connaissance mesure évalue puissance implicative règles considérant contenu informationnel cependant cadre recherche règles couples implicatifs bonne qualité nécessaire évaluer également significativité statistique règles ainsi comptons coupler intensité implication analyse statistique implicative exemple mesure synthétique reprendre paradigme intensité implication entropique ailleurs mesure blanchard intégrée outils issus travaux cours outil visualisation arvis fouille interactive règles blanchard 2003b plateforme arval évaluation mesures qualité popovici références agrawal agrawal imielinsky swami mining associations rules between items large databases sigmod kodratoff kodratoff evaluation résistance bruit quelques mesures extraction règles association extraction connaissances apprentissage bayardo agrawal bayardo agrawal mining interesting rules knowledge discovery mining blanchard 2003a blanchard kuntz guillet implication intensity basic statistical definition entropic version statistical mining knowledge discovery bozdogan press blanchard 2003b blanchard guillet briand driven quality oriented visualization mining association rules mining computer society press 1997a motwani silverstein beyond market baskets generalizing association rules correlations sigmod 1997b motwani ullman dynamic itemset counting implication rules market basket management press freitas freitas interestingness measures knowledge based systems journal implication statistique nouvelle méthode exploratoire données pensée sauvage éditions kuntz couturier guillet version entropique intensité implication corpus volumineux extraction connaissances apprentissage hilderman hamilton hilderman hamilton knowledge discovery measures interest kluwer academic publishers jaroszewicz simovici jaroszewicz simovici general measure interestingness knowledge discovery mining springer kodratoff kodratoff comparing machine learning knowledge discovery databases application knowledge discovery texts machine learning applications paliouras karkaletsis spyropoulos springer finding interesting patterns using expectations transactions knowledge engineering loevinger loevinger systematic approach construction evaluation tests ability psychological monographs mesurer qualité règles leurs contraposées informationnel padmanabhan tuzhilin padmanabhan tuzhilin belief driven method discovering unexpected patterns knowledge discovery mining piatestsky shapiro piatestsky shapiro discovery analysis presentation strong rules knowledge discovery databases piatetsky shapiro frawley press popovici popovici atelier évaluation indices qualité mémoire université lyon2 racai bucarest sebag schoenauer sebag schoenauer generation rules certainty confidence factors incomplete incoherent learning bases european knowledge acquisition workshop boose gaines linster gesellschaft mathematik datenverarbeitung shannon weaver shannon weaver mathematical theory communication university illinois press smyth goodman smyth goodman induction using information theory knowledge discovery databases piatetsky shapiro frawley press kumar srivastava selecting right interestingness measure association patterns knowledge discovery mining summary knowledge validation problematic steps association discovery process enable decision maker specialized studied interesting knowledge large amounts rules produced mining algorithms necessary measure quality rules article propose assess rules considering their informational content interestingness measure based shannon entropy informational ratio modulated contrapositive index advantage being suited semantics since respects their asymmetric feature other benefits their contrapositives furthermore knowledge interestingness measure which integrates independence imbalance which allows reject simultaneously rules between negatively correlated variables rules counter examples examples comparisons measure mutual information index confidence realized numerical simulations