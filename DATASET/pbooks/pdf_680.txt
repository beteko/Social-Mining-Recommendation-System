articles assemblage pdfProposition méthode classification associative adaptative Bahri Stéphane Lallich Laboratoire avenue Pierre Mendès France 69500 bahri stéphane lallich lyon2 lyon2 Résumé classification associative méthode prédiction règles issue fouille règles association Cette méthode particulière intéressante recherche façon exhaustive règles association pertinentes filtre garder règles association classe celles admettant conséquent modalité classe utilisées comme classifieur connaissances produites ainsi directement interpré tables études antérieures montrent inconvénients cette approche agisse génération massive règles utilisées vaise prédiction classe minoritaire lorsque classes déséquilibrées proposons approche originale boosting règles association classes utilise comme classifieur faible règles significatives construites algorithme génération itemsets fréquents limite extraction seules règles classe significatives prend compte déséquilibre données comparaisons autres méthodes sification associative montrent notre approche améliore précision rappel Introduction classification associative méthode apprentissage supervisé règles troduite améliorée différents auteurs ainsi façon générique cette méthode utilise prédiction ensemble règles association dites règles association classe conséquent modalité classe produites partir algorithmes recherche itemsets quents principal intérêt classification associative méthode classifieur ensemble règles permet expert comprendre processus classification justifier auprès tiers résultats prédiction exemple scoring bancaire domaine médical rapport arbres décision constituent principales méthodes apprentissage supervisé règles classification associative présente avantages premier procède exploration exhaustive règles exploration gloutonne second CARBoost obtient généralement meilleurs résultats algorithme arbre décision couramment utilisé comparaisons bases effectuées Bahri Lallich 2009b Cependant différents travaux souligné faiblesses classifica associative retiendra principalement temps exécution méthodes espace stockage nécessaire trouvent pénalisés génération massive itemsets utilisés débouchent nécessairement règle classe outre données déséquilibrées performances classification associative amoindries particulièrement celles relatives classe minoritaire travaux antérieurs avons compte problèmes élaborer méthode classification associative conçue fournir classifieur procédure classification associative adaptative tient compte déséquilibre classe recourant seuil support local génère itemsets indispensables savoir itemsets classe contiennent modalité classe partir itemsets classe construit règles association classe filtre règles significatives rassemblées règles significatives classifieur ainsi papier proposons CARBoost procédure classification associative adaptative utilise itérativement produite concen difficiles prédire règles prédisent correctement exemples prédire article structuré comme section introduit classification associative méthodes avant présenter section présente méthodes ensemblistes Notre approche CARBoost boosting règles association classe présentée section section compte expériences pratiquées analyse résultats obtenus Finalement concluons section classification associative classification associative méthode apprentissage supervisé règles introduite Depuis différents travaux évidence diffé rents avantages classification associative rapport arbres décision notamment diminution erreur exploration exhaustive règles conservant lisibilité résultats Notions bases classification associative fondée prédiction classe partir règles sociation particulières dites règles association classe règles association prédictives règle association classe règle conséquent variable catrice modalités classe telle règle écrit conjonction descripteurs booléens variable indicatrice modalité classe intérêt règles classe permettre focalisation groupes individus éventuellement petits homogènes point descripteurs présentant Bahri classe rapport arbres décision classification associative intérêt explorer règles façon exhaustive pratiquer stratégie gloutonne méthodes classification associative procèdent phases phase corres construction règles association classe décompose habituellement étapes consacrée extraction itemsets fréquents algorithmes Apriori Agrawal Srikant Growth autre filtrant fréquents obtenus conserver itemsets comportant classe itemset classe déduire règles association classe satisfaisant seuil confiance phase dévolue prédiction partir règles classe sélectionnées Principales méthodes classification associative Parmi méthodes utilisées classification associative Classification Based Association premier algorithme proposé phases préci accomplies façon suivante utilise Apriori générer toutes règles association satisfont seuils support confiance choisis départ algorithme heuristique assure prédiction chaque prentissage stocke règle forte confiance parmi règles couvrent règles stockées classées ordre confiance décroissant applique nouveau règle couvre forte confiance proposé version améliorée appelée Classifica based Predictive Association Rules améliore temps exécution assurant qualité classification similaire celle méthodes existantes Cette approche génère règles algorithme Predictive Mining principe First Order Inductive Learner Quinlan Cameron Jones prédiction évalue abord règles classe estimant expected accuracy moyen mesure Laplace pénalise confiance fonction nombre classe Ensuite chaque prédire détermine règles couvrent choisit meilleures régles débouchant chaque classe calcule expected accuracy moyenne retient classe ayant meilleur résultat autre amélioration proposée Classification based Multiple Association Rules utilise Growth Apriori sélectionne règles confiance élevée analyse corrélation entre antécédent conséquent règles mesure utilisée weighted square exprime force règle partir condition support distribution classe souci efficacité emploie nouvelle structuration données enregistrer sélectionner règles chercher rapidement antécédent règle Parmi reproches couramment faits méthodes usuelles classification ciative retiendra génération massive itemsets règles utilisées difficulté assurer bonne prédiction classe minoritaire déséquilibre classes répondre reproches avons proposé Bahri Lallich 2009b liore phase extraction extraction directe seuls itemsets classe règles classe correspondantes grâce Growth construit règles significa tives outre améliore phase prédiction grâce pondération adéquate règles significatives détaillons dessous améliorations CARBoost Phase extraction génération seuls itemsets règles classe générer règles classe utilise Growth défini Bahri Lallich 2009a Growth adaptation Growth destinée extraire seulement classe principe fonctionnement similaire Growth modifications construction procédure élagage différente améliorer prédiction classe minoritaire utiliser seuil support comme version Growth Growth utilise seuil support local adapté chaque modalité dépend nombre transactions validant modalité classe considérée modalité outre avons introduit Growth méthode élagage proposée cadre Apriori Celle repose toute mesure vérifie condition alors mesure optimale toute spécialisation règle diminue nombre contre exemples moins intéressante règle départ Phase extraction filtrage règles significatives assurer prédiction constitue règles significatives notée rassemble règles classe confiance significativement supérieure probabilité priori classe éviter inflation fausses découvertes éventuellement ajuster value Lallich produites signification règles retenues étant significatives celle reste pertinente différents échantillons bootstrap issus ensemble apprentissage remarquera règles obtenues complexité modérée exemple Breast trouve règles classe significatives items moyenne antécédent règles ayant items Waves obtient règles classe significatives items moyenne règles ayant items Phase prédiction procédure prédiction effectuée partir règles pondérant celles mesure Loevinger intérêt prendre compte distribution classes étant donné prédire détermine abord règles couvrent pondère règles valeur mesure Loevinger notée règle intérêt cette mesure avantage classe ritaire outre compatible stratégie élagage permet élaguer travailler seuils support chaque prédire calcule score Loevinger chaque classe correspond somme valeurs Loevinger toutes règles couvrant considéré débouchent classe considérée classe prédite celle maximise score Loevinger générer règles classe Growth complexité sachant nombre nombre attributs nombre règles générées complexité phase prédiction ordre puisque chaque prédire accède parcourt maximum toutes règles Comme montré Bahri Lallich 2009b rapide approches traditionnelles assurant précision moins égale précision celles candidat servir classifieur faible procédure adaptative boosting Bahri Intérêt méthodes ensemblistes contrepoint intelligibilité méthodes règles présentent souvent performances quelque inférieures celles autres algorithmes augmenter performances classification associative veillant conserver bonne intelligibilité sommes tournés méthodes ensemblistes théorème Condorcet montré majorité plusieurs juges prononcent indépendamment alternative risque inférieur permettait réduire considérablement risque erreur jusqu asymptotiquement Transposé fouille données théorème signifie agrégation classifieurs méthode ensembliste permet réduire considérablement risque erreur condition classifieurs soient suffisamment risque erreur inférieur suffisamment divers leurs erreurs indépendantes Toute difficulté approches ensemblistes assurer cette diversité Celle provenir abord utilisation classifieurs rogènes Sinon relance algorithme diversité provenir notamment modification paramètres algorithme individus biais échantillons bootstrap attributs formellement méthodes ensemblistes interprètent cadre compro entre biais algorithmes apprentissage erreur systématique dépend échantillon apprentissage variance provient variabilité résultats issus échantillon apprentissage Stacking Wolpert construit modèle décision minimiser biais alors Bagging Breiman opère échantillons boostrap ensemble apprentissage réduire variance augmenter biais Freund Schapire efforcent réduire simultanément biais variance travaillant échantillons bootstrap ensemble apprentissage forçant classifieur concentrer prédiction difficiles prédire grâce repondération adaptative risque apprendre données bruitées forêts aléatoires Breiman combinent construction arbres élagués échantillons bootstrap ensemble apprentissage diminue biais sélection hasard attributs participent éclatement chaque noeud chaque arbre forêt améliore diversité arbres forêt forêts aléatoires ainsi méthode référence rapide compétitive robuste bruit notre avons choisi mettre oeuvre procédure adaptative inspirée boosting paraît correspondre classification associative laquelle pable fournir règles couvrant exemples grande confiance procédure adaptive permettre règles valorisées notre connaissance travaux appliqué méthodes ensemblistes classi fication associative citera abord appliquant Adaboost règles prédictives simples obtiennent meilleurs résultats utilisant règles plexes utilisent approche équivalente boosting filtrer règles association adapter ainsi catégorisation textes grande échelle Enfin cadre concepts formels Meddouri Maddouri construit chaque itération concept pertinent exemples itération servira classifieur faible boosting CARBoost classification associative adaptative CARBoost Principes CARBoost poursuivi conception méthode classification associative bénéficie apport méthodes ensemblistes améliorer performances classification gardant mieux lisibilité principe prédiction règles Cette méthode itérative nommée CARBoost repose principes suivants classifieur faible retenu règles significatives produite section produit règles significatives permet classer performances moins aussi bonnes temps cution réduit avons choisi procédure adaptative inspirée boosting tient compte erreurs chaque itération forcer algorithme concentrer difficiles prédire chaque itération travaille échantillon bootstrap poids classés itération précédente accru construite toutes contribue réduire complexité méthode Cependant introduire diversité favoriser prédiction exemples difficiles chaque itération règles repondérées telle sorte favorise règles prédit correctement moins exemple classé itération courante prédiction finale résulte pondéré classifieurs permet échap ajustement modifications relance autre échantillon bootstrap repondération classés repondération règles efficaces moins exemple classé nouvel exemple itéra autre règles couvrent restent stables classes conséquents règles pondérations règles changent ainsi score Loevinger associé chaque classe exemple considéré effet bootstrap individus associé évolution adaptative poids modifie mesure Loevinger règles autre poids règles modifié façon adaptative favoriser règles prédisent correctement moins exemple classé prédiction finale nouvel exemple obtenue pondéré résultats différentes itérations présente comme ensemble liste règles couvrant exemple débouchent chacune classes chaque liste étant accompagnée ensemble poids optimisés résulte repondérations précitées Explication détaillée CARBoost Inputs règles significatives obtenue génère règles classe Growth permet générer règles classe utilisant condition élagage filtre règles obtenues garder celles confiance significativement supérieure probabilité priori classe figure conséquent règle constituant ainsi assurer prédiction nouveau pondère règles couvrent valeur Bahri mesure Loevinger calcule score chaque classe classe prédite nouveau celle meilleur score Loevinger Initialisation considère poids Itération nombre itérations Construction échantillon bootstrap Appel application règles pertinentes échantillon Calcul erreur divisant nombre erreurs prédiction obtenues score Loevinger nombre Calcul exactitude Repondération augmente poids prédits itération score Loevinger prédit score Loevinger alors expαt prédit score Loevinger alors Repondération règles augmente poids règles classifient moins exemple classé itération désigne erreur règle itération poids règle itération devient alors Prédiction classe nouveau prédite faisant voter classifieurs faibles pondérés Experiences analyse résultats évaluer efficacité CARBoost nouvelle approche classification associative proposons avons comparé expérimentalement précision généralisation celle issue principales méthodes classification associative savoir elles meilleurs résultats outre servir référence avons inclus comparaison autres méthodes règles savoir algorithme arbres décision populaire forêts toires Breiman considérées comme méthodes ensemblistes arbres décision performantes Cette comparaison porte mêmes bases données Machine Learning Repository Asuncion Newman celles utilisées Toutes expériences exécutées machine Pentium mémoire avons choisi experiences pratiquer itérations effet valeur couramment utilisée procédures Boosting aussi celle choisie comparaison fondée calcul précision rappel chaque méthode chaque méthode donnée donnée rappelons précision classe proportion prédictions correctes parmi prédits comme étant cette classe rappel classe proportion parmi classe correctement prédits précision rappel considérée alors moyennes arithmétiques respectives précisions rappels différentes classes avons choisi calculer précision plutôt accuracy mieux prendre CARBoost compte mauvais résultats éventuels classes minoritaires effet précision étant moyenne arithmétique précisions différentes classes intervenir résultats classes minoritaires titre résultats classes nombreuses accuracy tableau indique abord caractéristiques différentes bases nombre nombre attributs nombre classes poursuit précisions moyennes méthodes expérimentées chacune bases rappel moyens différentes méthodes chacune bases figurent tableau Bases WCARP CARBoost ANNEAL AUSTRAL BREAST CLEVE DIABETES GERMAN GLASS HEART HEPATIC HORSE LYMPH SONAR VEHICLE WAVEFORM Moyenne Precision CARBoost Random Forest assurer différences observées significatives simple fruit hasard avons abord utilisé apparié Student compa précisions moyennes méthodes mêmes bases avons redoublé paramétrique échantillons appariés signe teste gnification résultat match entre méthodes bases comparaison binomiale attendue hypothèse nulle méthodes équivalentes résul différents tests rapportés tableaux niveau signification comparaisons indiqué significatif significatif hautement significatif suivant value value value rappelle value probabilité obtenir valeur statistique Bahri Précision RFOREST CARPBoost Précision moins aussi extrême hypothèse alternative celle effectivement respectée supposant hypothèse nulle vraie Globalement résultats expériences concernant précision tableaux conduisent conclusions claires rapport méthodes usuelles classification associative Boost enregistre supérieur points précision hautement significatif values apparié Student ordre notera CARBoost emporte presque systématiquement méthodes précitées hautement significatif selon value signe ordre rapport méthode avons élaborée classifieur faible CARBoost peine moins marqué points restant hautement significatif value ordre étant presque systématique victoires égalité bases value ordre rapport méthodes règles prises comme référence CARBoost améliore précision points moyenne value hautement significative ordre connaît aucune défaite bases testées value ordre Comme attendu meilleur concurrent CARBoost algorithme forêts aléatoires CARBoost emporte quand égalités value signe égale moyen point reste significatif value Student égale concerne rappel trouve résultats peine moins marqués hautement significatifs ensemble CARBoost enregistre rappel points rapport victoires contre points rapport victoires égalités CARBoost améliore systématiquement rappel augmenté points moyenne CARBoost Bases WCARP CARBoost ANNEAL AUSTRAL BREAST CLEVE DIABETES GERMAN GLASS HEART HEPATIC HORSE LYMPH SONAR VEHICLE WAVEFORM Moyenne Rappel CARBoost Random Forest façon CARBoost gagne points rappel moyenne porte forêts aléatoires points reste significatif value retrouve plupart bases victoires égalité value Conclusion perspectives classification associative intérêt méthode prédiction règles bonnes performances papier proposons CARBoost version adapta classification associative inspirée boosting permet faire émerger règles capables prédire correctement exemples difficiles performances CARBoost termes précision moyenne rappel moyen améliorées aussi rapport méthodes classification associative couramment utilisées gardant grande partie intelligibilité processus classification nouvel individu supériorité CARBoost forêts aléatoires moins marquée demeure significative ordre point aussi Bahri Précision Avantage CARBoost ratio Student value Student signification succès CARBoost échecs CARBoost aequo value signe signification Signification précision Rappel Avantage CARBoost ratio Student value Student signification succès CARBoost échecs CARBoost égalités value Signe signification Signification rappel précision outre améliorations indiquées aspect systématique elles retrouvent moins intensité quasi totalité bases testées envisageons poursuivre travail testant diverses repondérations règles différentes itérations procédure intégrant critères évaluation supplémen taires souhaitons aussi examiner impact nombre itérations résultats notre méthode première analyse Breast Waves montre erreur apprentissage voisine erreur généralisation recommence croître partir expériences données réelles compléteront utilement celles réalisées Références Agrawal Srikant algorithms mining association rules Large Bases Asuncion Newman machine learning repository Bahri Lallich 2009a Introduction élagage extraction règles ciation classe génération candidats Atelier Strasbourg Bahri Lallich 2009b classification associative efficace Conférence francophone lŠapprentissage artificiel Breiman Bagging predictors Machine Learning CARBoost Breiman Random forests Machine Learning Freund Schapire Experiments boosting algorithm Machine Learning Proceedings Thirteenth National Conference Mining frequent patterns without candidate generation SIGMOD Management Press Lallich Teytaud Prudhomme Association rules interestingness measure validation Quality Measures Mining Heidelberg Germany Springer optimal discovery Transformation Knowldge neering Accurate efficient classification based multiple class association rules Integrating classification association mining Knowledge Discovery Mining Meddouri Maddouri Générer règles classification dopage concepts formels Quinlan programs machine learning Francisco Morgan Kaufmann Publishers Quinlan Cameron Jones Induction logic programs related systems Generation Computing Boosting associative classifier Transactions Knowledge Engineering Wolpert Stacked generalization Neural Networks Classification based predictive association rules International Conference Mining categorization based boosting association rules Inter national Conference Semantic Computing Summary Associative classification method effective prediction resulting mining sociation rules method particularly interesting because search exhaustive relevant association rules which filters class association rules those consequent class attribute Those association rules classifier Discovery knowledge directly interpretable Former studies disadvantages approach which massive generation useless rules about prediction minority class classes unbalanced proposes original approach boosting class association rules which learner significant rules built supervised frequent itemsets generation algorithm limited extraction significant class rules takes account imbalance Comparisons other methods associative classification approach improves precision recall