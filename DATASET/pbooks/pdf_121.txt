e33reconnaissance sections entités décisions justice application modèles probabilistes gildas tagny ngompé sébastien harispe guillaume zambrano jacky montmain stéphane mussard laboratoire lgi2p école mines gildas tagny ngompe sebastien harispe mines equipe chrome université nîmes résumé décision justice document textuel rapportant dénoue affaire judiciaire juristes servent régulièrement comme source interprétation compréhension opinion juges masse disponible décisions exige solutions automatiques aider acteurs droit proposons adresser certains défis cherche analyse volume croissant décisions justice france projet global première phase projet porte extraction formation décisions objectif construire connaissances jurisprudentielles structurant organisant décisions telle facilite analyse descriptive prédictive corpus décisions article présente application modèles probabilistes segmentation décisions reconnaissance entités contenu participants règles tests montrent avantage approches basées champs toires conditionnels rapport modèles simples rapides basés modèles cachés markov présentons pects techniques sélection annotation corpus apprentissage définition descripteurs discriminants spécificité textes importante prise compte application méthodes extraction formation domaine spécifique introduction décision justice résultat rendu juges issue procès document contenant description affaire résultat juges motifs conduit résultat article présente approche reconnaissance sections entête exposé affaire dispositif entités ville juges documents précisément évaluons application approches reconnaissance infor mation modèles markoviens hidden markov model conditio random fields décisions jurisprudentielles essentielles juristes parce elles sources interprétation juristes doivent rassembler analyser décisions pertinentes résoudre problèmes auxquels intéressent mieux reconnaissance sections entités décisions judiciaires anticiper décisions juges généralement manuelle cette analyse rencontre quelques mites abord accès corpus exhaustif décisions difficile énorme volume décisions réparti juridictions millions décisions france malgré disponibilité nombre important décisions ligne moteurs recherche juridiques proposent essentiellement critères extraction information derait mieux décrire organiser décisions enrichissant critères recherche notamment juges articles autre analyse manuelle décisions devenir pénible lorsque documents longs nombreux ailleurs justice complexe langage difficilement compréhensible cretin permettre juriste estimer conclusions décision initié droit technologies actuelles traitement langage naturel fouille textes peuvent mettre analyse automatisée documents atténuer obstacles exemple reconnaissance entités classification textes structurer large collection articles scientifiques faciliter recherche mccallum 2000b analyse automatisée décisions jurisprudentielles aider avocats chercheurs droit comprendre opinion juges certaines questions autre constitue tentiellement précieuse particuliers entreprises soucieux connaitre chances leurs requêtes aboutissent justice comment exploiter corpus décisions analyser voire prédire décisions juges sachant interprétation subjective règles juridiques application déterministe cette question intéresse nombreuses entreprises telles lexisnexis système lexmachina jeunes startups françaises telles predictice analytics répondre développons actuellement approche matisée permettant analyse exhaustive descriptive prédictive jurisprudence cette analyse nécessite abord structurer corpus décisions analyser partir infor mations caractérisant numéro inscription répertoire général juridiction ville juges normes utilisées demandes quanta demandés résultats juges quanta cordés cette formalisation informations leurs relations demande fondée norme permet description organisation décisions connais sances objectif premier notre projet ainsi extraire informations contenus textuels corpus décisions suite informations doivent normalisées construire connaissances jurisprudence française application pouvant bénéficier telle nombreux mieux comprendre application règles juridiques anticiper résultats juridictions rechercher décisions similaires analyser comparer risque judiciaire entre périodes lieux encore identifier facteurs influencent résultats juges construction telle connais sances nécessite description décisions dernières textes libres structure standard elles comprennent plusieurs informations nécessaires compréhen affaire parties juges requêtes parties résultats juges natures différentes informations imposent différentes tâches analyse texte exemple extraction juges règles juridiques normes assimile reconnaissance entités nommées problématique largement justice budget statistiques 10054 chiffres justice 10303 lexmachina predictice caselawanalytics tagny ngompé traitement automatique langage naturel marrero cependant extraction information concernant demandes parties résultats juges approches novatrices doivent définies article restreint segmentation décisions reconnaissance entités bleau modèles probabilistes distinguer quatre approches reconnais sance entités lexique règles statistiques apprentissage automatique approches appliquées extraction entités textes juridiques après segmentation documents combinent approches reconnaître entités décisions suprême etats définissent séparément entre autres détecteurs règles respectivement identifier juridiction géographique document juges détecteur lexique classificateur entrainé titre détecteurs performances prometteuses rappels limités entre ailleurs décisions tchèques comparent applica algorithme perceptron marges inégales reconnaitre institutions références autres décisions actes contrat modèles présentent bonnes performances mesures comprises entre trigrammes entre grammes lemmes rôles grammaticaux termes étiquetage texte modèles considérons texte comme étant séquence observations chaque segment texte ligne phrase tâche segmentation consiste découper groupes chevauchant telle sorte éléments soient groupe tandis étiquetage consiste assigner labels appropriés chaque segmentation passe étiquetage consécutifs ayant label partie groupe démontré efficacité diverses tâches comme distinction questions réponses foires questions mccallum 2000a extraction entités entêtes références articles scientifiques mccallum décrivons cette section principe fonctionnement modèles cachés markov machine états finis objectif affecter probabilité jointe séquences couplées observations labels étant modèle génératif chaque label correspond lequel machine généré observation autant labels états processus étiquetage consiste déterminer argmax évaluation toutes séquences possibles labels serait nécessaire déterminer globalement correspond mieux éviter complexité exponentielle cette approche processus étiquetage utilise généralement algorithme décodage viterbi viterbi programmation dynamique principe général parcourir texte recherchant chemin états labels meilleur score reconnaissance sections entités décisions judiciaires chaque position probabilité élevée rabiner donne détails tutoriel algorithme exploite paramètres estimés partir exemples textes annotés ensemble états alphabet observations probabilité génère première observation distribution probabilité transition distribution probabilité émission probabilités transition émission peuvent inférées méthode estimation maximum vraisemblance comme algorithme espérance maximisa algorithme welch welch spécification particulièrement conçue avantage simplicité rapidité entrainement contre difficile représenter plusieurs caractéristiques interactives modéliser dépendance entre observations éloignées hypothèse indépendance entre observations stricte courant dépend états précédents observation courante champs aléatoires conditionnels algorithme viterbi aussi utilisé application modèle quetage texte structure différente celle contrai rement maximisation probabilité jointe lafferty linéaire notre cherche séquence labels maximise probabilité conditionnelle facteur normalisation fonctions potentielles caractéristiques manipulent elles types caractéristiques transition pendent labels positions précédente courante entièrement caractéristiques fonction uniquement définies fonctions valeur réelle binaire wallach permettant exprimer combinaison descripteurs position trouvons discriminants étiquetage normes avoir exemple fonctions potentielles suivantes étiquetage contexte article procédure norme norme sinon norme sinon article unknown sinon article sinon tagny ngompé désigne position actuelle grammatical valeur numérique désignent respectivement lemme précédant suivant proches symboles unknown représentent lemmes inconnus lemmes nombres fonctions f1etf2 pouvant actives moment elles définissent caractéristiques chevauchant plusieurs fonctions activées croyance norme boostée somme poids fonctions activées utilise fonction lorsque conditions remplies férentes caractéristiques pondérées définies descripteurs définissons texte étiquetage entrainement entrainement consiste essentiellement estimer paramètres partir textes préalablement annotés texte séquence labels correspondante maximiser semblance conditionnelle données entrainement fonction objectif approche apprentissage consiste généralement calculer gradient fonction objectif utiliser algorithme optimisation comme suite article présente comment avons compte particularités documents définition notre approche tests avons menés application reconnaissance sections entités décisions françaises observation décisions remarquer répartition informations trois sections ordre métadonnées entête demandes leurs fondements normes juridiques exposé affaire motifs appellera corps conclu sions leurs fondements dispositif segmentation décisions sections contribuerait potentiellement mieux organiser tâches extraction information proche intuitive consisterait définir algorithme capable reconnaître transitions entre sections partir motifs marqueurs transitions parfois titres symboles astérisques tirets absents transitions explicites restent variées exemple passage entête corps défini titres faits procédures exposé affaire exposé faits quant dispositif démarre généralement expression motifs riantes simples motifs exceptionnelles certains greffiers préfèrent autres expressions telles décision dispositif arrive souvent marqueur utilisé aussi section nement sectionnement notre première tentative sectionnement règles ainsi montrée infructueuse consistait formaliser expressions gulières schémas transitions observés ensemble décisions ensemble schémas représenté forme graphe couches sommets chaque couche correspond section sommets correspondent chacun variante début section enfin graphe parcouru profondeur simultanément décision segmen trouver chemin connu correspond mieux schéma cette décision après expérimentation décisions apprentissage schémas décisions approche montré désavantages nombre important schémas multiples proposés difficulté définir manuellement expressions régulières surtout reconnaissance sections entités décisions judiciaires transitions marqueur avons choisi définir modèle après avoir segmenté décision entitées identifiées fonction structure interne sections comme décrit sections suivantes figure evaluation modèles application modèles architecture approche extraction descripteurs ligne reconnaître sections quelque document sections enchainent ordre plusieurs critères différentient sections longueur lignes longues corps courtes entête premiers termes certaines lignes typiques chaque section nombre lignes supporte descripteur généralement assimilé élément étiqueter autres descripteurs peuvent position élément étiqueter numéro ligne premiers ligne avons choisi numéro ligne parce donne meilleur résultat avons choisi capturer forme ligne toute ligne ligne premiers termes nombre termes contexte numéro ligne longueur ligne précédente premiers termes lignes précédentes lignes suivantes précisément considérons exemple trois lignes suivantes transition entre descripteurs lignes extraits forme nominale comme ligne application article procédure civile bardaille application article label ligne motifs application motifs label tagny ngompé ligne statuant label contre descripteurs lignes réduits numéro ligne label label label extraction descripteurs reconnaître entités entête retrouvent nombreux types entités contrairement autres sections contiennent normes ailleurs entête mieux structurée autres sections nombreuses variantes différentes selon greffier juridiction entités labels exemples numéro 02324 ville nîmes toulouse juridiction appel formation chambre chambre économique partie appelante syndicat partie intimée partie intervenante avocat dominique avocat barreau papeete monsieur andré bousquel fonction conseiller président norme article articles element éviter élément faisant partie aucune entité ciblée labels utilisés étiquetage entités sections reconnaissance entité entêtes exemples constitué quant entités ciblées sections labels correspondants tableau notre approche consiste entrainer notre modèle étiqueter différents éléments constituant entités ponctuation nombre identifiant parties avocats trouvent souvent après exemple appelants demandeur appelants intimes intimés intervenants intervenants personnes commencent majuscule entièrement majuscule méros dates contiennent éléments nombres grammatical contiennent souvent caractères ponctuation comme certaines initiales abréviations observe couramment ordre lignes contenant avons ainsi considéré descripteurs formes élément grammatical lemme commence lettre majuscule entièrement majus lettre initiale contient caractère ponctuation éléments précédents suivants ainsi lemme avons considéré aussi descripteurs contexte numéro ligne position élément ligne nombre ments ligne texte contient chaine intervenant élément reconnaissance sections entités décisions judiciaires propre abréviation nombre considérons aussi numéros lignes précédente suivante détecté numéro occurrence parce parties souvent rappelés plusieurs emplacements avons considéré élément apparait texte approche similaire normes avons défini différent cripteurs élément lemme grammatical lemmes éléments adjectifs précédents suivants élément terme normes dernier descripteur avons défini court lexique quelques termes comme article contrat règlement convention décret lemme homogénéise variantes terme éléments voisins choisis indiquer modèle proximité élément termes couramment utilisés référencer normes architecture phases notre approche applicative résumées comme traitement décisions téléchargeables divers formats documents téléchargés contiennent plusieurs décisions contenu textuel extrait nettoyant éléments inutiles comme caractères invisibles continus lignes vides éléments apparaissent généralement documents forme texte elles donnent aucune indication début sections autres informations suite décisions séparées fichiers plein texte distincts marquer leurs sections balises obtenir corpus exemples segmentation partant cuments constituons exemples détection entités marquant début entités ciblées sections figure exemple annotation manuelle normes corps début extraction descripteurs commence découpage texte éléments tracteur calcule ensuite descripteurs chaque élément stocké fichier chaque décision rappel éléments entités entières ments issus découpage textes lignes sectionnement nombres tifiants ponctuation reconnaissance entités entité contient éléments éléments faisant partie aucune entité étiquetés label défaut validation croisée permet randomiser exemples effectuer moins tests avoir meilleure appréciation performance modèles application modèle modèle segmentation appliqué premier niser extraction entités application modèles extraction entités paral lélisée processus suite modèle entrainé détection normes aussi corps dispositifs normes citées pareillement tagny ngompé expérimentations résultats constitution apprentissage tâches traitement langage naturel suggère choix échantillon suffisant volume équilibré variété données représentatif langage avons annoté manuellement décisions cours appel simuler représentativité corpus décisions choisies variant aléatoirement ville année origine conditions tests avons utilisé implémentation premier ordre markov librairie mallet mccallum modèles trainés méthode maximum vraisemblance méthode parce éxécute rapidement plusieurs processus parallèle extrac entités découpage texte sections extraction lemme grammatical effectués fonctionnalité française extraction rôles grammaticaux treetagger schmid avons implémenté extraction autres descripteurs cette expérimentation validation croisée reconnaissance normes effectuée exemples annotés sections résultats suite appelons notre modèle modèle caché markov notre modèle champs aléatoires conditionnels respecti vement descripteurs avons effectué validation croisée évaluer chacune tâches performances estimées calculant moyenne cisions rappels mesures nombre total tests notre derniers calculés chaque label comme nombre éléments correctement étiquetés modèle nombre éléments étiquetés modèle nombre éléments correctement étiquetés modèle nombre éléments manuellement étiquetés résultats moyennes comprises tronqués moyenne précision rappel mesure niveau lignes résultats sectionnement résumés tableau noter point descripteurs améliorent performances mesure inférieure mesure moyenne presque parfaite assure sectionnement décisions rares confusion quelques lignes généralement muenchen schmid tools treetagger reconnaissance sections entités décisions judiciaires situées transitions entre sections autre lignes présentant demandes parties parfois similaires lignes conclusions juges potentiellement pousser modèle étiqueter comme étant lignes dispositifs pourrait cependant conserver dispositif détecté document raison faiblesse justifier utilisation numéro absolu lignes comme descripteur position relative lignes document mieux remplacer numéro associée exemple considérant document découpé parties égale longueur descripteur ligne serait partie trouve résultats détection entités résumés tableau descripteurs permettent atteindre mesures général supérieures parties intervenantes entités général situées juste après liste parties intimées toujours présentes décisions justifie proba blement difficile apprentissage confusion majorité parties intimées détection préalable région chaque partie pourrait améliorer performance nécessite effort annotation manuelle section entête sections inférieures précision rappel mesure niveau éléments étiquetés sections ailleurs réussissent détecter normes uniquement éléments originaux textes règles juridiques existent nombre limité celles référencées notre exemples probablement majorité courantes décisions modèles semblent aussi aidés toutes rences normes respectent syntaxe standard article numero origine néanmoins descripteurs définis améliorent performances dernière remarque pourrait occurrence multiple entités sections exemple parties citées avant détails concernant entête certaines normes citées plusieurs reprises souvent manière abrégée occurrences multiples soient point identiques elles aident réduire risque manquer entité pourrait exploité combler imperfection modèles tagny ngompé conclusion article présente application modèles markoviens reconnaissance sections entités décisions judiciaires expérimentations actuelles montrent avantage approches descripteurs capturant forme contexte lignes étiqueter malgré bonnes performances descripteurs reconnaissance normes descripteurs notre projet cependant exemples entêtes annotées comprenant parties intervenantes zonage préalable types parties amélioreraient probablement tection intervenants restent seules entités difficilement détectables actuellement difficulté majeure reste constitution suffisant exemples prise compte motifs réguliers langage documents définir descripteurs caractéristiques entités détecter effort annotation réduit système performances actuelles correctement étiqueter majorité entités suffit ensuite vérifier nuellement annotation corriger éventuelles erreurs modèle nouvelles décisions cours futurs travaux envisageons étendre étude autres types juridictions tribunaux premier degré cassation ordre administratif constituer notre connaissance indispensable définir approche mbiguïsation entités multiples occurrences autre résolution entités faire correspondre entités extraites référentiels comme dozier entités seront exploitées extraction informations complexes comme demandes parties résultats juges mettons ainsi progressivement place chaîne traitements amenée faciliter conception approches analyse statistique large corpus jurisprudentiel références extracting meaningful entities police narrative reports proceedings annual national conference digital government research digital government society north america cretin opinion français justice infostat justice justice art_pix 1_infostat125_20140122 dozier kondadadi light vachher veeramachaneni wudali named entity recognition resolution legal semantic processing legal texts springer hladká statistical recognition references czech court decisions springer international publishing lafferty mccallum pereira conditional random fields probabilistic models segmenting labeling sequence international conference machine learning marrero urbano sánchez cuadrado morato gómez berbís entity recognition fallacies challenges opportunities computer standards interfaces reconnaissance sections entités décisions judiciaires mccallum freitag pereira 2000a maximum entropy markov models information extraction segmentation volume mccallum mallet machine learning language toolkit mallet umass mccallum nigam rennie seymore 2000b automating construction internet portals machine learning information retrieval mccallum information extraction research papers using conditional random fields information processing management rabiner tutorial hidden markov models selected applications speech recognition proceedings schmid probabilistic ofispeech tagging using decision trees methods language processing routledge viterbi error bounds convolutional codes asymptotically optimum decoding algorithm transactions information theory wallach conditional random fields introduction university pennsylva department computer information science technical report welch hidden markov models welch algorithm information theory society newsletter handbook natural language processing second edition chapter corpus creation chapman conditional random fields cs769 spring advanced natural language processing pages jerryzhu cs769 summary court decision document which synthesis outcome court lawyers regularly source interpretation order derstand opinion judges available quantity decisions requires automated solutions actors propose address challenges related search analysis growing court decisions france larger project first phase project focuses extracting information decisions order build jurisprudential knowledge structuring organizing decisions facilitates descriptive predictive analysis decisions corpora paper presents application probabilistic models zoning decisions recognition entities their content location participants rules tests advantage approaches based conditional random fields compared simpler faster models based hidden markov models present technical aspects selection annota training corpus definition discriminating descriptors specificity texts important should taken account applying information extracting methods specific domain