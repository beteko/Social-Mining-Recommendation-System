Caractérisation instances apprentissage mining évolutionnaire William Raynaut Chantal Soule Dupuy Nathalie Valles Parlangeau Cedric Philippe Valet Universite Toulouse France prenom INSERM U1048 Universite Toulouse France prenom inserm Motivation apprentissage secteur prolifique dernières décennies produisant nombre techniques algorithmes Cependant leurs performances sujettes importantes riations données autre retrouve ainsi lunch theorems Wolpert existe solution meilleure toute situation apprentis meilleur domaines Firent suite nombre applications apprentissage étude propre applicabilité posant fondations domaine apprentissage Malgré autres applications fructueuses Kalousis Hilario problème apprentissage toujours actualité perspectives applicatives restent nombreuses principaux verrous actuels apprentissage caractérisation tances apprentissage aussi appelées instances Cette caractérisation prend forme ensemble attributs devra permettre caractérisation toute rience apprentissage intuitivement diviser attributs selon trois dimensions description donnée traitements algorithmes utilisés performance traitements raisons volume intéressera attributs décrivant données décrivant traitements employés évaluation résultats seront privilégiés futurs travaux problème caractérisation données étudié selon premier consiste emploi mesures statistiques information théorétiques décrire données Cette approche notamment avant projet Michie présente nombre mesures expressives perfor mance repose intégralement adéquation entre biais apprentissage effectué niveau ensemble mesures choisies second approche introduit comme landmarking Pfahringer considère quant propriétés intrinsèques données étudié plutôt performance algorithmes apprentissage simples exécutés dessus Caractérisation instances apprentissage mining évolutionnaire principale limitation approches requis imposés algorithmes apprentissage employés niveau derniers imposent notamment utilisation vecteurs attributs taille implique agrégations exemple riance individuelle différents attributs données devient variance moyenne données importante perte information Kalousis Hilario Proposition contourner cette limitation propose conserver toute information disponible instances adresser problème apprentissage emploi heuristique évolutionnaire population instances effet alors construire fitness telle heuristique comme dissimilarité entre instance caractérisation solution idéale problème soumis attributs constitueront alors génome instances évolution contrainte divers mécanismes ristiques devra permettre découverte traitements apportant réponse satisfaisante besoin utilisateur transition paradigme entre cette approche apprentissage traditionnel affranchit pertes information causées agrégations évoquées place nouveau possible caractériser librement instances pouvoir comparer manière sensée validité approche repose intégralement définition telle dissimilarité Références Kalousis Hilario Model selection learning comparative study International Journal Artificial Intelligence Tools Michie Spiegelhalter Taylor Machine Learning Neural Statis tical Classification Upper Saddle River Ellis Horwood Pfahringer Bensusan Giraud Carrier learn Landmarking various learning algorithms Proceedings international conference machine learning Wolpert priori distinctions between learning algorithms Neural computation Summary Machine learning proven powerful diverse fields getting widely experts foremost difficulties encounter choice calibration machine learning algorithm objective provide assistance matter using learning approach based evolutionary heuristic introduce approach potential solution limitation current characterization