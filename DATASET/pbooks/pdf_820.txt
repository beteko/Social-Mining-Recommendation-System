Recherche EGC08 Final funss2pages dviEchantillonnage adaptatif données déséquilibrés forêts aléatoires Julien Thomas Pierre Emmanuel Jouve Prudhomme Société Fenics France Université Lumière Laboratoire Résumé nombre applications données présentent déséquilibre entre classes prédiction alors souvent détériorée classe ritaire contourner proposons échantillonnage guidé itérations successives forêt aléatoire besoins utilisateur Introduction données déséquilibrés constituent problème important prentissage supervisé plupart modèles conçus données équilibrées utilisation données déséquilibrées conduit souvent mauvaise prédiction classe minoritaire Pourtant cette situation retrouve régulièrement pratique tection pannes Pazzani textmining diagnostics médicaux applications besoin disposer méthodes capables prédire classe minoritaire performances adéquation attentes utilisateur évantail solutions tantes échantillonnage Japkowicz Chawla construction modèle prédiction spécifique classe intérêt passant utilisation matrices Pazzani Kubat FUNSS FUNSS Fitting Needs Sampling Strategy traduire besoin rappel classe minoritaire terme marge décision entre individus chaque classe individus minoritaires positifs entourés quantité importante indivi majoritaires négatifs empèchent classifieur apprendre correctemment augmenter rappel solution consiste choisir individus négatifs éloignés indivi positifs inverse augmenter précision suffit garder individus négatifs proches individus positifs FUNSS reprend principe modifiant échantillonnage cours forêts aléatoires échantillonnage dirigé chaque tirage remise processus suivant individu positif intégré nouvel échantillon sinon groupe individus négatifs ainsi individu positif individu négatif groupe proche éloigné individu positif intégré nouvel échantillon Chaque échantillon forêt aléatoire occasion augmenter diminuer rappel atteindre valeur fixée utilisateur rappel forêt estimé chaque nouvel arbre individus dessous rappel désiré échantillonnage suivant sélectionne individus négatifs éloignés contraire individus négatifs proches favorisés Enfin déterminer individu proche cible individus ordonnés chaque attribut proximité cette cible distance utilisée alors somme rangs individu FUNSS Fitting Needs Sampling Strategy Algorithme classe classe classe Correction Temps Indice positive négative positive globale temps Forêt aléatoire SMOTE900 FUNSS70 FUNSS80 FUNSS90 Résultats CrossValidation Satimage Rappel Précision Expérimentations résultats obtenus données Satimage individus variables individus positifs présentés table version SMOTE testée comporte échantillonnage classe négative algorithme Balanced Random Forest construit forêt aléatoire partir bootstraps équilibrés notation FUNSSXX signifie algorithme FUNSS paramétré barre rappel classe positive atteindre FUNSS montre possibilité apprendre manière correcte modalité minoritaire modifier distribution effectifs temps calcul sensiblement inférieurs SMOTE rappel classe positive obtenu adéquation souhait utilisateur Références Chawla Bowyer Kegelmeyer Smote Synthetic minority sampling technique Journal Artificial Intelligence Research Using random forest learn imbalanced Technical Report Japkowicz class imbalance problem Significance strategies Procee dings Volume Kubat Holte Matwin Machine learning detection spills satellite radar images Machine Learning Pazzani Murphy Brunk Reducing misclassifi cation costs Morgan Kaufmann Summary class imbalance problem occur several cases learning algorithms applied Prediction therefore degraded especially minority class issue proposed approach consists using adaptative sampling scheme through successive steps Random Forest ensure needs satisfied