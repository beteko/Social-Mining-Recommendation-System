revision_egc2008 dviUne nouvelle méthode divisive classification supervisée données symboliques intervalles Nathanaël Kasoro André Hardy Université Kinshasa Département Mathématique Informatique Kinshasa République Démocratique Congo kasoro mulenda yahoo Université Namur Unité Statistique Département Mathématique Rempart Vierge Namur Belgique andre hardy fundp Résumé article présentons nouvelle méthode classifica supervisée données symboliques intervalles tension méthode classification supervisée classique données intervalles méthode classique suppose points observés réali sation processus Poisson homogène domaines convexes disjoints première partie nouvelle méthode procédure monothé tique divisive règle coupure basée extension données intervalles critère classification Hypervolumes étape élagage statistique processus Poisson homogène résultat arbre décision seconde partie méthode consiste étape recollement permet certains améliorer classification première partie algorithme méthode évaluée ensemble données réelles Introduction classification supervisée décomposer groupe objets quels mesure ensemble variables nombre relativement restreint groupes objets semblables nombreuses méthodes classification publiées litté rature scientifique plupart entre elles utilisent critère classification mesure dissimilarité éviter choix souvent arbitraire dissimilarité utilisons modèle statistique classification processus Poisson homogène Hardy modèle issue méthode classification Hypervolumes Hardy Pirçon développé nouvelle méthode divisive classification basée critère classification Hypervolumes Notre objectif étendre cette méthode données intervalles variable domaine observation appelée valeurs ensemble nouvelle méthode classification données intervalles variable valeurs ensemble appelée variable intervalle existe modèle statistique classification cessus Poisson homogène Définition processus Poisson homogène processus Poisson homogène intensité ensemble conditions suivantes satisfaites Isham variables aléatoires comptent nombre points régions disjointes espace indépendantes variable aléatoire distribution Poisson moyenne mesure Lebesgue multidimensionnelle critère classification hypervolumes méthode classification Hypervolumes Hardy Rasson Hardy suppose observations dimensionnelles représentent échantillon toire simple processus Poisson homogène ensemble inclus espace Euclidien ensemble union domaines convexes pacts disjoints problème statistique consiste estimer domaines inconnus lesquels points générés désigne ensemble points appartenant estimations maximum vraisemblance domaines inconnus enveloppes convexes groupes points telles somme mesures Lebesgue enveloppes convexes disjointes minimale critère classification Hypervolumes défini problème classification Hypervolumes consiste trouver partition telle minPk représente ensemble toutes partitions classes exemple mesure Lebesgue domaine domaine mesure chacun objets valeur variables quantitatives méthode classification Hypervolumes cherche groupes contenant points somme aires enveloppes convexes ensembles minimale statistique nombre classes Grâce modèle statistique classification processus Poisson définir quotient vraisemblance nombre classes shishi teste points observés réalisation processus Kasoro Poisson homogène contre alternative points réalisation cessus Poisson homogène points ensembles inconnus statistique donnée espace space entre classes mesure Lebesgue multidimensionnelle règle décision suivante Kubushishi rejette niveau distribution asymptotique méthode classification Pirçon méthode classification supervisée divisive issue modèle statistique décrit dessus première étape consiste couper successivement noeuds arbre noeuds jusqu critère arrêt vérifié nombre points noeud chaque coupure recherche bipartition classe classes minimise critère classification Hypervolumes méthode monothétique choisit chaque noeud variable minimal processus coupure obtient arbre grande taille deuxième étape permet élaguer arbre vérifier coupures effectuées valides utilise teste chaque noeud hypothèses suivantes points distribués domaine contre hypothèse alternative points distribués domaines Lorsque hypothèse nulle rejetée conclut coupure mauvaise contre hypothèse nulle rejettée décide coupure bonne procédé utilise règle suivante élaguer toutes branches contiennent mauvaises coupures certain structure naturelle données obtenue étape élagage troisième étape outil recollement tests effectués uniquement classes issues noeud niveau précédent faire utilisons nouveau moins regroupement effectué étape recollement caractère hiérarchique devient alors méthode parti tionnement méthode classification symbolique SPART paragraphe présentons extension méthode données inter valles Diday faire représente chaque intervalle centre longueur point espace bidimensionnel Comme méthode classique première étape consiste trouver meilleure partition classe classes Comme SPART méthode monothétique travaillons espaces lesquels intervalles viennent points considère toutes bipartitions classe classes respectant ordre centres intervalles bipartitions droites verticales figure définit extension données intervalles nouvelle méthode classification données intervalles mesure espace entre classes façon suivante choisit intervalle maximal valeur coupure prise arbitrairement intervalle Habituellement choisit centre intervalle figure Bipartition classe classe divisée grâce question binaire forme valeur coupure définit fonction binaire sinon obtient alors bipartition souhaitée étapes élagage recollement effectuées façon classique utilise aussi extension symbolique données intervalles représentant chaque intervalle centre longueur Application applique méthode SPART données réelles comparerons sultats donnés SPART obtenus autres méthodes classification supervisées monothétiques divisives variables intervalles SCLASS Rasson méthode classification hiérarchique monothétique divisive basée extension variables intervalles critère classification généralisé Hypervolumes Chavent quant méthode classification hiérarchique monothétique divisive basée extension critère inertie intra classe données constitué voitures disponibles lesquelles mesurées variables intervalles répertorié bases logiciel SODAS SODAS2 objets repris figure variables suivantes empattement cylindrée longueur vitesse maximale largeur accélération maximale hauteur partition classes obtenue après étape élagage étape recollement difie cette partition classes Kasoro Arbre ensemble données première variable coupure voitures marché voitures marché deuxième variable coupure longueur voiture tandis voitures chères hauteur voiture figure montre arbre hiérarchique produit SPART classes peuvent étiquettées manière suivante classe voitures citadines classe voitures berline classe modèles sport classe voitures limousines méthode donne partition classes SCLASS produit autre parti classes semblent correspondre structure utile ensemble voitures Conclusion SPART nouvelle méthode classification supervisée données tervalles basée extension données intervalles critère classification Hypervolumes originalité approche double modèle jacent méthode utilise mesure dissimilarité critère classification déduit modèle statistique processus Poisson homogène autre méthode inclut étape recollement permet structures particulières retrouver classes naturelles ensemble données multidimensionnelles SPART donnent souvent résultats semblables SPART produit cependant résultats meilleurs lorsqu présence classes allongées explique principalement utilise extension données intervalles critère variance intra classe critère biaisé rapport classes forme ellipsoï SCLASS Rasson utilise modèle statistique classification processus Poisson homogène critère minimiser intensité intégrée nouvelle méthode classification données intervalles processus Poisson enveloppes convexes classes Cette méthode exige mation intensité processus Poisson homogène complexe point temps calcul version actuelle SCLASS comporte étape élagage étape recollement résultats obtenus SCLASS générale qualitativement moins produits SPART Enfin procédure SPART détermine automatiquement nombre classes préalable SCLASS Références Diday Analysis Symbolic Exploratory Methods Extracting Statistical Information Complex Berlin Heidelberg Springer Verlag Chavent monothetic clustering method Pattern Recognition Letters Isham Point Processes London Chapman Hardy Statistique classification automatique modèle nouveau critère algorithmes applications Thèse doctorat FUNDP Université Namur Hardy Rasson nouvelle approche problèmes classification matique Statistique Analyse Données Kubushishi Applications Point Process Theory Cluster Analysis Pattern Recognition Thèse doctorat FUNDP Université Namur Pirçon classification processus Poisson nouvelles méthodes monothétiques partitionnement Thèse doctorat FUNDP Université Namur Rasson Pirçon Lallemand Adans Unsupervised divisive classi fication Diday Noirhomme Symbolic Analysis Sodas Software Wiley SODAS2 Logiciel fundp Summary present clustering method symbolic interval extension interval classical clustering method classical method assumes observed points realisation homogeneous Poisson point process disjoint domains first method monothetic divisive procedure based extension interval Hypervolumes clustering criterion pruning statistical hypothesis based homogeneous Poisson process output decision second method merging process allows particular cases improve classification obtained first algorithm method applied