Sélection prototypes catégorisation textes proches voisins étude comparative Fatiha Barigou Naouel Barigou Baghdad Atmani Bouziane Beldjilali Département Informatique Université Naouer Senia Algérie Laboratoire informatique Équipe simulation intégration fouille données fatbarigou barigounaouel baghdad atmani gmail bouzianebeldjilali yahoo Résumé technique proches voisins méthode apprentissage instances appliquée catégorisation textes depuis nombreuses années contraste performances classification reconnu algorithme pendant classification nouveau document Techniques sélection prototypes comme méthodes compétitives améliorer grâce réduction données étude contenue papier objectif lyser impact méthodes performance classification textes algorithme Introduction termes performance classification textes classe parmi classifieurs performants résultat obtenu multitude tests comparaison effectués corpus Reuters contraste performances classification connu algorithme puisqu requiert mesure similarité calculée entre documents apprentissage nouveau document caractérisé prentissage rapide facile apprendre robuste ensembles apprentissage bruités efficace corpus grand Bhatia Vandana inconvénient reste temps classer nouveau document Différentes solutions proposées réduire complexité calcul intéressons papier méthodes sélection prototypes précisément étudions impact diffé rentes méthodes sélection prototypes performance catégorisation textes classifieur Essentiellement voici comment structure suite papier présente série méthodes sélection prototypes décrivant leurs principales caractéristiques section présente différentes expérimentations effectuées férents corpus textes comparer différentes méthodes sélection prototypes conclusion générale résume travail effectué résultats obtenus Sélection prototypes Sélection prototypes Depuis création algorithme proches voisins Cover grande variété techniques sélection prototypes apparition médier principaux inconvénients associés algorithme variations Olvera López Garcia objectif principal consistait améliorer temps classification Principe méthodes sélection prototypes Étant donné ensemble apprentissage objectif méthode sélection prototypes notée suite obtenir ensemble instances contient instances inutiles lorsqu classe nouvelle instance règle agissant avons Olvera López Selon sélection algorithmes peuvent classés trois catégories Algorithme condensation algorithmes essayent trouver réduction significative ensemble instances telle façon résultats classification aussi proches possible obtenus utilisant originaux cherchent instances correspondent leurs voisins proches Étant donné instances fournissent mêmes informations classification leurs voisins elles peuvent retirées dégrader exactitude classification autres instances entourent distinguons cette catégorie méthode ancienne décrite performance algorithme bonne inspiré construction nouvelles méthodes telles Gates Ritter Tomek Riquelme Angiulli Algorithme édition algorithmes édition tentent découvrir supprimer instances bruitées instances bruitées peuvent provoquer erreurs classification conséquent pression devrait aider augmenter exactitude classification procédé décrémental instance éliminée classifiée majorité proches voisins algorithme Wilson permet résoudre blème instances bruitées bonne performance réduction reste jours faible comparant autres méthodes Olvera López autre variante méthode ALLKNN Tomek Algorithmes hybrides algorithmes permettent élimination instances bruitées inutiles proposé série algorithmes version aboutie présenté étude expérimentale différents algorithmes évolutionnaires fonction leurs résultats approche génétique obtenu meilleures performances Barigou précision réduction outre méthode exigeait moins temps exécu méthode Drop3 Wilson Martinez utilise filtrage bruit avant trier instances objets restants classés mesure distance objet classe différente proche restant objets frontière cision réelle supprimés premier méthode Garcia proposée couvrir inconvénient majeur méthodes évolutionnaires classiques manque convergence grands problèmes Étude expérimentale Notre étude concentre problème particulier utilisation techniques sélection prototypes aidera améliorer catégorisation textes proches voisins point efficacité efficience Corpus utilisés mesures évaluation menons étude expérimentale impliquant différentes tailles ensembles cuments mesurer performance méthodes sélection prototypes termes précision capacités réduction exécution cadre catégorisation textes textes différents corpus subissent ensemble traitements récupérer présentation numérique exploitable algorithme apprentissage Cette représentation appelée représentation vectorielle prédire classe nouveau document algorithme cherche proches voisins nouveau document calculant distance euclidienne ensuite majoritaire prédit réponse fréquente proches voisins avons calculé chaque expérience réduction exactitude mesure micro mesure macro temps réduction secondes temps classification secondes Résultats discussion tableau donnés meilleurs résultats différentes expériences réalisées corpus corpus quatre méthodes binées donnent meilleurs résultats termes Exactitude contre aucune méthode condensation amélioré résultats examinant duction constatons trois méthodes donnent réduction élevés Comme tableau ALLKNN donnent Fmesure micro macro élevé rapport ensemble méthodes elles moins précises particulièrement remarquable réduction augmente temps classification diminue produisent réduction élevé elles nécessitent temps réduction élevé termes rapidité classification approches condensation meilleures remarquons partir expériences tenant compte exactitude réduction méthode meilleur plupart autres termes permet meilleur compromis entre exactitude réduction reste toujours gourmande temps réduction Sélection prototypes exemple nécessite environ secondes réduire corpus documents termes corpus 20NewsGroups expériences effectuées apprentissage restants examinant tableau résultats montrent méthodes ENRBF donnent meilleur réduction rapport autres donnent aussi meilleur compromis entre temps classification réduction contre méthodes nécessitent temps classification élevé apport dernière remarque importante DROP3 assez lentes temps réduction également participé corpus cause cette contrainte temps expériences corpus Reuters effectuées corpus équivalent documents apprentissage après résultats présentés tableau offrent meilleurs résultats classification termes Aucune méthode condensation améliorer Lorsque méthodes condensation dépassent termes Fmesure duction restent faibles particulier celui méthode remarquer aussi méthodes performantes approches incrémentales condensation termes exactitude réduction temps classification offrent elles lentes pendant réduction Conclusion nombreuses méthodes étudiées Garcia conclu précise donnée meilleure méthode réalisons choix dépend alors problème résoudre résultats différentes expériences obtenus sieurs chercheurs pourraient toujours aider orienter certaines méthodes considèrent comme intéressantes effet cette étude bibliographique expérimentale permis découvrir plusieurs méthodes intéressantes performance efficacité général meilleures méthodes termes performance elles principal défaut temps réduction reste élevé meilleures méthodes réduction avons constaté méthodes hybrides permettent réduction élevés préservant formance elles lentes méthodes rapides permettant atteindre réduction élevés approches condensation comme constatons cette dernière mesure améliorer termes précision Certaines méthodes présentent différences claires lorsqu grand corpus tableau également ENRBF amélioré temps classification réduction intéressant autres méthodes comme AllKNN améliorer petit corpus Barigou Méthode ALLKNN DROP3 ENRBF Résultats obtenus corpus Méthode ALLKNN DROP3 ENRBF Résultats obtenus corpus 20NewsGroups vocabulaire termes Méthode ALLKNN DROP3 ENRBP Résultats obtenus corpus Reuters vocabulaire Références Kibler Albert Instance based learning algorithms Machine Learning Sélection prototypes Angiulli condensed nearest neighbor International Conference Machine Learning Germany Bhatia Vandana Survey nearest neighbor techniques International Journal computer science information security Herrera Lozano Using evolutionary algorithms instance selec reduction experimental study Transactions Evolutionary Computation Garcia Derrac Prototype selection nearest neighbor Trans actions Pattern Analysis Machine Intelligence Gates Reduced nearest neighbor Transactions Information condensed nearest neighbour Transactions Information Theory Cover Nearest neighbor pattern classification Transactions Infor mation Theory Noise Classification thesis University Lisbon College Science Technology Olvera López Carrasco Ochoa Martínez Trinidad Kittler review instance selection methods Artificial Intelligence Review issue Riquelme Aguilar Finding representative patterns ordered projections Pattern Recognition Ritter Woodruff Lowry Isenhour algorithm selective nearest neighbor decision Transactions Information Theory Tomek modifications Transactions systems Cyber netics Wilson Asymptotic properties nearest neighbor rules using edited Transactions Systems Cybernetics Wilson Martinez Reduction techniques instance based learning algorithms Machine Learning evaluation statistical approaches categorization Information retrieval Summary learning method based instances applied categorization years contrast classification performance recognized algorithm running classification document Prototype selection methods emerged highly competitive methods improving reduction study contained paper analyzing impact these methods performances classification algorithm