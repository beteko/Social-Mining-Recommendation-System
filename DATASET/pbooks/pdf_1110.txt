apprentissage supervise temporelles means nouvelle thode gation gaudin nicolas nicoloyannis laboratoire universite lumie lyon2 batiment pierre mende france 69676 cedex france gaudin lyon2 nicolas nicoloyannis lyon2 utilisation algorithme apprentissage supervise means temporelles poser questions celle choix mesure similarite celle choix thode effectuant gation plusieurs estimer centre calculer moyennes pondre premie question sentons article principales mesures milarite existantes expliquons pourquoi entre elles dynamic warping adapte apprentis supervise deuxie question alors proble avons besoin thode gation respectant caracte ristiques particulie dynamic warping pensons ciation cette mesure similarite gation euclidienne perte informations importante cadre appren tissage forme proposons thode origi gation temporelles compatible dynamic warping liore ainsi sultats obtenus algorithme means fouille donne apprentissage supervise temporelles means dynamic warping introduction temporelles donne ordonne temps ordonnance signification ignorer ainsi appliquer thodes fouille donne classiques thodes cialement adapte respectent temporalite donne resserons uniquement apprentissage supervise partir temporelles utilisation algorithme apprentissage supervise moyenne connu means temporelles poser questions choix mesure distance entre temporelles celle choix thode effectuant gation plusieurs temporelles estimer centre calculer moyennes pondre premie allons dresser lieux principales thodes comparaison temporelles existantes paragraphe allons discuter chacune entre elles cadre apprentissage supervise paragraphe apprentissage supervise temporelles pondre seconde question expliciterons inconve nient associer similarite dynamic warping mesure avons retenu gation euclidienne recalculer centres chaque cluster graphe senterons ensuite notre nouvelle thode gation paragraphe valider notre apport avons effectue tests partir types temporelles diffe rentes paragraphe finir avons perspectives approfondissement notre travail diffe rentes pistes recherches futures semble ressantes paragraphe principales mesures similarite mesure similarite norme cette mesure similarite couramment utilise simple mettre Å“uvre similarite entre alors utilise distance manhattan alors utilise distance euclidienne dynamic warping particularite thode dynamic warping savoir calages temporels peuvent ventuellement exister entre berndt clifford comparer chaque point celui autre intervient instant permet mesure comparer chaque point plusieurs points autre pouvant temps comparaison entre mesure norme posse finition cursive calcule similarite entre manie suivante gaudin nicoloyannis distance entre quences sinon mesure similarite entre aussi parame temporel maximum permis mesure parer points finit ainsi temporelle appele delta glisser chacune comparer exemple taille delta chaque point intervient instant pourra compare points autre interviennent instants choix taille cette avoir influence sultat convient terminer ratanamahatana keogh longest common subsequence thode longest common subsequence comparer quement portions similaires chacune quences communes nombreuses conside comme similaires cette thode effectue aussi formation temps contrai rement compare chaque point points autre delta utilise temporelle compare chaque point point autre affiner lection quences communes parame temporelle manie aussi fixer spatiale appele epsilon servira finir maximum pouvoir conside quences comme communes cette thode posse aussi finition cursive yazdani distance entre quences epsilon sinon mesure similarite entre rappellera thode norme compare chaque point premie obliga toirement point seconde celui intervient instant apprentissage supervise temporelles quelle mesure utiliser apprentissage supervise temporelles temps calculs complexite mesure norme temps calculs excellents algorithme cursif beaucoup cessite avoir recours thode imple mentation appele programmation dynamique bellman berndt clifford celle permet duire complexite ramener ordre quadratique utilise temporelle delta utilise reste toutefois beaucoup moins rapide mesure norme handicapant lorsque analyser temporelles chacune entre elles taille conse quente aussi liore programmation dynamique complexite identique celle sensibilite bruit performances mesure norme effondrent sence donne bruite etant donne points chacune syste matiquement compare point anormalement loigne outlier influencera conside rablement sultat final mesure souple reste toutefois sensible bruit cessite traitement donne soudre partiellement proble robuste bruit contrairement autres mesures similarite droit mesurer points seulement proches entre autre toutes donne anormalement loigne automatiquement ignore parame trage mesure norme posse aucun parame trage2 cadre apprentissage supervise posse parame trage porelle delta limiter comparaison points loigne celui handicapant mesure taille correspond taille analyser donne moyenne sultats satisfaisants posse aussi parame trage temporelle effectuer parame trage spatiale epsilon celui important pouvant modifier conside rablement sultat final fonction valeur posse connaissances alables donne toujours apprentissage supervise fixer epsilon tonnement faire perdre temps gligeable pendant phase apprentissage parame sultats incertains parame celui normaliser distances entre influence sultats apprentissage gaudin nicoloyannis sultats mesure norme extre mement sensible carts temps similaires leurs formes seraient rement autre temps obtiendraient faible similarite obtient sultats satisfaisants similaires leurs formes inter viennent instants diffe rents temps obtiendront forte valeur similarite fournit aussi sultats privile giant portions similaires quences ralement rieurs sultats donne bruite mesures sentent inconve nient triques force respec galite triangulaire cette caracte ristique fortement contre intuitive certains apprentissage conclusion pensons distance indique cadre prentissage supervise sultats satisfaisants malgre sensibilite bruit parame trage contraignant mesure norme simple rapide parame obtient souvent sultats catastrophiques disqualifient automatiquement principale force robustesse bruit sultats satisfaisants conside parame trage epsilon lourd apprentissage supervise allons utiliser mesure similarite notre algorithme apprentissage supervise moyenne mobile occurence utiliserons means adapte temporelles means adapte temporelles thode means adapte temporelles consiste classer classes appele clusters disjointes algorithme suivant choisir valeur initialiser centres clusters atoirement cessaire affecter chaque cluster centre proche estimer centres clusters supposant toutes affectations correctes aucune change cluster alors algorithme sinon retour proble gation temporelles cadre apprentissage forme algorithme means donne classiques temporelles proble imple mentation estimation centre chaque cluster apprentissage supervise temporelles exemples comparaisons leurs formes habituellement calculant moyenne euclidienne objets affecte cluster algorithme contre cadre apprentissage classification fonction leurs formes pensons cette gation euclidienne entra perte informations importante entendons forme diffe rentes variations relatives effectue cours temps cette notion difficile finir assez subjective pouvons anmoins gager caracte ristiques suivantes cette similarite relative espace valeurs absolues points ressent seules variations valeurs cours temps importance implique ralement normalisation avant apprentissage amplitudes chacune variations doivent avoir influence mesure premier exemple figure conside comme similaires niveau forme malgre leurs carts spatiaux leurs variations amplitudes cette similarite relative temps variations valeurs peuvent intervenir diffe rents instants servant similarite exemple figure contre ordonnancement temps diffe rentes variations important posse formes ordre diffe pourront conside comme similaires exemple figure gation euclidienne permet respect caracte ristiques prenons exemple suivantes essayons troisie moyenne euclidienne obtenons suivante figure sente sultat graphique cette gation constate observant figure gation euclidienne conserve formes pourtant similaires originelles posse chacune valeur point retrouve sommets interviennent endroits diffe rents temps gation euclidienne calages temporels gation euclidienne conduit exemple gaudin nicoloyannis gation euclidienne temporelles perte importante information semble dommageable cadre apprentissage formes cette raison avons nouvelle thode gation sache ventuels calages temporels entre elaboration nouvelle thode gation avons mesure associe chaque point plusieurs points autre valuer distance appellerons chacune associations posse aucun point commun autres appellera simple posse point commun plusieurs autres appellera alors ensemble groupe groupement issus distance allons noncer gation suivantes sultante gation apprentissage supervise temporelles algorithme algorithme ensemble simples groupement issus mesure similarite entre nombre posse simple alors groupement alors nombre points ensemble points chaque ensemble composent prend valeur moyenne points composent etablir nombre points algorithme calculer valeur points algorithme obtient alors gation gaudin nicoloyannis nouvelle gation associatifs calcule gation finies algorithme trouve sultat suivant figure sente sultat graphique cette gation constate observant figure obtenue notre nouvelle thode conserve formes chacune originelles cette ressemble gation aurait naturellement dessine humain notre thode gerer calages temporels manie semble approprie gation euclidienne effectuer estimation centres chaque cluster algorithme means adapte temporelles algorithme sultats obtenus tester cette nouvelle thode gation avons appelle gation dynamic warping aadtw avons imple mente trois thodes apprentissage supervise suivantes means mesure similarite norme gation euclidienne means mesure similarite gation euclidienne means mesure similarite aadtw effectuer tests avons utilise chantillons tempo relles chacun librement disposition eammon keogh keogh folias chaque posse soixante valeurs chaque chantillon constitue cifique atoires artificiellement cycliques croissantes gulie croissantes seuil croissantes gulie croissantes seuil alablement normalise lisse moyenne mobile lissage liore sensiblement sultats nombreux apprentissage forme apprentissage supervise temporelles donne norme euclide euclide aadtw gories2 gories3 gories4 erreur classification obtenus chacune trois variantes avons trois variantes means plusieurs tests diffe rents avons confronte sultats obtenus chacune entre elles chaque variante ficiait essais mesure chaque essai ficiant maximum rations parame trage temporelle delta variantes euclide aadtw taille sultats tests sente tableau premier montre abord riorite avoir mesure mesure eucli dienne cadre apprentissage supervise tests suivants mettent valeur lioration performances apporter variante aadtw variante euclide liorations statisti quement significatives value second celle troisie conclusions perspectives avons veloppe nouvelle thode gation temporelles mesure similarite dynamique warping cette thode associe algorithme means liorer cette thode apprentissage pervise adapte temporelles notre thode gation surtout efficace fusionner origine proches celles diffe rentes gation signi fication algorithme means initialisation atoire clusters conduit notre thode devoir dissemblables handicape processus apprentissage pensons pouvoir liorer notre thode solvant proble suivants effectuer apprentissage initialisation clusters notre thode gation fusionner pertinentes modifier notre thode gation lorsqu fusionner semblables interdisant effectuer carts temporels grands adapter notre thode gation mesure similarite derivated dynamic warping keogh pazzani version liore mesure dynamic warping choisit atoirement atoires cycliques croissantes seuil croissantes seuil choisit atoirement chacune gories croissantes gulie croissantes seuil gaudin nicoloyannis rences agrawal sawhney similarity search presence noise scaling translation series databases international conference large database bellman dynamic programming princeton university press jersey berndt donald clifford james using dynamic warping patterns series workshop berndt donald clifford james finding patterns series dynamic programming approach advances knowledge discovery mining gunopulos manilla finding similar series principles mining knowledge discovery databases trondheim keogh eamonn lonardi stefano finding surprising patterns series database linear space sigkdd international conference knowledge discovery mining edmonton alberta canada keogh eamonn pazzani michael enhanced representation series which allows accurate classification clustering relevance feedback international conference knowledge discovery mining keogh eamonn pazzani michael derivative dynamic warping first international conference mining chicago keogh folias series mining archive eamonn tsdma index riverside university fornia computer science engineering department jessica keogh eamonn lonardi stefano patel pranav finding motifs series proceedings workshop temporal mining sigkdd international conference knowledge discovery mining edmonton alberta canada jessica vlachos michail keogh eamonn gunopulos dimitrios iterative incremental clustering series proceedings conference extending database technology crete greece march ratanamahatana chotirat keogh eamonn making series sification accurate using learned constraints proceedings inter national conference mining buena vista florida april ratanamahatana chotirat keogh eamonn using relevance feedback multimedia databases proceedings international conferences visual information system francisco apprentissage supervise temporelles salvador learning states detecting anomalies series master thesis submitted college engineering florida institute technology encore publie vlachos michail kollios georges gunopulos dimitrios discovering similar multidimensional trajectories international conference engineering vlachos michail kollios georges gunopulos dimitrios robust similarity measures mobile object trajectories database expert systems applications international workshop mobility databases distributed systems provence france vlachos michail hadjieleftheriou marios gunopulos dimitrios keogh eamonn indexing multidimensional timeseries support multiple distance sures international knowledge discovery mining sigkdd washington yazdani bozkaya ozsoyoglu matching indexing sequences different lengths sixth international conference information knowledge management vegas nevada summary unsupervised clustering algorithm means algorithm series dataset questions which series distance measures choose which series merging method estimate cluster answer first question present existing distance measures explain called dynamic warping seems efficient others series unsupervised clustering second question ficult because merging method respect specific characteristics dynamic warping think sophisticated distance measure dynamic warping basic merging method euclidian merging disturb results clustering operation based series shape propose paper original series merging method which compatible dynamic warping which improves results obtained means algorithm keywords unsupervised learning clustering series means dynamic warping