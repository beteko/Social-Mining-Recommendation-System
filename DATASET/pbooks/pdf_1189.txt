Microsoft EGC2004_Khiops Robust Method Partitioning Values Categorical Attributes Boullé France Telecom Avenue Pierre Marzin 22300 Lannion France boulle francetelecom Résumé domaine apprentissage supervisé méthodes groupage modalités attribut symbolique permettent construire nouvel attribut synthétique conservant maximum valeur informationnelle attribut initial diminuant nombre modalités proposons généralisation algorithme discrétisation Khiops1 problème groupage modalités algorithme proposé permet contrôler priori risque apprentissage améliorer significativement robustesse groupages produits Cette caractéristique robustesse obtenue étudiant statistique variations critère regroupements lignes tableau contingence modélisant comportement statistique algorithme Khiops expérimentations intensives permis valider cette approche montré méthode groupage Khiops aboutit groupages performants terme qualité prédictive faible nombre groupes Introduction While discretization problem studied extensively grouping problem explored deeply literature However mining datasets there cases where grouping values categorical attributes mandatory preprocessing grouping problem consists partitioning values categorical attribute finite number groups example decision trees exploit grouping method handle categorical attributes order increase number instances Zighed Rakotomalala Neural based numerical attributes often binary encoding preprocess categorical attributes categories numerous encoding scheme might replaced grouping method problem arises other classification algorithms bayesian networks linear regression logistic regression Moreover grouping general purpose method intrinsically useful preparation mining process grouping methods clustered according search strategy partition grouping criterion evaluate partitions simplest algorithm tries bipartition category against others interesting approach consists searching bipartition categories Sequential Forward Selection method derived Cestnik evaluated Berckman French patents 07006 16733 Robust Method Partitioning Values Categorical Attributes greedy algorithm initializes group category against others iteratively categories first group class attribute values Breiman proposed optimal method group categories groups criterion algorithm first sorts categories according probability first class value searches split sorted algorithm complexity where number categories Based ideas presented Lechevallier Fulton result probably extended optimal partition categories groups class values dynamic programming algorithm complexity general class values there algorithm optimal grouping groups apart exhaustive search However proposed approach based means allows finding locally optimal partition categories groups Decision algorithms often manage grouping problem greedy heuristic based bottom classification categories algorithm starts single category groups searches merge between groups process reiterated until further merge improve grouping criterion CHAID algorithm greedy approach criterion close ChiMerge Kerber merges searched minimizing confidence level square criterion applied locally categories merged statistically similar algorithm Quinlan information criterion evaluate categorical attributes without grouping criterion tends favor attributes numerous categories Quinlan proposed exploit ratio criterion dividing information entropy categories square criterion applied globally whole categories normalized version square value Cramer Tschuprow Ritschard order compare different partitions Khiops grouping method straightforward generalization Khiops discretization method Boullé 2003a Instead merging adjacent numerical values order build intervals grouping method merges categorical values groups values cases search algorithm bottom greedy heuristic optimizes square criterion applied whole intervals groups stopping based confidence level computed square statistics method automatically stops merging process confidence level related independence between partitioned attribute class attribute decrease anymore groups resulting grouping method provides elementary univariate classifier which predicts distribution class values learned group grouping method considered inductive algorithm therefore subject overfitting apply methodology similar developed Khiops discretization method order bring control overfitting principle analyze behavior algorithm during grouping explanatory attribute independent class attribute study statistics variations square values during merge categories propose model maximum these variations complete grouping process algorithm modified order force merge whose variation square value below maximum variation predicted statistical modeling change algorithm yields interesting probabilistic guarantee independent attribute grouped within single terminal group attribute whose Boullé grouping consists least groups truly contains predictive information class attribute experimentally confirmed remainder document organized follows Section briefly introduces initial Khiops grouping algorithm Section presents statistical modeling algorithm tuning prevent overfitting Section proceeds extensive experimental evaluation Khiops Grouping Method section recall principles square present Khiops grouping algorithm whose detailed description analysis found Boullé 2003b square Principles Notations consider explanatory attribute class attribute determine whether independent First instances summarized contingency table where instances counted value explanatory class attributes square value computed contingency table based table notations Observed frequency explanatory value Total class value Total observed frequency explanatory value Total observed frequency class value Total observed frequency Number explanatory attribute values Number class values Total Contingency table compute square value stand expected frequency explanatory class attributes independent square value measure whole contingency table difference between observed frequencies expected frequencies interpreted distance hypothesis independence between attributes Within hypothesis independence square value subject square statistics degrees freedom basis statistical which allows reject hypothesis independence higher square value smaller confidence level Initial Algorithm square value depends local observed frequencies individual global observed frequencies whole contingency table Robust Method Partitioning Values Categorical Attributes candidate criterion grouping method square statistics parameterized number explanatory values related degrees freedom order compare groupings different group numbers confidence level instead square value principle Khiops algorithm minimize confidence level between grouped explanatory attribute class attribute means square statistics square value reliable hypothesis independence expected frequency contingency table falls below minimum value algorithm copes constraint preprocessing initial category fulfill minimum frequency constraint unconditionally merged special group Khiops method based greedy bottom algorithm starts initial categories searches merge between categories algorithm reiterated until further merge decrease confidence level computational complexity algorithm reduced optimizations Boullé 2003b There differences between initial Khiops algorithm similar CHAID algorithm First square criterion applied globally whole partition Khiops algorithm whereas applied locally adjacent groups CHAID algorithm Second Khiops algorithm stops merging process confidence level increases after candidate merge whereas CHAID algorithm stops confidence level beyond threshold Statistical Analysis Algorithm Khiops algorithm chooses merge among possible merges categories iterates process until stopping explanatory attribute class attribute independent resulting groups should composed single group meaning there predictive information explanatory attribute following study statistical behavior initial Khiops algorithm independent attributes square value subject square statistics known expectation variance study DeltaChi2 variation square value after merge categories independent attributes During grouping process large number merges evaluated Khiops algorithm chooses merge maximizes square value merge minimizes DeltaChi2 value since square value before merge fixed stopping DeltaChi2 value large However independent attributes merging process should continue until grouping algorithm reaches single terminal group largest DeltaChi2 value encountered during algorithm merging decision steps accepted estimate MaxDeltaChi2 value independent attributes modify algorithm order force merges bound reached Statistics MaxDeltaChi2 Values Khiops Algorithm focus contingency table frequencies probabilities class values Boullé probabilities class values whole contingency table square value decrease merged define DeltaChi2 value variation square value during merge DeltaChi proved explanatory attribute independent class attribute class values DeltaChi2 value resulting merge frequencies asymptotically distributed square statistics degrees freedom Boullé 2003b MaxDeltaChi2 value equal maximum DeltaChi2 values encountered during complete grouping process downward single terminal group grouped attribute independent class attribute discretization process where merges constrained adjacent contingency table proposed Boullé 2003a analytic formula approximate statistics MaxDeltaChi2 grouping process approximate statistics MaxDeltaChi2 analytically However showed Boullé 2003b statistics MaxDeltaChi2 depends parameters number initial categories number class values precisely following propositions conjectures checked through extensive experiments synthetic statistics MaxDeltaChi2 independent sample statistics MaxDeltaChi2 independent distribution categories statistics MaxDeltaChi2 independent distribution class example first conjecture evaluated random datasets equidistributed initial categories equidistributed classes collected MaxDeltaChi2 values resulting complete grouping process randomly generated datasets experiment repeated large number sample sizes ranging 200000 instances showed repartition functions MaxDeltaChi2 values independent sample experiments performed check other conjectures proved following propositions cases where there categories classes Proposition categories classes statistics MaxDeltaChi2 value square statistics degrees freedom Proposition equidistributed categories equidistributed classes MaxDeltaChi2 value asymptotically equal general statistics MaxDeltaChi2 value could modeled mathematical expression Khiops discretization method choose compute experimentally standard deviation MaxDeltaChi2 large number pairs parameters analysis results reveals linear behavior Robust Method Partitioning Values Categorical Attributes respect parameters which consistent propositions observation allows value table approximate standard deviation MaxDeltaChi2 values linear interpolation between computed values Finally assumption confirmed experimental evaluation repartition function MaxDeltaChi2 values approximated normal standard deviation details simulation given Boullé 2003b conclude MaxDeltaChi2 value Khiops grouping algorithm calculated owing linear interpolation standard deviation found computed value table given numbers categories class values Using inverse normal MaxDeltaChi2 value determined greater observed DeltaChi2 values probability instance Robust Khiops Grouping Algorithm Algorithm Robust Khiops Initialization explanatory attribute values Create elementary group value Create special group handle initial categories fulfill minimum frequency constraint necessary merge special group least frequent remaining category Compute MaxDeltaChi2 value related number initial groups class values Optimization grouping repeat following steps Evaluate possible merges between pairs groups Search merge Merge continue following conditions relevant confidence level grouping decreases after merge DeltaChi2 value merge below MaxDeltaChi2 value independent attributes grouping should result single terminal group given probability statistical modeling Khiops algorithms provides theoretical value MaxDeltaChi2 greater DeltaChi2 values merges completed during grouping process probability initial Khiops grouping algorithm modified order force merges whose DeltaChi2 value smaller MaxDeltaChi2 ensures expected behavior algorithm probability attributes unknown dependency relationship enhancement algorithm guarantees grouped attribute consists least groups explanatory attribute truly holds information concerning class attribute probability higher suggest order ensure reliable grouping results impact initial Khiops algorithm restricted evaluation stopping retains supra linear computational complexity algorithm Boullé Experiments Dataset Continuous Nominal Class Majority Attributes Attributes Values Accuracy Adult 48842 Australian Breast Heart HorseColic Ionosphere Mushroom TicTacToe Vehicle Waveform Datasets experimental study compare Khiops grouping method other supervised grouping algorithms criterions predictive performance number groups order evaluate intrinsic performance grouping methods eliminate choice specific induction algorithm protocol similar Zighed Rakotomalala where grouping method considered elementary inductive method which predicts distribution class values learned groups choose accuracy criterion because focuses majority class value cannot differentiate correct predictions probability correct predictions probability slightly greater Furthermore applications especially marketing field scoring instances evaluate probability class value evaluate predictive quality groupings Kullback Leibler divergence Kullback applied compare distribution class values estimated learning based learned groups distribution class values observed based initial values tested methods given category probability class value estimated learning group containing category probability class value observed using category Kullback Leibler divergence between estimated distribution observed distribution global evaluation predictive quality computed Kullback Leibler divergence order smooth empirical distributions probabilities Laplace estimator other approaches defining goodness measures example Ritschard Zighed Robust Method Partitioning Values Categorical Attributes grouping problem criteria problem tries compromise between predictive quality number groups optimal classifier Bayes classifier univariate classifier based single categorical attribute optimal grouping nothing experiments collect predictive quality results using Kullback Leibler divergence number groups gathered datasets Irvine repository Blake dataset least tenths instances class value categorical attributes values order increase number categorical attributes candidate grouping continuous attributes discretized preprocessing equal width unsupervised discretization Table describes datasets column corresponds accuracy majority class grouping methods studied comparison Khiops method described paper Initial Khiops initial version method described section CHAID grouping method CHAID method Tschuprow grouping method described example Ritschard Ratio grouping method method Quinlan these methods based greedy bottom algorithm iteratively merges categories groups automatically determines number groups final partition categories Ratio method method based entropy other methods square based criterions initial Khiops method applies square criterion whole contingency table evaluates partition related confidence level robust Khiops method enhances initial Khiops algorithm providing guarantees against overfitting Tschuprow method based global evaluation contingency table Tschuprow normalization square value instead confidence level evaluate partitions CHAID method applies square criterion locally contingency table CHAID method significance level square threshold Bonferroni correction applied implemented these alternative grouping approaches order eliminate variance resulting different cross validation splits groupings performed attributes datasets using stratified tenfold cross validation order determine whether performances significantly different between Khiops method alternative methods statistics difference results computed Under hypothesis value Student distribution degrees freedom confidence level tailed performed reject hypothesis Quality Groupings whole result tables large printed paper predictive quality results summarized table which reports dataset Kullback Leibler divergences number significant Khiops losses method comparison results normalized using Kullback Leibler divergence evaluated grouping means geometric means order focus ratios performances between tested methods Boullé results significant differences between methods which allow tested methods first cluster method Khiops grouping method obtains results followed initial Khiops grouping method CHAID method Khiops method significantly better results CHAID method grouped attributes significantly worse results attributes second cluster methods Tchuprow Ratio methods clearly outperformed leading three methods example Khiops method surpasses Ratio method attributes beaten attributes Dataset Khiops Khiops CHAID Tschuprow Ratio Adult Australian Breast Heart HorseColic Ionosphere Mushroom TicTacToe Vehicle Waveform Synthesis Means predictive quality groupings number significant losses dataset Khiops method compared alternative methods summarize predictive quality criterion suggests following ranking tested methods Khiops Initial Khiops CHAID Tschuprow Ratio Grouping group number results summarized table differences significant between tested methods Tschuprow Ratio methods produce smallest groupings average expense predictive quality Among quality grouping methods Khiops method clear winner group number criterion followed initial Khiops method CHAID method groupings produced Khiops method always smaller these produced CHAID method differences significant attributes Although Tschuprow Ratio methods obtain smaller groupings average results contrasted among datasets almost fourth attributes Khiops method significantly smaller groupings Ratio method interesting analyze deeply results waveform dataset where about attributes noise attributes inspection groupings reveals Robust Method Partitioning Values Categorical Attributes robust Khiops grouping method method correctly identifies noise attributes groupings reduced group Dataset Khiops Khiops CHAID Tschuprow Ratio Adult Australian Breast Heart HorseColic Ionosphere Mushroom TicTacToe Vehicle Waveform Synthesis Means groupings number significant losses dataset Khiops method compared alternative methods summarize group number criterion suggests following ranking tested methods Tschuprow Ratio Khiops Initial Khiops CHAID criteria Analysis Results order better understand relations between predictive quality groupings figure global means results criteria group number coordinate predictive quality coordinate comparison purposes report results obtained three alternative simple grouping methods unsupervised bipartition categories group containing frequent category Single Value bipartition categories category against others selected using square criterion final merge still possible Exhaustive CHAID bipartition categories obtained CHAID algorithm forcing merges until partition contains groups three bipartition grouping methods ranked expected predictive quality criterion Tschuprow Ratio methods allowed build partition groups obtain better results predictive quality Exhaustive CHAID method cluster efficient methods Khiops Initial Khiops CHAID clearly takes benefit multi group partitions Among these leading methods Khiops method dominates others methods criteria Lastly considering computational complexity algorithms optimized Khiops algorithm Boullé whereas other methods However difference runtime minor cases number categorical values small Group Number Khiops Initial Khiops CHAID Single Value Exhaustive CHAID Tschuprow Ratio criteria evaluation grouping methods group number predictive quality criteria Conclusion principle Khiops grouping method minimize confidence level related independence between grouped attribute class attribute During bottom process algorithm numerous merges between categories performed produce variations square value contingency table Owing statistical modeling these variations explanatory attribute independent class attribute enhanced initial Khiops grouping algorithm order guarantee groupings independent attributes reduced single group attested resistance overfitting interesting alternative classical cross validation approach Extensive comparative experiments Khiops method outperforms other tested grouping methods allows drastically reduce number values categorical attributes preprocessing mining while keeping their monothetic predictive performance Références Berckman Berckman Value grouping binary decision trees Technical Report Computer Science Department University Massachusetts Blake Blake Repository machine learning databases mlearn MLRepository Irvine University California Department Information Computer Science Boullé 2003a Boullé Khiops Discretization Method Continuous Attributes Guaranteed Resistance Noise Proceedings Third International Conference Machine Learning Mining Pattern Recognition Robust Method Partitioning Values Categorical Attributes Boullé 2003b Boullé Groupage robuste valeurs attribut symbolique méthode Khiops technique France Telecom Breiman Breiman Friedman Olshen Stone Classification Regression Trees California Wadsworth International Cestnik Cestnik Kononenko Bratko ASSISTANT knowledge elicitation sophisticated users Bratko Lavrac Progress Machine Learning Wilmslow Sigma Press Optimal Partitioning Classification Regression Trees Transactions Pattern Analysis Machine Intelligence Fulton Fulton Kasif Salzberg Efficient algorithms finding multi splits decision trees Proceeding Thirteenth International Joint Conference Artificial Intelligence Francisco Morgan Kaufmann exploratory technique investigating large quantities categorical Applied Statistics Kerber Kerber Chimerge discretization numeric attributes Proceedings International Conference Artificial Intelligence Kullback Kullback Information Theory Statistics Wiley republished Dover Lechevallier Lechevallier Recherche partition optimale contrainte ordre total Technical report INRIA Preparation Mining Morgan Kaufmann Quinlan Quinlan Induction decision trees Machine Learning Quinlan Quinlan Programs Machine Learning Morgan Kaufmann Ritschard Ritschard Zighed Nicoloyannis Maximisation association regroupement lignes colonnes tableau croisé Ritschard Zighed Ritschard Zighed Modélisation tables contingence arbre induction Extraction Gestion Connaissances Zighed Rakotomalala Zighed Rakotomalala Graphes induction Hermes Science Publications Summary supervised machine learning partitioning values called grouping categorical attribute constructing synthetic attribute which keeps information initial attribute reduces number values paper propose grouping method Khiops based generalization Khiops discretization algorithm grouping method provides guarantees against overfitting leads robust groupings property derives statistical modeling Khiops method which allows algorithm Extensive experiments demonstrate validity approach Khiops grouping method builds quality groupings terms predictive quality small number groups