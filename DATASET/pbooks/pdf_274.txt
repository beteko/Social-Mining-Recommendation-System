Réduction complexité spatiale temporelle Compact Prediction prédiction séquences Gueniche Philippe Fournier Viger Département informatique Université Moncton Antonine Maillet Moncton gueniche gmail philippe fournier viger umoncton Résumé prédiction séquences symboles tâche ayant tiples applications Plusieurs modèles prédiction proposés order markov Récemment montré nouveau modèle nommé Compact Prediction utilisant structure arbre algorithme prédiction complexe offre prédictions exactes plusieurs approches littérature Néanmoins limite importante complexité temporelle spatiale élevée article lions problème proposant trois stratégies réduire taille temps prédiction résultats expérimentaux données réels montrent modèle résultant nommé jusqu compact rapide conservant exactitude élevée rapport order Markov Introduction problème prédiction séquences problème important fouille défini façon suivante alphabet contenant semble éléments symboles séquence suite éléments totalement ordonnée modèle prédiction modèle traîné ensemble séquences entraînement entraîné modèle utilisé effectuer prédictions prédiction consiste prédire prochain élément séquence utilisant modèle prédiction séquences applications importantes multitude domaines préchargement pages Deshpande Karypis Padmanabhan Mogul recommandation duits consommation prévision météorologique prédiction tendances marché boursier grand nombre modèles prédictions proposés prédiction quences modèle connus Prediction Partial Matching Cleary Witten modèle propriété Markov engendré multitude proches dérivées telles Dependancy Graph Padmanabhan Mogul order Markov Pitkow Pirolli Transition Directed Acyclic Graph Laird propositions faites réduire complexité temporelle Réduction complexité spatiale temporelle Compact Prediction spatiale modèles Begleiter exactitude leurs prédictions amélioration autre certain nombre algorithmes compression adaptés prédiction séquences Lempel Active Gopalrat algorithmes apprentissage machine comme réseaux neurones découverte règles association séquentielles employés faire prédiction séquences Fournier Viger Giles Néanmoins modèles souffrent limites importantes Premièrement plupart entre partent pothèse Markovienne événement dépend prédécesseur nombreuses applications exactitude prédictions Deuxièmement modèles construits perte information rapport séquences entraî nement utilisent toute information disponible séquences entraîne effectuer prédictions pallier limites modèle nommé Compact Prediction Gueniche récemment proposé utilise structure arbre compresser quences entraînement perte perte minime information emploie algorithme prédiction conçu tenir compte bruit plusieurs événements rieurs prédiction plutôt seulement dernier montré modèle obtenir prédictions jusqu exactes order markov données provenant divers domaines constitue important Néanmoins limite complexité temporelle spatiale élevée article lions problèmes proposant trois stratégies réduire taille temps prédiction présentons comparaison expérimentale davantage modèles prédiction littérature order Markov résultats expérimentaux données réels montrent modèle résultant nommé jusqu compact jusqu rapide conserve exactitude élevée rapport autres approches littérature reste article organisé façon suivante section décrit brièvement modèle sections proposent respectivement nouvelles stratégies réduire taille modèle temps prédiction section présente évaluation expérimentale plusieurs données principaux modèles prédictions littérature Finalement section dédiée conclusion travaux futurs Compact Prediction Compact Prediction modèle prédiction récemment proposé niche principales caractéristiques distinctives stocke forme compressée ensemble séquences entraînement perte perte minime information utilise mesure similarité identifier séquences laires séquence prédire faire prédiction Cette mesure tolérante bruit permet prédire prochains éléments séquences séquences entraînement alors autres approches strictes telles order markov peuvent faire prédiction modèle défini processus processus entraînement processus prédiction Gueniche processus entraînement processus entraînement génère trois structures distinctes partir séquences traînement Arbre Prédiction Dictionnaire Séquences Index Inversé Pendant entraînement séquences considérées après autres construire incrémentalement trois structures titre exemple figure illustre création structures insertion successive séquences phabet utilisé Index inversé Arbre prédiction Dictionnaire séquences Insertion Index inversé Arbre prédiction Dictionnaire séquences Insertion Index inversé Arbre prédiction Dictionnaire séquences Insertion Insertion Insertion Index inversé Arbre prédiction Dictionnaire séquences Index inversé Arbre prédiction Dictionnaire séquences Construction structures Arbre Prédiction forme arbre préfixe alias Chacun noeuds arbre représente élément chacune séquences entraînement représentée chemin partant racine arbre terminant noeud interne arbre feuille construction arbre basse complexité Insérer séquence éléments demande parcourir créer noeuds construction complète arbre nombre séquences insérer comme arbre préfixe arbre représentation compacte séquences entraînement séquences partageant préfixe commun partagent chemin arbre exemple figure séquences partagent chemin correspondant préfixe spatial offert cette compression pratique dépendant densité Réduction complexité spatiale temporelle Compact Prediction similarité séquences données utilisé arbre offrir réduction spatiale importante allant jusqu Gueniche Dictionnaire Séquences structure permet extraire chacune quences entraînement arbre prédiction construction modèle identifiant unique assigné chaque séquence première séquence insérée dénoté incrémenté chaque séquence subséquente dictionnaire séquences associe chaque identifiant séquence pointeur noeud arbre noeud représente dernier élément séquence arbre Grâce cette structure possible parcourir chaque séquence entraînement arbre prédiction dernier premier élément Index Inversé permet identifier rapidement quelles séquences apparaît semble éléments séquence prédire index inversé contient vecteur chaque élément alphabet présent séquences entraînement vecteur prend valeur élément apparaît séquence sinon prend valeur exemple figure vecteur élément après insertion séquences 10110 apparaît séquences index inversé utilisé déterminer rapidement séquences entraînement contenant ensemble éléments séquence prédire réalisé faisant intersection vecteurs éléments exemple déterminer ensemble séquences contenant éléments réalisé opération 11101 10110 donnant résultat 10000 trement Grâce index inversé cette tâche rapide nombre éléments ensemble processus prédiction processus prédiction utilise trois structures décrites précédemment séquence éléments nombre entier représentant nombre éléments considérer faire prédiction suffixe taille dénoté défini comme étant prédiction prochain élément effectuée façon suivante identifie abord séquences similaires contiennent derniers éléments importe ordre positions chaque séquence similaire considère conséquent consé quent séquence séquence débutant après dernier élément commun jusqu Chaque élément conséquents ensuite stocké structure nommé Table Compte nombre occurrences nombre estimation probabilité élément ayant grand nombre currences élément prédit mesure similarité utilisée déterminer séquences similaires nature stricte relâchée dynamiquement processus prédiction raisons Premièrement mesure similarité stricte séquence prédire similaire aucune séquence entraînement aucune prédiction possible Deuxièmement mesure similarité stricte permet considérer séquence partiellement similaire autre plications réelles souvent éléments présents séquences bruit relâcher mesure similarité suppose plusieurs éléments présents suffixe séquence prédire bruit peuvent ignorés calcul similarité calcul similarité suffixe niveau chaque Gueniche niveau toutes séquences taille générées Chacune séquence utilisée trouver séquences similaires ensemble séquences entraînement mettre relâchement mesure similarité poursuit séquence prédire niveau autre nombre minimum Stratégies compression arbre prédiction offre prédictions exactes principaux modèles prédiction littérature selon étude antérieure Gueniche limite importante complexité spatiale montré taille structures inférieure order Markov demeure nettement supérieures autres modèles comme arbre prédiction étant structure imposante proposons après stratégies réduire taille Stratégie Compressions Chaînes Fréquentes Certaines répétitions peuvent identifiées séquences entraînement Dépendamment données titions peuvent nombreuses fréquentes compression chaînes fréquentes consiste identifier chaînes fréquentes éléments apparaissant séquences entraîne remplacer chaînes fréquentes éléments individuels séquence séquence chaine dénoté seulement ensemble séquences entraînement chaîne fréquente minsup seuil minsup utilisateur compression chaînes fréquentes effectuée pendant phase entraînement trois étapes identifier chaînes fréquentes ensemble séquences traînement créer nouvel élément alphabet représenter chaque chaîne fréquente remplacer chaînes fréquentes élément correspondant construction arbre prédiction identification séquences fréquentes ensemble séquences problème populaire fouille données lequel grand nombre algorithmes proposés cette tâche avons adapté algorithmes performants nommé PrefixS découvrir séquences fréquentes éléments consé cutifs chaînes avons ajouté contrainte chaînes fréquentes doivent respecter contraintes longueur minimale minSize maximale maxSize paramètres chaînes fréquentes identifiées stockées nouvelle structure nommée Dictionnaire chaînes fréquentes Cette structure associe nouvel élément présent alphabet séquences entraînement chaque chaîne fréquente permet rapidement convertir chaîne élément correspondant versa insertion séquences entraînement arbre prédiction utilisé remplacer chaque chaîne élément correspondant titre exemple illustration figure affiche compression arbre diction illustration figure stratégie chaîne fréquence remplacée nouveau symbole réduisant nombre noeuds arbre diction Réduction complexité spatiale temporelle Compact Prediction stratégie compression séquences effet seulement arbre diction nombre noeuds hauteur tendent diminuer grandement stratégie transparente processus prédiction effet extraction séquences similaires branches arbre prédiction sélectionnées décompressées volée Application stratégie Application stratégies Index inversé Arbre prédiction Dictionnaire séquences Index inversé Arbre prédiction Dictionnaire séquences Application stratégies compression arbre Stratégie Compressions Branches Simples compression branches simples stratégie compression intuitive efficiente réduire taille arbre prédiction branche simple branche seule feuille Chaque noeud branche simple entre noeud stratégie consiste remplacer chaque branche simple noeud représentant chemin feuille début exemple illustration figure illustre arbre prédiction exemple après application stratégies stratégie respectivement remplacé branches simples noeuds uniques identification remplacement branches simples faits parcours arbre prédiction index inversé dictionnaire séquences étant influencés cette approche changement processus prédiction décompression dynamique branches simples lorsque nécessaire complexité remplacement nombre séquence recouvrement arbre dernier défini comme ratio noeuds partagent plusieurs séquences nombre total noeuds arbre Stratégie réduction temps prédiction Stratégie Prédiction réduction Bruit Amélioré expliqué cédemment prédire prochain élément séquence utilise suffixe taille dénoté derniers éléments ramètre propre chaque donnée prédit prochain élément parcourant séquences similaires suffixe recherche séquences similaires rapide Toutefois mécanisme réduction bruit prédictions décrit section Gueniche requiert considérer seulement prédiction aussi toutes séquences taille grands nombre séquences considérer aussi temps prédiction tâche prédiction certains éléments séquence prédire peuvent considérés comme bruit simple présence affecte façon négative résultat prédiction stratégie hypothèse bruit observé séquence constitué éléments ayant faible fréquence fréquence élément nombre séquences traînement contenant élément cette raison enlève seulement éléments faible fréquence pendant phase prédiction Puisque définition bruit restrictive celle moins grand nombre séquences considé Cette réduction impact positif tangible temps calculs présentés notre évaluation expérimentale section pseudo illustrant stratégie présenté après Algorithme algorithme prend paramètres préfixe prédire autres structures bruit nombre minimum faire faire prédiction bruit représente pourcentage éléments séquence doivent considérés comme bruit bruit indique séquence bruit alors bruit signifie éléments séquence pourrait bruit récursive nature considère nombre minimal séquences dérivées faire prédiction bruit abord retiré chaque séquence Lorsque nombre minimal atteint prédiction faite comme utilisant stratégie généralisation stratégie réduction bruit utilisée effet selon paramètres utilisés possible reproduire fonctionnement original trois contributions principales apportées imposition nombre minimal faire prédiction définition bruit fréquence élément réduction relative bruit rapport longueur séquence Algorithme algorithme prédiction input suffixe structures bruit output plusieurs éléments prédits ajouter while nombreMiseAjour minNombreMiseAJourTC nonVide suffixe prochain elementsBruit selectionnerElementsMoinsFrequents foreach elementBruit elementsBruit suffixeSansBruit copierSuffixeSansBruit suffixe elementBruit suffixeSansBruit length ajouter suffixeSansBruit mettreAJourCountTable countTable suffixeSansBruit nombreMiseAjour retourne faireUnePrediction countTable Réduction complexité spatiale temporelle Compact Prediction Évaluation expérimentale avons effectué série expériences comparer performance principaux modèles prédiction littérature order Markov implémenter avons obtenu modifié source proposé article original Gueniche permettre reproduction expériences source modèles données fournis adresse LE4uYO modèles implémentés expériences réalisées machine dotée processeur coeurs Intel génération mémoire modèles prédiction utilisés configurés empiriquement tenter donner valeurs optimales chacun leurs mètres paramètres respectivement fenêtre ordre finalement soucis espace hauteur maximale paramètres leurs valeurs elles aussi déterminées exploration expérimentale espace valeurs possibles valeurs accessible fichiers sources projet paramètres propres expérience limitent longueur minimale maximale séquences utilisées taille suffixe considérer séquence prédire quantité éléments prédire chacune séquences données ayant caractéristiques variées utilisés Table quences courtes longues séquences denses éparses petit grands alphabets divers types données données Kosarak MSNBC consistent séquences pages visitées utilisateurs scénario modèles diction appliqués prédire prochaine visitera chaque utilisateur données ensemble phrases exprimées langage signes transcrites partir vidéos Bible Bible données proviennent Bible livre religieux premier ensemble phrases découpées second ensemble phrases découpées caractères évaluation prédictions modèles prédiction succès échec abstention modèle effectuer prédiction mesures utili couverture nombre abstentions divisé nombre séquences prédire exactitude alias précision nombre succès divisé nombre séquences prédire Nombre deséquence Éléments uniques Longueur moyenne données Pages KOSARAK Pages Pages MSNBC Pages Langage BIBLE Phrases BIBLE Caractères données Gueniche Expérience comparaisons optimisations cette première expérience avons abord évalué améliorations spatiales présentées section terme compression temps calcul entraînement autres mesures performance telles temps prédiction couverture exactitude affectées compression arbre prédiction arbre prédiction noeuds avant pression noeuds après compression compression défini comme compris entre inclusivement valeur haute compression importante stratégies compression évaluées abord viduellement dénotées conjonction dénoté Toute compression permet obtenir spatial temporel figure présente cette relation chacune stratégies compression MSNBC Bible Bible Kosarak Temps entraînement Bible Bible Kosarak compression compression temps entraînement stratégies compression résultats présentés figure montrent compression arbre varie selon données offre compression moyen faible écart alors compression moyen écart beaucoup prononcé efficacité dépen dante données MSNBC données moins affecté stratégies compression faible cardinalité alphabet permet MSNBC naturellement compressé grâce recouvrement branches arbre prédiction effet MSNBC possède éléments uniques taille moyenne quences ressemble celle autres données taille arbre avant compression petite données stratégies compression effectives faible nombre séquences chacune longue moyenne éléments caractéristiques sorte arbre prédic faible recouvrement importante partie noeuds données candidat idéal stratégie offre compression figure présente également temps entraînement engendrés stratégies compression mesure utilisée facteur multiplicatif temps entraînement exemple facteur signifie phase entraînement longue données exception rapide intéressant observer temps combinaison stratégies compression simplement addition entraînement Réduction complexité spatiale temporelle Compact Prediction appliqués indépendamment pourtant utilisation réduit temps calcul grâce diminution nombre branches besoin compressées avons également évalué temps prédiction exactitude précision obtenue appliquant stratégie figure gauche illustre temps prédiction gains temporels importants plupart données notamment MSNBC temps entraînement jusqu moindres données Bible temps prédiction élevés obtenir exactitude comme montre figure droite effet exactitude prédictions positif données MSNBC Cette amélioration élève jusqu Bible montre stratégie effective réduire temps prédiction augmenter exactitude prédictions MSNBC Bible Bible Kosarak MSNBC Bible Bible Kosarak Gains temps prédiction exactitude ajout Expérience échelle avons également comparé complexité spatiale stratégies compression celle order Markov termes échelle rapport nombre séquences seuls données utilisés Kosarak cause grand nombre séquences respectivement accroissement nombre séquences cette expérience quadratique arrête séquences énormes temps calcul requis réaliser chaque expérience figure présente résultats compression baisser légèrement accroissement nombre quences phénomène causé recouvrement important branches arbre prédiction taille alphabet étant constante séquences utilisées branches unifient modèles croissance linéaire basés taille alphabet indirectement nombre séquences traînement autres modèles croissance beaucoup importante notamment Expérience Comparaison autres modèles prédiction expérience avons comparé exactitude prédictions celle évaluer contribution stratégie cette expérience effec tuons comparaison exactitude celle autres principaux modèles prédiction littérature order Markov mêmes données noter ajoutons cette comparaison modèles prédictions utilisés article original proposant Chaque modèle Gueniche Nombre séquences Mark1 Nombre séquences Kosarak échelle modèles prédiction prédiction entraîné testé validation croisée assurer faible variance inter expériences exactitude prédictions obtenues différents modèles présentée table résultats montre continue comme offrir exactitude généralement nettement supérieure autres modèles populaires littérature données MSNBC Bible Bible Kosarak modèles prédiction évalués leurs exactitude Conclusion article avons présenté trois stratégies réduire taille temps prédiction nommées Compression Chaînes Fréquences Compression Branches Simples Préduction réduction Bruit Améliorée résultats expérimentaux données réels montré modèle résultant nommé jusqu compact cette compression demeure lorsque nombre séquence augmente termes temps exécution montré jusqu rapide Finalement montré comme étant modèle offrant dictions généralement exactes comparaison principaux modèles littérature order Markov Comme travaux futurs adapterons prédiction séquences contexte infini séquences nature incrémentale pourrait adapté problème Réduction complexité spatiale temporelle Compact Prediction Références Begleiter yaniv prediction using variable order markov models Journal Artificial Intelligence Research Cleary Witten compression using adaptive coding partial string matching Communications Transactions Deshpande Karypis Selective markov models predicting cesses Transactions Internet Technology Fournier Viger Gueniche Tseng Using partially ordered sequential rules generate accurate sequence prediction Advanced Mining Applications Springer Gopalratnam Online sequential prediction incremental parsing active algorithm Intelligent Systems Gueniche Fournier Viger Tseng Compact prediction lossless model accurate sequence prediction Advanced Mining Applications Springer Laird Discrete sequence prediction applications Machine Padmanabhan Mogul Using predictive prefetching improve world latency SIGCOMM Computer Communication Review Mortazavi Pinto Dayal fixspan Mining sequential patterns efficiently prefix projected pattern growth International Conference Engineering Computer Society Pitkow Pirolli Mining longest repeating subsequence predict world surfing USENIX Internet Technologies Systems Giles Sequence learning recognition prediction sequential decision making Intelligent Systems Lempel Compression individual sequences variable coding Information Theory Transactions Summary Predicting symbol sequence symbols applications Compact Prediction recently proposed prediction model provide accurate predictions several state prediction models paper introduce strategies reduce prediction Experimental results seven datasets shows resulting model compact times faster remains overall accurate state predictions models order Markov Données Textuelles Séquentielles Réduction complexité temporelle spatiale Compact Prediction prédiction séquences Gueniche Philippe Fournier Viger