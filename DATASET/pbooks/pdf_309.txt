Clustering données relationnelles structuration télévisuels Vincent Claveau Patrick IRISA INRIA Rennes Campus Beaulieu 35042 Rennes vincent claveau irisa patrick inria Résumé approches existantes structurer automatiquement télévision reconstituer guide programme exact complet pervisées Elles requièrent grandes quantités données annotées manuelle aussi définir priori types émissions publicités bandes nonces programmes sponsors éviter contraintes posons classification supervisée nature multi relationnelle données proscrit utilisation techniques clustering habituelles reposant représentations forme attributs valeurs proposons validons expérimentalement technique clustering capable manipuler détournant programmation logique inductive fonctionner cadre supervisé Introduction nombreux services télévision requièrent segmentation étiquetage rects corpus thématiques issus archives demande ainsi dispo guide programme complet documentant aussi inter programmes précis image guide malheureusement rarement disponible auprès chaînes culer guide programme structuration automatique Plusieurs approches présentées littérature faire elles exploitent données indices audio vidéo Naturel Manson Ibrahim toutes reposent étape classification supervisée nécessitant connaissances priori requièrent annotation manuelle facilement utilisables pratique ailleurs utilisateur définir classes pertinentes article proposons réduire drastiquement intervention priori lisateur passant classification supervisée résiduel utilisateur serait alors étiqueter classes émergent ainsi données plusieurs classes pouvant tendu partager étiquette image célèbre MEANS techniques clustering reposent représentation simple données notion distance entre repré sentations également fournie utilisateur points cherchons éviter Depuis quelques années certains travaux tenté mettre profit pacités discrimantes techniques apprentissage supervisé cadre supervisé Clustering relationnel structuration principe commun déduire similarité partir classifications identiques problèmes apprentissage factices Horvath Claveau Ncibi Elles permettent avoir expliciter notion distance entre données reposent toujours représentation classique données forme attributs valeurs adaptée nature multi relationnelle données veine derniers proposons technique clustering capable manipuler données précisément détournons programmation logique inductive technique appren tissage supervisé expressivité permet représenter naturellement données fonctionner cadre supervisé Programmation logique inductive données relationnelles cadre supervisé supervisé usuel décrire données manipuler forme propositionnelle attribut valeur encore vectorielle objets doivent alors avoir nombre attributs attributs considérés dépendamment relations exploitées notre objets manipuler segments correspondant programmes inter programmes beaucoup publicités répétés plusieurs appelées après occurrences nombre occurrences entendu différent segment autre chaque occurrence décrite ensemble attributs Cette variabilité description forme vectorielle impossible certaines relations entre attributs peuvent particulière pertinentes comme entre chaînes diffusion dates différentes occurrences émission occurrences entourent Cette nature multi relationnelle Dzerosky Lavrac données importante prendre compte assurer pertinence clustering technique apprentissage supervisé permettant inférer règles rales décrivant concept partir exemples contre exemples concept ensemble informations externes appelé Background Knowledge Muggle Raedt présentation détaillée fondée logique prédicats données apprentissage décrites Prolog classifieur ensemble clauses cette expressivité permet décrire problèmes multi relationnels figure montre extrait description émission Prolog standard façon simple décrire relations entre différentes occur rences grâce prédicats binaires next_occ next_in_stream aussi données définitions prédicats pouvant utiles inférer règles extrait précé trouvent définitions prédicat prev_occ relation occurrences émissions diffusées après autre prédicat interval indique intervalle temps entre occurrences émissions alors inférer classifieur forme ensemble clauses expliquant impliquant couvrant exemples positifs rejetant possible négatifs trouver clauses composant précise quels prédicats définis peuvent utilisés comment peuvent combinés clauses langage hypothèse Claveau description occurrence has_occ broadcast12 b12_occ1 duration b12_occ1 date_time b12_occ1 friday channel b12_occ1 next_occ b12_occ1 b12_occ2 next_in_stream b12_occ1 b28_occ5 connaissances générales prev_occ next_occ interval Duration date_time date2epoch Epoch1 date_time date2epoch Epoch2 Duration Epoch1 Epoch2 Extrait descriptions exemples connaissances monde règles composant alors recherchées itérativement travers espace hypothèses règles compatibles Celles retenues celles maximisant score généralement défini fonction nombre exemples contre exemples couvre Voici exemple règle pouvant inférée broadcast has_occ duration next_occ next_in_stream next_in_stream has_occ has_occ Cette règle valeur intérêt représentation multi relationnelle couvre toutes émissions variable ayant moins occurrences suivent durée secondes elles mêmes suivies occurrences émission Cette règle couvrirait exemple émissions sponsoring supervisé supervisé Principes principale notre approche déduire distance similarité partir classifications répétées émissions tâches apprentissage aléatoire émissions couvertes souvent mêmes clauses inférées seront supposées proches algorithme donne aperçu global démarche Comme bagging Breiman classification répétée grand nombre faisant varier différents ramètres apprentissage exemples étape divise données exemples positifs train ensemble utilisé ensuite contre exemples étape langage hypothèse étape chaque itération compte paires émissions couvertes mêmes clauses parle couvertures matrice tenant compte couvertures règle discriminante rapporte dernière étape relève simplement emploi technique clustering opérant cette matrice couvertures considérées comme mesures similarité expérimen tations présentées section suivante utilisons Markov Clustering Dongen avantage rapport MEANS MEDOIDS nécessiter fixer priori nombre clusters attendus éviter problème initialisation clusters Clustering relationnel structuration Algorithme Clustering input Etotal émissions étiquetées grand nombre itérations train Diviser Etotal Générer exemples négatifs train Générer aléatoirement langage hypothèse Inférence train train clause parmi paire telle return Clustering stratégie cette approche varier biais apprentissage chaque itération premier biais ensemble exemples utilisés périences utilisons dixième exemples positifs tirés aléatoirement chaque ration restants appliquées règles inférées trouver couvertures génération exemples négatifs point important algorithme notre inventer émissions leurs différentes occurrences leurs ractéristiques exemples doivent suffisamment réalistes produire tâches prentissage difficulté assure pertinence règles trouvées couvertures produites générer contre exemples copions parties descriptions sions piochées aléatoirement format règles autorisées langage hypothèse aussi différent chaque pratique modes dicats possibles décrits initialisation algorithme ensemble tiers ensuite choisi aléatoirement chaque itération apprentissages tâches super visées factices conférent variété propriétés importantes similarité obtenue Celle mélange ainsi naturellement descriptions complexes opère construction sélection caractéristiques prend compte redondances descripteurs ignore mauvaise qualité robuste données aberrantes Validation expérimentale Évaluer tâche découverte connaissances comme clustering toujours délicat puisqu suppose existence vérité terrain souhaite passer données utilisons expériences celles Naturel enregistre jours consécutifs chaîne France segmenté émissions différentes répétitions occurrences émission identifiées automatiquement consolidées manuellement Naturel étiquetées selon classes programme série publicité sponsoring habillage chaîne bande annonce classes émissions constituent notre vérité terrain clustering référence figure répartition mesures évaluation celles utilisées habituellement compa raison clustering celui produit notre approche celui référence Adjusted Purity Normalized mutual information Adjusted Index Claveau Répartition classes vérité terrain Résultats méthodes clustering présentons figure résultats clustering relationnel après itérations ainsi plusieurs baselines fondés représentation classique données forme attribut valeur attributs utilisés décrire émission suivants nombre occurrences durée moyenne intervalle minimal entre occurrences intervalle maximal intervalle moyen nombre maximal occurrence plage durée entre première dernière occurrence présence toutes occurrences journée nombre moyen émissions uniques apparaissant avant après occurrences algorithmes baseline MEANS CobWeb implémentés chacun rapportons résultats meilleures configurations terme indiquons aussi résultats notre système cette description attribut valeur prédicats relationnels Quelle mesure luation notre technique clustering offre meilleurs résultats autres représentation apparaît clairement clusters obtenus néanmoins différents nombre contenu classes attendues vérité terrain analyse différences montre classe bande annonce difficile capturer distribuée plusieurs clusters autres problématiques causées émissions bornes notre lesquelles trois semaines suffisantes identifier schémas récurrences examen règles inférées chaque itération permet aussi validation indirecte notre approche puisqu elles exploitent aspect multi relationnel données règle suivante couvre ainsi émissions diffusées intervalle régulier broadcast has_occ next_occ next_occ interval interval Conclusions méthode clustering avons proposé permet tirer mieux profit nature particulières données offre ainsi moyen obtenir notion distance espaces description riches métriques Clustering relationnel structuration définition explicite distance autres biais induits utilisateur présents exemple description données définition modes possibles biais représentent connaissance utilisateur permettent définir problème apport connaissances terme description émissions autant informations permettant utilisateur canaliser tâche découverte objet étude Références Breiman Bagging predictors Machine Learning Claveau Ncibi Découverte connaissances séquences supervisés Actes conférence Dzerosky Lavrac Relational Mining Berlin Springer Verlag Frank Holmes Pfahringer Reutemann Witten mining software update SIGKDD Explorations Ibrahim stream structuring Signal Processing clustering years beyond means Pattern Recognition Manson Berrani Automatic broadcast structuring International Journal Digital Multimedia Broadcasting Muggleton Raedt Inductive Logic Programming Theory Methods Journal Logic Programming Naturel Detecting repeats video structuring Multimedia Tools Applications automatic television stream structuring system television archives holders Multimedia Systems Horvath Unsupervised learning random forest predictors Journal Computational Graphical Statistics Dongen Graph Clustering Simulation Thèse doctorat Université Utrecht Summary automatic structuring stream restore complete accurate guide approaches supervised require large quantities manually notated priori different types broadcasts commercials trail programs sponsors avoid these constraints propose replace unsupervised classification multi relational nature prohibits usual clustering techniques based attribute value representations propose cluster technique capable handling divert Inductive Logic Programming unsupervised context validity approach through different experiments