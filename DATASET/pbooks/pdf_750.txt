actes_non_num 351rotes Détection séquences atypiques basée modèle Markov ordre variable Cécile Laurent Maguelonne Teisseire Montpellier Eugène Bataillon Montpellier France cecile lowkam montp2 LIRMM Montpellier Montpellier France laurent teisseire lirmm Résumé Récemment nombre volume bases données séquen tielles biologiques augmenté manière considérable contexte dentification anomalies essentielle plupart approches extraire fondent apprentissage contenant outlier nombreuses applications experts disposent telle méthodes existantes demeurent exigeantes mémoire souvent impossibles utiliser présentons article nouvelle approche basée modèle Markov ordre variable mesure similarité entre objets séquentiels ajoutons méthodes istantes critère élagage contrôler taille espace recherche qualité ainsi inégalité concentration précise mesure similarité conduisant meilleure détection outliers démontrons expérimentalement validité notre approche Introduction outlier défini Hawkins comme observation écarte telle autres susceptible avoir générée mécanisme différent dernières années détection outliers étudiée types données divers effet applications associées découverte anomalies nombreuses domaines aussi variés détection fraudes analyse séquences biologiques Parmi elles bases protéines objet nombreuses études meilleure compréhension phénomènes biologiques exemple extraction motifs Ferreira Azevedo perspective identifier anomalies alors compléter propositions actuelles effectuer cette recherche demeure problématique puisque outliers rares définition doivent confondus bruit inhérent Néanmoins certaines propositions existent pouvons citer celles fondées emple tests discordance hypothèse distribution probabilités observations donnée cadre univarié multivarié Barnett Lewis autres Détection séquences atypiques basent également notion distance détecter anomalies données multidimensionnelles Knorr Toutefois méthodes adaptées certaines bases biologiques partic ulières structure séquentielle taille importante enjeu alors sélectionner modèle approprié approche efficace découverte anomalies telles bases proposée fonde modèle arbre suffixes introduction mesure similarité cette méthode exigeante moire nécessite séquences typiques construire modèle proposons article étendre cette approche pallier inconvénients particulier utilisons critère information sélectionne modèle adéquat parcimonieux concerne mesure similarité obtenons bornes précises desquelles séquences considérées comme atypiques permet meilleure détec anomalies considérée Extraction anomalies bases séquentielles cette section décrivons approche extraction anomalies bases séquentielles considérons bases données séquences forme lettres probabilité probabilité suive hypothèse laquelle approche séquences protéines possè propriété mémoire courte existe entier Autrement valeur séquence temps dépend valeurs précédentes propriété Markov ordreK ordre variable représentation usuelle modèle arbre suffixes chaque noeud parent grand suffixe arbre chaque feuille représente mémoire chaîne Markov associée modèle origine nombreuses applications telles classification familles séquences protéines Bejerano effet permet estimer probabilité chaque séquence Arbre Probabiliste Suffixes Supposons avons ensemble séquences alphabet arbre probabiliste suffixes Probabilistic Suffix arbre suffixes classique probabilités conditionelles associées chaque noeud précisé chaque noeud associé séquence contient nombre occurences vecteur longueur probabilités conditionnelles Comme taille arbre augmente façon exponentielle longueur mémoires élagué effet longueur maximale fixée arbre noeuds fréquence faible également élagués étant considérés comme négligeables exemple alphabet binaire Exemple figure montre construit alphabet longueur maximale ordre maximum chaîne Markov également fréquence minimale séquences noeuds alors élagués rares arbre construit probabilités conditionnelles associées noeuds estimer distribution chaque séquence puisque toute séquence Exemple utilisant exemple précédent probabilité chaque séquence calculée mesure similarité introduite distinguer observations atypiques Mesure similarité théorie information chaque séquence mesure similarité définie pouvoir estimer similarité importe quelle nouvelle séquence probabilités lissées mesure normalisée biaisée longueur séquence certaines hypothèses possède intéressante propriété asymptotique supposons séquences générées source information signifie elles valeurs alphabet elles distribution stationnaire varie cours temps Rappelons aussi entropie variable aléatoire mesure régularité Cette notion étend facilement variables concepts distri bution jointe conditionnelle menant entropie jointe conditionnelle incertitude source information alors définie comme limite entropie conditionelle Détection séquences atypiques Supposons enfin séquences générées unique source information alors après théorème Shannon McMillan Shannon condition ergodicité source converge incertitude source preuve résultat trouven Ainsi quand grand vrait incertitude source réellement générée Sinon similarités autres séquences conséquent inégalité concen tration Bienaymé Tchebycheff utilisée déterminer bornes desquelles séquences susceptibles anomalies cette inégalité moins performante points éloignés moyenne précisément outliers potentiels expérimentations bases protéines menées succès elles reposent connaissance préliminaire séquences typiques puisque seules celles utilisées construire effet abord modèle construit séquences auteurs déterminent nouvelles séquences outliers rapport modèle Cependant notre approche souhaitons extraire directement anomalies ensemble séquences puisque connaissons séquences typiques méthode présentée cette section efficace mettre évidence différences structures entre familles protéines échoue lorsque souhaite identifier outliers parmi séquences partie réduite élagage selon fréquence taille arbre demeure problématique conséquent notre proposition amélioration approche particulièrement article déterminons séquence outlier étant donnés seuil approche générique cette section détaillons notre approche précisément introduisons élagage supplémentaire arbre critère information conduisant découverte systématique anomalies grâce modèle adéquat réduit utilisation inégalité concentration exponentielle mesure similarité résultant seuils précis ainsi meilleure séparation entre outliers séquences typiques adoptons mêmes hypothèses mémoire courte stationnarité consid érons également alphabet Elagage critère information Akaike avons section élagué étapes longueur branche maximale fixée noeud situé arbre élagué noeud lequel fréquence séquence associée inférieure seuil donné élagué procédures construit façon suivante noeud ajouté arbre diffère statistiquement critère information Kullback Leibler utilisé effet information distance Kullback Leibler parfois appelée entropie relative représente information perdue quand distribution utilisée approximer autre Burnham Anderson statistique erreur lettre séquence définie supérieur seuil donné noeud correspondant ajouté arbre Ainsi information supplémentaire apportée mesurée Comme information Kullback Leibler originelle pondérée probabilité noeuds correpondant séquences probabilités obervation faibles élagués différent Etant rares considérés comme néglige ables dernier critère appliqué niveau arbre nécessairement niveaux suivants distributions pouvant différer profondeur supérieure conséquent descendants potentiels chaque noeud élagué aussi testés Exemple Considérons nouveau arbre binaire figure seuil noeuds alors élagués puisque leurs vecteurs probabiliés conditionnelles similaires celui apportent aucune connaissance supplémentaire méthode élagage dessus utilisée conséquent réduire davantage taille arbre utilisons critère appelé Information Criterion introduit Akaike critère permet trouver compromis entre ajustement modèle données complexité fonction vraisem blance modèle nombre paramètres Alors critère défini comme relié information Kullback Leibler également vraisemblance contient terme supplémentaire corriger biais estimation asymptotiquement critère permet comparer distance modèles potentiels boîtés modèle inconnu choisir proche Burnham Anderson détails Ainsi ensemble modèles candidats choisissons celui lequel faible pratique performant nombre paramètres élevé rapport taille données problème notamment soulevé Sugiura conséquent critère information second ordre défini Hurvich longueur totale données adapté nombre paramètres modèle utilisons toujours cette version corrigée applications appliquons critère étapes abord notonsML modèle Markov ordre choisissons meilleur modèle critère parmi ensemble Ainsi longueur maximale arbre fixée Ensuite appliquons critère chaque niveau modèle celui alors exprime différence entre modèles ajoutons cette différence significative Burnham Anderson Sinon ajoutons aucun Ainsi obtenons modèle Markov ordre variable introduisons critère Akaike corrigé algorithme proposé expérimentations Détection séquences atypiques montrent taille arbre diminue considérablement nouveau critère qualité discrimination améliorée résumé seulement notre modèle possède fondement statistique permet aussi réduire nombre noeuds arbre littérature critère Akaike souvent associé autre critère connu appelé critère information Bayes introduit Schwarz différence entre critères concerne terme correction puisqueBIC longueur totale données Comme sujet notre travail comparaison critères bornons remarquer employés différentes parvenir meilleur compromis entre biais variance alors sélectionné converge quasi modèle modèle parmi ensemble candidats proche utilisons critères obtenons résultats comparables modèle sélectionné probabilités conditionnelles utilisées calculer chaque séquence bornes précises concentration section précédente avons comment mesures similarités culées partir détecter outliers inégalité Bienaymé Tchebycheff utilisée soient espérance variance variable aléatoire Alors outliers séquences similarité trouve autres dehors bornes définies dessus satisfaisante points proches moyenne cette inégalité connue adéquate observations moyenne outliers potentiels derniers inégalités concentration exponentiel particulièrement adaptées intéressons particulier inégalité Bennett Théorème SoientX1 variables aléatoires réelles indépendantes centrées telles probabilité Alors fonction définie considérons variables Elles bornées puisque probabilités conditionnelles arbre lissées Comme inégalité exponentiel obtenons résultats concentration précis mesure similarité effet expérimentations montrent concerne détec outliers bornes obtenues inégalité Bennett meilleures celles issues inégalité Bienaymé Tchebycheff Expérimentations analyse valider notre approche expérimentalement avons considéré Bateman contient environ familles protéines alphabet acides aminés taille connue couvrir nombreuses familles protéines Ferreira Azevedo utilisons logiciel package Bio3D Grant données format FASTA judicieusement observé bonne mesure similarité devrait détecter différence structure entre familles construit famille similarités chaque séquence calculées obtenir bornes Ensuite arbre utilisé calcul similarités membres autres familles savoir combien entre trouvent extérieur bornes avons expérimen tations similaires comparant résultats obtenus élagage selon utilisant inégalités Bienaymé Tchebycheff Bennett Toutes méthodes donnent résultats satisfaisants suggère modèles Markov ordre raisonnable fonctionnent effet Cependant notre détecter quels outliers parmi ensemble séquences savoir quels membres typiques devraient utilisés construire arbre considérons alors famille HCV_core compte membres auxquels ajoutons quelques séquences appartenant famille NADHdh article présentons résultats obtenus données premier contient séquences issues famille NADHdh environ deuxième appelé contient séquences NADHdh représentant environ total construisons données vérifions mesure similarité distingue séquences atypiques elles devraient famille NADHdh abord sélectionnons modèle global ordremaximal chaîne deMarkov utilisant considérons quatre modèles Markov ordre crois tableau montre résultats obtenus après Modèle Critères information modèles Markov ordre critères choisissons modèle chaîne Markov ordre correspondant score faible Intéressons histogrammes similarités obtenues figure montre estimation distribution similarités séquences iques atypiques selon modèle utilisé sépare mieux groupes mesures similarité inégalité concentration adéquate devrait permettre pouvoir identifier outliers parmi données comme verrons contraire autres modèles laissent groupes déborder autre distinction difficile voyons ainsi modèle complexe liste adéquat Détection séquences atypiques Comparaison modèles Markov ordre modèle simple choix modèle faire critère approprié Procédonsmaintenant deuxième étape notre stratégie élagage avons section profondeur maximale arbre trouvée pouvons également utiliser critère localement chaque noeud élaguons selon niveau local obtenons histogramme similaire celui modèle figure arbre possède désormais noeuds Comme anomalies mises évidence manière comparable calcul critère local important somme alphabet question utilité cette seconde étape Cependant lorsque affaire grands alphabets souhaitable sélectionner modèle Markov niveau niveau avoir abord fixer profondeurmaximale construire arbre enfin élaguer noeuds échéant construisons utilisant critère signifie fixons longueur maximale mémoires ainsi obtenu possède noeuds seulement profondeur maximale montre efficacité détecter outliers comme montre histogramme figure résumé lorsque élaguons arbre suffixes critère local obtenons modèle parcimonieux détecte anomalies Cependant habituellement recommandé abord sélectionner modèle global Burnham Anderson Cette approche utilisée précaution modèle choisi cherchons obtenir bornes déterminer observation outlier rapport seuil donné modèle appliquons inégalité Bennett seuils correspondants réelle proportion Histogramme obtenu utilisant critère local Histogramme obtenu utilisant critère local profondeur maximale anomalies comparons bornes celles obtenues inégalité Bienaymé Tchebycheff seuil comme recommandé revient fixer borne écarts moyenne obtenons résultats tableaux contiennent pourcentages anomalies extraites chaque selon chaque méthode premier données inégalités mènent résul Inégalité Seuil Vrais Bienaymé Tcheb Bennett Pourcentages vrais outliers bornes Inégalité Seuil Vrais Bienaymé Tcheb Bennett Pourcentages vrais outliers bornes similaires Cependant seuil utilisé inégalité Bennett puisqu correspond proportion outliers général impossible savoir avance combien séquences atypiques Toutefois histogramme figure donne indication deuxième données inégalité Bennett clairement performante celle Bienaymé Tchebycheff pourtant seuil proche meilleurs résultats pourraient obtenus changeant seuil inégalité Bienaymé Tchebycheff autant écarts fondement théorique effet figure 5montre bornes obtenues inégalités Bienaymé Tchebycheff mêmes seuils ligne pointillés représente similarité grande outliers voyons correspond seuil inégalité Bennett celle Bienaymé Tchebycheff conséquent pourrions utiliser cette dernière seuil détecter anomalies Cependant seuil inégalité Bennett correspond intuition avoir propos outliers puisqu informe leurs similarités auraient moins chances trouver dehors bornes elles avaient typiques Détection séquences atypiques Bornes inégalités concentration seuils Mesures similarité séquences typiques vrais liers Seuils Nombre noeuds Outliers détectés Résultats critère élagage fréquence pourcentage vrais outliers détectés optimal résultats fausses anoma correct moins cependant quelques séquences typiques demeurent bornes exemple inégalité Bennett représente bonne performance inégalité vrais outliers remédier problème recommençons processus contruction élagage arbre réduite vrais outliers enlevés Ensuite regardons point observations mises écart mises évidence nouveau modèle similarités outliers excepté seule séquence maintenant beaucoup proche séquences typiques alors similarités vrais outliers détachent clairement figure illustre résultat Finalement élagage critèreAICc couplé inégalité concentration adaptée donne résultats satisfaisants critère élagage seule fréquence était utilisé demander pourrait mener détection comparable tableau montre résulats élagage profondeur arbre utilisant inégalité Bennett seuil seuils férieurs outliers détectés seuil supérieur toutes anomalies dehors bornes arbre grand celui obtenu élaguant critère information résumé cette méthode résultats compa rables parfois meilleurs taille arbre Cependant aucune information seuil donnée pourtant dernier dépend taille notre données nombre anomalies structure séquences effet fixant seuil fréquence minimale utilisant inégalité Bennett seuil outliers détectés qualité détection variable alors élagage selon critère information permet identifier systématiquement outliers cette section avons présenté résultats notre approche bases protéines Notons avons également expérimentations aussi efficaces autres familles obtenu résultats également pertinents Conclusion perspectives article avons proposé méthode détecter anomalies bases séquences avons déterminé obervation atypique selon seuil Notre approche extension celle consiste struire arbre suffixes utiliser mesure similarité effet lorsque données générées unique source information convergence cette mesure incertitude source assure appropriée Cependant taille arbre extraction exacte outliers demeuraient problématique conséquent avons étendu cette méthode travers élagage supplémentaire arbre grâce critère information Akaike réduire taille améliorer modèle utilisation inégalité concentration Bennett borner précisément mesure ilarité ajouts permis détection efficace systématique anomalies effet qualité discrimination améliorée alors taille arbre contrôlée assurer avons testé notre méthode bases séquences protéines Ainsi avons bases détection anomalies cadre général permettre extension notre méthode structures données complexes telles motifs séquentiels séquences données Agrawal Srikant Remerciements remercions AndréMas conseils avisés Merci égale Yoann Pitarch expérimentations Références Agrawal Srikant Mining sequential patterns Eleventh International Conference Engineering Taipei Taiwan Computer Society Press Akaike Information theory extension maximum likelihood principle Petrox Caski Second International Symposium Information Theory Information Theory Dover Publications Barnett Lewis Outliers Statistical Wiley Bateman Birney Durbin Sonnhammer protein families database Nucleic Acids Détection séquences atypiques Bejerano Modeling protein families using probabilistic suffix trees Istrail Pevzner Waterman ComputationalMolecular Biology RECOMB France Press Bennett Probability inequalities independent random variables Journal American Statistical Association Burnham Anderson Model Selection Inference Practical Information Theoretic Approach Springer Verlag Telos Ferreira Azevedo Chapter Deterministic motif mining protein databases Masseglia Poncelet Teisseire Successes Directions Mining Grant Rodrigues ElSawy McCammon Caves Bio3d package comparative analysis protein structures Bioinformatics Hawkins Identification Outliers Chapman Hurvich Regression series model selection small samples Biometrika Knorr Algorithms mining distance based outliers large datasets Large Bases Singer Tishby power amnesia Learning probabilistic tomata variable memory length Machine Learning Schwarz Estimating dimension model Annals Statistics Shannon mathematical theory communication System Technical Sugiura Further analysis akaike information criterion finite corrections Communications Statistics Theory Methods Chawla Arunasalam Mining outliers sequential databases Mining Language Environment Statistical Computing Vienna Austria Foundation Statistical Computing 900051 Summary Recently biological sequential databases increased number context identifying outliers essential extract approaches sample known typical sequences build model However database often Besides existing methods remain greedy terms memory usage paper approach based variable order markov model measure similarity existing methods pruning criterion control search space quality sharp inequality concentration measure similarity better outliers prove feasability approach through experiments