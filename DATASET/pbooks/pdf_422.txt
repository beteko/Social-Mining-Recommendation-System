Technique factorisation multi biais recommandations dynamiques Modou Gueye Talel Abdesssalem Hubert Naacke Institut Telecom Telecom ParisTech Barrault 75013 Paris France prénom telecom paristech telecom paristech Université Cheikh 16432 Dakar Sénégal gmodou Sorbonne Universités place Jussieu 75005 Paris France hubert naacke Résumé factorisation matrices offre grande qualité prédiction systèmes recommandation nature statique empêche tenir compte nouvelles notes utilisateurs produisent continu Ainsi qualité prédictions décroît entre factorisations lorsque nombreuses notes prises compte quantité notes écartées autant grande période entre factorisation longue accentue baisse qualité travaux visent améliorer qualité recommandations proposons factorisation matrices utilisant groupes produits intégrant ligne nouvelles notes utilisateurs attribuons chaque utilisateur biais chaque groupe produits similaires mettons Ainsi améliorons significativement prédictions entre factorisations expérimentations données réels montrent efficacité notre approche Introduction objectif systèmes recommandation déterminer parmi grande quantité produits lesquels intéresseront utilisateur donné produits recommandés intéressent effectivement utilisateur qualité recommandation grande recommandations dynamiques recommandation valeur commerciale capitale commerce concentre aujourd beaucoup attention améliorer qualité Schafer Fleder Hosanagar factorisation matrices technique filtrage collaboratif apportant qualité satisfaisante Khoshgoftaar Koren Paterek Takács Koren consiste construire profils caractérisant utilisateurs produits moyen vecteurs facteurs profils déduits notes utilisa teurs attribuent produits Ainsi possible estimer intérêt utilisateur produit combinant profil utilisateur celui produit produit scalaire produits estimations grandes recommandés utilisée factorisation présente limites inconvénient majeur modèle résultant factorisation reste statique modèle tient compte nouvelles notes utili sateurs produisent continuellement nouvelles notes seront prises compte prochaine factorisation Ainsi modèle besoin régénéré fréquemment toujours possible cause prohibitif factorisation qualité recommandations décroît graduellement entre générations modèle contexte profils utilisateurs évoluent dynamiquement Prenons exemple mélomane désirant acheter chansons marchand recommande liste chansons partir dernier modèle factorisé utilisateur répond notant chansons connaît vient juste écouter renseigne marchand précisant préférences actuelles utilisa marchand souhaite tenir compte toutes dernières notes utilisateur prochaines recommandations sinon recommandations risquent faible qualité travaux visent améliorer qualité recommandations proposons facto risation multi biais supportant arrivée continuelle nouvelles notes partons servation utilisateurs tendance noter différemment produits différents groupes attribuons chaque utilisateur liste biais décrivant tendances biais continuellement lorsque nouvelles notes arrivent permet tenir qualité recommandation satisfaisante longtemps différer ration nouveau modèle Notre approche améliore passage échelle différent besoin recalculer expérimentations avons effectuées données Netflix grand MovieLens confirment adaptée environnements dynamiques nouvelles notes arrivent continuellement Wikipedia GroupLens intégration nouvelle faible qualité recommandations décroît rapide entre factorisations successives notre affiner biais utilisateurs indépendante modèles factorisation utilisée modèles évolués réunissant exemple aspect temporel valeurs confiance Koren Koren Takács papier organisé comme section introduisons notions prélimi naires recommandation notre contexte section présentons notre solution factorisation basée groupes résultats expérimentaux présentés section Enfin section exposons travaux connexes avant conclure Gueye Préliminaires système recommandation découvrir intérêts utilisateur proposer produits susceptibles intéresser plupart temps intérêt utilisateur produit donné forme valeurs numériques plage donnée produit valeur donnée élevée utilisateur intéresse produit considère ensemble utilisateurs ensemble produits liste notes chaque valeur représente intérêt utilisateur produit étant moment soumise recommandation consiste prédire tures notes utilisateurs telles écart entre prédite celle réellement donnée ultérieurement petit possible permet proposer utilisateur produits présentant grandes valeurs prédiction Ainsi qualité système recom mandation rattachée précision prédictions pratique estimer cette précision écarts ensemble notes existantes subdivisé parties grande apprentissage seconde évaluation mesure appelée utilisées évaluation racine carré moyenne carrés écarts Herlocker Khoshgoftaar Wikipedia utilisons suite représente nombre total notes prédire petit meilleures prédictions factorisation matrices systèmes recommandation utilisant factorisation matrices représentent notes utilisateurs matrice creuse colonnes représentent utilisateurs lignes produits Ainsi celle donnée utilisateur produit généralement creuse Wikipedia objectif factorisation prédire valeurs manquantes forme basique basique cherche approximer comme produit autres matrices matrices contiennent respectivement vecteurs facteurs utilisateurs produits matrices facteurs prédire utilisateur donnerait produit suffit simplement appliquer formule étant respectivement vecteurs facteurs utilisateur produit processus apprentissage effectue factorisation détermine valeurs telles approche notes existantes utilise descente recommandations dynamiques gradient stochastique calcule minimum local somme erreurs écarts entre notes prédites celles réelles données utilisateurs faible possible minimise somme erreurs quadratiques ajustant facteurs jusqu cette somme diminue permet diminuer erreurs conséquent avoir meilleure approximation notes réelles paramètre introduit ajustement facteurs représente apprentissage paramètre régularisation Après cette phase prédictions calculées comme produits effectué suite trouver produits intéressants grandes notes prédiction recommander utilisateur concerné Factorisation biaisée matrices Plusieurs améliorations possibles factorisation présentée dessus proposées littérature suppose plupart variations observées notes utilisateurs principalement effets associés utilisateurs produits Takács Koren Paterek Autrement certains utilisateurs dance donner notes élevées faibles autres utilisateurs certains produits aussi moins appréciés autres factorisation basique sique présentée précédemment prend compte tendances factorisation biaisée matrices introduit biais tenir compte variations notation biais reflètent tendances utilisateurs produits formule prédiction suivante dénote moyenne toutes notes confondues respectivement biais utilisateur celui produit tendance utilisateur perception produit rapport moyenne bonne approximation biais cruciale avoir prédictions bonne qualité Paterek Koren Ainsi doivent ajustés durant phase apprentissage utilisant paramètre régularisation comparable équation Recommandation dynamique travaux considèrent contextes dynamiques nouvelles notes continuelle soumises contextes possible avoir modèle cause Gueye temps nécessaire calculer minimum notes soumises durant génération modèle prises compte Après génération modèle situation dégrader assez rapidement puisque nombre notes prises compte augmente rapide perte qualité grandissante observée recommandations aussi longtemps nouveau modèle généré faire proposons modèle combinant biais globaux biais locaux biais locaux calculés partir groupes produits similaires calcul faible permet ajuster volée lorsque nouvelles notes arrivent assurent ainsi robustesse modèle maintenant meilleure qualité temps Factorisation multi biais matrices basons observation beaucoup utilisateurs tendent apprécier apprécier produits notent manière simple quantifier cette tendance assigner biais global chaque utilisateur comme Paterek Koren Takács Cependant tendance utilisateur généralement uniforme changer groupe produits autre certains groupes produits utilisateur avoir tendance noter comme monde alors surestime estime autres groupes manque objectivité Cette tendance devient uniforme ensemble produits similaires avons formalisé Gueye prendre compte cette diversité notation attribuons biais local chaque utilisateur chaque groupe produits jugés similaires proches Cette titude biais utilisateur permet avoir modèle raffiné visant meilleure recommandation utilisons techniques clustering existantes grouper produits considérons disposer informations supplémentaires produits construisons groupes reposant uniquement notes attribuées biais utilisateur groupe produits déduit notes reçues produits groupe chaque produit notée utilisateur nissons déviation utilisateur produit comme différence entre moyenne notes produits groupe biais local utilisateur niveau groupe comme moyenne déviations tenons compte aussi nombre relatif notes existant chaque groupe atténuer décalage entre biais locaux Ainsi définissons comme étant écart pondéré entre biais local utilisateur groupe produits biais global équation nombre notes utilisateur groupe produits nombre total notes soumettre Notre formule prédiction devient suivante recommandations dynamiques représente groupe auquel appartient produit biais produit perception utilisateurs Finalement affinons aussi biais locaux travers leurs écarts pondérés durant phase apprentissage utilisant algorithme détaille étapes génération modèle ligne clustering effectué déterminer groupes produits ligne calcule valeurs initiales biais produits celles biais globaux locaux utilisateurs écarts pondérés entre biais locaux globaux aussi calculés ligne initialise matrices facteurs valeurs aléatoires faibles lignes constituent partie principale apprentissage chaque itération lignes erreur prédiction calculée chaque matrices facteurs biais globaux locaux ajustés conséquence lignes utilisant équations ligne calcule somme globale erreurs quadratiques apprentissage arrête lorsque cette somme décroît lorsqu nombre spécifié itérations atteint Algorithme Algorithme nombre groupes nombre facteurs Result Créer groupes partir chaque produit utilisateur calculer Initialiser matrices repeat foreach Calculer Ajuster Ajuster Calculer somme globale erreurs until condition arrêt return Intégration nouvelles notes utilisateurs Après génération modèle nouvelles notes arrivent continuellement elles insérées matrice intégrons modèle ajustant simplement biais locaux utilisateurs ayant nouvelles notes ajustement biais locaux impact important recommandation lorsque seuls premiers produits recommandés premiers produits appartiennent plusieurs groupes cette Gueye situation ajustement biais locaux réordonne groupes rapport autres produits groupe peuvent ainsi remplacer autre groupe liste produits recommandés expérimentations avons effectivement observé cette situation trois groupes produits définis utilisateurs Netflix moins groupes produits présents leurs MovieLens lorsqu nouvelle arrive ajustement biais local calcul faible considère seulement notes utilisateur attribuées groupe nombre moyen notes considérer autant faible nombre groupes grand descente gradient effectuée mettre biais local utilisant équation algorithme présente étapes intégration Comme algorithme processus ajustement arrête lorsque somme globale erreurs quadratiques décroit certain nombre itérations Algorithme Algorithme intégration nouvelles notes repeat foreach Calculer ajuster Calculer somme globale erreurs until condition arrêt Évaluation expérimentale expérimentations objectifs démontrer qualité initiale modèle générons grande montrer intégration nouvelles notes maintient modèle niveau qualité factoriser nouveau permet avoir système réactif coûteux ressources puisque génération nouveaux modèles retardée validons points séparément montrons abord termes qualité notre solution supérieure autres précédemment citées démontrons perte qualité subit système durant temps lorsque nouvelles notes utilisateurs prises compte enfin validons obtenu notre intégration avons effectué expérimentations données Netflix MovieLens tailles respectives notes Wikipedia GroupLens données utilisés littérature Khoshgoftaar Notre implémentation faite machine Linux Intel threads avons effectué calibrage préliminaire fixer paramètres valeurs proches celles Paterek avons limité nombre itérations utilisons facteurs clustering produits avons effectué basique itérations suivie Means recommandations dynamiques Qualité initiale objectif cette expérimentation comparer qualités initiales trois modèles trions données croissante séparons parties première apprentissage notes anciennes reste notes récentes Ainsi Notre Netflix contient notes taille proche celle Netflix Prize contenait notes Wikipedia table rapporte différentes erreurs obtenues trois modèles basique dépasse autres termes qualité atteint qualité Notons point amélioration aussi petite traduit différence significative plupart produits recommandés utilisateurs Koren données basique Movielens Netflix Qualités initiales trois modèles Quantifier besoin intégration ligne ignorer nouvelles notes arrivées après factorisation impact qualité recommandation répondons cette question contexte utilisateurs soumettent quantité importante notes plusieurs millions notes compagnie Netflix exemple reçoit jusqu notes Amatriain Basilico mettre place cette situation devons utiliser données grande taille celui Netflix contient suffisamment notes Celui MovieLens assez petit souhaitons observer impact global nouvelles notes provenant lisateurs exception construisons telle sorte chaque utilisateur présent Ainsi contient notes récentes chaque utilisateur hauteur reste apprentissage préci sément alignons échantillon séquence arrivée notes notes arrivées chaque utilisateur mesurons ensuite évolution qualité prédictions dates cessives lorsqu progresse travers utilisons fenêtre glissante notes moitié partagée fenêtre précédente lisser résul figure montre évolution qualité trois modèles basique erreur prédiction augmente confirme perte qualité temps observons augmentation lorsque velles notes prises compte pratique signifie trois modèles deviennent rapidement obsolètes Gueye Delay since million ratings Basic Biased clusters Croissance erreur lorsque nombre nouvelles notes prises compte augmente Delay since million ratings static update biases Évolution intégration ligne Évolution qualité intégration Robustesse temps notre modèle intégration ligne montrer robustesse notre modèle temps Autrement maintient bonne qualité temps Utilisant toujours apprentissage expérimentation précédente prenons maintenant compte intégration ligne nouvelles notes utilisateurs ajustant leurs biais locaux Algorithme parcourons nouvelles notes Chaque nouvelle comparée rapport prédiction aurait faite calcul écart matiquement intégrée améliorer futures prédictions temps moyen intégration millisecondes intégration rapide constitue léger calcul figure présente nouvelle évolution qualité prédictions modèle lorsqu intègre nouvelles notes utilisateurs importance prise compte nouvelles notes bénéfice lorsqu atteint nouvelles notes intégrées amélioration significative recommandations prouve notre solution robuste avons effectué expériences supplémentaires démontrant bénéfice mettre biais plutôt facteurs résultats présentés Gueye Travaux connexes contributions papier utilisation plusieurs biais factorisation intégration ligne nouvelles notes utilisateurs dernier point objet plusieurs travaux alors premier compte autant Cependant notre connaissance précédents travaux utilisaient factorisation comme technique recommandation utilisaient ajustement biais intégration nouvelles notes Chakraborty Sarwar concentrent uniquement intégration nouveaux utilisateurs leurs notes focalisent nouvelles notes recommandations dynamiques utilisateurs existants alors Rendle Schmidt Thieme Rendle prennent compte mettant uniquement facteurs utilisateur concerné produit utilisent fonction estimation choix modification facteurs utilisateur produit ordre attaquent problème autrement utilisent factorisation négative matrices nonnegative matrix factorization anglais mettent ensemble facteurs utilisateurs donne temps intégration élevé nôtre effet notre solution biais local utilisateur concerné intérêt utilisation biais multiples concerne utilisation biais multiples compte beaucoup attention littérature comptons juste quelques travaux proches nôtre Koren nigstein Koren utilise sessions temps suivre évolution tendances utilisateurs produits Ainsi attribue biais session utilisateurs produits conduit meilleures recommandations Contrairement avons biais groupe produit session Koenigstein auteurs assez proches notre approche utiliser biais session temps prennent compte types produits selon leurs attributs ordre notre clustering exception avons besoin formations produits grouper basons uniquement notes reçues expérimentations montrent besoin tenir compte nouvelles notes utili sateurs plutôt possible maintenir qualité recommandations niveau Évidemment utiliser distribution réduire temps factorisation comme étudiée Gemulla Bickson permettrait recalculer modèle fréquemment Cependant besoin solutions intégration ligne demeure nécessaire applications large échelle milliards notes utilisateur millions nouvelles notes chaque citer Netflix milliards notes utilisateur reçoit chaque millions nouvelles notes Amatriain silico types application balance entre recalcul élevé intégration ligne perte significative qualité probablement meilleure solution Conclusion sommes intéressés problème recommandation lorsque nouvelles notes cesse soumises avons proposé solution factorisation contexte dynamique effet factorisation faisant partie meilleures techniques recomman dation souffre ignore toute nouvelle ajoutée utilisateur jusqu nouvelle factorisation calculée période entre factorisations avère longue quantité informations prise compte grande dégrade recommandations Notre solution introduit biais personnalisés utilisateurs mieux capturer subjectivité selon groupes produits produits étant groupés partir notes elles reçues biais lorsque nouvelles notes arrivent Gueye résultats expérimentaux montrent notre solution surpasse celle utilisant biais global utilisateur celle ayant contexte dynamique nouvelles notes continuellement soumises apporte amélioration jusqu qualité initiale intégrant nouvelles notes faible intégrations confirme viabilité passage échelle systèmes recommandation contextes dynamiques notes utilisateurs arrivent cesse Amatriain Références Amatriain Basilico Netflix recommendations Beyond stars Netflix Bickson Large scale matrix factorization yahoo Large Scale Machine Learning Other Animals Detect track latent online nonnegative matrix factorization Proceedings international joint conference Artifical intelligence Francisco Morgan Kaufmann Publishers Chakraborty scalable collaborative filtering based recommender system using incremental clustering Advance Computing Conference International Koenigstein Koren Weimer yahoo music dataset Proceedings KDDCup Fleder Hosanagar Recommender systems their impact sales versity Proceedings conference Electronic commerce Gemulla Nijkamp Sismanis Large scale matrix factorization distributed stochastic gradient descent Proceedings SIGKDD international conference Knowledge discovery mining GroupLens grouplens Gueye Abdessalem Naacke Dynamic recommender system using cluster based biases improve accuracy predictions Technical report arXiv Herlocker Konstan Terveen Riedl Evaluating collaborative filtering recommender systems Trans Koenigstein Koren Yahoo music recommendations modeling ratings temporal dynamics taxonomy Proceedings conference Recommender systems RecSys Koren useful lower Netflix Prize Forum Koren bellkor solution netflix grand prize recommandations dynamiques Koren Collaborative filtering temporal dynamics Commun Koren Volinsky Matrix factorization techniques recommender systems Computer Paterek Improving regularized singular value decomposition collaborative tering Workshop SIGKDD Knowledge Discovery Mining Rendle Schmidt Thieme Online updating regularized kernel matrix factoriza models large scale recommender systems Bridge Mobasher Ricci RecSys Sarwar Karypis Konstan Riedl Incremental singular value decom position algorithms highly scalable recommender systems Proceedings International Conference Computers Information Technology Schafer Konstan Riedi Recommender systems commerce Proceedings conference Electronic commerce Khoshgoftaar survey collaborative filtering techniques Artif Intell Takács Pilászy Németh Investigation various matrix factoriza methods large recommender systems Proceedings Workshop Large Scale Recommender Systems Netflix Prize Competition NETFLIX Takács Pilászy Németh Scalable collaborative filtering approaches large recommender systems Learn Wikipedia wikipedia netflix_prize Summary today accepted matrix factorization models allow quality rating predic recommender systems However major drawback matrix factorization static nature results progressive declining accuracy predictions after torization obtained ratings taken account until factorization computed which often because matrix factorization paper aiming improving accuracy recommender systems propose cluster based matrix factorization technique enables online integration ratings significantly enhance obtained predictions between matrix factorizations finer grained biases clustering similar items groups allocating these groups experiments large datasets demonstrated efficiency approach