méthode supervisée initialiser centres moyennes Oumaima Alaoui Ismaili Vincent Lemaire Antoine Cornuèjols Orange Pierre Marzin 22307 Lannion cedex France oumaima alaouiismaili vincent lemaire orange AgroParisTech Claude Bernard 75005 Paris antoine cornuejols agroparistech Résumé cours dernières années classification clustering imposée comme sujet recherche important Cette approche décrire prédire concept cible manière simultanée Partant choix centres algorithme moyennes standard impact direct qualité résultats obtenus article alors tester point méthode initialisation supervisée pourrait aider algorithme moyennes standard remplir tâche classification moyennes Introduction Depuis quelques années étude nouvel aspect apprentissage connu classification clustering Supervised clustering anglais suscité intérêt Cevikalp approches appartenant apprentissage visent décrire prédire manière simultanée Alaoui Ismaili 2015a cadre étude suppose classification clustering étroitement estimation distribution données conditionnellement variable cible partir données étiquetée approches cherchent découvrir struc interne variable cible pouvoir prédire ultérieurement classe nouvelles instances Types apprentissage figure illustre différence entre trois types apprentissage clustering standard classification supervisée classification clustering classification pervisée compacité classes apprises phase apprentissage condition importante groupe cluste regroupe instances homogènes tenir compte étiquetage groupe classification clustering former groupes compacts termes classes groupes Méthodes initialisation supervisées classification clustering utile domaines critiques inter prétation résultats fournis système apprentissage condition primordiale permet utilisateur découvrir différentes voies peuvent mener prédiction exemple découvrir instances classe peuvent hétérogènes instances appartenant groupe groupe classification moyennes version modifiée algorithme moyennes standard cherche générer partitions ayant compromis entre compacité groupes formés pureté termes classes partie figure dessus prédiction classe nouvelles instances réalise suite basant structure interne découverte phase apprentissage nature algorithme standard moyennes converge rarement global qualité optimum local atteint temps requis algorithme dépendent entre autres choix centres initiaux utilisation mauvaise méthode initialisation générer plusieurs effets indésirables clusters vides convergence lente grande probabilité tomber mauvais optimum local nécessité exécuter algorithme plusieurs éviter risque centres choisis départ doivent fournir bonne couverture espace données permet algorithme obtenir résultat recourir nombreuses excécutions voire exécution méthode déterministe partir constat devient naturel demander utilisation méthode initialisation supervisée aider algorithme moyennes standard obtenir résultats classification clustering Spécifiquement bonne méthode initialisation supervisée devrait réussir capter points appartenant régions denses pures termes classes obtention points candidats faciliter tâche rithme moyennes standard puisqu débuter bonne partition initiale travail alors répondre question point méthode initiali sation supervisée pourrait aider algorithme moyennes standard former groupes compacts homogènes classification clustering article consacré exclusivement étude impact méthode initialisation supervisée performance prédictive algorithme moyennes suppose compacité groupes garantie algorithme moyennes atteindre objectif proposons nouvelle méthode supervisée initialisation centres section résultats obtenus grâce algorithme moyennes utilisant cette nouvelle méthode méthodes issues littérature présentés discutés section Finalement conclusion générale validité hypothèse objet section Contribution Rocchio Split intérêt utilisation méthode supervisée initialiser centres cadre classification moyennes clairement déséquilibre classes prédire cours phase initialisation probabilité choisir centre classe majoritaire choisir aucun centre classe minoritaire élevée conséquent détérioration niveau pureté terme classe prédire cette étude algorithme moyennes exécuté Ensuite partition optimale considérée comme étant celle minimise Erreur Quadratique Moyennes Alaoui clusters serait introduite partir constat pense intégration information contenue variable cible processus initialisation avérer utile méthode initialisation proposée article appelée Rochio Split nombre clusters nombre classes cette méthode associe chaque classe centre centre gravité méthode Rocchio contraire lorsque nombre clusters supérieur nombre classes cette méthode division hiérarchique descendante groupes chaque groupe représente classe Ensuite chaque itération groupe vérifie critère déterminé divisé partant groupes formés doivent homogènes compacts possible groupe diviser groupe dispersé mesurer cette dispersion inertie intra clusters utilisée processus répété jusqu nombre groupes formés nombre centres Finalement centres obtenus calculant centres gravité chacun groupes basant objectif finale classification clustering méthode cherche identifier régions denses classe dispersée faire méthode commence sélectionner classe groupe ayant dispersion élevé groupe considéré comme étant groupe candidat diviser diviser commence sélectionner instance éloignée centre gravité groupe notée Ximax Notons cette distance maximale Ensuite approche regroupe toutes instances distantes Ximax moins correspond diviser cercle rayon différentes étapes approche présentées algorithme Algorithm Rochio Split Entrées données apprentissage nombre clusters nombre classes Calculer centre gravité chaque classe alors Sortie Centres gravité alors nombre clusters atteint faire Calculer dispersion chaque cluster inertie intra Diviser cluster dispersé clusters manière suivante Sélectionner instance Ximax telle argmax Ximax centre gravité cluster allant jusqu nombre instance faire Ximax alors Sinon Supprimer centre groupe sélectionné calculer centres gravité clusters Sortie centres initiaux Discerner groupes compacts termes classe prédire ultérieurement classe nouveaux exemples Méthodes initialisation supervisées points approche approche déterministe réduire temps calcul puisqu seule exécution nécessaire complexité cette approche linéaire technique suivie diviser groupes dispersés effet capter points appartenant régions denses pures termes classe inconvénient majeur cette approche sensible présence données bruitées outliers raison utilisation distance maximale division Néanmoins point atténué éliminé utilisant exemple prétraitement capable éliminer bruit existant Expérimentation vérifier validité notre hypothèse savoir méthodes initialisation pervisées aident elles algorithme moyennes standard fournir résultats termes prédiction comparaison performances prédictives moyennes rithme moyennes précédé différentes méthodes initialisation supervisées supervisées effectuée méthodologie utilisée suivante méthodes initialisation cette étude comparative intéresse thodes initialisation communément utilisées littérature méthodes super visée avons choisi utiliser Forgy Random Sample MaxiMin déterministe déterministe Variance Partitioning means lecteur pourra trouver description détaillée méthodes Celebi Kingravi méthodes supervisées avons choisi utiliser méthode means Lemaire méthode proposée Rocchio Split prétraitement prétraitement utilisé cette étude expérimentale traitement supervisé nommé Conditional choix suite étude menée Alaoui Ismaili 2015b auteurs montré utilisation prétraitement algorithme moyennes standard atteindre bonne performance prédictive processus prédiction expliqué dessous Australian Hepatitis Vehicle Glass Tictactoe Heart Horsecolic German Soybean Segmentation Breast Abalone Liste données utilisés pourcentage classe majoritaire données données utilisés cette étude tirés réper toire Lichman données choisis avoir bases données diverses termes nombre classes variables continues catégo rielles instances Tableau Alaoui critères évaluation cadre apprentissage supervisé critère évalua communément utilisé Adjusted Index Hubert Arabie Nombre clusters varie jusqu chaque données déterminé préalable manière partition obtenue permette obtenir ratio inertie inter inertie totale Tableau Affectation classes clusters processus apprentissage chaque groupe appris prend comme étiquette majorité exemples forme classe utilisation majoritaire prédiction prédiction nouvel exemple selon appartenance groupes appris Autrement exemple reçoit comme prédiction proche centre gravité groupe classe utilisation proche voisin rappeler approches classification clustering cherchent décrire prédire manière simultanée objectif alors trouver cours phase apprentissage meilleur compromis entre compacité pureté groupes appris découvrir structure interne variable cible prédiction classe nouvelles instances réalisée basant cette structure Puisqu existe critère global permettant mesurer compromis performances prédictives méthodes seront évaluées utilisant concerne compacité suppose article garantie algorithme moyennes Après nombreuses exécutions algorithme choisit celle minimise Erreur Quadratique Moyenne évaluation commençons tracer chaque données chaque méthode initialisation courbe fonction nombre clusters méthodologie dessus cette courbe ensuite calculée under Learning Curve Enfin valeurs synthétisent résultats chaque méthode initialisation appliquons Friedman couplé Nemenyi seuil significativité Friedman couplé Nemenyi figure présente résultat tests tistiques effectués données thodes cette figure classées ordre décrois selon leurs performance prédictives thode proche meilleure prédic Friedman montre existe férence significative pvalue entre méthodes tandis Nemenyi partitionne méthodes groupes Cette figure montre également méthode méthode résultats termes prédiction rapport autres méthodes important rappeler méthode méthode déterministe algorithme moyennes exécuté seule méthode capable obtenir bonne performance prédictive permet également réduire notablement temps calcul autres méthodes cette étude comparative exécute algorithme moyennes Méthodes initialisation supervisées Conclusion article présenté influence étape initialisation supervisée qualité résultats générés algorithme moyennes standard avons montrer bonne méthode initialisation supervisée capacité aider algorithme atteindre jectif classification moyennes résultats expérimentaux montré algorithme moyennes précédé méthode parvient obtenir résultats termes prédiction seule exécution Références Alaoui Ismaili Lemaire Cornuéjols 2015a Classification clustering comment décrire prédire simultanément Rencontres Jeunes Chercheurs Intelligence Artificielle RJCIA Alaoui Ismaili Lemaire Cornuéjols 2015b Supervised preprocessings useful supervised clustering Springer Series Studies Classification Analysis Knowledge Organization Celebi Kingravi Linear deterministic order invariant initialization methods means clustering algorithm Partitional Clustering Algorithms Springer Cevikalp Larlus Jurie supervised clustering algorithm initiali zation neural network classifiers Signal Processing Communications Applica tions Zeidat Supervised clustering algorithms benefits Tools Artificial Intelligence ICTAI Hubert Arabie Comparing partitions Journal Classification clustering years beyond means Pattern Recogn Lemaire Ismaili Cornuéjols initialization scheme supervized means International Joint Conference Neural Networks IJCNN Ireland Lichman machine learning repository Manning Raghavan Schütze Introduction information retrieval Volume Cambridge university press Cambridge Summary years researchers focused their attention approach pervised clustering combines characteristics traditional clustering supervised classification tasks Motivated importance initialization traditional clustering context paper explores extent supervised initialization could traditional clustering obtain better performances supervised clustering tasks