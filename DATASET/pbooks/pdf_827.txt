ExpLSA utilisation informations syntaxico sémantiques associées améliorer méthodes classification conceptuelle Nicolas Béchet Mathieu Roche Jacques Chauché Équipe LIRMM Université Montpellier 34392 Montpellier Cedex France nicolas bechet mroche chauche lirmm Résumé analyse sémantique latente Latent Semantic Analysis aujourd utilisée nombreux domaines comme modélisation nitive applications éducatives aussi classification approche présentée article consiste ajouter informations grammaticales Différentes méthodes exploiter informations grammaticales étudiées cadre tâche classification conceptuelle Introduction domaine classification données textuelles décline nombreux parmi lesquels classification conceptuelle Cette dernière consiste regrouper termes concepts définis expert Citons exemple termes échappement brise essuie glace peuvent classés concept automobile établir telle classification sémantique proximité chacun termes issus textes mesurée termes ensuite classés fonction leurs proximités sémantiques algorithme fouille données proches voisins moyennes Cornuéjols Miclet focalisons article première étape réalisation classifica conceptuelle étude proximité termes calculer telle proximité appuyons méthode appelée Latent Semantic Analysis développée dauer Dumais méthode uniquement fondée approche statistique appliquée corpus grande dimension consistant regrouper termes classification conceptuelle contextes classification textes analyse sémantique latente appliquée corpus espace sémantique associant chaque vecteur retourné proximité alors obtenue calcul similarité comme cosinus entre vecteurs objectif travaux améliorer performances approche nommée ExpLSA Expansion contextes approche ExpLSA consiste enrichir corpus constituera entrée analyse sémantique latente classique enrichissement utilise informations sémantiques obtenues 1voir aussi memphis wiemerhp followup Informations syntaxico sémantiques grâce syntaxe permet utiliser ExpLSA aussi corpus spécialisés effet utile utiliser corpus apprentissage nécessaire connaître thème général corpus article allons appuyer corpus Ressources Humaines société PerformanSe2 écrit français3 Notons premiers travaux corpus initiés équipe Roche Kodratoff caractéristique essentielle corpus utilise vocabulaire spécialisé ailleurs contient tournures phrases revenant souvent influencer positivement traitement corpus objet expertise manuelle permettant ainsi valider expérimen tations proposons section suivante détailler caractéristiques théoriques méthode ainsi limites telle analyse section propose domaine utilisation connaissances syntaxiques associées présen ensuite notre méthode développant différentes étapes section décrirons également section protocole expérimental utilisé finalement présenter résultats obtenus méthode appuie hypothèse harrissienne fondée apparaissent contexte sémantiquement proches corpus représenté forme matricielle lignes relatives colonnes représen différents contextes choisis document paragraphe phrase Chaque cellule matrice représente nombre occurrences chacun contextes corpus proches niveau sémantique représentés vecteurs proches mesure proximité généralement définie cosinus angle entre vecteurs Caractéristiques théoriques théorie laquelle appuie décomposition valeurs singulières matrice fréquence apparition contexte décompose produit trois matrices matrices orthogonales matrice diagonale matrice produite enlevant colonnes petites valeurs singulières matrices obtenues enlevant colonnes correspondantes matrices matrice UkSkV alors considérée comme version compressée matrice originale expériences décrites section menées nombre facteurs facteur faible davantage approprié contextes taille réduite coutume méthode statistique numérique appuie théorie mathématique connue Cependant également méthode géométrique seuls résultats algèbre linéaire utilisés performanse 3Fragment corpus disponible adresse lirmm mroche Recherche corpusPsy Béchet précisons avant effectuer décomposition valeurs singulières première étape normalisation matrice origine exécutée Cette normalisation consiste appliquer logarithme calcul entropie matrice Ainsi plutôt fonder directement nombre occurrences chacun telle transformation permet appuyer estimation importance chacun contexte manière similaire travaux Turney cette étape normalisation également appuyer méthode approche connue domaine Recherche Information Précisons prenons compte ponctuations ainsi certain nombre significatifs point sémantique limites offre avantages parmi lesquels notion indépendance rapport langue corpus étudié dispenser connaissances linguistiques ainsi celles domaine thésaurus cette approche prometteuse demeure moins utilisation soulève contraintes Notons abord importance taille contextes choisis Rehder montré leurs expérimentations contextes possèdent moins résultats avèrent décevants également évidence Roche Chauché efficacité fortement influencée proximité vocabulaire utilisé résoudre problèmes solutions consister ajouter connais sances syntaxiques comme décrit section suivante ajout connaissances syntaxiques Landauer posent problème manque informations syntaxiques comparant cette méthode évaluation humaine question proposer experts humains attribuer notes essais humain rédigés étudiants espace sémantique partir articles écrits anglais traitant humain appris tests effectués concluent méthode obtient résultats satisfaisants comparativement expertise humaine ressort mauvais résultats étaient absence connaissances syntaxiques approche utilisée Ainsi travaux décrits dessous montrent quelle manière telles connaissances peuvent ajoutées première approche Wiemer Hastings Zipitria utilise étiquettes maticales Brill appliquées ensemble corpus étudié corpus textes étudi étiquettes étant rattachées chaque blanc souligné analyse considère associé étiquette comme terme résul calculs similarités obtenus telle méthode restent décevants Notons telles informations grammaticales connaissances syntaxiques proprement dites contrairement seconde approche Wiemer Hastings Zipitria décrite dessous Cette seconde approche traduit utilisation analyseur syntaxique segmenter texte avant appliquer analyse sémantique latente Cette approche appelée struc turée décomposition syntaxique phrases différents composants sujet Informations syntaxico sémantiques verbe objet abord effectuée similarité ensuite calculée traitant séparé trois ensembles décrits précédemment similarités calcul cosinus entre vecteurs trois matrices formées alors évaluées moyenne similarités enfin calculée Cette méthode donné résultats satisfaisants rapport classique augmentant corrélation scores obtenus experts tâche évaluation réponses données étudiants informatique Kanejiya proposent modèle appelé SELSA générer matrice occurrences document proposé matrice laquelle chaque ligne tient toutes combinaisons mot_étiquette colonne documents étiquette préfixe renseigne grammatical voisinage traité effet donné voisinage grammatical duquel Cette approche assez similaire tilisation étiquettes Brill présentée travaux Wiemer Hastings SELSA étend travail cadre général contexte syntaxique spécifié adjacents considéré comme unité représentation connaissances évaluation cette approche montré méthode était perti nente SELSA corrélation experts Cependant SELSA révèle précise tester bonnes mauvaises réponses SELSA moins fautes retourne nuisibles approche ExpLSA présentons article place contexte férent effet notre cadre travail contextes représentés phrases taille réduite tendance donner résultats décevants tilisation Rehder Roche Chauché notre approche proposons utiliser régularité certaines relations syntaxiques enrichir contexte comme allons monter section suivante Notre Approche ExpLSA final fixons consiste regrouper automatiquement termes extraits grâce systèmes ACABIT Daille LEXTER Bourigault SYNTEX Bourigault Fabre Roche notre proposons regrouper termes nominaux extraits termes extraits système groupes respectant patrons syntaxiques préposition adjectif adjectif ailleurs appuie méthode statistique classer termes extraits utilise approche itérative construire termes complexes première étape regroupement finalement construire classification ceptuelle effectuée ExpLSA principe décrit section suivante Principe général ExpLSA Notre approche enrichir corpus initial lemmatisé faisant expansion phrases ExpLSA fondée méthode syntaxique ressort contexte riche Celui construit complétant corpus jugés séman tiquement proches Citons exemple phrase interlocuteurs seront inspirés placer échanges transformons abord phrase lemmatisée système SYGFRAN Chauché Votre interlocuteur inspiré placer échange Béchet Enfin enrichie autres devenant phrase Votre interlocuteur collaborateur inspiré placer échange méthodes utilisées déterminer utilisés enrichissement ainsi sélection présentées section suivante analyse syntaxique mesurer proximité sémantique enrichir corpus initial proposons effectuer abord analyse taxique corpus SYGFRAN dernier renvoie relations syntaxiques présentes chaque phrase notre approche sommes particulièrement intéressés relations syntaxiques Verbe Objet Verbe_Preposition_Complément Verbe_COD exemple avons extrait relation syntaxique Verbe intéresser Objet inter locuteur partir phrase intéressent leurs interlocuteurs ensemble relations Verbe Objet extraites utilisons mesure évaluer proximité sémantique verbes mesure Asium Faure Faure Nedel Cette mesure considère verbes comme proches possèdent nombre important objets commun principe cette approche similaire celle présentée Bourigault Soient verbes leurs objets respectifs NbOccComp représente nombre occurrences objets relation verbe aussi objets verbe NbOcc représente nombre occurrences objets mesure Asium définie manière suivante Asium logAsium NbOccComq logAsium NbOccComp logAsium NbOcc logAsium NbOcc logAsium valant logAsium sinon logAsium mesure Asium proche implique importante proximité sémantique emple figure illustre application mesure Asium verbes écouter convaincre considérerons suite plusieurs seuils similarité appelés signifi verbes seront considérés comme proches mesure Asium méthode expansion utilisant méthode Asium décrite section suivante Étapes ExpLSA Après avoir explicité mesure Asium permettant mesurer proximité verbes corpus proposons détailler différentes étapes définissant ExpLSA étendre contextes première étape approche ExpLSA identifie différents termes extraits Cette identification consiste représenter terme exemple terme attitude profondément participative corpus Ressources Humaines devient nom234 représente 234ème terme parmi liste extraite Après extraction relations syntaxiques Verbe Objet biais analyse syntax phase suivante notre approche consiste étudier proximité sémantique entre Informations syntaxico sémantiques Mesure Asium entre verbes écouter convaincre verbes utilisant mesure Asium section Chaque verbe corpus évalué autres conservant couple ayant obtenu meilleur score similarité pourrons exemple déduire verbes écouter convaincre sémantiquement proches Asium partagent communément objets interlocuteur collabora figure étape suivante regrouper objets communs verbes jugés proches sémantiquement seuil similarité élevé parmi ensemble couples verbes considérons possibilités regroupement première consiste considérer objets communs verbes interlocuteur collaborateur exemple figure seconde considère objets communs complémentaires verbes comme travaux Faure Nedellec interlocuteur collaborateur autrui personne exemple figure proposons compléter corpus initial attachant chaque autres communs Ainsi notre phrase initiale Votre interlocuteur inspiré placer échange devenir première méthode expansion méthode intersections Votre interlocuteur collaborateur inspiré placer échange devenir seconde méthode expansion méthode complémentaires Votre interlocuteur collaborateur autrui personne inspiré placer échange approche alors appliquée partir corpus enrichi Notons liste porteurs compte richir contexte exemple chose personne Cette liste constituée manuellement évaluation présentée section suivante consiste comparer résultats obtenus automatiquement appuyant ExpLSA expert associé manuellement termes pertinents concepts Expérimentations discuter qualité résultats retournés notre approche appuyons protocole expérimental décrit section suivante Béchet Protocole expérimental expérimentations appuyons corpus Ressources Humaines pertisé manuellement cette expertise ressort classification conceptuelle ensemble termes extraits concepts ayant définis expert exemple expert défini concept Relationnel termes confrontation ouverte contact superficiel entourage compréhensif instances objectif expérimentations évaluer similarités entre termes retournées méthodes automatiques dessous méthode intersections ExpLSA méthode complémentaires ExpLSA Tagger méthode Tagger consiste utiliser étiqueteur grammatical Tagger Schmid comme approche Wiemer Hastings Zipitria présen section Ainsi appliquons corpus préalable étiqueté Tagger comparer méthodes avons évalué termes concepts avons sélectionné parmi concepts étant représentés concepts regroupant minimum termes distincts selon expertise manuelle laisse total quatre concepts proposons ainsi comparer chaque concept objectif expérimentations consiste évaluer appartenant concept correctement associés termes concept quatre méthodes décrites dessus effectuer telle comparaison termes concept compte similarité cosinus alors calculée entre ensemble termes concept autres termes concepts comparer exemple termes couples termes ainsi obtenus classés valeur décroissante quatre méthodes système retourne résultats bonne qualité couples pertinents placés début liste couple pertinent termes appartiennent concept évaluer qualité liste calculons précision premiers couples retrournés rappel ayant adapté5 précision permet évaluer proportion couples pertinents retrouvés système Notons réalisation expérimentations concepts assez conséquente puisqu produit calculs similarité Comparaison méthodes ExpLSA Cette première évaluation propose comparer méthodes ExpLSA utilisées enrichissement corpus méthode intersections méthode complé mentaires tableau compare moyenne précisions premiers couples termes seuil mesure Asium telle valeur faisons large expansion corpus tableau montre approches ExpLSA utilisant 4Nous utilisons logiciel Infomap mener expérimentations infomap sourceforge notre approche avoir couples pertinents placés début liste Cependant couples compte rappel naturellement faible nécessairement adapté évaluer performance notre approche 6Cette valeur établie correspond nombre raisonnable couples proposés expert Informations syntaxico sémantiques Précision fonction premiers couples termes ExpLSA méthode intersections ExpLSA méthode complémentaires méthode intersections celle complémentaires inférieures améliorent rarement précision résultats expliquent quantité importante données pertinentes utilisées enrichissement effet seuil faible tendance ajouter bruit comparativement utilisation seuil élevé permet expansion quantitativement faible souvent pertinente confirme résultats préliminaires présentés Béchet meilleur compromis entre quantité données ajoutées qualité celles experimentalement établi seuil notre corpus constatons ailleurs méthode donne globalement résultats faibles méthode toutes soient férieures table montre mêmes expérimentations table utilisant Précision fonction premiers couples termes ExpLSA méthode intersections ExpLSA méthode complémentaires Béchet tableau montre meilleurs résultats méthode améliore résultats trois trois obtient meilleure précision incluent concept Relationnel Relationnel sémantiquement proche autres concepts tière difficile identifier manière automatique exemple concepts Relationnel Comportement Attitude Ainsi considérer concept réveler tains ambigu notre méthode améliore expérimentations autres corpus exploitant concepts discriminants devront menées confirmer résultats Enfin figure confirme méthode complémentaires donne résultats moins bonne qualité rapport celle intersections conserverons uniquement méthode intersections prochaines expérimentations Nombre termes ExpLSA seuil Asium methode complementaire ExpLSA seuil Asium methode intersections Précision fonction premiers termes comparant méthodes propres ExpLSA concepts Comportement Attitude Environnement ExpLSA comparé méthode Tagger Précision fonction premiers couples termes ExpLSA méthode intersections Tagger Informations syntaxico sémantiques proposons comparer cette section méthodes utilisant connaissances syntaxiques ExpLSA Tagger Tagger consiste ajouter connaissance grammaticales corpus complétant étiquette grammat icale Cette approche permet lever ambiguités certains pouvant appartenir catégories grammaticales différentes exemple adverbe adjectif méthode considérons exemple trois formes distinctes représenter bien_ADV bien_NOM bien_ADJ figure montre méthode Tagger améliore résultats derniers couples correspond attentes utilisateur effet fonction général satisfaisante nombre important exemples positifs placés liste Cette tendance généralise autres concepts comme montre tableau méthode Tagger reste cependant presque toujours inférieure notre approche ExpLSA résultats encouragent envisager futurs travaux hybridation méthodes conserver résultats ExpLSA bénéficier améliorations méthode Tagger derniers couples Nombre termes ExpLSA seuil Asium methode intersections tagger Précision fonction premiers couples termes comparant méthode ExpLSA Tagger concepts Comportement Attitude environ nement Conclusion discussion méthode statistique utilisée notamment regrouper termes établir classification conceptuelle Néanmoins cette méthode donne résultats parfois vants expliquent entre autres absence connaissances linguistiques résultats également influencée taille contextes utilisés obtenant meilleurs résultats contextes grande taille pourquoi sommes intéressés travaux améliorer performances contextes assez courts phrases proposant approche ExpLSA consis effectuer expansion contextes avant appliquer rendons contextes riches utilisant outils syntaxiques parvenir Béchet avons présenté expérimentations comparer approche ExpLSA avons conclu première expérience ExpLSA fondée méthode complémen taires expansion réalisée était pertinente ajoutait quantité importante bruit ExpLSA utilisant méthode intersections donne quant résultats satisfaisants concepts discriminants point sémantique termes concepts générer ambiguités révelent moins difficiles traiter automatiquement notre approche inconvénient méthode ExpLSA nécessite temps cution conséquent environ heures traiter corpus temps important explique principalement durée execution tâche extraction relations taxiques seconde expérimentation montré Tagger améliore rarement notre approche ExpLSA donne meilleurs résultats envisageons comme futurs travaux approfondir expérimentations identifiant précisément quels ExpLSA donne meilleurs résultats comparativement permettra mettre place approche hybride utilise ExpLSA Tagger selon situations appropriées souhaiterions valider regroupement ExpLSA appuyant mesures statis tiques données numériques issues moteurs recherche Turney ailleurs proposerons autres méthodes ajouter connaissances syntaxiques validerons notre méthode expansion contextes confrontant problèmes classification textes envisageons enfin utiliser vecteurs mantiques SYGMART Chauché considérant terme comme produit ensemble concepts issus thésaurus Larousse Remerciements remercions Kodratoff Equipe France Serge Baquedano société PerformanSe travail expertise réalisé corpus ressources humaines Références Béchet Roche Chauché Improving expanding contexts Context Based Information Retrieval workshop CONTEXT Bourigault Analyse syntaxique locale repérage termes complexes texte Bourigault UPERY outil analyse distributionnelle étendue construc ontologies partir corpus Actes Nancy Bourigault Fabre Approche linguistique analyse syntaxique corpus Cahiers Grammaires Brill advances transformation based speech tagging Chauché outil multidimensionnel analyse discours Proceedings Coling Standford University California Cornuéjols Miclet Apprentissage artificiel Concepts algorithmes Eyrolles Informations syntaxico sémantiques Daille Approche mixte extraction automatique terminologie statistiques lexicales filtres linguistiques thesis Université Paris Faure Conception méthode apprentissage symbolique automatique acquisition cadres catégorisation verbes connaissances sémantiques partir textes système ASIUM thesis Université Paris Faure Nedellec Knowledge acquisition predicate argument structures technical texts using machine learning system ASIUM Proceedings European Workshop Knowledge Acquisition Modelling Management number Kanejiya Kumar Prasad Automatic evaluation students answers using syntactically enhanced Proceedings Human Language Technology Conference NAACL Workshop Building Educational Applications using Landauer Dumais solution plato problem latent semantic theory acquisition induction representation knowledge Psychological Landauer Laham Rehder Schreiner passage meaning derived without using order comparison latent semantic analysis humans Proceedings annual meeting Cognitive Science Society Rehder Schreiner Wolfe Laham Landauer Kintsch Using latent semantic analysis assess knowledge technical considerations Discourse Processes Volume Roche Chauché limites approche statistique Actes atelier Fouille Données Complexes conférence Roche Heitz Matte Tailliez Kodratoff système itératif extraction terminologie domaine partir corpus spécialisés Proceedings Volume Roche Kodratoff Utilisation comme première étape classi fication termes corpus spécialisé Actes conférence MAJEC MAnifestation JEunes Chercheurs domaine Schmid Improvements speech tagging application german Proceedings SIGDAT Workshop Dublin Turney Mining synonyms versus TOEFL ceedings Lecture Notes Computer Science Wiemer Hastings Zipitria Rules syntax vectors semantics Proceed Twenty third Annual Conference Cognitive Science Society Summary Latent Semantic Analysis nowadays various fields cognitive educational applications classification propose paper approach which grammatical knowledge Different methods studied finally perform conceptual classification