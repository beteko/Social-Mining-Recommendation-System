articles assemblage pdfDécouverte itemsets fréquents fermés architectures multicœurs Benjamin Négrevergne Alexandre Termier François Méhaut Takeaki Passerelle 38402 Saint Martin Hères France Benjamin Negrevergne Francois Mehaut Alexandre Termier liglab National Institute Informatics Hitotsubashi Chiyoda Tokyo Japan research Résumé papier proposons algorithme parallèle découverte itemsets fréquents fermés algorithme reconnu comme algorithme séquentiel efficace cette tâche présen aussi interface parallélisme simple puissante basée notion Tuple Space permet avoir bonne répartition dynamique travail Grâce étude expérimentale détaillée montrons algorithme suffisamment générique calculer efficacement fréquents fermés bases creuses bases denses améliorant ainsi Introduction découverte motifs fréquents domaines majeurs fouille données origine domaine trouvent travaux Agrawal Srikant découverte itemsets fréquents problème découverte itemsets fréquents consiste étant donné données transactions listes items seuil support minimal minsup découvrir itemsets apparaissent minsup données problème simple domaine découverte motifs fréquents comparativement recherche séquences arbres graphes fréquents Toutefois retrouve nombreuses applications particulier analyse données vente organisations commerciales relative simplicité toutes améliorations algorithmiques significatives découverte motifs fréquents abord réalisées itemsets fréquents avant adaptées motifs complexes ticulier fermeture Pasquier méthodes génération candidats workshop Goethals confronté algorithmes cherche itemsets fréquents déterminer meilleures solutions gagnant 2004b combine améliorations niveau issues théorie énumération optimisations niveau optimisant répartition entre Découverte itemsets fréquents fermés multicœurs temps calcul mémoire utilisée Depuis aucun algorithme séquentiel présenté meilleures performances Toutefois algorithmes séquentiels présentés capables ploiter potentiel parallélisme processeurs modernes effet depuis concep processeurs ordinateurs radicalement changé limites physiques teintes permettant augmenter fréquence horloge performances contre Moore toujours valable implique nombre transistors graver double permettre augmentation performances chercheurs constructeurs proposé solution mettre plusieurs cœurs calcul composant physique exploiter mieux cesseurs multicœurs impératif concevoir algorithmes parallèles lesquels choix algorithmiques faits algorithmes séquentiels nécessairement mieux adaptés objectif article présenter algorithme parallèle extraction itemsets fréquents fermés capable exploiter efficacement processeurs multicœurs ordinateurs actuels retrouve bureaux majorité chercheurs analystes données expériences focaliseront machines processeur multicœurs présentons nouvelle interface parallélisation basée notion Tuple Space Cette interface expose primitives implémenteur algorithme permet utiliser internes modèles efficaces distribution calcul présentons ensuite algorithme utilise cette interface paralléliser article suivant section définissons brièvement blème extraction itemsets fréquents fermés présentons extraction parallèle motifs fréquents multicœurs décrivons section méthode Tuple Spaces algorithme parallèle section présente étude expérimentale détaillée comparant Enfin section concluons dressons quelques perpectives travaux futurs principes extraction itemsets fréquents fermés cette section introduisons principales notations utilisées article définissons problème extraction itemsets fréquents fermés présentons ensuite Position problème ensemble items données transactionnelle ensemble chaque inclus appelé transaction ensemble appelé itemset itemset transaction contenant appelée occurrence notée tidlist ensemble occurrences tidlist appelé support encore fréquence également support seuil minimal support donné minsup itemset fréquent support minsup notera ensemble itemsets fréquents Négrevergne toute paire itemsets équivalents tidlist tidlist Cette relation partitionne itemsets classes équivalences itemsets inclusion chaque classe équivalence appellés itemsets fermés notera ensemble itemsets fréquents fermés problème intéresse étant donné donnée transactionnelle seuil support minimal minsup extraire itemsets fréquents fermés nombreux travaux menés années extraction parallèle motifs fréquents clusters Agrawal Shafer travaux concentrent capacité augmenter taille bases données traitées amélioration performances faisons mentionner focaliserons extraction parallèle motifs fréquents architectures multicœurs problématiques sensiblement différentes algorithme existant littérature extraction itemsets fréquents fermés proposé Lucchese stratégie parallélisme nique travail Blumofe Leiserson lorsqu thread beaucoup travail autre dernier voler partie travail premier thread rédui ainsi déséquilibre charge solution contient optimisations améliorer utilisation cache création bases données conditionnelles appellées projec tions article technique couramment utilisée extraction itemsets fréquents parallèle cette section expliquons modèle parallélisation avons adopté présentons algorithme Faute place invitons lecteur intéressé référer article 2004a explication algorithme séquentiel Modèle distribution calcul algorithme récursif appels structure arbre rithme présente qualités intéressantes parallélisation effet nœuds niveau peuvent calculés manière indépendante besoin synchronisation plexe problème extraction motifs fréquents général particulier itérations récursives temps calcul variables distribution tique travail engendrerait déséquilibre charge comme montré Lucchese Comme autres travaux proposons approche réparti dynamique travail Notre interface basée modèle Linda proposé Gelernter modèle threads communiquent biais espace mémoire parta appelé Tuple Space auquel peuvent ajouter retirer tuples primitives notre interface parallélisation simplement tuple tuple primitives assurent elles seules répartition dynamique travail tuples travail threads récupèrent primitive itération génère Découverte itemsets fréquents fermés multicœurs travail distribuer insérant tuples tuple space modèle distribution calcul depend manière organisés tuples tuple space capacités passage échelle programme utilisant tuple space dépendront gestion tuple space Notre implémentation tuple space stoque tuples bancs travail nombre threads utilisés avoir travail assigné chaque thread permet limiter contention moment appels primitives Chaque thread ajoute consomme tuples propre Lorsque thread tuple space donne tuples autre forme travail directement gérée tuple space transparente algorithme opérations synchronisation soient nécessaire cette architecture tuple space généralement contention plupart threads calculent tuples engendrés améliore utilisation cache Parallélisation tuple contient paramètres appel récursif parallélisa arbre appels récursif chaque appel récursif remplacé opération dépose tuple space tuple paramètres appel programme principal initialiser tuple space tuple contenant paramètres correspondant racine arbre appels récursifs démarre threads traite Chaque thread boucle récupère tuple procédure effectue appel fonction traitement paramètres correspondants limiter nombre tuple surcoûts gestion partir certaine profondeur arbre recherche appels récursifs traités directement créer nouveaux tuples Expériences comparons cette section MT_Closed Lucchese seule autre approche parallèle extraction itemsets fréquents fermés implémenta notre implémentation Cette implémentation partage implémentation originale entièrement réécrite utilisant Tuple Spaces Tuple Spaces écrite Posix Threads implémentation MT_Closed implémentation originale auteurs titre référence avons également comparé temps calcul implémentation séquentielle expériences menées Intel processeur cœurs bases données utilisées bases fournies workshop disponibles workshop Goethals avons fectués tests toutes bases manque place reportons résultats données dense accidents données creuse T10I4D100K résultats présentés Figures terme temps calcul speedup pouvons remarquer données dense MT_closed présente meilleurs temps exécution explique MT_closed utilise Négrevergne nombre threads accidents temps sequentiel Closed Execution nombre threads accidents speedups Closed Speedup Résultats accidents dense nombre threads T40I10D100K temps sequentiel Closed Execution nombre threads T40I10D100K speedups Closed Speedup Résultats T10I4D100K creux représentation bitmap transactions efficace bases données denses améliorer encore cette efficacité MT_Closed utilise instructions processeur faire calculs bitmaps après expériences Lucchese amener speedup contre présente aussi bonnes capacité passage échelle MT_Closed bases données revanche bases données creuse minimum ordres rapide MT_Closed Cette différence différences algorithmiques entre MT_Closed itemsets fréquents fermés données comme linéaire fonction nombre itemsets fréquents fermés temps exécution faible Notre stratégie parallélisation permet profiter pleinement avantage terme complexité théorique MT_Closed exploitant performances processeur multicœur Conclusion perspectives avons présenté article interface simple parallélisation algorithmes algorithme utilise cette interface paralléliser algorithme intérêt méthode parallélisation présentons générale appliquée autres algorithmes extraction motifs fréquents Découverte itemsets fréquents fermés multicœurs expériences bases données référence domaine montré notre algorithme donnait résultats aussi bases données creuses bases données denses améliorant ainsi prévoyons intéresser machines multi processeurs multicœurs passer échelle cœurs machines nouveaux problèmes apparaissent particulier saturation entre mémoire cœurs Références Agrawal Shafer Parallel mining association rules Trans Knowl Agrawal Srikant algorithms mining association rules Proceedings Conference Blumofe Leiserson Scheduling multithreaded computations stealing Gelernter Multiple tuple spaces linda Goethals repository website helsinki Mining frequent patterns without candidate generation SIGMOD Proceedings International Conference Management Lucchese Orlando Perego Parallel mining frequent closed patterns Harnessing modern computer architectures Pasquier Bastide Taouil Lakhal Efficient mining association rules using closed itemset lattices Information Systems Uchida Arimura 2004a efficient algorithm enumerating closed patterns transaction databases Discovery Science Kiyomi Arimura 2004b Efficient mining algorithms frequent closed maximal itemsets Parthasarathy Ogihara Parallel algorithms discovery association rules Knowl Discov Summary paper present parallel algorithm discovering closed frequent based algorithm recognized efficient serial algorithm present simple powerfull parallelism interface based concept Tuple Space which allows efficient dynamic sharing Thanks detailed experimental study algorithm which generic enough compute efficiently closed frequent itemsets sparse dense databases improving state