Développement système recommender distribué utilisant framework Hadoop Chiky Renata Ghisloti Zakia LISITE Notre Champs 75006 Paris firstname lastname Résumé production recommandations haute qualité devenue dernières années effet croissance quantité données impliquées processus recomman dation problèmes évolutivité efficacité questions encouragé recherche nouvelles technologies dévelop nouveau système recommender améliorons méthode existante cadre était considéré fonction qualité connue simplicité projet MapReduce projet Source Hadoop fondamental cette recherche aucun doute encouragé facilité construction notre application fournissant outils nécessaires Notre principal objectif cette recherche était prouver construction système recommender distribué était seulement possible simple productive Introduction quantité informations considérablement augmenté cours dernière décennie nomène favorisé avancée systèmes recommender domaine recherche systèmes recommandations fournit recommandations personnalisées aident utilisateurs gesting objets utiles traitant généralement quantités énormes données Amazon exemple intégré systèmes recommender personnaliser boutique ligne chaque utilisateur enregistré millions utilisateurs plusieurs millions articles catalogue Linden nombreux systèmes recommender approches développées cours dernières années quantité considérable entre construits évalués petits ensembles données outre volume informations considérablement augmenté cours dernières années plusieurs systèmes recommender souffrent problèmes performance évolutivité lorsqu traitent ensembles données importants Notre principal objectif article décrit méthode surmonter éventuellement problèmes proposons système recommender distribué avons intention démontrer pourrait facilement développé présenter résultats avons choisi pente Lemire Maclachlan comme algorithme recommender étudions projet MapReduce Ghemawat construire système distribué Développement système recommender distribué utilisant framework Hadoop MapReduce cadre place Google supports calcul distribué grande quantité données cluster ordinateurs implémentation source travail disponible CADRE Apache Hadoop avait projet article décrivons processus adaptation algorithme recommender choisi plate forme Hadoop vérifions performances comparant version distribuée méthode autonome reste article organisé comme section décrit section présentons approche globale construction système recommender distribué section présente étude expérimentale résultats Enfin section conclut article donne perspective recherches actuelles futures domaine Contexte pente pente OneLemire Maclachlan moyen simple efficace algorithme recommender Introduit Daniel Lemire Maclachlan implique simple plupart autres implémentations filtrage collaboratif calculent généralement similitude entre vecteurs éléments utilisant cosinus méthodes Pearson approche Slope recommande articles utilisateurs fonction différence moyenne préférences articles principale algorithme créer relation linéaire entre préférences éléments relation Slope vient multiplié calcule essentiellement différence entre évaluations éléments chaque utilisateur chaque élément utilisateur évalué alors différence moyenne chaque paire éléments faire prédiction article utilisateur exemple obtiendrait évaluations utilisateur donné autres éléments ajouter différence entre chaque élément pourrions obtenir moyenne utilisateur donné point différence entre cotes point point supposant avons éléments prédiction utilisateur pourrait donner article donnée dessous présentons version pseudo algorithme divisé parties traitement phase prédiction phase traitement calcule différence entre toutes valeurs préférence élément élément chaque élément autres éléments chaque utilisateur notation ajouter différence moyenne Ghisloti phase prédiction chaque élément classé utilisateur chaque élément trouver ajouter cette retour éléments prédit termes exécution phase coûteuse celle prétraiter précalculée algorithme intéressante partie ligne phase prédiction rapide temps fonctionnement dépend nombre utilisateurs dépend principalement différence moyenne entre chaque paire éléments Supposons ayons utilisateurs éléments calcul différences moyennes pourraient prendre jusqu temps stockage matrice aussi coûteux prendre jusqu unités stockage Approche MapReduce cadre place Google traiter quantités données larges cadre utilise fonction simple dérivée carte communément appelé réduire utilisés programmation fonctionnelle exemple divise principal problème petits problèmes distribuer groupe ordinateurs combine ensuite réponses problèmes obtenir réponse définitive premier carte reçoit ensemble paires valeur produit paire intermédiaire valeur sortie Ensuite valeurs triées cadre regroupés manière toutes valeurs appartenant ensemble fonction combinaison Ainsi entrée réduire avons fournie carte liste valeurs correspondantes données ensuite traitées réduction produit signal sortie final données entrée primaire coupé cadre aussi responsable vieillissement transition données intermédiaire utilisateur reste tâche définir interfaces entrée sortie fournir carte réduire fonctions cette avons commencé identifier format entrée créer notre propre MapReduce pente méthode format décidons utiliser typique format texte utilisateur identification utilisateur ItemID identification article utilisateur élément pente phase traitement divisé parties première lorsque calculées articles diffs chaque utilisateur deuxième partie diffs chaque paire éléments ajoutés ensemble créer différentiel moyen entre éléments Notre approche suivante abord données entrée divisé manière indépendante regrouper évaluations éléments utilisateurs Ensuite diffs utilisateur calculé Après diffs intermédiaires serait calculer moyenne chaque paire éléments fondant cette méthode processus séparés MapReduce créés divise entrée blocs indépendants calcule point diffs utilisateur autre avoir listes éléments calcule overa entre éléments point système recommender distribué utilisant framework Hadoop premier présente MapReduce carte reçoit entrée origine produit ensemble valeurs intermédiaires contenant chaque ligne fichier entrée utilisateur élément relatives valeurs triées cadre réduire reçoit utilisateur comme liste éléments notes Réduire calcule diffs entre chaque paire éléments certains utilisateurs retourner sortie deuxième carte serait fonction identité signifie valeur donnée entrée donnée sortie autre réduire secondaire recevrait comme paire élément itemi itemj valeurs liste diffs cette paire éléments serait simple question calcul moyenne chaque paire éléments aurait comme résultat liste finale chaque paire éléments contenant moyennes diffs évaluation expérimentale essais expérimentaux ensemble données utilisé celui fourni MovieLens MovieLens système recommender films utilisateurs reçoivent recommandations fournit actuellement trois paquets données poing notes films utilisateurs second million évaluations films utilisateurs troisième paquet millions évaluations 10681 films 71567 utilisateurs cotes représentent notes donnant utilisateurs MovieLens films variant aimer vraiment aimer fichiers contiennent informations UserId ItemId format article utilisons million millions paquets notation assurer exactitude demandes utilisé données essai forgé petit groupe utilisateurs permettre comparaison claire simple résultats ensemble données contient utilisateurs articles notes machines maître esclave expériences mêmes spécifications matériel caractéristiques suivantes processeur Intel disque fonctionne Ubuntu Linux utilisons maître esclaves expérimentation entièrement distribuée première étape cette procédure expérimentale était exécution chaque approche SlopeOne chaque ensemble données Ensuite résultats sortie comparés vérifier résultats correspondants Enfin temps exécution approches comparées analysées tests réalisés phases chaque ensemble données chaque phase compare temps exécution millisecondes entre chaque pente approche autonome pseudo distribuée entièrement distribué uniformité résultat final première expérience petites données forgées sortie trois approches comparées notre résultat correcte trois présenté sortie correcte prouve exactitude algorithmes générer temps exécution finale chaque approche exécutée trois suite résultat présenté figure moyenne trois exécutions deuxième phase expérimentale testé ensemble données million MovieLens encore trois approches exécution comme dessus moyenne trois exécutions simples resuls donnée figure Enfin dernière phase testé ensemble données millions MovieLens opération autonome mesure traiter cette quantité données présentant exception OutOfMemoryError autres approches réussi terminer tâche Ghisloti Temps Temps Temps temps Exectution trois ensembles données présente temps exécution moyen représenté figure analyse résultats figure possible noter seulement partir certain point devient raisonnable utiliser Hadoop Comme chaque cadre fournit couche abstraction exécution cadre initial testant premier deuxième ensemble données visible poids exécution Hadoop était grand avantages pourrait apporter conséquent durée fonctionnement méthode autonome était petite autres approches pensé avaient threads nœuds informatiques travail troisième scénario pouvons approche entièrement distribuée surmonte celui distribué pseudo raison possible pseudo faire mieux autres scénarios impliqué établissement cluster distribué augmentation quantité données avantages cluster distribué différence fourni performance rapide Notre principal objectif cette recherche était vérifier approche distribuée vraiment apporté tages recommender Vérification résultats finaux clair petit ensemble données telles inférieur million évaluations méthode autonome meilleure approche Cependant prouvé lorsqu grandes quantités données framework Hadoop solution réalisable Lorsque volume données croît entièrement distribué meilleure performances indiquées autres méthodes méthode autonome mesure effectuer troisième scénario pouvait donner résultat Conclusion systèmes confrontés Recommender important lorsqu traitent énorme quantité données article notre objectif principal résoudre problème décrivant développe facile système recommender distribué possible utilisant outils puissants source Hadoop MapReduce œuvre slopeone efficace algorithme collaboration recommender simplicité pente ajoutée structure forte offerte Hadoop permis compléter notre tâche résultats montré effet cadre distribué donner résultats espérons encouragé intérêt domaine recherche Notre travail futur analyser autres types algorithmes recommandation étudier possibilité rendre efficaces grands ensembles données utilisant Hadoop autre avalaibe CADRE Développement système recommender distribué utilisant framework Hadoop fonctionne Nicolae envisageons également envisager distribution générique algorithmes recommandation nécessite aucun effort réécriture Références Apache Hadoop hadoop apache GroupLens architecture ouverte filtrage collaboratif Netnews MovieLens ensemble données grouplens Ghemawat MapReduce simplifié traitement données grands clusters Lemire Maclachlan pente ligne Prédicteurs basée laboration oration Filtrage Proceedings Mining Linden Smith recommandations Amazon Point point filtrage laborative Volume Nicolae Moise Antoniu Bougé Dorier BlobSeer Apporter débit lourd Concurrency Hadoop Carte reduce Applications parallèle International distribué Symposium traitement IPDPS Atlanta États information LeWeb bureaux AUGMENTE Dernières Années phénomène progression favorisé recherche domaine Systèmes recommendation intention Ontario Aider fournissant Utilisateurs suggestions Utiles proposons papier algorithme UTILISER recommendation favoriser existant montée charge verser utilisons cadre développement Hadoop propose Paradigme MapReduce Implémentation répartition Traitements Notre principale jectif papier construction prouver Système recommendation Distribué possible simple Bénéfique