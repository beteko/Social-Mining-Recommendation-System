EGC04 dviAcce ration donne qualitatives comparative diffe rentes versions Mohamed Nadif Franc Xavier Jollois Universite Saulcy 57045 Cedex France jollois nadif algorithme populaire efficace mation parame lange inconve nient majeur algorithme lenteur convergence application tableaux grande taille pourrait ainsi prendre norme temps proble tudions comportement plusieurs variantes connus ainsi nouvelle thode Celles permettent convergence algorithme obtenant sultats similaires celui travail concentrons aspect classification alisons comparative entre diffe rentes variantes donne simule elles proposons strate utilisation notre thode efficace Introduction utilisation lange classification devenue proche classique puissante exemple Banfield Raftery Celeux Govaert traitant classification cette approche rithme Dempster compose tapes Estimation Maximi sation devenu quasiment incontournable Celui populaire estima parame Ainsi nombreux logiciels cette approche comme Mclust EMclust Fraley Raftery EMmix McLachlan Biernacki succe tient simplicite proprie oriques comportement pratique grandissant ressen actuellement donne qualitatives citer logiciel AutoClass Cheeseman Stutz utilise communaute Fouille Donne Malheureusement principal inconve nient lenteur nombre rations parfois cessaire convergence utilisation inapproprie donne grande taille Plusieurs versions faites algorithme beaucoup entres elles agissent maximisation comme ressons classes latentes maximi sation sente aucune difficulte calcul parame avons choisi tudier versions particulie rement adapte donne grande taille utilisent partielle estimation Estimation comple Cette version semble efficace langes Gaussiens proposons appliquer lange classes latentes discuter comporte ration donne qualitatives lange algorithme approche lange individus classifier provenir lange densite proportions inconnus Ainsi chaque objet alisation densite probabilite crite repre sente densite parame vecteur parame estimer compose duisons vraisemblance vecteur donne suite allons aborder proble classification approche estimation parame abord estime partition duite thode maximum posteriori estimation parame passe maximisation solution rative solution proble algorithme Dempster principe algorithme maximiser manie rative rance vraisemblance comple conditionnellement donne valeur parame courant probabilite conditionnelle posteriori Chaque ration tapes Estimation calcule notons contexte lange cette calculs Maximisation cherche parame maximise Donne qualitatives classes latentes principe classes latentes propose Lazar Henry supposition variable qualitative latente modalite donne associations entre chaque paire variables paraissent variable latente constante basique analyse classes latentes hypothe fondamentale pendance locale Cette pothe courament choisie quand donne qualitatif binaire Celeux Govaert Cheeseman Stutz Ainsi densite observa crire comme Nadif Jollois chaque attribut qualitatif nombre modalite modalite variable observe sinon hypothe pendance locale permet estimer parame parement Cette hypothe simplifie grandement calculs principalement quand nombre variables grand cette affirmation toujours fausse donne elles pendance locale ralement performante classification paradoxe explique Domingos Pazzani ration Incremental algorithme Incremental Hinton variante destine duire temps calcul alisant tapes Estimation partielles partition donne blocs disjoints propose utilisateur rapport taille blocs demande utilisateur pourcentage taille initiale algorithme parcourt blocs cyclique chaque ration probabilite poste riori Estimation dessous ration Estimation cette retient probabi posteriori toutes observations appartenant quant autres observations appartenant autres blocs avons rance conditionnelle associe quant celles associe autres blocs elles restent inchange Autrement globale cherchera maximiser maximisation crire Maximisation cherche comme algorithme classique parame maximise cette chaque observation visite tapes estima partielles approximation vraisemblance chaque ration justification orique algorithme faite Hinton cemment avons tudie comportement lange Bernoulli Jollois Nadif Enfin notons lorsque ration donne qualitatives Sparse algorithme Sparse introduit Hinton minimise Estimation choissisant calculs effectuer partir seuil contrairement cherche probabilite posteriori petites rieur certain seuil recalcule pendant certain nombre rations individu faible probabilite appartenance classe chance devenir grande seule ration probabilite bloque pendant certain temps recalculer cours ration standard algorithme comme Estimation standard Calculer probabilite posteriori Identifier yisparse comme ensemble classes ignorer durant tapes sparse chaque sparse cette calcule probabilite posteriori toutes classes appartenant blocs yisparse Seule rance condition nelle associe ysparse Qsparse Autrement quantite globale cherchera maximiser maximisation celle quation remplacant Qsparse Maximisation cherche comme algorithme classique parame maximise algorithme ration standard effectue nombre nsparse ration Estimation sparse revenir ensuite ration standard ainsi suite jusqu convergence Ayant objectif dentes thodes rithme Thiesson cherche duire temps Estimation cherche identifier gulie rement individus impor tants porter attention plusieurs rations individu conside comme important changement probabilite entre rations successives grande Notons ylazy ensemble significatif ylazy ensemble restants Suivant roulement similaire chaque ration requiert Estimation standard Estimation suivi ensuite Maximisation standard comple calcule individus probabilite posteriori tablit liste individus importants partie probabilite posteriori Estimation standard Calculer probabilite posteriori Identifier ylazy comme ensemble individus ignorer durant tapes cette calcule probabilite posteriori toutes observations appartenant ylazy quant autres obser vations appartenant ylazy avons Seule rance Nadif Jollois conditionnelle associe ylazy Qlazy Autrement quantite globale cherchera maximiser maximisa celle quation remplacant Qlazy Maximisation cherche comme algorithme classique parame maximise roulement ration standard suivie nlazy rations dites jusqu convergence algorithme viabilite algorithme partiellement toutes donne importance aussi calcul terminer importance chaque individu stockage garder cette information lange peuvent grandement duits voire simplement supprime stockage crite portance derrie crite suivante individu forte probabilite appartenir classe approprie assigner autre fallait serait soudainement pluto progressivement Ainsi supposons observations fortement classe contribuent volution parame individus conside comme importants toutes probabilite appartenance rieures certain seuil monstration Hinton convergence algorithme justifie oriquement applicable chaque coupage arbitraire dividus moment visite gulie rement diffe rences Thiesson carter certain nombre vidus conside comme important calculs Cette notion importance rapporte volution probabilite posteriori effet individu montre volution importante entre tapes priori stable fortes chances rester moment prend cision carter calculs prendre compte pendant certain nombre rations contraire volution significative ressant garder calculs partir nouveau proble Comment terminer individu volue significativement avons choisi mesurer diffe rences entre probabilite posteriori avant Estimation standard remet individus cisement comparons moyenne valeurs absolues diffe rences chaque classe seuil avons teste plusieurs valeurs seuil apparu celui grand ralement dessus algorithme individus automatiquement cette raison riences tests seront alise seuil rieur ration donne qualitatives sultats Donne simule comparer diffe rentes thodes ration avons lance algorithmes donne simule avons choisi tableaux parame avons simule donne moyennement lange environ observations classe tableau suivant capitulons parame choisis chacune thodes utilise thode Parame Taille blocs ration Seuils tableau crivons meilleurs sultats ainsi moins chaque valeur sultat ressante temps Coefficient ration classe chaque thode moyenne tableaux figures sentons rations moyennes pourcentages moyens classe chaque thode respectivement fonction parame choisis clair montre rapide minimum algorithme toujours rapide toutes autres thodes parfois moins terme pourcentage classe quation entre partition simule celle obtenue remarque notre thode encore stable proche population classe contre montre moins performant trouvant jamais partition proche celles regardons sultats fonction parame choisis chaque thode ressort ments suivants petit seuil quelque nombre important rations sparse ailleurs performant partition surtout rations grosses rations seuil important proche nombres rations choisis Malheureusement cette ration effectue triment qualite partition obtenue semble rable choisir seuil faible risque aller obtient meilleures rations seuil entre assez grand cette thode principalement ration parame obtient partitions assez proches celles simule Nadif Jollois meilleur moins sultat chaque thode ration algorithme moyennes tableaux simule thode sultat Parame sultat Parame 83720 83720 83616 83721 83688 83731 83610 83703 83620 83915 Coefficient ration Pourcentage classe Coefficient ration moyen gauche pourcentage donne classe moyen droite algorithme tableaux simule seuil nombre ration sparse ration donne qualitatives Coefficient ration moyen gauche pourcentage donne classe moyen droite algorithme tableaux simule fonction seuil nombre ration Coefficient ration moyen gauche pourcentage donne classe moyen droite algorithme tableaux simule seuil nombre ration Coefficient ration moyen gauche pourcentage donne classe moyen droite algorithme tableaux simule fonction taille blocs choisie pourcentage population Nadif Jollois rapide lorsque taille blocs blocs taille blocs rieure ralentit algorithme ralen tissant obtient meilleurs sultats premiers sultats semble thode proprie performante terme ration partition obtenue notre thode allons maintenant donne elles confirme Donne elles avons teste thodes ration algorithme tableaux donne elles Congressional Votes Titanic Mushroom sentons suite Sachant algorithmes solution fortement initialisation lancons chaque algorithme parame trage diffe rentes thodes avons utilise teste paragraphe avons choisi retenir essai thode rapide performante terme partition avons aussi teste utilisation notre thode consiste prendre comme parame ration seuils puisque utilisons seuils lancons algorithme chacun seuils teste retenons solution fournissant maximum Congressional Votes tableau comprend votes chacun repre tants congre ricain votes diffe rents sujets handicap religion immigration ducation chaque trois ponses prises compte contre abstention individus classes distinctes mocrates publicains Titanic tableau adulte enfant classe premie deuxie troisie quipage personnes sentes Titanic naufrage pleine naufrage rescape accident tableau donne obtenu partir exemples Genbank plusieurs utilise articles apprentissage automatique contient observations chacune crites variables repre sentant nucle otides toutes modalite possibles observations parties classes intron parfois nomme donneurs objets Congressional Quarterly Almanac Congress session Volume Congressional Quarterly Washington homepage genbank ration donne qualitatives intron parfois nomme receveurs objets autre objets partir tableau selon indications apporte ateurs donne avons choisi retenir variables repre sentent nucle otides proches jonction Mushroom tableau donne obtenu Machine Learning Repositery contient descriptions champignons variables nominales couleur forme taille habitat partis classes Comestible champignons inconnu conside comme potentiellement dangereux Donne thode Parame Temps Coefficien ration classe Votes Titanic 82507 82507 82507 82507 82513 82512 Mushroom 150988 19028 150995 150986 151138 151189 151089 Comparaison diffe rentes thodes ration initialisation donne elles tableau simule signifie utilise seuils ration sultats sente tableau Titanic notre thode rapide fournissant sultats mlearn MLRepository Nadif Jollois toutefois tableau Titanic vraisemblance obtenue proche celle obtenue contrairement sultats notre thode obtiennent seuils diffe rents selon tableau ainsi nombre rations variant contre utilisant notre strate utilisation remarque ration propose pluto ressante proche celle obtenue seuil sultats toujours semble ressante utiliser viter utilisateur choisir seuil nombre ration Conclusion avons sente plusieurs variantes algorithme permettant convergence basant entre elles avons propose nouvelle thode reposant volution probabilite posteriori chaque dividu entre tapes limiter nombre calculs Malheureusement chaque algorithme sente cessite choix nombre blocs choix seuil nombre rations choix semble difficile effectuer priori pourquoi avons propose strate ressante utilisation Celle utilise plusieurs seuils nombre rations toujours avons valide donne elles performante rences Banfield Raftery Banfield Raftery Model based gaussian gaussian clustering Biometrics Biernacki Biernacki Celeux Govaert Langrognet Mixmod performance model based cluster discriminant analysis fcomte MIXMOD index Celeux Govaert Celeux Govaert classification algorithm clustering stochastic versions Computational Statistics Analysis Celeux Govaert Celeux Govaert Gaussian parcimonious clustering methods Pattern Recognition Cheeseman Stutz Cheeseman Stutz Bayesian classification class Theory results Fayyad Piatetsky Shapiro Uthurusamy editors Advances Knowledge Discovery Mining pages Press Dempster Dempster Laird Rubin Mixture densities likelihood incomplete algorithm Journal Royal Statitical Society Domingos Pazzani Domingos Pazzani Beyond independence Conditions optimality simple bayesian classifier Machine Learning ration donne qualitatives Fraley Raftery Fraley Raftery Mclust Software model based cluster discriminant analysis Technical Report University Washington Jollois Nadif Jollois Nadif algorithme donne naires thodes Perspectives Classification pages Neucha Suisse septembre Lazarfeld Henry Lazarfeld Henry Latent Structure Analysis Houghton Mifflin Boston McLachlan McLachlan guide emmix version Technical report University Queensland Hinton Hinton algorithm justifies incremental sparse other variants Jordan editor Learning Graphical Models pages Thiesson Thiesson Heckerman Accelerating large databases Technical Report Microsoft Research Summary algorithm popular efficient method estimation mixture model parameters major inconvenient convergence application large databases spend unsuitable order solve problem study known variants propose novel allows speed convergence algorithm obtain similar results focus clustering aspect perform comparative study between variants simulated Finally propose interesting strategy method called which seems efficient