result 5nnSlimBaseline epsUnsupervised Video Correction System Hoang Elisa Fromont Francois Jacquenet Baptiste Jeudy Adrien Martins Laboratoire Hubert Curien Professeur Beno√Æt Lauras 42000 Saint Etienne hoang elisa fromont francois jacquenet etienne baptiste jeudi adrien martins etienne Abstract present system video tagging which recting completing provided users videos uploaded Internet Unlike existing systems learn classifiers questionable textual information compare videos propose compare directly visual content videos described different features visual Words frequent patterns built propagate between visually similar videos according frequency these given video neighborhood propose controlled exper imental evaluate system Experiments suitable features correct reasonable amount videos Introduction Classic based search engines already offer access multimedia contents online world However cannot index extensive number online videos unless these videos carefully annotated before being However provided notations often incorrect irrelevant video increase video number views incomplete overcome these drawbacks focus automatic system improve annotations videos There already efforts automatically annotate videos Morsillo However proposed systems limited concepts supervised formation learn classifiers video dataset These approaches inappropriate video large website Youtube where number possible unlimited where labels inaccessible priori would propose unsupervised approach based comparison visual content videos propagate neighbor videos based their textual frequency proach scientific locks reside choice features relevant unsupervised comparisons comparison method itself propagation process evaluation entire system review related works concerning above mentioned problems briefly given Section Section describe details apply mining techniques proposed method compare videos experiments presented Section conclude Section Unsupervised video correction system General framework related Finding relevant features first process decompose video sequence keyframes using example Zhuang scribe video based frames Different features usually suited different tasks current trend computer vision concatenate different kinds level tures dimensional vector subsequently solving vision tasks distribution histograms color moments wavelet texture color autocor relograms Moxley Histograms Oriented Gradient audio features global color histograms Gabor wavelets Morsillo Another popular technique construct visual Words level feature vectors However using visual content compare videos above mentioned features might discriminative enough Frequent pattern mining techniques often computer vision munity better features Sivic Zisserman recently Fernando Those approaches often class information select compact relevant features output mining algorithms Computing similarities between videos though video considered sequence images variations videos duration number keyframes difficult compare first method consists taking average frames histograms Toderici produce single description whole video histogram thresholded remove potential noise classical distance functions estimate similarity between videos method efficient loses available information averaging frames second approach consists comparing pairs keyframes computing similarity between similar frames videos Moxley comparison videos using unique frames sequential information taken account makes common identical frames different terms formatting viewpoints camera parameters called duplicate compare videos These duplicate found videos propagation procedure video tagging systems learn multiple classifiers propagation needed However duplicate based method presented propagation procedure which based video possible relevant obtained similar videos using nearest neighbor algorithm After score function applied estimate relevance according given video score function depends frequency number associated video video similarity Finally score greater threshold considered suitable video Improvement proposed tagging system Proposed features explained Section possible features describe video crucial point relevant propagation process propose constructed descriptors obtained regularly keyframe video level features pattern mining algorithm extract better called level features compare videos algorithms proposed literature input binary vectors explained Fernando binarization original carefully propose simple equal discretization number equal visual transform original histogram binary vector Besides mining techniques output number patterns exponential number dimensions binary vectors Those patterns filtered using supervised information shown Fernando However supervised information available different criteria proposed decided algorithm Smets Vreeken algorithm optimize criterion based Minimum Description Length reduce number output patterns compress employs simple accurate heuristic estimate adding candidate output pattern frequent patterns obtained using build binary vector keyframe vector pattern appears keyframe otherwise Since number patterns still large Principal Component Analysis reduce dimension vector Finally vector describing keyframe either histogram vector patterns reduced these vectors concatenated Proposed asymmetrical video similarity measure first method consists calculating pairwise similarities between keyframes videos compute average maximum similarities corresponding video other words keyframe video search keyframes video highest pairwise matching score record value compute average recorded values keyframes video return similarity score video towards video denote keyframe number keyframes similarity between frames inverse distance between vectors representing frames Experiments first performed series experiments image datasets assess interest ingness frequent patterns features different distances method output pattern histogram space these experiments reported showed frequent patterns interesting features compared simple words carefully chosen distance distance measure compare dimensional vectors describing video better usual intersec kernel computer vision compare histograms where enough components explain variance reducing dimensionality feature vectors without damaging accuracy Unsupervised video correction system percentage noise introduced Added noise percentage noise introduced Averaging Threshold Frequent Pattern Result correction algorithm video dataset synthetic right using features frequent patterns second series experiments proposing experimental protocol evaluate propagation method first videos dataset taken benchmark dataset YouTube videos video decomposed keyframes There about keyframes video dimension vocabulary video represented matrix which contains keyframes video visual histogram which describes frame dataset reasonably small assess manually interest original propagated video videos chosen belong topics ensure dataset contains pairs similar videos pairs dissimilar videos manually videos results dataset conclusive created synthetic dataset videos built different videos previous dataset cases interested evaluating frequent pattern based features compared based features propagation video dataset triple where videos possible relation video evaluation procedure noise choose noise proportion compute noisy function tagnoisy probability tagnoisy value given probability apply correction technique output correction tagcorr compute proportion incorrect after correction tagcorr tagcorr ideal tagcorr Notice tagnoisy means tagcorr there incorrect noisy after propagation before error tagcorr against value curve below diagonal state algorithm decreased number incorrect Results dataset applied evaluation procedure videos dataset presented beginning section averaged results noise level results presented almost noise level number incorrect higher after correction algorithm before These errors result correction algorithm computed distance between videos reflect similarity videos particular number videos quite small dataset millions videos nearest neighbors given video should similar small dataset similar Another problem themselves algorithm visual similarity between videos correct efficient correlated visual content Results synthetic dataset maximum number dataset means adding noise dataset values flipped dataset added removed build synthetic video choose randomly between videos video dataset choose randomly frames chosen videos frames obtained synthetic video synthetic video contains frames video contains frames video synthetic video therefore between possible construction synthetic videos share instance means contain similar frames extracted video Moreover construction associated visual content video therefore avoid problem encountered dataset noise level between right proportion incorrect significantly decreases instance noise level error proportion after correction around algorithm removed about quarter errors introduced noise higher level noise number incorrect large expect improving results propagation Analysis results Although giving promising results propagation shown right series experiments video datasets questions fulness pairwise video comparison method proposed level frequent pattern features Indeed results using pairwise comparison introduced Section similar obtained using simple averaging frames although later efficient compute shows frequent patterns built using algorithm improve comparison compared simple features bination feature vectors gives similar results which shows videos contrary images patterns computed algorithm additional information compared which built Conclusion presented complete unsupervised tagging system which corrects pletes original videos system seems effective especially number videos dataset sufficiently relevant enough neighborhood video However proposed features pairwise video comparison procedure improve results compared baseline methods future account sequential information video create better level features account spatial position features frames scalability proposed system tackle larger datasets Unsupervised video correction system References Zhang Zhang benchmark dataset video analysis Technical report Fernando Fromont Tuytelaars Effective frequent itemset mining image classification European Conference Computer Vision Distinctive image features scale invariant keypoints International Journal Computer Vision Morsillo Youtube scale large vocabulary video annotation Video Search Mining Volume Studies Computational Intelligence Springer Moxley Manjunath Video annotation through search graph reinforcement mining Transactions Multimedia Multimedia tagging present future Proceedings international conference Multimedia Sivic Zisserman Video mining using configurations viewpoint invari regions Computer Vision Pattern Recognition Smets Vreeken Directly mining descriptive patterns Inter national Conference Mining Jiang Hauptmann Evaluating visual words resentations scene classification International workshop multimedia information retrieval Toderici Discriminative learning youtube videos latent Computer Vision Pattern Recognition Mining discriminative occurrence patterns visual recognition Computer Vision Pattern Recognition annotation videos efficient duplicate search Transactions Multimedia Zhuang Huang Mehrotra Adaptive frame extraction using unsupervised clustering Image Processing R√©sum√© proposons nouveau syst√®me marquage automatique vid√©os visant corriger compl√©ter automatiquement fournis utilisateurs ligne nouvelle vid√©o internet contraire syst√®mes existants d√©cidons utiliser information textuelle possiblement fausse fourni utilisateurs techniques apprentissage supervis√© baser d√©cisions comparons directement contenu visuel vid√©os basant attributs discriminants appris √©tape fouille motifs fr√©quents papier d√©crit √©galement m√©thode simple propagation entre vid√©os visuellement proches protocole exp√©rimental permettant √©valuer notre approche