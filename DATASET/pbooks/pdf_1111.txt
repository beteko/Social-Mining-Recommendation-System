Apprentissage supervisé classification images structure Najeh Naffakhi Khaled Mellouli LARODEC Carthage Présidence Tunisie Khaled Mellouli LARODEC Tunis Bardo Tunisie Najeh Naffakhi Résumé problème important production automatique règles classification concerne durée génération règles effet algorithmes œuvre produisent souvent règles pendant certain temps assez proposons nouvelle méthode classification partir données images Cette méthode situe jonction techniques algèbre arbre décision accélérer processus classification recherche grandes bases images modélisation proposons descripteurs visuels couleur forme texture indexer images autre génération automatique règles classification nouvel algorithme valider notre méthode avons développé système baptisé implémenté confronté application réelle domaine traitement images résultats expérimentaux montrent cette méthode réduit efficacement temps classification Introduction caractérisation classes classification importants domaines recherche fouille données apprentissage objectif extraction triviale informations utiles potentielles connues avance partir données structurées objectif difficile atteindre lorsqu devant données multimédia applications actuelles traitent plutôt bases données structurées extraction connaissances issues données multimédia images signaux séquences vidéo devient recherche actif notamment traitement informations recueillies recherches intéressons aspects problème complexe celui extraction connaissances partir données images documents images comme caractéristique principale manque langage permettant exprimer sémantique résulte grande difficulté proposer systèmes classification recherche partir images Chahir Apprentissage supervisé classification images structure Notre travail inscrit précisément domaine recherche générer règles production réduire considérablement temps classification exemple avons utilisé images fraise images représentées ensemble couples attribut valeur cette étude proposons nouvelle méthode classification basant algorithme développé Quinlan Quinlan classification images temps facteur important Cependant données structurées volumineuses taille données leurs classifications méthodes existantes temps assez élevé travail avons développé nouvelle méthode classification basée arbre décision utilisant structure donnée appelée arbre Peano Count Cette méthode évite balayage direct données opération assez coûteuse mémoire temps exécution autre offre comparaison attributs items comparaison effectue section suivante présentons quelques travaux existants méthodes classification apprentissage section introduit structure détaillons section notre méthode classification images basée algorithme utilisant structure section consacrée implémentation système valide notre méthode terminons présentation quelques perspectives travail Classification apprentissage automatique cadre cette étude intéressons particulier apprentissage apprentissage inductif processus apprentissage inductif considéré comme recherche descriptions générales plausibles expliquent données entrée utiles prédire nouvelles Borgi existe nombreux travaux théorie apprentissage général apprentissage inductif particulier Dietterich Michalski Carbonell Kodratoff approches distinctes apprentissage existent première qualifiée apprentissage supervisé regrouper classes objets basant ressemblances similarités entre deuxième approche apprentissage supervisé quand ensemble apprentissage constitué objets classe connue priori dernier apprentissage intéressons Fonction classement Apprentissage supervisé Description exemples étiquetés classe apprentissage supervisé notre méthode prémisse conjonction descripteurs logiques Attribut Valeur conclusion forme appartenance classe parmi classes objectif apprentissage inductif génération règles identifier nombre minimal règles généralisent exemples apprentissage problème recherche ensemble minimal combinaisons problème Complet méthodes existantes toujours heuristiques Bonnet heuristiques diffèrent façon construire combinaisons minimales plupart méthodes génération règles construisent prémisses ajoutant descripteurs correspondant optima locaux dernières méthodes attributs monothétiques arbres décision correspondent approche classification attributs Trois systèmes particulièrement marqué travaux arbres décision Quinlan Quinlan communauté Breiman origine statistique récemment travaux étudiés arbres décision flous Marsala Ramdani permettent traiter connaissances imprécises autres étudiés arbres décisions basées croyance Mellouli traitent incertitudes principales caractéristiques méthode développée cadre notre étude suivantes méthode apprentissage attribut monothétique permet prendre compte pouvoir explicatif ensemble exemples effet cette méthode consiste décomposer apprentissage bases chacune induite modalité liste modalités attribut traité construction prémisses règles étape étape chacune elles ajoute condition meilleur attribut choix meilleur attribut selon information attribut celui possédant important règles générées règles classification leurs conclusions forme appartenance classe chemin arbre décision équivalent règle classification prémisse cette règle conjonction tests réalisés parcours question partie conclusion contient classe libellant feuille chemin atteinte parcours réduire masse information surcharger espace mémoire éviter temps complexité traitements élevés utilisons structure comprimer données originales conséquence faciliter accélérer exploitation efficace données Notre méthode situe jonction méthodes classification attribut structure permet combiner avantages classifieurs basés règles classification structure structure permet accélérer processus classification effet données origine converties format binaire permet réduire temps classification proposons section suivante quelques détails supplémentaires algèbre Apprentissage supervisé classification images structure Présentation structure extraction règles classification partir données structurées telles données images tâche importante complexe classer images environnement groupes environnement pollué environnement dépollué médecine regrouper images poumons classes poumon contaminé concert Cependant plupart tailles données images grandes extraites temps raisonnable utilisant méthodes standards nouvelle organisation spatiale données appelée Sequential Organisation nouvelle structure données appelée Peano Count proposées Perrizo Qiang principale diviser récursivement données quadrants enregistrer nombre chaque quadrant arbre utilisant structure accélérer processus calcul facilite manière efficace représentation exploitation données image algèbre inclut trois opérations Complement notre méthode utilisons uniquement opérateur faire intersection arbres conséquent calcul probabilités déterminer attribut présente information important tableau illustre règles respecter déterminer intersection entre trees trees opérande1 opérande racines respectivement Opérande Opérande Résultat arbre racine arbre racine quatre quadrants comme conséquence alors Sinon règles ANDing Peano variante particulièrement utile optimisation opération ANDing entre trees consiste utiliser logique valeurs laquelle employé représenter quadrant employé représenter quadrant utilisé représenter quadrant mixte figure illustre opération appliquée arbres Bande Séquentielle forme organisation données proposée Cette forme permet meilleure compression données intersection trees allons suite travail proposition formulons classer images technique arbre décision combinée structure Classification images arbre décision utilisant structure notre méthode chaque image représentée vecteur binaire dérivé partir descripteurs visuels Cette représentation correspond conversion données binaire cette dernière représentée ensemble trees représentant chacun vecteur binaire montrons suite technique combinée algorithme réduisent considérablement temps classification données binaire notre étude données convertie binaire cette données chaque attribut associé ensemble valeurs exemple attribut classe possède items transformés binaires attributs caractérisés valeurs binaires représentant présence absence liste items représentée ensemble nombre items données Classe Conversion données attributs binaire Apprentissage supervisé classification images structure attribut domaine binaire multi valeurs associons chacune valeurs exemple meilleure représentation attribut couleur affectons valeurs suivantes rouge ambré résultat conversion items défini comme rouge ambré Couleur rouge ambré rouge Conversion données attributs binaire Construction simplifier travail supposons nœuds sortants quatre chaque vecteur associons Chaque présente nombre divisible constitué quatre quadrants quadrant origine représente totalité formant attribut table binaire toujours trees table binaire formée items construction consiste diviser périodiquement vecteur binaire quadrants enregistrer nombre chaque quadrant formant arbre calcul quadrants Stockage manière générale génération partir trames données manière ascendante stockage chaque arbre vecteur entiers génération dépend nombre nœuds internes arbre racine représenter différents utilisons notation suivante racine nœuds internes niveau notre utilisons représentation divisons nombre tuples composant données blocs blocs doivent avoir minimum quatre tuples nombre tuples inférieur complétons obtenir format tuples manière générale nombre tuples compris entre alors stocké nombre tuples égale procédure stockage stockons nœuds racines vecteur nœuds binaires formant quadrants autre vecteur faciliter accès données quadrants chaque bande colonne table binaire comparer quadrants autres bandes déterminer probabilité chaque nombres tuples initialisé désigne nombre total items considérons algorithme suivant Procédure Stockage_de_P racine rootcount bandj vecteur stocke racines trees alors bandj FinPour FinSi calcul racines quadrants rootbandj rootcount bandj vecteur racines internes FinPour rootbandj rootbandj alors Bitsbandj subquadranti vecteur FinSi FinPour FinPour Génération trees Après avoir classé données question suivante comment produire trees avons tuples voulons choisir balayer données chaque tuples Ajouter additionnel Après chaque nœuds produits ajouter interne comme parent ainsi suite cette façon produit gauche droite balayant données données convertie racine racine quadrant Génération Apprentissage supervisé classification images structure algorithme étapes difficiles algorithme choisir prochain attribut choisit attribut résulte partition exemples retrouvent ensemble alors augmente taille arbre augmenter habileté classer exemples classant éléments rejoindre feuille contenant exemples posant moins questions arbre petit possible Puisque difficile trouver arbre chemin court parmi arbres possibles construit arbre utilisant heuristique permettant choisir attribut déterminant informatif existe plusieurs techniques Index théorie information allons utiliser suite travail Algorithme éléments classe Alors quitter Sinon Faire étapes suivantes Choisir attribut assigner information déterminer partir trees Partitionner exemples ensembles selon valeurs attribut Créer nouveaux nœuds chaque ensemble partition liste nouveaux noeuds devient enfants Appliquer procédure récursivement nouveaux nœuds FinSi début arbre décision noeud simple représentant ensemble entier apprentissage échantillons classe noeud devient feuille marqué cette étiquette classe mesure basée entropie information employée comme heuristique sélectionner attribut sépare mieux échantillons différentes classes attribut décision branche créée chaque valeur attribut essai échantillons divisés conséquence algorithme avance périodiquement former arbre décision échantillon réglé chaque nouveau algorithme arrête quand échantillons noeud donné appartiennent classe quand aucun attribut restant attribut choisi chaque niveau arbre décision celui élevé information Calcul probabilités valeur entropie structure exemple allons essayer calculer information attribut couleur noter attribut contient trois items rouge ambré travail répété autres attributs texture forme phase calcul valeur information chaque attribut achevée attribut présente grande valeur choisi comme meilleur attribut classification racine arbre allons partitionner tuples ensembles nœuds selon valeur meilleur attribut retenu rouge ambré Classe Classe Tableau binaire attribut couleur partir cette table binaire allons générer arbres trees associés chacun défini exemple arbre tree1 valeur racine obtenue comptant nombre premier quadrant valeur deuxième racine correspond deuxième quadrant valeur racine obtenue addition valeurs nœuds racines tree1 rouge classe Résultat tree1 ANDing tree4 Résultats intersections trees ANDing calcul probabilités déduit automatiquement partir trees exemple déterminer valeur probabilité apparition couleur rouge divise valeur racine arbre tree1 égale nombre total enregistrements Apprentissage supervisé classification images structure table binaire égale valeurs probabilités conditionnelles obtenues application opérateur trees exemple calculer valeur rouge divise valeur racine arbre tree1 ANDing tree4 égale valeur racine arbre tree4 égale calculer entropie attribut couleur appliquons formule suivante conclusion pouvant valoir notre exemple attribut pouvant valoir probabilité sachant quantité information notée entropie rapport conclusion notée information calculé comme Probabilités classes Entropie attribut classe tree4 tree5 8log2 Probabilités apparition Probabilités conditionnelles rouge tree1 tree2 ambré tree3 rouge tree1 ANDing tree4 tree2 ANDing tree4 ambré tree3 ANDing tree4 rouge tree1 ANDing tree5 tree2 ANDing tree5 ambré tree3 ANDing tree5 Entropie attribut couleur information attribut couleur Couleur rouge ambré Couleur Couleur Calcul information attribut couleur trees Implémentation validation données évaluation fruits fraise contient exemples réels représentant images fraise quatre attributs Trois attributs représentent partie prémisse règle classification attribut partie conclusion valeurs attributs définies comme Valeurs attributs décision Classe fraise petits fruits fraise fruits Valeurs attributs prémisse Couleur rouge ambré Texture lisse caillé Forme allongé oblongue forme conique comparaison résultats classification obtenus algorithme algorithme autre montre amélioration performances utilisant structure étude comparative entre algorithmes présentée figure suivante Comparaison entre algorithme algorithmeC4 temps classification seconde nette amélioration performances noter Cette amélioration atteint temps classification effet structure données utilisée représenter données ensemble trees représentant vecteur binaire table binaire trees stockés fichiers binaires Cette structure données permet charger complètement images volumineuse fichier binaire objectif cette opération éviter balayage direct images travers application avons développée avons montré algorithme structure donnée offre temps considérable rapport algorithme classification données Enfin technique combinée algorithme offrir temps minimum classification comparée algorithme Conclusion perspectives avons présenté méthode binaire classification algorithme proposé implémenté système baptisé calcul probabilités choisir meilleur attribut règles comparaison trees treei ANDing treej Notre système présente plusieurs avantages évite balayage direct données opération assez coûteuse mémoire temps exécution autres offre comparaison attributs effet comparaison effectue tuples binaire perspectives proposons concernent également amélioration notre système classification développer interface permettrait utilisateur déterminer directement vecteurs attributs associés images saisir algorithme proposé pourrait ailleurs comparé autres algorithmes classification appliqué autres bases données Références Bonnet Intelligence Artificielle promesses réalités Inter Paris Borgi Akdag Apprentissage supervise raisonnement approximatif hypothèse imperfections Revue Apprentissage supervisé classification images structure Breiman Friedman Olshen Stone Classification regression trees Champan Carbonell Michalski Mitchell Overview Machine Learning Machine Learning Artificial Intelligence Approach Michalski Carbonell Mitchell editors Morgan Kaufmann Chahir Spatialized Visual Features Based Image Retrieval Inter Computers Their Applications December Dietterich Michalski Comparative Review Selected Methods Learning Examples Machine Learning Artificial Intelligence Approach Morgan Kaufmann Perrizo Algebra SIGKDD Qiang Perrizo Association Rules Mining Remotely Sensed Images using trees Proceedings PAKDD Taipei Taiwan Qiang Perrizo Decision Classification Spatial Streams Using Peano Count Technical Report Kodratoff Diday Préambule Approche symbolique Approche Numérique Induction Symbolique numérique partir Données Cépaduès Marsala Apprentissage inductif présence données imprécises construction utilisation arbres décision flous Thèse doctorat Paris Mellouli Elouedi Smets Belief decision trees Theoretical foundations Inter Approximate Reasoning Compiègne France Michalski Ryszard theory methodology inductive learning Approach Morgan Kaufmann Perrizo Qiang Deriving Confidence Rules spatial using Peano Count Trees advances Information Management Second International Conference Springer Verlag Quinlan Learning efficient classification procedures their application chess games Artificial Intelligence Approach Morgan Kaufman Publishers Quinlan Programs Machine Learning Morgan Kaufmann Ramdani Système Induction Formelle connaissances Imprécises Thèse doctorat université Paris Summary propose method classification starting images which junction techniques algebra decision approach necessary accelerate process classification research great bases images modelling based visual descriptors colour texture indexing images other automatic generation rules classification approach training proposed supervised based whole training objects whose classes known priori system baptized implemented confronted application field image processing results obtained possible validate method authorize carry experimental tests various bases would interesting other descriptors build rules classification