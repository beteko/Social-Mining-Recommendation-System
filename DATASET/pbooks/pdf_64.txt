modèle bayésien clustering données mixtes aichetou bouchareb boullé fabrice rossi fabrice clérot orange prenom orange université paris panthéon sorbonne prenom paris1 résumé proposons modèle clustering données mixtes critère bayésien sélection meilleur modèle modèle infère automati quement discrétisations optimales toutes variables effectue clustering minimisant critère bayésien sélection modèle cette approche nécessite aucun paramètre utilisateur critère proposé mesure façon exacte qualité modèle étant régularisé optimisation critère permet améliorer continuel lement modèles trouvés autant apprendre données périences réalisées données réelles montrent intérêt cette approche analyse exploratoire grandes bases données introduction monde technologies acquisition données croissance rapide analyse exploratoire bases données hétérogènes grandes tailles reste domaine étudié technique fondamentale analyse supervisée celle clustering objectif découvrir structure jacente données regroupant indivi similaires groupes homogènes cependant nombreux contextes exploratoire données cette technique regroupement objets reste insuffisante découvrir motifs pertinents clustering hartigan apparu comme tension clustering technique supervisée objectif regrouper conjoin tement dimensions table données profitant interdépendance entre entités individus variables représentées dimensions traire structure jacente données cette technique adaptée example contextes comme analyse paniers consommation objectif identifier ensembles clients ayant tendance acheter mêmes produits plutôt grouper simplement clients produits fonction modèles achat vente littérature plusieurs approches clustering développées particulier certains algorithmes clustering proposent optimiser fonction mesure écart entre matrice données matrice clusters cheng church autres techniques basées théorie information dhillon modèles mélange définir modèles blocs latents govaert nadif estimation bayésienne paramètres banerjee approximation matricielle modèle clustering données mixtes seung partitionnement graphes dhillon cependant méthodes appliquent naturellement données bouchareb avons proposé méthodologie permettant étendre utilisation clustering table données contenant variables riques catégorielles simultanément approche basée discrétisation toutes variables fréquences égales suivant paramètre utilisateur suivi application méthode clustering données discretisées papier proposons nouvelle famille modèles permettant formaliser cette méthodologie modèle proposé nécessite aucun paramètre utilisateur permet inférence automatique discrétisa tions optimales variables selon approche regularisée opposition discrétisation définie utilisateur proposée bouchareb nouveau critère mesurant capacité modèle représenter données nouveaux algorithmes présentés reste papier organisé comme section présentons modèle proposé critère sélection stratégie optimisation implémentée section présente résultats expérimentaux données réelles section conclusion perspectives modèle clustering données mixtes avant présenter modèle proposé décrivons données telles elles notre modèle données composées ensemble instances identifiants ligne matrice ensemble variables pouvant numériques catégorielles définissons notion observation représente interaction entre instance variable cette représentation permet considérer valeurs manquantes données aussi plusieurs observations couple instance variable comme séries temporelles example simple illustrant cette représenta donné example contient instances variables numériques riables catégorielles total observations paramètres modèle modèle clustering défini hiérarchie paramètres chaque étage hiérarchie paramètres choisis fonction paramètres précédents définition modèle clustering données mixtes défini taille partition chaque variable partition regroupement valeurs variable catégorielle discrétisation intervalles variable numérique partition valeurs chaque variable catégorielle groupes valeurs nombre clusters instances clusters parties variables choix définissent taille matrice clusters bouchareb partition instances parties variables selon nombre clusters choisi distribution observations cellules matrice clusters distribution observations associées chaque cluster instances parties variables ensemble instances parties variables cluster distribution observations chaque partie variable catégorielle semble valeurs partie notations formaliser modèle considérons notations suivantes nombre total observations connu nombre variables numériques connu nombre variables catégorielles connu ensemble variables nombre valeurs uniques variable catégorielle connu nombre parties variable inconnu nombre total instances connu nombre total parties variables déduit nombre clusters instances inconnu nombre clusters parties variables inconnu nombre clusters déduit nombre observations cluster formé cluster instances cluster parties variables inconnu nombre observations cluster instances déduit nombre observations cluster parties variables déduit nombre instances cluster instances déduit nombre parties cluster parties variables déduit nombre valeurs partie variable déduit nombre observations associées instance inconnu nombre observations associées partie variable inconnu nombre observations associées valeur variable catégorielle inconnu modèle définition complètement défini choix paramètres dessus notés inconnu critère bayésien sélection meilleur modèle faisons hypothèse distribution priori paramètres moins informative possible exploitant hiérarchie paramètres priori uniforme chaque niveau étant donné paramètres vraisemblance conditionnelle données sachant modèle définie distribution multinomiale chaque niveau hiérarchie produit probabilité priori modèle vraisemblance permet calculer manière exacte probabilité posteriori modèle connaissant données partir cette probabilité définissons critère sélection modèle donné théorème modèle clustering données mixtes théorème parmi modèles définis définition modèle suivant priori hiérar chique uniforme optimal minimise critère logngu logni lognvk nombre stirling deuxième espèce donnant nombre répartitions possibles valeurs groupes trois première lignes représentent priori modèle tandis nières représentent vraisemblance raisons manque espace preuve théorème présentée papier algorithme optimisation raison grande expressivité modelés clustering données mixtes complexes optimiser papier proposons heuristique optimisation étapes première étape commençons partitionner variables fréquences égales utilisant ensemble prédéfini tailles partitions appliquons thodologie proposée bouchareb trouver clusters initiaux parmi tailles testées choisissons solution initiale correspond valeur minimale critère comme point départ partir cette solution initiale deuxième étape optimisation effectue fusions clusters fusions parties variables déplacements parties variables entre clusters déplacements valeurs entre parties minimisent mieux critère cette optimisation permet choisir meilleur parmi large ensemble modèles testés améliorant interpretabilité étant donné modèle optimisé souvent compact comparé solution initiale expérimentation valider apport modèle proposé analyse exploratoire données mixtes avons appliqué bases données censusincome lichman composée instances observations variables numériques variable catégorielle tailles partitions départ parties variable bouchareb 7414313456 clusters parties variables meilleur modèle clusters parties variables censusincome clusters meilleur modèle représentant modèle simplifié censusincome figure montre meilleur modèle modèle résultat crétisation initiale parties variable fréquences égales suivi optimisation fusionne parties faire total couleur cluster montre infor mation mutuelle entre instances parties variables formant cluster couleur rouge représente représentation observations rapport indépendance couleur représente représentation couleur blanche cluster confirmation nombre observations cluster montré figure modèle optimisé comporte clusters instances clusters parties variables compositions clusters parties variables mieux représentés permettent expliquer clusters instances particulier distinguons cluster instances contenant petites fleurs setosa caractérisées class setosa petallength petalwidth cluster instances contenant grandes fleurs virginica caractérisées petallength petalwidth class virginica cluster instances contenant fleurs moyennes versicolor caractérisées petallength petalwidth class versicolor remarque variables class petallength petalwidth fortement corrélées informatives clusters instances censusincome composée instances observations variables numériques variables catégorielles tailles partitions départ puissance meilleur modèle trouvé partir solution initiale correspon parties variable modèle optimisé contient parties variables clusters instances clusters parties variables première analyse notre modèle clustering permet distinguer globalement familles instances figure individus actifs payeurs impôts gagnant individus inactifs payeurs impôts moins gagnant moins globalement modèle obtenu permet obtenir résumé données riche informations exploitable plusieurs niveaux granularité piloter analyse exploratoire modèle clustering données mixtes conclusion papier avons proposé modèle clustering données mixtes critère sélection meilleur modèle algorithme optimisation avons efficacité modèle extraire motifs intéressants partir bases petites simples comme bases grandes complexes comme censusincome toutefois quand données volumineuses grande complexité notre modèle cette complexité fourni clustering détaillé détriment interprétabilité travaux futurs viserons développer méthodologie permettant interpré résultats différents niveaux granularité définir instances parties variables représentatives chaque cluster faciliter interprétation modèle références bouchareb boullé clérot rossi application coclustering analyse exploratoire table données extraction gestion connaissances volume cheng church biclustering expression inter intelligent systems molecular biology volume press dhillon clustering documents words using bipartite spectral graph partitio sigkdd dhillon mallela modha information theoretic clustering ninth inter knowledge discovery mining govaert nadif block clustering bernoulli mixture models comparison different approaches computational statistics analysis hartigan clustering algorithms wiley seung algorithms negative matrix factorization vances neural information processing systems volume lichman repository archive banerjee bayesian clustering eighth washington computer society summary propose bayesian approach perform evaluate clustering mixed tables proposed model infers optimal segmentation variables performs clustering minimizing bayesian model selection function advan approach parameter another advantage proposed criterion which gives exact measure model quality measured probability fitting continuous optimization criterion ensures finding better better models while avoiding fitting experiments conducted interest clustering approach exploratory analysis large