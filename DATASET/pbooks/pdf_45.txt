modélisation métadonnées vault nogueira maram romdhane jérôme darmont université avenue pierre mendès france f69676 cedex deolindonogueira lyon2 maram romdhane lyon2 jerome darmont lyon2 résumé avènement mégadonnées informatique décisionnelle trouver solutions gérer données grands volume riété données lakes répondent besoins point stockage nécessitent gestion métadonnées adéquates garan accès efficace données modèle multidimensionnel métadonnées conçu données présentant défaut évolu tivité schéma proposons utilisation vault traiter problème montrer faisabilité cette approche instancions notre modèle conceptuel métadonnées modèles logiques physiques relation orienté document comparons également modèles physiques termes stockage temps réponse requêtes métadonnées introduction données lakes introduits dixon proposent manière mégadonnées stocker format natif données volumineuses variées diversement structurées analyser reporting visualisa fouille données concept oppose celui entrepôts données intégrés orientés sujet inconvénient diviser données silos étanches stein morrison toutefois monde accorde données conçu peine devenir marécage swamp inexploitable alrehamy walker permettre requêtage données sélection restriction temps réponse seulement stockage accès valeur revanche solutions parvenir inexistantes littérature relèvent heure actuelle pratiques industrielles divulguées pourquoi pathirana proposé modèle conceptuel métadonnées mettant indexation interrogation efficace données patrimoniales modèle multidimensionnel proche modèles flocons usage entrepôts données concerne métadonnées corpus documents tancié niveau physique différents systèmes gestion bases données nosql cependant schéma employé difficile faire évoluer lorsque sources données évoluent nouvelles sources prendre compte alors point crucial gestion données modélisation métadonnées vault conséquence proposons article remplacer modèle multidimen sionnel pathirana modèle ensembliste occurrence vault modèle données permettant évolutions schémas aisées notre connaissance jamais employé contexte gestion métadonnées vérifier faisabilité efficacité modèle termes réponse quêtes métadonnées manière index autre induit nombreuses jointures traduisons notre metadata vault conceptuel différents modèles logiques relationnel orienté document physiques postgresql mongodb permet également comparer efficacité respective modèles physiques données généralement construits intégrer grands volumes données structurées manière rapide limitent toutefois technologie stockage plupart temps hadoop distributed system proposent nouvel écosystème données permettant rapidement demande croiser besoin prétraitements coûteux construction entrepôt données données immédiatement accessibles contrairement nouveau entrepôts données rafraîchis périodiquement phase extraction transformation chargement coûteuse miloslavskaya tolstoy modélisation ensembliste ensemble modeling approche utilisée indus renormaliser entrepôts données permettre meilleure lutivité termes données schéma rönnbäck hultgren approches dégagent anchor modeling regardt vaults linstedt elles proches rönnbäck hultgren lutivité aisée évolution schéma destructive anchor modeling grand nombre objets gérer raison modélisation sixième forme normale ainsi procédures maintenance attributs temporels timestamps automatisées vaults proches modélisation multidimensionnelle traditionnelle supportés grand nombre outils guidé notre choix vault défini niveau logique relationnel comme ensemble tables normalisées orienté détail suivi historique prend charge plusieurs domaines fonctionnels organisation approche hybride englobant schéma étoile linstedt concrètement vault composé éléments cipaux suivants centre entité représente concept métier niveau hiérarchique dimension entrepôt données classique client produit exemple contient principalement business matérialise association entre centres correspondrait entité faits entrepôt classique satellite contient attributs relatifs centre modèle métadonnées vault proposer utilisation susceptible illustrer notre propos servir preuve concept avons exploité corpus données projet tectoniq nogueira valoriser patrimoine industriel textile lille métropole kergosien corpus rassemble données hétérogènes fournies différentes sources descriptions bâtiments industriels documents orientés données articles presse industrie textile cuments orientés documents photos plans bâtiments monuments indus textile images livres histoire france domaine public documents permettre divers types analyses pourquoi stockage corpus effectué données pathirana proposé modélisation multidimensionnelle métadonnées proposons article rendre métadonnées évolutives ajout nouvelles sources données détournant quelque sorte concepts vaults centres liens satellites stocker métadonnées figure illustre notre modèle conceptuel métadonnées vault rectangles arrondis bleus représentent centres rectangles satellites hexagone associations entre centres liens toutes cardinalité plusieurs sieurs assurer grande généralité tandis associations entre centres liens satellites cardinalité plusieurs modèle métadonnées vault identifier centres ciblons métadonnées indicatrices caractéristiques chaque document entrée susceptibles constituer ainsi sélec tionnons titre hub_title localisation hub_location hub_date catégorie documents hub_category chacun centres associons ensuite satellite contient attributs descriptifs centre centre hub_category associé quatre tellites forment classification correspondant chacune source données modélisation métadonnées vault disposons attributs descriptifs satellites spécifiques chacune sources document link_document permet associer centres finalement puisque notre modèle concerne seulement métadonnées chaque entité centre satellite décrite référence directe source document fichier physique données grâce cette modélisation toute nouvelle source données évolution schéma données prise charge ajout satellites simples voire centres liens entités deviendraient obsolètes simplement identifiées grâce horodatage attribut datetime montrer notre modèle conceptuel adapter différents contextes comparer déclinons types modèles logiques physiques modèle tionnel postgresql modèle nosql orienté document mongodb modèle relationnel métadonnées traduit modèle conceptuel figure manière classique notons seulement satellites primaire constituée primaire centre dépend satellite attribut datetime modèle orienté document données exploite notion collection chaque centre satellite traduit collection comportant documents ayant chacun identifiant objectid modèle physique mongodb identifiant généré automatiquement création document chaque centre associé link_document satellites grâce objectid validation expérimentale objectif cette section montrer faisabilité notre modèle métadonnées vault comparer modèles physiques posgresql mongodb avons expériences intel 5300u mémoire windows versions postgresql mongodb après avoir inséré métadonnées format natif choisis scripts avons mesuré volume stockage nécessaire mesures tiennent compte espace mémoire utilisé celui libéré suppression déplacement données volume métadonnées générées fichiers faible moins ailleurs mongodb nécessite systématiquement moins espace postgresql justifié utilisation format léger mongodb revanche postgresql chaque table stockée comme vecteur pages taille prédéterminée induit pages totalement remplies mesurer performance notre modèle métadonnées avons requêtes projection restriction complexité croissante termes nombre centres impliqués jointures link_document appli quons modèles physiques documents titre contient terme indus trielle documents titre contient terme industrielle emplacement bibliothèque documents titre contient terme industrielle placement bibliothèque documents titre contient terme industrielle emplacement bibliothèque appartiennent categorie ouvrage documents titre contient terme dustrielle appartiennent catégorie passée paramètre figure présente temps exécution moyen requêtes postgresql mongodb respectivement avons exécuté chaque requête ordre nogueira diqué dessus pallier éventuelles variations temps exécution figure montre temps réponse spectaculairement mongodb alors obtenus postgresql semblent évoluer manière exponentielle figure illustre temps exécution moyen requête exécutions distincte figure requête complexe précédentes effet possible déter miner dynamiquement satellite catégorie utiliser exécuter requête étapes première déterminer catégorie seconde récupérer reste informations sachant catégorie opérations induisent temps réponse supérieurs requêtes mongodb montre nouvelle efficace trois rapide moyenne postgresql cette différence temps exécution explique réécriture interne postgresql requête induisant coûteuse alors mongodb permet union rapide collections requêtes requête temps moyen réponse requêtes conclusion partant modélisation métadonnées données forme multidimen sionnelle constatant évolution schéma était garantie avons proposé modélisation vault métadonnées traduction notre modèle conceptuel métadonnées modèles logiques physiques expériences menées corpus toniq permis montrer faisabilité notre approche termes volume stockage temps réponse requêtes formulées métadonnées comparaison modèles physiques postgresql mongodb également apparaître supériorité modèles logiques orientés document stocker métadonnées perspectives ouvertes travail incluent tester robustesse modèle tadonnées passage échelle données sources ajouter sources données vérifier pertinence modélisation vault tester requêtes plexes projections restrictions serait également intéressant comparer efficacité modélisation vault anchor modeling tenants cette dernière argumentant modélisation permet malgré temps réponse grâce technique élimination jointures employée optimiseurs modernes finalement différentes modélisation métadonnées vault modélisations alternatives métadonnées indépendamment techniques modélisation employées pourraient envisagées comparées schémas documents corpus pourraient aussi extraits automatiquement enrichir métadonnées remerciements auteur remercient kergosien porteur projet tectoniq disposition corpus données ainsi évaluateur trices article leurs retours références alrehamy walker personal gravity international conference cloud computing bdcloud dalian china dixon pentaho hadoop lakes jamesdixon wordpress pentaho hadoop lakes kergosien technologies information communication territoire numérique valorisation patrimoine tectoniq meshs linstedt super charge warehouse invaluable modeling rules implement vault createspace independent publishing miloslavskaya tolstoy concepts procedia computer science pathirana modeling territorial knowledge about natural cultural heritage mémoire master université lumière regardt rönnbäck bergholtz johannesson wohed anchor deling international conference conceptual modeling gramado brazil volume lecture notes computer science rönnbäck hultgren comparing anchor modeling vault modeling hanshultgren files wordpress modeling_compare_05_larshans stein morrison enterprise better integration deeper analy technology forecast technology forecast cloud computing assets technology forecast lakes summary business intelligence devised solutions managing great volume variety lakes answer storage point require manag adequate metadata guarantee efficient access multidimensional metadata model designed presenting schema evolutivity propose vault address issue illustrate feasibility approach instantiate metadata conceptual model relational document oriented logical physical models compare physical models terms metadata storage query response