Sélection supervisée instances approche descriptive Sylvain Ferrandiz Boullé France Télécom avenue Pierre Marzin 22300 Lannion sylvain ferrandiz francetelecom boulle francetelecom GREYC Université boulevard Maréchal 14032 Cedex Résumé classification suivant proche voisin règle simple performante oeuvre pratique nécessite raisons calcul robustesse sélectionner instances conserver parti Voronoi induite prototypes constitue structure jacente cette règle article introduit critère descriptif évaluation telle partition quantifiant compromis entre nombre cellules discrimi nation variable cible entre cellules heuristique optimisation proposée tirant partie propriétés partitions Voronoi critère méthode obtenue comparée standards vingtaine données Notre technique souffre aucun défaut performance prédictive sélectionnant minimum instances apprend Introduction classification supervisée constitue problème apprentissage classique dispose variables descriptives endogènes variable cible phase exploration données dépendance variable cible variables descriptives expliciter phase modélisation meilleure prédiction possible toute nouvelle instance classifier Quelle situation connaissance extraire échantillon instances étiquetées méthode classification usuelle règle classification suivant proche voisin introduite Hodges consiste attribuer instance étiquette instance proche parmi celles constituant échantillon œuvre cette modélisation soulève questions fondamentales Quelle mesure similitude employer Quelles instances échantillon conserver première question couvre plusieurs champs investigation gestion présence jointe variables continues symboliques normalisation variables continues prétrai tement variables symboliques pondération contribution variables continu usage consacré emploi distance euclidienne distances Sélection supervisée instances Minkowski distance Mahalanobis effectuant transforma globale instances calcul élevé permet intégrer calcul similitude corrélations entre couples variables descriptives mesures successives quantité Dynamic Warping procédé traitant corré lation temporelle Berndt Clifford symbolique distance Hamming autant simplificatrice nombre modalités variables croît pourquoi mesures similitude basées probabilités occurence souvent utilisées Stanfill Waltz entre autres procédé gestion mixité variables continues symboliques proposé Wilson Martinez 1997a intéresse article question choix mesure similitude focalise sélection instance classification proche voisin impose chaque nouvelle instance sifier parcourir ensemble échantillon entraîne déploiement rédhibi toire étape sélection instances permet diminuer recherche Classique méthodes prédictives attellent qualifier degré utilité prédictive instance conservent instances jugées utiles méthodes décrites section instances sélectionnées prototypes induisent partition Voronoi chaque groupe étant associé prototype ensemble instances répartit groupes cette partition considère alors distribution étiquettes chacun groupes méthodes prédictives prennent compte étiquette prototype associe chaque prototype cette distribution probabilité Cette dichotomie reflète celle observée processus fouille données entre phase préparation données celle modélisation Chapman présente section approche criptive évaluation qualité telles fonctions ainsi critère découle question apprentissage étant prise charge critère propose section heuristique optimisation poussée Enfin comparaison expérimentale données réelles menée section sélection instances méthode Condensed Nearest Neighbor décrite ancienne méthode sélection instances Toute instance classifiée proche voisin parmi prototypes sélectionnés aussitôt conservée procédé incrémental itéré existe instances classifiées ensemble prototypes méthode consistante élément échantillon classifié proche prototype complexité algorithme amélioration proposée Gates Reduced Nearest Neighbor règle appliquée toute suppression prototype provoquant aucune mauvaise classification instance validée intérêt cette méthode réside capacité produire ensemble prototypes taille minimale relativement condi consistance réserve ensemble inclus solution proposée décisions prises techniques robustes conservation bruit exemple remédier consiste prendre compte proches voisins typiquement procédé décrémental instance éliminée classifiée majorité proches voisins règle Ferrandiz Boullé Edited Nearest Neighbor présentée Wilson complexité algorithmique élimination ainsi fiabilisée limitée Notons cette méthode appliquée itérativement précédentes méthodes étant complexité élevée réalisant objectif sélection drastique après Wilson Martinez proposé série algorithmes version aboutie notion acceptabilité introduite instance conservée classifiée proche prototype acceptable complexité algorithmique prototype acceptable bonne classification significativement supérieur fréquence classe éliminés prototypes acceptables permet fiabiliser décisions évitant conservateur également notion association utilisée Wilson Martinez 1997b proches voisins associé Autrement associé participe classification éliminé nombre associés classifiés diminue après suppression règle préliminairement appliquée instances considérées ordre décroissant distance proche instance classe différente méthode obtenue DROP3 complexité croisée chemins entre DROP3 trouve statistique évaluant pothèse contribution instance classification associés Sebban critère paramétrique calcul nécessite approximation densité statistique associée adaptation algorithme AdaBoost permettant traiter sifieurs locaux prototypes aboutit heuristique recherche incrémentale version rapide algorithme complexité Cameron Jones proposé critère évaluation qualité prédictive semble prototypes approche adoptée Minimum Message Length critère obtenu écrit nombre prototypes nombre instances nombre instances sifées proche prototype nombre classe cibles quantité mesure longueur nécessaire spécification instances parmi évaluée formule désigne somme termes positifs termes correspondent longueurs nécessaires spécification étiquettes prototypes exceptions respectivement heuristique également proposée nomme Explore première phase itérative consiste ajouter instance valeur critère diminue toutes instances considérées prototype suppression conduit diminution valeur critère effectivement éliminé Enfin mutations évaluées acceptées valeur critère décroît mutation ajout instance ensemble prototypes suppression prototype échange entre instance prototype final méthode complexité proche moyenne Sélection supervisée instances approche descriptive approche prédictive classique consiste évaluer qualité prédictive classifieur mesurant risque structurel empirique exemple parti ensemble thodes sélection intéresse notre qualité distribution étiquettes conditionnellement instances mesure cette qualité proposée adopte approche descriptive Notations Fixons notations dispose échantillon instances étiquetées ensemble instances leurs étiquettes étiquettes appartiennent alphabet taille instances ensemble ensemble mesure similitude partition Voronoi associée définie cellule Voronoi contient points lesquels élément similaire relativement élément appelé prototype cellule figure donnent exemples telles partitions Exemple partitions Voronoi définit modèle descriptif comme couple partition Voronoi formée cellules matrice taille coefficient donne probabilité étiquette cellule Autrement chaque cellule chaque prototype associée distribution probabilité partition Voronoi composée cellules cardinal cardinal Ainsi Ferrandiz Boullé Formalisation considère modèle comme étant aléatoire cherche spécifier probabilité jointe modèle étiquettes connaissant instances Cette probabilité décomposée formule probabilités itérées intéresse cette probabilité probabilité mauvaise classification classifieur associé comme décrit Vapnik qualifie approche descriptive précisément désigne nombre cellules commence écrire permet comparer ensembles prototypes différentes tailles itère ensuite dépendance utilisant formule Bayes suppose comportements distributions chaque cellule conditionnellement indépendants donne ligne cellule instances tombant leurs étiquettes applique nouvelle règle Bayes obtient Spécification probabilité décomposée formule Bayes spécifie maintenant chacune probabilités précisant chaque étape support probabilité concernée appliquant priori uniforme concerne nombre cellules probabilité valeurs sibles comprises entre application priori uniforme donne partition Voronoi caractérisée uniquement prototypes ensembles prototypes considérés parties Adopter priori uniforme conduirait introduire coefficient binomial puisque choisir prototypes parmi instances coefficient symétrique relativement Comme préfère valeurs faibles utilise coefficient croissant proche faibles valeurs caractérisant ainsi finement notre préférence Sélection supervisée instances cellule exploite dépendance données restreint support distributions possibles probabilités rationelles dénominateur Formellement support cardinal adoption priori uniforme donne partition fréquences classes cibles chaque cellule stade connues reste spécifier étiquettes chaque instance chaque cellule chaque cellule support restreint relativement dépendance cellule problème revient placer éléments cellule urnes contrainte effectif coefficient multinomial donne nombre exact possibilités obtient final prenant opposé logarithme modèle descriptifM évalué formule suivante premier terme correspond description nombre groupes second description prototypes troisième description fréquences étiquettes cellules dernier description attribution étiquettes instances cellules Notons après approximation Stirling dernier terme formule comporte asymptotiquement comme entropie conditionnelle distribution connaissance fonction assignement associée partition Heuristique optimisation dispose critère évaluant ensemble ensemble instances espace recherche cardinal rendant recherche exhaustive réaliste propose nouvelle heuristique encapsulant optimisation gloutonne descendante ensemble prototypes heuristique recherche voisinage variable Ferrandiz Boullé Optimisation gloutonne ensemble prototypes heuristique gloutonne GLOUTON applique ensemble prototypes Chaque ensemble obtenu suppression élément évalué Parmi ensembles celui minimisant critère déclaré vainqueur étape procédé itéré application vainqueurs successifs jusqu évaluation finale singleton meilleur ensemble rencontré parcours renvoyé Autrement algorithme GLOUTON écrit Faire meilleur ensemble obtenu suppression élément Retourner meilleur ensemble prototypes rencontré Cette méthode évalue ensembles chaque évaluation nécessite chaque tance rechercher proche prototype GLOUTON possède basiquement complexité temporelle astuces implantation réduisent complexité rithmique chaque étape toute suppression prototype conduit réattribuer uniquement instances appartenant cellule prototype étape instances traiter rendre constant effet dispose chaque instance liste triée éléments distance croissante acquisition proche prototype suivant constant algorithme GLOUTON adjoindre phase initialisation devient prépondérante complexité temporelle construction listes triées taille stockage listes induit complexité spatiale valeur critère également constant Seuls derniers termes dépendent répartition instances cellules suppression totype conduit abord soustraire participation valeur critère Ensuite réattribution instance proche prototype suivant induit simple incré mentation unitaire compteurs indice classe laquelle appar tient instance terme critère porté prototype ajoutant Notons introduire GLOUTON contrainte préservation certains prototypes GLOUTON évalue suppression prototype celui appartient optique inclusion heuristique cette modification permet limiter redondance recherche Recherche voisinage variable heuristique gloutonne nature susceptible empêtrer optimum local naturel envisager remise question solution proposée GLOUTON applique heuristique recherche voisinage variable décrite Mladenovic Celle consiste modifier localement solution réappliquer heuristique heuristique gloutonne obtient ainsi meilleure réitère explorant voisinage éloigné Sinon réitère considérant Sélection supervisée instances voisinage taille minimale nouvelle meilleure solution nombre étape usuelle contrôlé valeur maximale spécifiée utilisateur notion voisinage solution définie ensemble proto types voisin ensemble prototypes inclus ensemble instances appartenant cellules associées éléments voisinage contient voisins proportion prototypes remplacée proportion instances union cellules correspondantes Figure Exemple partitions voisines Répartition instances cellules partition prototypes prototypes remis cause instances instances appartenant cellules associées remplacent Partition voisine obtenue unique paramètre Niveau quantifie degré optimisation souhaité utilisateur incrémentation unitaire paramètre revient doubler temps consacré optimisa algorithme RVVGLOUTON Niveau complexité 2NiveauN2 écrit alors DegreMax 2Niveau GLOUTON Degre TantQue Degre DegreMax Faire Degre DegreMax Sélection solution GLOUTON meilleur Degre Sinon Degre Degre TantQue Retourner Ferrandiz Boullé Expérimentation évalue méthodes sélection instances selon trois performance prédictive bonne classification compression rapport nombre prototypes nombre instances robustesse rapport prédiction prédiction apprentissage indicateurs estimés validation croisée stratifiée niveaux DROP3 Explore Sonar Heart Ionosphere Australian Breast Vehicle German Yeast Segmentation Abalone Waveform WaveformNoise PenDigits Moyenne bonne prédiction notre méthode RVVGLOUTON DROP3 Explore classification proche voisin estimés valida croisée stratifiée niveaux nombre Victoire Egalité Défaite significatives statistique Student niveau reporté Notre méthode comparée DROP3 Explore règle classification proche voisin niveau RVVGLOUTON donne temps calcul ordre celui Explore données issus Blake données utilisés tableau lesquels performance dictive règle classification proche voisin significativement supérieure celle prédicteur majoritaire attribue toute nouvelle instance classe majoritaire échantillon éviter toute interférence résultats relative choix tance prétraitement considère données valeurs Sélection supervisée instances manquantes variables continues distance Minkowski office mesure similitude bonne prédiction reporté tableau compression moyen tableau méthodes classiques représentées DROP3 réalisent pression ordre perte terme performance prédictive respectivement contre classification proche Notre méthode sélectionne minimum instances contre Explore moyenne performance prédictive affectée méthodes plaçant cadre apprentissage modèles formantes méthodes classiques basées définitions nécessairement heuristiques utilité individuelle approche descriptive adoptée permet gagner encore compres rapport Explore conduit améliorer robustesse tableau fiabilité résultat propriété importante approche descriptive permet améliorer autant intéressant modèles considérés fonctions probabilités conditionnelles riches modèles usuels classifieurs chaque prototype associé distribution probabilité étiquettes Notre méthode extrait connaissance manière fiable profitable utilisation phase préparation données méthodes prédictives inadaptées DROP3 Explore Compression Moyenne Robustesse Moyenne Compression robustesse moyenne méthodes testées estimées validation croisée stratifée nombre Victoire Egalité Défaite significatives statistique Student notre méthode Conclusion classification suivant proche voisin repose construction partition Voronoi article avons proposé critère évaluation partitions induites ensembles prototypes inclus ensemble instances formant échantillon approche descriptive adoptée ayant permis faire porter gestion apprentissage critère avons également proposé heuristique optimisation poussée critère expériences données montré notre méthode pétitive terme performance prédictive sélectionnant minimum instances étude robustesse également illustré méthode apprend décision prise fiable pertinente concourt emploi déploiement modèles classification proche voisin richesse connaissance extraite lisation méthode limitée prédiction Ferrandiz Boullé Annexe Taille Variables Classes Prédiction majoritaire Sonar Heart Ionosphere Australian Breast Vehicle German Yeast Segmentation Abalone Waveform WaveformNoise PenDigits Caractéristiques données utilisés Références Kibler Albert Instance based learning algorithms Machine Berndt Clifford Finding patterns series dynamic programming approach Technical report Advances Knowledge Discovery Mining Blake repository machine learning databases mlearn MLRepository Cameron Jones Instance selection encoding length heuristic random tation climbing Proceedings eighth australian joint conference artificial intelligence Chapman Clinton Kerber Khabaza Reinartz Shearer Wirth CRISP mining guide Stork Pattern classification Wiley Sélection supervisée instances Hodges Discriminatory analysis nonparametric discrimination Consis tency properties Technical Report Project Number School Aviation Medicine Randolph Field Gates reduced nearest neighbor transactions information theory Hansen Mladenovic Variable neighborhood search principles applica tions European journal operational research condensed nearest neighbor transactions information theory Sebban Lallich Stopping criterion boosting based reduction techniques binary multiclass problem Journal machine learning research Stanfill Waltz Toward memory based reasoning Communication Vapnik nature statistical learning theory Srpinger Verlag Wilson Asymptotic properties nearest neighbor rules using edited Transactions systems cybernetics Wilson Martinez 1997a Improved heterogeneous distance functions Journal artificial intelligence research Wilson Martinez 1997b Instance pruning techniques Fisher Procee dings international conference machine learning Francisco Morgan Kaufmann Wilson Martinez Reduction techniques instance based learning algorithms Machine learning Summary Nearest Neighbor simple efficient practice instances fully selected order computing avoid overfitting voronoi tesselation induced selected instances prototypes underlying structure descriptive approach adopted paper results global evaluation criterion which makes compromise between number prototypes discrimination target feature explicit optimisation heuristic proposed properties Voronoi partitions criterion allows reduce algorithmic complexity method pared several state twenty repository presented technique suffer accuracy selects stances consequence robustness improved overfitted