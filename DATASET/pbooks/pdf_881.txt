UntitledUn modèle espace vectoriel concepts noyaux sémantiques Sujeevan Aseervatham Université Paris Clément 93430 Villetaneuse France Sujeevan Aseervatham paris13 Résumé noyaux largement utilisés traitement données textuelles comme mesure similarité algorithmes Sépara teurs Vaste Marge modèle espace vectoriel ample utilisé représentation spatiale documents Cependant représentation purement statistique papier présentons modèle espace vectoriel concepts connais sances linguistiques priori capturer documents propo aussi noyau linéaire noyau latent espace noyau linéaire exploite concepts linguistiques extraction alors noyau latent combine concepts statistiques linguistiques effet noyau utilise concepts latents extraits Analyse Sémantique Latente noyaux évalués tâche catégorisation texte domaine biomédical corpus Ohsumed connu difficulté catégorisation utilisé résultats montré performances catégorisation améliorées Introduction mesures similarité éléments algorithmes traitement matique langues Elles utilisées orienter processus extraction connais sance Ainsi elles principales responsables performances algorithme mesure similarité pertinente améliorera performances mauvaise mesure risque mener résultats incohérents définition bonne mesure processus effet mesure donner bonne indication degré similarité entre documents notion sémantique clairement définie essayons imiter perception humaine information sémantique prendre différente forme selon approche adoptée existe grandes approches basée information statistique fréquence occurrence termes autre basée sources connais sances externes telles ontologies communauté apprentissage noyaux Shawe Taylor Cristianini utilisés depuis décennie comme fonctions similarité basées cosinus formé modèle espace vectoriel concepts vecteurs noyaux réalité produits scalaires définis espace Hilbert spécificité plonger implicitement données espace Hilbert espace description avant calculer produit scalaire noyaux peuvent intégrés algorithme apprentissage produit scalaire Séparateurs Vaste Marge Vapnik Ainsi étendent utilisation apprentissage numérique tâches Traitement Automatique Langues effet aucune contrainte étant imposée espace données noyaux peuvent définis données données textuelles modèle espace vectoriel Salton repré sentant document forme vecteur fréquences termes largement utilisé noyaux basés modèle permis obtenir résultats prometteurs domaine catégorisation texte Joachims article présentons modèle espace vectoriel concepts représentation documents textuels Cette représentation induite connaissances priori présentée comme alternative modèle classique espace vectoriel uniquement fréquence occurrence termes nomie concepts linguistiques utilisée comme source connaissance définir vectoriel proposons noyaux basés concepts premier noyau noyau linéaire défini chaque document représenté vecteur concept intégrant information taxonomie concepts second noyau noyau latent mélange approche agnostique basée information statistique approche priori utilisant connaissances externes propres domaine noyau Cristianini noyau latent utilise décomposition valeurs singulières découvrir structures latentes entre concepts linguistiques utilisation noyaux illustrée tâche catégorisation texte domaine biomédical Unified Medical Language System utilisé source priori connaissances biomédicales extraction concepts partir documents textuels performances noyaux évaluées cette tâche utilisant classifieur corpus Ohsumed connu corpus difficile utilisé évaluation expérimentale modèle espace vectoriel modèle espace vectoriel représentation documents textes espace vectoriel communément utilisée introduit Salton problème indexation documents document associé vecteur chacun composants représente fréquence occurrence terme document ainsi repère chaque représente fréquence terme précis simplicité efficacité largement adopté résoudre large variété problème Joachims plusieurs classifieurs utilisés problèmes gorisation texte classifieurs particulier donné excellents résultats Aseervatham raffiner Analyse Sémantique Latente Deerwester proposée principale représenter document termes concepts hypothèse concepts adaptés déliser documents termes espace sémantique faible dimension défini appliquant Décomposition Valeurs Singulières matrice termes document vecteurs documents alors projetés espace sémantique utilisant nouvel espace Noyau Sémantique Latent proposé Cristianini noyau utilisé projeter documents espace sémantique calculer produit scalaire noyau utilisé succès tâche catégorisation texte montré noyau atteindre mêmes performances espace faible dimension noyau utilisé Joachims espace sémantique permet obtenir bonnes performances espace étant défini concepts statistiques difficile linguistiquement inter préter espace concepts Noyau linéaire modèle espace vectoriel concepts traitement documents documents textuels formatés utilisation humaine Ainsi contiennent riche variété symboles protocoles règles typographiques infor mations ajoutées rendre lecture compréhension aisées Toutefois traitement automatique données rendu compliqué effet éléments cument correctement gérés peuvent source bruits ambiguïtés entraînera inexorablement baisse performances système façon éviter problème traiter document avoir représentation adaptée système traitement cadre travail utiliserons traitement suivant Nettoyage document éléments peuvent introduire bruit éliminés Ainsi nombres aussi format numérique format littéral données textuelles retirés noter utilisons terme bruit général Segmentation texte document segmenté unité lexicale composée plusieurs lexique utilisé notre lexique médical Specialist Lexicon utilisé Suppression vides unités lexicales contenant vides savoir signification éliminés Normalisation termes éviter différentes formes fléchies proces normalisation effectué lexique normalisation consiste lemmatiser chaque unité lexicale ordonner alphabétiquement cette unité unités lexicales absentes lexique décomposées unité lexicale composée processus stemming ensuite appliqué chacun Annotation Sémantique Chaque unité lexicale associée groupe concepts plusieurs concepts Cette étape nécessite utilisation thésaurus outre modèle espace vectoriel concepts taxonomie relation entre concepts utilisée phase traite cadre notre travail Metathesaurus utilisé thésaurus intègre ontologie concepts complexe ontologie transformée taxonomie conservant relations supprimant cycles modèle espace vectoriel concepts modèle espace vectoriel forme morphologique termes ainsi hautement dépendant langue texte fréquence occurrence termes effet utilise simplement fréquence termes capturer information document ainsi limité correctement gérer termes synonymes termes polysémiques liens entre termes sémantiquement proches peuvent modélisés Toutefois espace haute dimension induit permet systèmes utilisant obtenir performances parmi meilleures chims cette section présentons modèle espace vectoriel concepts modèle devrait permettre gérer problèmes rencontrés énumé dessus espace vectoriel lequel chaque représente concept défini dictionnaire concepts dictionnaire constitué concepts définis thésaurus racines obtenus stemming lorsque peuvent sociés concepts prenons alors hypothèse expriment concept entière documents traités selon méthode décrite document traité chaque unité lexicale document associée vecteur concepts local composant associé concept alors donné ensemble termes normalisés unité lexicale compo associé concept vecteur concept terme normalisé défini sinon ensemble concepts associés ensemble chemins allant concept concept racine taxonomie chemins allant concept spéci fique concept général distance entre concept concept chemin valeur exprimant puissance décroissance décroître influence concepts généraux représentation terme effet étant donné terme concept associé chemin allant concept Aseervatham général concept racine concepts proches terme distance fourniront principal comparés concepts éloignés concepts généraux expriment clairement pertinent peuvent mener ambiguïtés voire bruit conséquent intéressant diminuer pouvoir expressif concepts selon leurs distances rapport concept spécifique fixant pouvons considérable réduire expressivité concepts généraux fixant pouvons donner pouvoir expression concepts faisant aucune différence entre concepts généraux spécifiques manière empirique fonction corpus Étant donné ensemble vecteurs concepts locaux cument vecteur concept global donné formule suivante normalisation équation utilisée représenter documents longueur différente échelle concepts apparaissent beaucoup documents corpus fourniront information utile discrimination ments alors concepts rares corpus peuvent significatifs conséquent proposons utiliser vecteur pondéré utilisant pondération Inverse Document Frequency vecteur défini ΦIDFi nombre document corpus ensemble documents corpus contenant concept figure illustre modélisation document textuel noyau linéaire définissons noyau linéaire modèle espace vectoriel concept comme noyau latent analyse sémantique latente permet mettre relations entre termes relations extraites décomposition linéaire valeurs singulières matrice fréquences termes document Elles conséquent relations occurrences termes documents relations extraites appelés concepts latents permet ainsi seulement diminuer dimension espace conservant relations importantes aussi gérer polysémie synonymie esprit proposons papier utilisation capturer structures latentes entre concepts concepts peuvent perçus modèle espace vectoriel concepts représentation document texte selon modèle espace vectoriel concepts comme concepts abstraits niveau intéressant analyser expérimenta lement effet mélange entre concepts linguistiques concepts statistiques définissons matrice concept document comme dimension nombre total concepts nombre documents étant méthode supervisée savoir méthode utilise information étiquettes documents utiliserons documents étiquetés documents appren tissage documents étiquetés documents donne dénotons vecteurs singuliers associés valeurs singulières élevées matrice diagonale contenant valeurs singulières projection vecteur espace sémantique latente donnée Aseervatham noyau latent alors défini Évaluation expérimentale avons plusieurs expérimentations corpus médical évaluer présentation avons utilisé modèle espace vectoriel standard comme comparaison cette section présentons corpus médical utilisé opératoire expérimentations résumé résultats expérimentaux corpus Ohsumed expérimentations menées corpus Ohsumed corpus médical contenant documents apprentissage documents Hersh documents résumés articles médecine issus bibliographique médicale MEDLINE Chaque document documents étiqueté plusieurs étiquettes étiquettes correspondent catégories cardio vasculaires tâche catégorisation corpus connue difficile effet systèmes catégorisation fonctionnent relativement corpus Reuters 21578 NewsGroups voient leurs performances diminuées exemple Joachims classifieur linéaire atteint performance alors atteint performance corpus Reuters 21578 difficultés catégorisation données bruitées termes médicaux spécifiques catégories degré corrélation préparation expérimentations toutes expérimentations documents traités représentation selon modèle espace vectoriel concepts modèle espace vectoriel avons utilisé stemming réduire fléchis leurs bases communes avons outre éliminés vides stemming avons utilisé rithme Porter Porter gestion problème multi catégories avons utilisé stratégie contre Cette stratégie décomposition problème principal problèmes catégorisation binaire librairie libSVM Chang utilisée prentissage classifieurs évaluer avons utilisé comme comparaison avons utilisé noyau linéaire pondération normalisa vecteurs selon opératoire defini Joachims noyau nommé noyau Words kernel avons aussi utilisé modèle espace vectoriel concepts noyau utilisant équation noyau utilisé comme comparaison noyau latent utiliserons dénomination désigner noyau mesure utilisée évaluer performances classifieurs principalement mesure Sebastiani mesure moyenne harmonique précision rappel système catégorisation Évaluation puissance décroissance première expérimentation cherchons empiriquement valeur optimale puissance décroissance corpus Ohsumed rappelons contrôle manière concepts généraux compte équation valeur donnera poids concepts généraux spécifiques cette expérimentation utilisons uniquement données apprentissage données performance utilisons échantillonnage stratifié conserver proportions figure montre scores micro différentes valeurs meilleur score obtenu valeur micro outre meilleure performance obtenue point signifie concepts généraux jouent important tâche catégorisation corpus Ohsumed effectivement lorsque plusieurs general commun utilisés différents documents catégorie variation micro fonction pouvoir décroissance résultats obtenus utilisant données apprentissage données Évaluation nombre concepts latents noyaux basés dimension espace sémantique fixée piriquement conséquent avons ensemble expérimentations corpus Aseervatham entier faisant varier nombre concepts latents savoir nombre vecteurs guliers associés valeurs singulières élevées figure montre variation score micro noyaux latent atteignent leurs performances quasi optimales approximativement concepts latents croissance rapide performances nombre concepts compris allant montre premiers vecteurs singuliers fournissent information principale décrire cuments croissance performances diminue nombre concepts indiquant ainsi présence faible quantité information performances noyau latent meilleures rapport noyau différences prononcées nombre dimensions faible signifie noyau latent capable capturer exprimer infor mation principale espace faible dimension information principale résumée faible nombre vecteurs singuliers reste expérimentations avons fixés nombre concepts latents variation micro fonction nombre concepts latents Évaluation noyaux performances noyaux corpus Ohsumed reportées tableaux expérimentations réalisées ensemble données sélection termes noyaux obtiennent meilleurs résultats jusqu noyaux Comme attendu noyaux meilleurs performances noyaux linéaires concepts abstraits niveau espace sémantique résument information principale réduisent bruit outre noyau linéaire performant noyau déduisons concepts basés ontologie concepts linguistiques adaptés exprimer documents médicaux concepts abstraits concepts statistiques obtenus composition linéaire modèle espace vectoriel concepts Noyau Précision Rappel Linéaire Linéaire Latent scores micro moyennés corpus Ohsumed Noyau Précision Rappel Linéaire Linéaire Latent scores macro moyennés corpus Ohsumed Réduction quantité données apprentissage figure montre impact quantité données utilisées apprentissage performances noyaux Comme précédemment noyaux performants noyaux linéaires Néanmoins existe points intéressants résultats Premiè rement noyau performant noyau linéaire lorsque moins données apprentissage utilisées noyau linéaire performant signifie concepts statistiques pouvoir discriminatoire rieur concepts petits échantillons données apprentissage Toutefois quand apprentissage suffisamment importante concepts deviennent expressifs Deuxièmement noyaux réussissent capturer information principale faible quantité données effet performances cessent liorer fonction quantité données apprentissage conséquent pouvons déduire chaque document apprentissage fournit nouvelle information améliore performance catégorisation principalement corpus contient termes spécifiques faible fréquence occurrence Conclusion article avons présenté modèle espace vectoriel concepts représentation documents modèle utilise connaissances priori capturer documents textuels avons montré façon simple utiliser efficacement ontologies intégrer modèle espace vectoriel standard avons aussi adaptés noyau linéaire noyau avons illustré utilisation application domaine biomédical Metathesaurus utilisé comme source priori connaissance définir performances noyaux expérimentalement évaluées tâche catégorisation documents biomédicaux noyaux comparés noyau noyau résultats montré noyaux améliorent Aseervatham variation micro fonction pourcentage documents apprentis utilisés performances catégorisation expérimentations montré utilisation concepts latents extraits partir concepts linguistiques permettent améliorer résultats travail futur pensons améliorer représentation intégrant pondération attributs adaptée pondération montré Debole Sebastiani pondération supervisée termes pouvait améliorer catégorisation documents effet recherches récentes matière pondération termes donné résultats prometteurs Soucy Mineau Références Chang LIBSVM library support vector machines Cristianini Shawe Taylor Lodhi Latent Semantic Kernels Journal Intelligent Information Systems Debole Sebastiani Supervised weighting automated categoriza Proceedings symposium Applied computing Press Deerwester Dumais Landauer Furnas Harshman Indexing Latent Semantic Analysis Journal American Society Information Science Hersh Buckley Leone Hickam OHSUMED interactive retrieval evaluation large collection research SIGIR Proceedings annual international SIGIR conference Research development information retrieval Springer Verlag Joachims categorization support vector machines learning relevant features European Conference Machine Learning modèle espace vectoriel concepts Heidelberg Springer Verlag Joachims Learning Classify Using Support Vector Machines Methods Theory Algorithms Norwell Kluwer Academic Publishers Proposing weighting scheme categorization Proceedings National Conference Artificial Intelligence representations categorization study biomedical domain IJCNN International Joint Conference Neural Networks Porter algorithm suffix stripping Program Salton Vector Space Model automatic indexing Communications Sebastiani Machine Learning Automated Categorization Computing Surveys Shawe Taylor Cristianini Kernel Methods Pattern Analysis Cambridge University Press Soucy Mineau Beyond TFIDF Weighting Categorization Vector Space Model Kaelbling Saffiotti IJCAI International Joint Artificial Intelligence Professional Center Vapnik nature statistical learning theory Springer Verlag Summary Kernels widely Natural Language Processing similarity measures within inner product based learning methods Support Vector Machines Vector Space Model extensively spatial representation documents purely statistical representation paper present Concept Vector Space Model representation which linguistic prior knowledge capture meanings documents propose linear kernel latent kernel space linear kernel takes advantage linguistic concepts whereas latent kernel combines statistical linguistic concepts Indeed latter kernel latent concepts extracted Latent Semantic Analysis kernels evaluated categorization biomedical domain Ohsumed corpus known being difficult catego results shown improves performances compared