Apprentissage structure seaux siens donne incomple Olivier Franc Philippe Leray Rouen Laboratoire Universite 76801 Etienne Rouvray Cedex Olivier Francois Philippe Leray rouen rouen formalisme graphiques connait actuellement essor domaines machine learning particulier seaux siens capables effectuer raisonnements probabilistes partir donne incomple alors thodes actuellement capables utiliser bases exemples comple apprentissage inpirant principe propose Friedman travaux proposons thode permettant faire apprentissage seaux siens particuliers structure borescente partir donne incomple rimentale expose ensuite sultats liminaires possible attendre telle thode montre potentiel apporte lorsque utilisons arbres obtenus comme initialisation thode recherche gloutonne comme Introduction termination cessite finition graphe clique dirige sommets repre sentent ensemble variables atoires structure matrices probabilite conditionnelles connaissant parents parame nombreuses thodes apprentissage structure seaux siens dernie Alors possible faire apprentissage parame seaux siens partir donne incomple rence seaux siens sible lorsque attributs observe Jensen Pearl algorithmes apprentissage structure donne incomple restent rares possible diffe rencier trois types donne manquantes selon canisme premier repre sente donne manquantes hasard missing probabilite variable mesure certaines autres variables observe Lorsque cette probabilite variables observe donne manquantes dites missing completely random contre lorsque probabilite variable manquante certaines autres variables observe galement rieurs donne dites suite supposerons sommes sence donne incomple suivant canisme Ainsi posse toute information cessaire estimer distribution donne manquantes exemples Lorsque donne incomple possible terminer parame structure partir entre comple Comme donne manquantes suppose atoirement construisons ainsi estimateur biais anmoins exemple attributs probabilite mesure manquante disposerons moyenne complets autres donne notre disposition gligeables serait rable faire apprentissage utilisant toute information laquelle avons avantage seaux siens suffit seules variables soient observe estimer table probabilite conditionnelle correspondante alors possible utiliser exemples incomplets variables observe seaux siens apprentissage structure donne incomple exemple supposant posse trois parents aurions exemples moyenne estimer parame correspondants recherche structure seaux siens utiliser bases donne incomple exemple biais chantillonnage Gibbs Myers encore utili approche comme algorithme Friedman Friedman autres travaux utilisent techniques originales comme Sebastiani Ramoni effectue appren tissage structures locales encore Druzdzel utilise thode recherche pendances conditionnelles proposons inspirer thode Friedman associant score structure arborescente partir donne incomple choisissant meilleur arbre selon score section suivante rappelons comment associer score manie estimer score lorsque exemples incomple introduisons thode ralisation recherche arbre recouvrement maximal adapte seaux siens Heckerman finissons exposer quelques sultats liminaires apports ventuels telle technique notamment lisation arbre rendu initialiser recherche gloutonne comme Friedman Score donne incomple Soient ensemble variables atoires tirages pendants identiquement distribue Supposons ailleurs seule version incomple disponible celle alors composer ensemble variables mesure ensemble variables manquantes Score donne incomple score exemples comple supposant toutes variables discre Cooper Hersovits donne sultat suivant nombre instances sence donne incomple avons quation alors value application multiple quation toutes comple tions possibles variables manquantes complexite calcul alors nentielle fonction nombre valeurs manquantes exemples pratique utilisable utiliser thode approximation Approximation score donne incomple fonction score quelconque comple score score autre score information Olivier Franc Philippe Leray fonctions score possible estimer score donne incomple calculant Malheureusement avons falloir approcher cette partir suppose rateur alors possible crire obtenue rence Cette thode permet partir fonction score quelconque fonction score donne sultat approche bases exemples incomple score particularite conserver proprie composabilite alors exemple score donne Algorithme apprentissage structure Structural Friedman premiers proposer thode terministe efficace faire recherche structure partir donne incomple principe thode propose Friedman rappele algorithme Algorithme Algorithme apprentissage structure Choisir graphe parame atoirement utilisant heuristique convergence Faire convergence Faire argmax argmax argmax pouvons terminer maximise score parmi Robinson Heureusement version ralise algorithme Dempster montre suffit trouver meilleure solution pluto meilleure perdre convergence thode cadre thode argmax ainsi calcule ensemble voisins graphe graphes obtenus suppression ajout inversion nouvelle thode espace arbres inspirant recommandations Heckerman Franc Leray montre donne comple thode maximum weight spanning recherche arbre recouvrement maximal adapte seaux siens permet obtenir seaux siens apprentissage structure donne incomple Structures utilise bases exemples Jouet Jouet Jouet Jouet Jouet rapidement structure simple ayant score pouvant galement servir initialisation thode recherche gloutonne proposons adapter cette thode bases donne incomple algorithme proche celui sente demment diffe rence principale recherche argmax proposons rechercher meilleur graphe ensemble arbres pluto meilleur voisinage Cette cessite calcul matrice similarite laquelle devons utiliser fonction score composable localement terme rique cette matrice donne sinon algorithme Kruskal permet ensuite obtenir cette matrice arbre maximise algorithme comme algorithme thode rative initialise Friedman propose choisir reliant toutes variables comme initialisation algorithme allons faire comme initialisation proposons ensuite initialiser arbre rendu tudier apports ventuels telle initialisation Variante proble classification souvent utilise classification structure correspond hypothe pendance variables conditionnellement variable classe possible assouplir cette hypothe pendance ajoutant entre variables particulier thode augmented naive Bayes ajoute structure Bayes meilleur arbre reliant variables autres classe pouvons maintenant utiliser approche donne incomple notre algorithme obtenir variante proble classification appellerons rimentations avons teste algorithmes suivants arbre recouvrement maximal donne quantes Structural Structural initialise arbre bases donne incomple utilise partir seaux siens structures crites figure donne manquantes diffe rentes probabilite Durant apprentissage avons utilise approximation score section bases comple galement table contient moyenne scores bases obtenus partir bases apprentissage diffe rentes ainsi moyennes temps calculs secondes donne titre indicatif obtenu machine Interpre tations sultats structures initialement arborescentes jouet jouet trouve meilleur graphe rapidement Olivier Franc Philippe Leray Jouet Jouet Jouet Jouet Jouet ntest 12393 16476 11266 Scores calcule donne seaux initiaux seaux appris thodes calcule bases apprentissage atoirement temps calculs entre parenthe sultats moyenne cutions diffe rentes bases apprentissage seaux complexes trouve structure moins bonne score souvent proche toujours beaucoup rapidement sultats souvent meilleurs initialisation proposons semble permettre converger rapidement solution converger meilleure solution remarquons galement cette thode stable thode effet recherche gloutonne posse inconvenient optimum locaux alors initialisation permet trouver meilleur graphe Conclusions perspectives avons propose thode originale apprentissage structure arborescente seaux siens partir bases donne incomple avons compare empiriquement cette thode algorithme Friedman premiers sultats permettent thode assez efficace complexe permet retrouver structures ayant score rapidement anmoins notre thode savantage travailler espace arbres restrictif Ensuite avons utilise notre thode initialiser algorithme Cette initiali sation permet souvent obtenir meilleurs sultats utilisant initialisation propose Friedman envisageons maintenant tester valuer algorithmes ventail proble large notamment donne proble classification thodes adaptations algorithmes recherche struc espace graphes acycliques dirige Chickering propose cemment algorithme optimal recherche autre espace espace repre sentants quivalents Markov suite logique travaux adaptation bases donne incomple Remerciements travail partiellement finance programme communaute europe excellence PASCAL 506778 Cette publication refle opinions auteurs rences Chickering Chickering Learning equivalence classes bayesian network structures Journal machine learning research pages seaux siens apprentissage structure donne incomple Approximating discrete probability distributions dependence trees Transactions Information Theory pages Cooper Hersovits Cooper Hersovits bayesian method induction probabilistic networks Maching Learning pages Druzdzel Druzdzel Robust independence testing constraint based learning causal structure Proceedings Nineteenth Conference Uncertainty Artificial Intelligence UAI03 Dempster Dempster Laird Rubin Maximum likelihood incomplete algorithm Journal Royal Statistical Society pages Franc Leray Franc Leray Evaluation algorithmes appren tissage structure seaux siens 14ieme Congre francophone Recon naissance formes Intelligence artificielle pages Friedman Friedman Learning belief networks presence missing values hidden variables Proceedings International Conference Machine Learning Morgan Kaufmann pages Friedman Friedman Bayesian structural algorithm Moral Proceedings Conference Uncertainty Artificial Intelligence Francisco Morgan Kaufmann pages Heckerman Heckerman Geiger Chickering Learning Bayesian networks combination knowledge statistical taras Poole Proceedings Conference Uncertainty Artificial Intelligence Francisco Morgan Kaufmann Publishers pages Jensen Jensen introduction Bayesian Networks Taylor Francis London United Kingdom Myers Myers Laskey Lewitt Learning bayesian network incomplete stochatic search algorithms Proceedings Fifteenth Conference Uncertainty Artificial Intelligence UAI99 Wuillemin Leray Pourret Becker seaux siens Eyrolles 11137 Pearl Pearl Graphical models probabilistic causal reasoning Gabbay Smets Handbook Defeasible Reasoning Uncertainty Management Systems Volume Quantified Representation Uncertainty Imprecision pages Dordrecht Kluwer Academic Publishers Robinson Robinson Counting unlabeled acyclic digraphs Little Combinatorial Mathematics volume Lecture Notes Mathematics Springer Berlin pages Sebastiani Ramoni Sebastiani Ramoni Bayesian selection composable models incomplete Journal American Statistical Association Summary framework graphical models Machine Learning Specially Bayesian Networks allow carry probabilistic reasonning incomplete datasets methods incomplete datasets learn their structure Using principle Structural Friedman propose method perform structural search bayesian network space graphs incomplete datasets experimental study gives first results method shows potential improvement trees gives initialise greedy method Structural