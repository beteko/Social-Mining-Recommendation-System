Construction descripteurs partir coclustering classification supervisée séries temporelles Dominique Boullé Orange Lannion FRANCE prenom orange Résumé présentons processus construction descripteurs classification supervisée séries temporelles processus libre paramétrage utilisateur décompose trois étapes partir originales générons multiples nouvelles représentations simples chacune représentations appliquons algorithme clustering partir résultats clustering construisons veaux descripteurs séries temporelles obtenons nouvelle données objets attributs objets identifiant séries temporelles décrits attributs issus diverses représentations générées utili classifieur Bayésien cette nouvelle données montrons expérimentalement processus offre bonnes performances prédic tives comparées Introduction classification séries temporelles sujet intensivement étudié durant dernières années prédire classe objet série temporelle courbe valeur courbe temps étant donné ensemble séries temporelles labellisées apprentissage problèmes différents problèmes classification supervisée bases transactionnelles puisqu dépendance temporelle entre attributs ainsi ordre attributs importe applicable nombreux domaines données séries temporelles diagnostic médical exemple classification trocardiogramme patients aussi autres domaines comme maintenance machines industrielles finance météo grand nombre applications succité nombreuses approches toutefois majorité communauté attachée suivre cessus suivant choisir nouvelle représentation données choisir mesure similarité distance comparer séries temporelles enfin utiliser algorithme proche voisin mesure choisie représentation choisie comme classifieur propose différentes représen tations mesures ainsi étude expérimentale comparative basée classifieur ressort classifieur couplé distance Euclidienne Dynamic Warping présente meilleures performances prédictives problèmes Construction descripteurs classification supervisée séries temporelles récemment Bagnall démontre expérimentalement performances certains classifieurs augmentent fortement utilisant certaines représentations rapport domaine temporel original ainsi classifieur donné existe forte variance performance selon transformation données utilisée pallier problème Bagnall proposent méthode ensembliste basée trois représentations ainsi données originales résultats expérimentaux démontrent importance repré sentation problèmes simple combinaison ensembliste sieurs représentations permet atteindre performances prédictives compétitives adhérons cette conclusion importance représentations toutefois faiblesses certains classifieurs ensemblistes perte interprétabilité combinaison pondération classifeurs exemple illustratif graphiques figure confirment intérêt changement représentation partir données originales évident différencier classes rouge simples transformations intégrale cumulative double intégrale cumulative facilitent discrimination classes effet après trans formation double intégrale cumulative courbes séries ayant valeurs supérieures bleues courbes valeurs inférieures rouges exemple jouet extrait TwoPatterns Keogh transfor mation descripteurs permettent caractériser classes courbes TwoPatterns sample original values TwoPatterns sample cumulative integral values TwoPatterns sample cumulative double integral values Extrait quelques séries temporelles classes TwoPatterns représentation originale intégrale cumulative double intégrale cumulative Boullé article proposons processus construction descripteurs interprétables problème Notre contribution essentiellement méthodologique section suivante décrit différentes étapes notre processus étape transformation données originales nouvelles représentations étape coclustering exploitation résultats coclustering construire nouveaux descripteurs ainsi nouvelle données enfin classifieur utilisé section rapporte validation expérimentale notre processus Processus construction descripteurs Notations problème classification supervisée séries temporelles série temporelle définie paire ensemble observations données longueur valeur classe données séries temporelles définie comme ensemble paires chaque série temporelle avoir nombre observations férent longueur différente construire classifieur partir prédire classe nouvelles séries temporelles faire appliquons processus construction descripteurs décrit figure chaque étape détaillée suite transformation Data1 Data2 based coclustering Recoding FFFForig FFFFDp series Datap Transformed Enriched Processus construction descripteurs Etape Transformation données multiples nouvelles représentations Etape Coclustering chacune représenta tions Etape Construction ensemble descripteurs chaque résultat cocluste construction nouvelle données réunissant différents ensembles descripteurs construits Notons aussi séries peuvent avoir valeurs différentes Construction descripteurs classification supervisée séries temporelles Transformations Représentations nombreuses méthodes transformation proposées littérature présenter séries temporelles exemple transformations polynomiales symboliques spectrales ondelettes synthétique repré sentations notre processus utilisons données originales ainsi représen tations dérivées utilisons dérivées dérivées doubles séries porelles différences différences doubles locales entre valeurs temps transformations permettent représenter évolution locale croissante décroissante accélération décélération séries intégrales cumulatives utilisons aussi intégrales cumulatives simples doubles séries temporelles calculées approximation méthode trapèzes transformations permettent représenter évolution globale accumulée séries spectre puissance série temporelle décomposée combi naison linéaire sinusoïdes amplitudes phase Ainsi 2πwkt 2πwkt appelle transformée Fourier série paires spectre puissance obtenu somme carrés coefficients Fourier représentent fréquence puissance signal Cette transformation permet représenter série domaine fréquence fonction corrélation transformation fonction corrélation Boullé moyenne variance série originale décrit comment valeurs originales séparées certaine durée évoluent ensemble permet détecter structures autocorrélation séries temporelles Ainsi données séries temporelles Dorig construisons velles bases données suivant transformation utilisée suite souci généralisation objet représentations appelé courbe série temporelle puisque domaine temporel Coclustering courbe comme ensemble points décrits valeurs abscisses ordonnées ensemble courbes comme ensemble points identifiant courbe Cette représentation tridimensionnelle variable catégorielle variables numériques courbes nécessaire application méthodes coclustering effet partitionner variable tégorielle discrétiser variables numériques obtenir clusters courbes intervalles résultat final grille tridimensionnelle chaque cellule définie groupe courbes intervalle intervalle faire utilisons méthode coclustering Boullé utilisable logiciel KHIOPS Originalement développée général données fonction nelles Ramsay Silverman adapte particulier courbes comme définies dessus libre paramétrage utilisateur robuste évite apprentissage supporte bases données courbes plusieurs millions points complexité temps nombre points méthode adaptée notre problématique méthode basée estimation densité constante morceaux proche Boullé similaire approche Bayésienne Maximum teriori modèle optimal grille optimale obtenue optimisation gloutonne bottom critère Bayésien compromis entre précision robustesse modèle posterior prior vraisemblance grille obtenue constitue estimateur paramétrique densité jointe courbes dimensions points point théorie information selon Shannon logarithmes négatifs probabilités interprètent comme longueurs codage Ainsi critère interprété comme longueur codage modèle grille longueur données connaissant modèle selon principe Minimum Description Length Rissanen exemple visualisation résultat coclustering figure présente exemple visualisation clusters courbes grille optimale obtenue TwoPatterns transformée graphique présente cluster courbes majoritairement classe exemple introductif figure khiops Construction descripteurs classification supervisée séries temporelles Représentation information mutuelle cellules clusters courbes obtenus méthode TwoPatterns entière transformée cluster courbes majoritairement classe cluster courbes majori tairement classe couleurs vives différence distribution points entre cellule courante cluster reste données significative rouge exemple introductif grille optimale obtenue composée clusters courbes intervalles intervalles estimateur densité jointe obtenue grille optimale nécessite problème départ effet TwoPatterns problème classification classes obtenons clusters courbes donne potentiel caractérisation classes problème lorsque représentation prête Construction descripteurs partir chaque résultat coclustering obtenus chacune représentations utilisées Dorig créons ensemble descripteurs Forig descripteurs attributs notre nouvelle données objets courbes chaque représentation créons trois types descripteurs définis comme représentation parmi celles décrites grille tridimensionnelle optimale obtenue coclustering nombre clusters nombre intervalles dimension créons attributs suivants attributs numériques chaque cluster courbes valeur courbe distance définie différence entre modèle optimal grille optimale laquelle intégré courbe cluster courbes Intuiti vement distance mesure perturbation apporte intégration courbe cluster grille optimale Boullé attribut catégoriel indiquant index cluster courbes proche objet courbe selon distance définie dessus critère utilisé optimisation grille attributs numériques chaque intervalle deMrep valeur courbe nombre points intervalle Ainsi courbe donnée avons informations suivantes fournies cripteurs chaque représentation distance clusters courbes index cluster courbes proche nombre points chaque intervalle Classification supervisée avons notre processus construction descripteurs générer taines descripteurs représentation Ainsi ensemble total attributs générés contenir plusieurs milliers attributs classifieur processus pouvoir supporter grand nombre attributs capable sélectionner attributs pertinents tâche classification supervisée choisissons classifieur sélectif Naive Bayes Boullé répond attentes Notons aussi prédicteur exploite prétraitements variables numériques discrétisation variables tégorielles groupement valeurs utilisant estimateurs densité conditionnelle robustes Ainsi varibles construites profitent prétraitements offrent potentiel interprétabilité section libre paramétrage utilisateur facilite utilisation ensemble processus Validation expérimentale implémentation notre processus utilise outils existants cocluste classification supervisée disponibles khiops branchement entre outils encore stade prototype réalisé MATLAB Protocole valider notre processus utilisons bases données classifica séries temporelles bases Keogh nouvelles bases intro duites Bagnall description succinte caractéristiques données présentée table ensemble données présente grande variété bases terme applications terme nombre instances classes longueur série expériences menées suivant protocole train prédéfini chaque comparons notre processus classification appellera classifieur proche voisin distance Dynamic Warping considéré littérature comme difficile battre ENSEMBLE Bagnall exploite multiples représentations méthode ensembliste agorithme proche voisin Notons depuis existe autres bases données répertoriées Toutefois limitons bases expérimentations comparatives performances prédictives concurrents rapportées Bagnall Construction descripteurs classification supervisée séries temporelles Bases Train Longueur Classes Ligthing2 Lighting7 ECG200 Adiac FaceFour 50words GunPoint OSULeaf SwedishLeaf SyntheticControl Trace TwoPatterns Wafer FaceAll Coffee OliveOil Earthquakes HandOutlines FordA FordB ElectricDevices ARSim Description bases données séries temporelles accessibles bases autre bases séries ticulier cadre général lequel plaçons puisque donnée toutes séries longueur utilisent domaine temporel identiques Résultats résultats terme erreur reportés table meilleur résultat chaque Premièrement résultats globaux erreur moyen nombre victoires moyen indiquent compétitif rapport méthodes avons avantage numérique ensemble données permet montrer différence significative performance entre trois méthodes avons procédé Friedman Demsar pouvons rejeter hypothèse nulle Notons performances remarquables bases OSULeaf FordA tricDevices ARSim bases différence performance moins rapport concurrents apport représentations nouveaux cripteurs certainement oeuvre notre processus alors ENSEMBLE ploite représentations données originales inverse performances dramatiques bases ECG200 Coffee OliveOil différence performance tourne notre défaveur moins rapport concur rents pensons cette différence raisons bases appren tissage ECG200 OliveOil Coffee petites quelques dizaines courbes apprentissage difficile avons encore trouvé bonne représentation Boullé Attributs Bases ENSEMBLE Ligthing2 Lighting7 ECG200 Adiac FaceFour 50words GunPoint OSULeaf SwedishLeaf SyntheticControl Trace TwoPatterns Wafer FaceAll Coffee OliveOil Earthquakes HandOutlines FordA FordB ElectricDevices ARSim Moyenne 19965 21620 19918 Victoires Moyenne 03846 88461 Comparaisons performances prédictives terme erreur méthodes ENSEMBLE notre processus bases dernière colonne rapporte nombre descripteurs construits chaque représen tation Construction descripteurs classification supervisée séries temporelles permet construire descripteurs OliveOil étape coclus tering chacune représentations génère cluster courbes autres ECG200 Coffee étape coclustering produit clusters fournit descripteurs majorité entre considérés comme pertinents expériences rappellent importance représentations manière nérale particulier notre processus pouvons espérer amélioration performances prédictives rajoutant représentations littérature notre processus Interprétation exemple représentation TwoPatterns grille optimale obtenue composée clusters courbes intervalles intervalles variables pertinentes parmi toutes variables générées partir toutes représentations selon prétraitements issues représentation nombre points intervalle index cluster proche groupement valeurs discrétisation fournissent tables contin gence suivantes apprentissage tables points Table contingence variable nombre points intervalle issue représentation Groupes index clusters Table contingence variable index cluster proche issue représentation observons table nombre points courbe nombre points valeur inférieure pertinent caractériser classe effet apprentissage courbes telles classe lorsque elles majoritairement classe lorsque elles majoritairement classe table observons abord prétraitement supervisé groupement valeurs variable index cluster courbes proche produit Boullé groupes constitués index clusters majoritairement classe forme diagonale table contingence table indique pertinence attribut caractériser classe courbe effet exemple index cluster courbes proche courbe appartient groupe alors considéré comme similaire courbes classe variable index cluster courbes proche indicateur pertinence représentation notre processus problème courant exemple variable seule permet caractériser environ représentation pertinente caractériser classes TwoPatterns inverse représentation originale grille optimale générée composée clusters courbes prétraitement indique variable index cluster courbes proche pertinente caractériser classes TwoPatterns Conclusion Perspectives avons proposé processus générique construction descripteurs problème classification supervisée séries temporelles processus libre paramétrage utilisateur simple utilisation décompose trois étapes génération multiples représentations données biais transforma tions application technique coclustering chacune représentations construction descripteurs partir résultats coclustering nouvelle données objets attributs objets identifiant séries temporelles décrits attri issus diverses représentations générées notre apprentissage classer nouvelles séries utilisons classifieur Bayésien sélectif résultats expéri mentaux montré performances prédictives compétitives comparables meilleures approches littérature premiers résultats expérimentaux prometteurs confirment importance transformations effet selon applications certaines transformations ciliteront découverte motifs caractérisant classes séries temporelles combinaison plusieurs représentations biais notre processus permet atteindre performances prédictives compétitives avons utilisé quelques présentations simples travaux préliminaires démontrer fondé cessus construction descripteurs laisse potentiel amélioration performances données moins performant concurrents trouve bonne représentation Chercher bonnes représentations transformation certainement principale perspective travail pouvons recommander intéressent littérature regorge représen tations ensemble trouver bonne représentation toujours sujet actualité Lines autre perspective pratique identifier bonnes représentations domaine application spécifique consommation électrique Construction descripteurs classification supervisée séries temporelles Références Bagnall Davis Hills Lines Transformation based ensembles series classification Boullé bayes optimal discretization method continuous attributes Machine Learning Boullé Compression based averaging selective naive Bayes classifiers Journal Machine Learning Research Boullé Functional clustering piecewise constant nonparametric density estimation Pattern Recognition Demsar Statistical comparisons classifiers multiple Journal Machine Learning Research Trajcevski Scheuermann Keogh Querying mining series experimental comparison representations distance measures PVLDB Keogh Ratanamahatana series classification clustering eamonn time_ series_data Clustering series survey Pattern Recognition Lines Davis Hills Bagnall shapelet transform series classification Ramsay Silverman Functional analysis Springer Rissanen Modeling shortest description Automatica Shannon mathematical theory communication System Technical Journal Mueen Trajcevski Scheuermann Keogh Experi mental comparison representation methods distance measures series Mining Knowledge Discovery Summary suggest parameter process feature construction series classification process decomposed three steps transform original several simple representations representation apply coclustering method clustering results build features series results transactional series identifiers described features related various generated resentations Selective Naive Bayes classifier highly competitive compared state times series classification methods