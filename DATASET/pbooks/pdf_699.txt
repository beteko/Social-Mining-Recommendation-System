articles assemblage pdfSous échantillonnage topographique apprentissage supervisé Mustapha Lebbah Younès Bennani Université Paris avenue Baptiste Clément 93430 Villetaneuse prénom paris13 Résumé Plusieurs aspects pourraient influencer systèmes apprentissage existants aspects déséquilibre classes lequel nombre observa tions appartenant classe dépasse fortement celui observations autres classes assez fréquent système apprentissage difficultés cours phase entraînement liées déséquilibre inter classe proposons méthode échantillonnage adaptatif traiter bases déséquili brées processus procède échantillonnage données majoritaires guidé données minoritaires phase apprentissage supervisée utilisons comme modèle apprentissage cartes organisatrices approche proposée validée plusieurs bases données utilisant arbres décision comme classificateur validation croisée résultats expérimentaux montré performances prometteuses Introduction plupart algorithmes apprentissage basés hypothèses première critère minimiser nombre erreurs deuxième données prentissage doivent êtres échantillon représentatif population laquelle modèle appliqué hypothèses respectées certains modèles quand construits partir données déséquilibrées pouvons illustrer exemple simple souvent littérature données appartiennent seule classe difficile faire mieux erreur obtenue classant individus cette classe convient trouver autres solutions hypothèses adaptées problème déséquilibre remettre cause fondements algorithmes Weiss propose distinguer catégories problèmes données déséquilibrées apprentissage classes rares catégories Marcellin Métriques inappropriées mesures utilisées cours processus apprentissage adaptées classes déséquilibrées Manque absolu données problème observé lorsque données disponibles assez suffisantes définir clairement frontières classe Manque relatif données problème similaire manque absolu manque relatif taille données majoritaires mentation données problème algorithmes ayant approche descendante partent espace individus partitionnent récursivement espaces échantillonnage adaptatif petits Marge induction inappropriée marge appliquée règle apprise données apprentissage pouvoir généraliser Données bruitées bruit impact classes rares classes fréquentes distribution inégale classes problème responsable échec algorithmes prentissage Plusieurs méthodes proposées traiter problèmes déséquilibre plupart regroupent catégories principales niveau algorithmique méthodes tiennent intrinsèquement compte déséquilibre compensant données altérer distribution classes Raskutti Kowalczyk Kubat Barandela niveau données stratégies échantillonnage mettent équilibrer données constituer échantillons manière encourager algorithmes apprentissage converger modèle spécifique catégories considérées échantillonnage classe majoritaire échantillonnage classe minoritaire échantillonnage objectif rééquilibrer données augmentant nombre individus appartenant classe minoritaire Chawla inverse échantillonnage moyen rééquilibrer données suppres certain nombre individus appartenant classe majoritaire papier intéressons cette catégorie algorithmes méthode évidente simple celle consiste supprimer aléatoirement individus classe majoritaire inconvénients échantillonnage aléatoire autres techniques proposent guider échantillonnage classe majoritaire rendre moins aveugle retrouvons cipalement algorithme liens Tomek Tomek Considérons vidus appartenant respectivement classe classe distance entre individus paire Tomek existe aucun individu individus forment Tomek bruit points frontières trouvons aussi autre technique règle proches voisins condensé Condensed Nearest Neighbor autres méthodes consistent combiner différents algorithmes échantillonnage Batista Marcellin Echantillonnage Topographique Adaptatif Topogra Neighborhood Cleaning Règle nettoyage voisinage Cette méthode utilise règle proches voisins Wilson supprimer individus classe majoritaire Neighborhood Cleaning Laurikkala Après sélection trois voisins proches chaque exemple règles suivantes appliquée appartient classe majoritaire trois voisins proches classés classe minoritaire alors observation supprimée partient classe minoritaire trois voisins proches classés classe majoritaire alors trois voisins proches supprimés Lebbah Quantification topographique nettoyage adaptatif mieux guider échantillonnage rendre moins aveugle utilisation cartes organisatrices Kohonen paraît solution efficace choisir façon intelligente données supprimer classe majoritaire tenant compte leurs topologies méthode proposée consiste modifier algorithme appren tissage proposant supprimer chaque itération observations gênent données minoritaires approche consiste intégrer règles nettoyage algorithme comme troisième étape algorithme Cette règle appliquée localement niveau chaque cellule carte conséquent algorithme utilisé supervisé puisque étiquettes associées classe positive minoritaire utilisées étiquettes utilisées comme variable uniquement phase nettoyage élimination cours apprentissage observations implique modification apprentissage diminue mesure itérations individu Chaque observation dispose étiquette label positive données minoritaires négative majoritaires étiquette négative utilisée uniquement règle nettoyage notera suite ensemble données positives ensemble données négatives approche proposons approche hybride action données phase nettoyage voisinage modification algorithmique opposé obligation supprimer données classe majori taire notre approche puisque nettoyage voisinage applique manière locale niveau chaque cellule modèle classique cartes organisatrices utilisé présente forme carte possédant ordre topologique cellules cellules réparties nœuds maillage prise compte carte taille notion proximité impose définir relation voisinage topologique influence mutuelle entre cellules définie fonction distance graphe entre cellules chaque cellule grille associée vecteur référent dimension suite ensemble référents associés carte chaque référent associé ensemble données affectées cellule ensemble ensembles forment partition ensemble données proposons minimiser fonction suivante affecte chaque observation cellule unique carte phases principales algorithme apprentissage Entrées apprentissage paramètre taille voisinage Sortie Référents carte apprentissage échantillonnée Afinal Afinal telle final 1Self Organizing échantillonnage adaptatif Phase affectation chaque observation affectée referent proche distance euclidienne Phase adaptation vecteurs référents expression suivante Phase nettoyage chaque cellule itération alors alors trois phases permettent minimiser fonction premières phases similaires algorithme nuées dynamiques classique troisième phase permet minimiser fonction rapport apprentissage carte organisatrice détermine partition données groupes associés chaque référent carte important noter carte topologique aussi nouvelle apprentissage taille inférieure égale initiale Afinal Validation avons utilisé différents types bases données provenant répertoire Newman utilisés telle manière avoir degrés déséqui libre variables évaluer notre approche tableau Plusieurs indices évaluation existent littérature expérimentations avons choisi calculer indices synthétiques premier indice classique under curve nouvel appelé Index Balanced Accuracy présenté García TPrate TNrate TPrate TNrate TPrate TNrate indiquent pectivement positives négatives résultats présentés dessous obtenus paramètre voisinage local Bases Taille Taille Classe quanti quali operative Thyroid Ecoli Satimage Glass Bases apprentissage colonnes présentent nombre exemples nombre attributs quantitatifs qualitatifs classe minoritaire majoritaire leurs distribution tableau présente mesures calculées arbres décision nombres entre parenthèses indiquent écart calculé expériences correspondant validation croisée divisant ensembles répétant Lebbah Bases operative Thyroid Ecoli Satimage Glass calculés arbres décision nombres entre parenthèses correspondent écart calculé après validation croisée under curve Index Balanced Accuracy données supprimées après application algorithme correspond taille classe majoritaire processus analyse résultats permet premier confirmer échantillonnage topographique adaptatif permet obtenir meilleurs performances terme indice plupart bases données avons constaté légère baisse thyroid observant uniquement indice Cette baisse uniquement faible valeur TNrate bases exemple TNrate passe contre concernant classe positive TPrate passe traduit augmentation indice donne avantage classe positive mieux comprendre comportement méthodes avons suppression obtenu apprentissage supervisé table observons clairement méthode fournit majoritairement pression élevé comparant celui avons constaté atteignons performances meilleures similaires moins données méthode Conclusion perspectives sommes intéressés travail problème déséquilibre classes différentes méthodes solutions existantes Ensuite avons présenté approche échantillonnage cartes topologiques Cette solution guide choix données supprimer voisinage local prenant considération distribution topologie données série expériences réalisées valider méthode proposée résultats obtenus comparés méthode échantillonnage connue permis mieux évaluer notre approche avérée prometteuse comme solution problème déséquilibre classes perceptives issues travail touchent grand nombre étapes premier temps comptons comparer notre approche autres méthodes échantillonnage étudier influence recouvrement données performances deuxième temps envisageons étudier performances méthode présence autres méthodes classement simplement autres indices évaluation seront aussi étudiés échantillonnage adaptatif Références Asuncion Newman machine learning repository mlearn MLRepository Barandela Sánchez García Rangel Strategies learning class imbalance problems Pattern Recognition Batista Prati Monard study behavior several methods balancing machine learning training SIGKDD Explor Newsl Chawla Bowyer Kegelmeyer Smote Synthetic minority sampling technique Journal Artificial Intelligence Research García Mollineda Sánchez Index balanced accuracy perfor mance measure skewed class distributions Araújo Mendonça Pinho Torres IbPRIA Volume Lecture Notes Computer Science Springer Measuring classifier performance coherent alternative under curve Machine Learning condensed nearest neighbor Trans Inform Kohonen organizing Springer Berlin Kubat Holte Matwin Learning negative examples abound Proceedings European Conference Machine Learning London Springer Verlag Laurikkala Improving identification difficult small classes balancing class distribution Proceedings Conference Medicine Europe London Springer Verlag Marcellin Zighed Ritschard Evaluating decision trees grown asymmetric entropies Matwin Slezak ISMIS Volume Lecture Notes Computer Science Springer Raskutti Kowalczyk Extreme balancing study SIGKDD Explor Newsl Tomek experiment edited nearest neighbor Transactions Systems Cybernetics Weiss effect small disjuncts class distribution decision learning thesis Brunswick Director Hirsh Summary Several aspects could affect existing machine learning algorithm these related imbalance classes which number observations belonging class greatly exceeds observations other classes propose method adaptive subsampling treat imbalanced databases process proceeds subsampling majority class guided minority supervised learning learning model organizing proposed approach validated multiple databases using decision trees classifier cross validation experimental results showed promising performance