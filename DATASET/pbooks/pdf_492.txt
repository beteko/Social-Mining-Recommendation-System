environnement efficace classification images grande échelle Thanh François Poulet Université Rennes IRISA Campus Beaulieu 35042 Rennes Cedex France thanh francois poulet irisa Résumé plupart processus classification images comportent trois principales étapes extraction descripteurs niveaux création vocabulaire visuel quantification apprentissage algorithme classification nombreux problèmes posent passage échelle comme ensemble données ImageNet contenant millions images classes complexité concerne temps exécution chaque tâche besoins mémoire disque stockage SIFTs cessite présentons version parallèle LibSVM traiter grands ensembles données temps raisonnable perte information phase quantification visuels obtenus assez discriminants grands ensembles images proposons utiliser plusieurs descripteurs simultanément améliorer précision classification grands ensembles images sentons premiers résultats grandes classes images ImageNet Introduction classification images tâche importante domaine vision nateur reconnaissance objets apprentissage automatique utilisation descripteurs niveau image modèle coeur systèmes classifi cation images actuels plupart environnements classification images comportent trois étapes extraction descripteurs niveau images création vocabulaire visuels apprentissage modèle classes images mière étape extraction descripteurs niveau choix courants méthodes récentes SIFTs SURFs DSIFTs Bosch étape création vocabulaire visuel choix habituel cette étape utilisation algorithme means création troisième étape apprentissage classifieur beaucoup systèmes choisissent souvent Support Vector Machines noyaux linéaires linéaires plupart systèmes ensuite évalués petits ensembles données tiennent problème mémoire centrale comme Caltech Caltech Griffin PASCAL Everingham Cependant apparition notamment ensemble environnement efficace classification images grande échelle vocabulaire visuel descripteurs image means parallele DSIFT feature apprentissage parallele classification images représentation image Creation vocabulaire Description notre environnement classification images grande échelle données ImageNet contient millions images 21000 classes tâche classification images beaucoup complexe difficile effectuer challenge motivé développer système performant temps calcul précision classification présentons notre solution traitement efficace ensembles données premiers résultats prometteurs rapport approches ensemble ImageNet proposons système rapide ficace classification images grande échelle avons développé système version parallèle algorithme libSVM traiter grands ensembles données temps raisonnable proposons nouvelle approche utilisant plusieurs descripteurs niveaux combinant ensembles approche multi descripteurs multi vocabulaires Classification grande échelle travaux récents classification images conver modèle Csurka quantification descrip teurs locaux Support Vector Machine comme techniques modèles peuvent Poulet améliorés pyramides spatiales multi échelles Lazebnik histogrammes gradients orientés Dalal Fergus utilisent apprentissage supervisé Images classes images quetées manuellement présentent classification maximum classes étudient classification paysages collection classes millions images petit ensemble classes amélioré résultats classification augmentant taille vocabulaire visuel jusqu 80000 visuels permettre apprentissage grands ensembles données plusieurs approches commencent transformer données utilisant fonction noyau linéaire utilisant classifieur linéaire rapide espace résultant ronnin travaux récents utilisant hiérarchies reconnaissance catégorisation images permis gains importants précision efficacité étude surcoût hiérarchies classification problème détection souvent traité comme répétition classifications contre reste fenêtres coulissantes beaucoup cette localisation objets utile améliorer classifica approches performantes Vedaldi Everingham nécessitent temps calculs longs rendent difficiles utiliser ensembles données ImageNet différence entre notre approche approches récentes oeuvre algorithmes parallèles accélérer trois processus traction descripteurs niveau images quantification apprentissage classifieur expérimentations montrent premiers résultats prometteurs confirment algorithmes parallèles essentiels classification images grande échelle terme temps exécution Représentation images SIFTs modèle coeur tèmes classification actuels représentation image modèle requiert trois étapes triviales détection points intérêt description points quantification trois étapes objet progrès significatifs nières années Cependant chacune étapes significative information perdue résultats obtenus approches utilisant souvent discriminantes classification images grande échelle Différentes approches proposées améliorer pouvoir discriminant différentes étapes étape détection points intérêts plusieurs détecteurs combinés meilleure discri mination codage descripteurs utilise descripteurs grande dimension encodant informations Winder Enfin étape quantification différentes approches utilisées réduire erreur quantification mieux server information descripteurs Moosmann Philbin prenons vision globale trois étapes proposons nouvelle approche combine multiples descripteurs multiples vocabulaires visuels présentation images Notre améliorer pouvoir discriminant représentation images encodant information simples descripteurs approche tiples descripteurs multiples vocabulaires visuels descripteurs leurs vocabulaires utilisés construire obtient chaque descripteur utilisé appelle ensemble paquets différents tenus alors concaténés obtenir représentation finale image comme montré Cette nouvelle approche utilise simultanément multiples descripteurs environnement efficace classification images grande échelle PASCAL ImageNet MNIST LabelMe Caltech Caltech images Comparaison ImageNet autres ensembles données images multiples vocabulaires visuels améliorer pouvoir discriminant cette représentation images classification grands ensembles données images Ensembles données images existe nombreux ensembles données images Caltech Caltech Pascal Cependant beaucoup moins grandes tailles nombre important images classes citer Images Torralba ensemble images 32x32 pixels obtenu requêtes WordNet Fellbaum vérification posteriori contenu ImageNet obtenu manière étiquettes vérifiées manuellement nécessaire construire outils classification soient capables traiter grand nombre classes Caltech Caltech premiers ensembles données cette direction dernière version ImageNet beaucoup 21841 classes millions images entendu nécessaire avoir nombre suffisant images classe couvrir variations illumination points différences apparences classe Caractéristiques niveaux images Comme montré partir ensemble données images notre système extrait SIFTs SURFs DSIFTs images caractéristiques niveau utilisées succès différentes applications reconnaissance objets analyse textures classification scènes David présenté descripteur robuste appelé Scale Invariant Feature Trans approxime laplacien gaussiennes utilisant filtre différence Poulet siennes consiste quatre étapes détection extrema localisation points intérêts calcul orientation descripteur point intérêt premiére étape fonction différences gaussiennes place laplacien améliorer vitesse calcul étape localisation point intérêt points présentant contraste rejetés matrice hessienne utilisée calculer courbure principale éliminer points ratio rapport courbure principale supérieur seuil histogramme orientation calculé partir orientation gradients échantillon points autour point intérêt après expériences décrites auteur meilleurs résultats obtenus grille orientation discrétisée valeurs cripteurs SIFTs vecteurs dimensions Herbert présenté nouveau détecteur points intérêts robustes change ments échelle rotations appelé SURFs Speeded Robust Features approxime obtient meilleurs résultats approches précédentes calculé comparé beaucoup rapidement calcul SURFs utilise détecteurs hessiens pides approximation ondelettes denses SIFTs denses variante SIFTs descripteurs extraits multiples échelles équivalent calcul SIFTs grille échelle orientation fixées descripteur souvent utilisé catégorisation objets taille intervalle échelle point intérêt DSIFT spécifie taille paramètre contrôle taille intervalle nombre pixels cripteur standard taille intervalle échelle point intérêt facteur multiplicateur défaut conséquence descripteur DSIFT taille correspond échelle lissage descripteur effectue lissage image fonction échelle point intérêt défaut lissage équivalent convolution gaussienne variance étant échelle point intérêt Classification nombreuses applications fonctions noyaux comme Support Vector chines utilisées succès donnant souvent meilleurs résultats thodes noyaux utilisées nombreux domaines permettent fusion données concaténant espaces noyau utilisant multiples apprentissages noyaux Avant effectuer classification images appliquons approche multi descripteurs multi vocabulaires visuels construire représentation finale images ensemble données bénéficier efficacité classifieur linéaire utilise trans formation explicite Vedaldi améliorer précision classification images environnement efficace classification images grande échelle descripteur C2vocabulaire vocabulaire vocabulaire descripteur descripteur paquets representation finale image Construction paquets multiples descripteurs vocabulaires visuels Multiples descripteurs multiples vocabulaires visuels ensemble descripteurs extraits image descripteurs extraits image nombre descripteurs différents Notre approche consiste construire autant types descripteurs utilisés comme montré utiliser vocabulaire visuel construire visuels finaux utilise multiples vocabulaires construits partir différents descripteurs précisément vocabulaire utilisé construire correspondant descripteur Ensuite ensemble concaténés former visuels finaux chaque image visuel composé éléments simplifier appellera paquets représentation finale image composée différents vocabulaires visuels image entrée paquets discriminant paquets considérés comme identiques seulement ensemble constituent identiques Cette approche améliore pouvoir discriminant visuels finaux rapport approche classique unique LibSVM parallèle LibSVM bibliothèque algorithmes Support Vector Machines classifi cation régression epsilon estimation distribution class supporte également classification multi classes Depuis version implémente algorithme LibSVM facilement interfacer programmes utilisateurs Parmi principaux composants citer différents algorithmes gestion multi classes validation croisée LibSVM donne souvent meilleurs résultats LibLINEAR apprentissage beaucoup important plusieurs jours voire semaines calcul nécessaires traiter ensembles données ImageNet duire temps apprentissage avons développé version parallèle utilisant OpenMP Poulet openmp appelons pLibSVM implémentation originale étape coûteuse temps calcul calcul matrices noyaux notamment lorsque traite ensembles données grandes tailles calculs valeurs éléments matrices indépendants autres avons parallélisés faire avons utilisé OpenMP pouvoir bénéficier architectures multi coeurs disponibles plupart machines actuelles Cette nouvelle implémentation algorithme permet réduire manière significative temps calcul LibSVM évaluer performances pLibSVM avons comparé LibLINEAR Franc expérimentations Franc montrés algorithme avait convergence rapide autres méthodes cette raison choisi paraison notre algorithme pLibSVM Pegasos Primal Estimated GrAdient SOlver Stochastic Gradient Descent Expérimentations résultats Ensembles données totalité ensemble données ImageNet représente environ octet données premières expérimentations avons évalué notre système grandes classes ImageNet représente 24817 images octets données classes n00483313 n01882714 n02086240 n02087394 n02094433 n02100583 n02100735 n02138441 n02279972 n09428293 Chaque classe contient images Extraction paralléle caractéristiques images expérimentations avons utilisé Intel E5345 33GHz temps calcul extraction caractéristiques image varie seconde fonction paramètres traiter grandes classes 24817 images entre heures calcul difficile passer échelle traiter totalité ensemble données ImageNet images faudrait secondes environ jours calcul avons parallélisé processus permettre calcul temps raisonnable beaucoup images tailles variables ensemble données ImageNet avons choisi réduire grandes images taille maximale pixels Cette normalisation permet réduire temps calcul permet aussi représentation robuste variations échelle DSIFT extraire SIFTs DSIFTs avons utilisé version Matlab VL_FEAT vlfeat développée Andrea Vedaldi Vision University California implémentation originale descripteurs SIFTs fournit vecteurs entiers dimensions pouvoir combiner SURFs avons transformés vecteurs entiers vecteurs flottants Parallel Computing Toolbox Matlab permet programmation parallèle multi thread implicite Matlab possible créer ensemble processus permettant exécuter tâches indépendantes parallèle seule restriction ensemble tâches exécuter machine avons utilisé extraire SIFTs DSIFTs environnement efficace classification images grande échelle parallèle machine dotée coeurs Comme montré tableau fallu heure minutes extraire SIFTs grandes classes ImageNet moyenne seconde extraire SIFTs image traiter totalité ensemble données faudrait jours calcul jours machine coeurs version parallèle SURFs Gossow cripteurs locaux calculés implémentation originale SURFs vecteurs tants dimensions pouvoir combiner SIFTs avons étendu dimension Toujours utilisant machine dotée coeurs fallu heure extraire SURFs grandes classes ImageNet comme montré tableau moyenne seconde extraire SURFs image traiter totalité images ensemble données ImageNet faudrait jours calculs machine coeurs jours machine coeurs entendu temps calcul donnés titre indicatif peuvent facilement réduits utilisant exemple plusieurs machines Construction parallèle paquets temps calcul chaque vocabulaire visuel similaire approche sique utilise vocabulaires visuels calculs permettre obtenir résultat temps calcul approches standards avons effectuer calcul parallèle paquets temps calcul global temps calcul différents ensemble descripteurs calculés représentent données Descripteur Temps points Taille DSIFT Extraction descripteurs grandes classes ImageNet Construction vocabulaires visuels approches usuelles étapes coûteuses temps construction vocabulaire visuel ensembles données grandes tailles grand nombre points construire vocabulaire visuel discriminant tâche devient coûteuse temps calcul solutions utilisée algorithme means Cependant implémentation originale algorithme means nécessite plusieurs jours calcul ensembles données ImageNet Réduire temps exécution algorithme problème majeur système classifica images grande échelle avons utilisé version parallèle algorithme means University Michigan Cette implémentation caractéristiques suivantes permet traiter ensembles données peuvent tenir mémoire Poulet supporte lecture parallèle plusieurs fichiers entrée disques distincts accélère calcul distance grâce utilisation librairie æuvre avons utilisé machine coeurs exécuter algorithme means taille vocabulaire visuel nombre images utilisées classe nombre maximum itérations Descripteur points Temps DSIFT jours Exécution means parallèle grandes classes ImageNet Précision classification noyau linéaire appliqué directement histogramme classiquement utilisé donne bonne précision nombreuses approches utilise transformation représentation originale images espace intermédiaire dimension augmentée rechercher séparatrice linéaire espace dimension augmentée séparatrice linéaire espace initial calcul séparatrice linéaire étant beaucoup moins important avons expérimenté résultats transformation figurent tableau transformation tableau avons utilisé noyau homogène Vedaldi dernier permet amélioration sensible précision évaluer performance notre algorithme pLibSVM avons comparé LIBLINEAR version originale LibSVM concerne précision temps calcul chaque classe avons utilisé images ensemble apprentissage restant ensemble pLibSVM utilise noyau linéaire exécuté machine coeurs Descripteur LIBLINEAR LIBSVM pLIBSVM 0mn14s 0mn17s 2h50mn 19mn55s 0mn16s 0mn14s 1h46mn 13mn48s DSIFT 0mn3s 1mn21s 5h15mn 47mn55s DSIFT 1mn22s 1mn35s 6h22mn 59mn05s Précision temps exécution classification grandes classes geNet environnement efficace classification images grande échelle Descripteur LIBLINEAR LIBSVM pLIBSVM 1mn30s 2mn19s 3h12mn 33mn34s 2mn82s 1mn47s 2h12mn 34mn01s DSIFT 2mn20s 6mn11s 3h47mn 49mn56s DSIFT 3mn04s 1h14mn 5h50mn 1h00mn Précision temps exécution classification grandes classes geNet noyau homogène Vedaldi Comme avons précédemment mentionné challenge majeur classification grandes bases données images étape apprentissage présentons parallèle algorithme LibSVM pLibSVM efficace classification grandes classes ensemble données ImageNet résultats tableau montrent exception DSIFTs LibSVM pLibSVM obtiennent meilleurs résultats pLibSVM obtient résultats temps beaucoup réduit original LibSVM Evidemment résultats pourraient encore meilleurs utilisait ressources évaluer performance approche multiples vocabulaires visuels grandes classes ImageNet avons expérimenté combinaison descripteurs DSIFT conservant taille vocabulaire visuel identique Comme montrent résultats tableaux cette approche permet améliorer précision gains peuvent aller jusqu données originales données transformées noyau homogène Conclusion travaux futurs avons présenté système efficace classification images grande échelle illustré performance grandes classes ensemble données ImageNet système avons développé version parallèle algorithme LibSVM permettre classification grands ensembles données temps raisonnable accélérer processus calcul descripteurs images avons montré comment utilisation boîte outil Matlab permettait réduire temps calcul architectures multi coeurs courantes heure actuelle avons aussi présenté nouvelle approche utilisant simultanément plusieurs descripteurs images permettre améliorer précision algorithmes classification grands ensembles données images extension évidente travaux utiliser simultanément descripteurs niveaux comme SIFTs SURFs descripteurs globaux comme GISTs textures mécanisme décrit version courante permet parallélisation classification binaire comptons étendre Poulet classification multi classes Toutes pistes semblent prometteuses améliorer classification grands ensembles données images Remerciement travaux bénéficient sountien financier partiel région tagne Références Tuytelaars Speeded Robust Features European Conference Computer Vision Bosch Zisserman Munoz Image classifcation using random forests ferns International Conference Computer Vision Csurka Dance Willamowski Visual categorization keypoints European Conference Computer Vision Dalal Triggs Histograms oriented gradients human detection Conference Computer Vision Pattern Recognition David Distinctive image features scale invariant keypoints International Journal Computer Vision Socher ImageNet large scale hierarchical image database Conference Computer Vision Pattern Recognition classifying image categories European Conference Computer Vision Everingham Williams Zisserman PASCAL Visual Object Classes Challenge Results Working selection using second order information training Journal Machine Learning Research Chang Hsieh LIBLINEAR library large linear classification Journal Machine Learning Research Fergus Weiss Torralba supervised learning gigantic image collec tions Advances Neural Information Processing Systems Fergus Peron Learning generative visual models training examples incremental bayesian approach tested object categories Conference Computer Vision Pattern Recognition Fellbaum WordNet Electronic Lexical Database Press Cambridge Franc Sonnenburg Optimized Cutting Plane Algorithm Support Vector Machines International Conference Machine Learning Gossow Decker Paulus Evaluation Source Implemen tations RoboCup Robot Soccer World Griffin Holub Peron Caltech object category dataset Technical Report California Institute Technology environnement efficace classification images grande échelle Lazebnik Schmid Ponce Beyond features Spatial pyramid ching recognizing natural scene categories Conference Computer Vision Pattern Recognition Crandall Huttenlocher Landmark classification large scale image collections International Conference Computer Vision Moosmann Triggs Jurie Discriminative Visual Codebooks using domized Clustering Forests Advances Neural Information Processing Systems Perronnin Sanchez Large scale image categorization explicit embedding Conference Computer Vision Pattern Recognition Philbin Isard Sivic Zisserman quantization Impro particular object retrieval large scale image databases Conference Computer Vision Pattern Recognition Torralba Fergus Freeman million images large nonparametric object scene recognition Pattern Analysis Machine Intelligence Vedaldi Gulshan Varma Zisserman Multiple kernels object detec International Conference Computer Vision Vedaldi Zisserman Efficient Additive Kernels Explicit Feature Conference Computer Vision Pattern Recognition Zhang Large scale natural image classification sparsity ploration International Conference Acoustics Speech Signal Processing Winder Brown Learning local image descriptors Conference Computer Vision Pattern Recognition Summary usual frameworks image classification involve three steps feature extraction building codebook feature quantization training classifier standard classi fication algorithm However complexity becomes large applying approach large scale datasets ImageNet dataset containing images classes complexity about needed perform memory usage needed store descriptors puted datasets developed parallel version LIBSVM large datasets reasonable Temps Furthermore information performing quantization obtained words visual words often enough discriminative large scale image classification present novel approach using several local descriptors simultaneously improve classification accuracy large scale image datasets first results dataset largest classes images ImageNet