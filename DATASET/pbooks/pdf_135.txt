E33Une mesure expertise crowdsourcing Hosna Arnaud Martin Laetitia Mouloud Kharoune Zoltan Miklos IRISA DRUID Université Rennes Lannion France hosnaouni gmail arnaud martin mouloud kharoune zoltan miklos rennes1 druid irisa Orange Pierre Marzin 22307 Lannion Cedex France laetitia orange Résumé crowdsourcing enjeu économique majeur exter naliser tâche interne entreprise grand public foule ainsi forme traitance digitale destinée toute personne susceptible pouvoir réaliser tâche demandée généralement rapide automatisable évaluation qualité travail participants cependant problème majeur crowdsourcing effet contributions doivent contrôlées assurer efficacité pertinence campagne Plusieurs méthodes proposées évaluer niveau expertise participants travail ticularité proposer méthode calcul degrés expertise présence données ordre classement connu degrés expertise suite considérés données ordre établi Cette méthode fondée théorie fonctions croyance tient compte incertitudes réponses évaluée données réelles campagne réalisée Introduction crowdsourcing concept lancé stimule participation collective élaboration certaines tâches entreprise souhaite réaliser interne faute ressources temps compliqué voire impossible confier ordinateur inscrit logique partage dérivée essor effet échange idées savoir faire réalise intermédiaire plateforme internet Plusieurs plateformes telles Amazon Mechanical Microworker Foule Factory destinées petites tâches machine incapable effectuer rapidement façon fiable tâches généralement simples courtes instar analyse émotions catégorisation produits comparaison designs Néanmoins environnement plateforme crowdsourcing incertain finale maîtrisé suite évaluation qualité fiabilité contributions travailleurs indispensable déroulement processus Ainsi plusieurs travaux proposés identifier experts travailleurs sérieux plateforme papier propose solution permettant calculer pertinence réponses parti cipants partir réponses campagne lancée Orange Durant cette campagne mesure expertise crowdsourcing propose faire évaluer travailleurs plateforme crowdsourcing sonore restituée différentes solutions codage audio procédure consiste faire écouter participants extraits musicaux différentes qualités demander évaluer qualité audio échelle catégories Excellente Bonne Moyenne Médiocre Mauvaise chaque catégorie associée allant Mauvais cellent Parmi extraits sonores présentés ordre aléatoire qualité connue ajout bruit modulé signal différents rapports signal bruit MNRUs Modulated Noise Reference signaux utilisés tests comme références ancrages échelle qualité cette étude signaux permettre définir degrés expertise structurer réponses travailleurs graphes représentant ordre préférences notes entre signaux comparer graphes celui référence notes théoriques attendus Ensuite cette estimation prise compte sélectionner participants perts autres extraits sonores atteindre objectif souhaité classement signaux codeurs issus comparaison graphes consiste quantifier similarité entre graphes problème courant surtout réseaux sociaux graphes révèlent priétés topologiques cherche comprendre comparer Malheureusement manque références permettant construire échelle comparaison leurs caractéristiques géométriques effet métrique méthode comparaison graphes universelle point algorithmique méthodes classiques aborder genre problèmes complexes réponses étant fournies humains environnement contrôlé contrairement tests écoute classiques laboratoire nécessaire modéliser imperfections réponses théorie fonctions croyance permet répondre cette problématique offrir cadre théorique réaliser combinaison informations issues différentes sources proposons travail approche originale permettant estimation mesure expertise partir comparaison graphes cadre théorie fonctions croyance Ainsi section suivante présente concepts théorie fonctions croyance section après rappel approches existantes propose approche originale représentation réponses forme graphes calcul degrés expertise Finalement évaluation méthode données réelles objet section théorie fonctions croyance théorie fonctions croyance issue travaux Dempster Shafer permet représentation incertitudes imprécisions aussi ignorance source réponse contributeur Considérant ensemble représente réponses possibles question fonction masse définie ensemble toutes disjonctions valeur contraintes fonction masse représente croyance allouée proposition affectée ensemble strict comme mille ensembles pondérées distribution probabilité généralisée ensemble élément focal exemple considérons fonction masse cette quantité représente imprécision incertitude valeur affectée cette proposition manipulation données imparfaites issues plusieurs sources distinctes nécessite fusionner informations parle combinaison fonctions masse permettant aboutissement connaissance générique pertinent opérateur combinaison conjonctive proposé Smets donné fonctions masse issues sources masse affectée ensemble issue cette combinaison interprétée comme inconsistance fusion mesurer écart fonction masse attendue exemple prendre décision définir mesure plusieurs distances proposées distance selme communément utilisée propriétés répartitions pondérations fonction imprécision éléments focaux donnée Caractérisation experts crowdsourcing Positionnement travail identification experts plateformes crowdsourcing objet plusieurs travaux récents distinguer types approches celles tenant compte questions connaît réponse nommées données celles aucunes connaissances priori disponible effet contexte dernier approches intéressés calculer degré exactitude précision supposant majorité raison définissant degré partir distance Jousselme entre réponse moyenne réponses autres participants autre Dawid Skene Ipeirotis utilisé algorithme Expectation Maximisation permettant première phase estimer bonne réponse chaque tâche utilisant étiquettes affectées participants évaluer qualité travailleurs comparant réponses soumises bonne réponse inférée Également Smyth Raykar utilisé cette approche classements binaires étiquetages catégoriques Raykar généralisé classements ordinaires associer mesure expertise crowdsourcing notes fonction qualité objet service méthodes proposent calculer sensibilité vrais positifs spécificité vrais négatifs chaque label Ainsi participant spammer score proche expert parfait score Cependant algorithmes proposent déterminer qualité réponses partici pants quand vérité inconnue alors notre notes correctes théoriques attribuées signaux MNRUs connues effet cherchons plutôt identifier experts fondant données correctes référence définir degré exper proportionnel similarité entre réponses participant réponses connues avance Ainsi notre travail fondé données servent estimer directement qualité participants proposé données questions réponses correctes connues avance injectées façon arbitraire données avantage mesurer explicitement précision travailleurs utilisées prendre décisions concernant travailleur pouvons utiliser laisser finir tâche méritent bonus second processus transparent assure travailleurs comprennent détails nuancés difficiles exigences tâche évaluer impact utilisation données Ipeirotis examiné formance algorithme Dawid Skene modifié tenir compte existence données variant pourcentage données essayé mesurer chaque erreur classification quelle mesure algorithme classe correcte exemples erreur estimation qualité quelle mesure algorithme estime qualité travailleurs trouvé genre données différence rapport modèle supervisé contre considéré utilisation données nécessaire quelques travail ensembles déséquilibrés évaluer toutes classes Selon Ipeirotis raisons importantes confiance personnes techniques proposant proche contrôle qualité calibrage résultats lorsque sensibilité utilisateurs influent leurs réponses Également Philips traite données comme outil associer scores confiance contributeurs participants doivent dépasser seuils confiance minimum continuer travailler tâche moment contributeur tombe dessous seuil confiance exclue travail travail allons pondérer réponses contributeurs partir relations réponses données Cette pondération réalisée partir degré expertise pourra aller jusqu considérer contributeurs éloignés réponses attendues données Calcul degré expertise Comme mentionné réponses contributeurs plateforme représentées graphes considérant participant associé notes présentées tableau MNRUs données graphe orienté pondéré correspondant construit figure graphe orienté lisibilité préférences signifie préféré facilité travail successeurs prédécesseurs conçu comme Exemple notes associée insertion point départ virtuel correspondant toujours extraction associée morceau MNRUi façon suivante MNRUi chaque itération ensemble nœuds ayant élevée cherché ensemble ajouté graphe profondeur respectant normes suivantes différence entre notes MNRUs profondeurs consé cutives numéro Graphe complet calculer degrés expertise considérons graphe référence corres notes théoriques attendues données tableau corres graphe graphes correspondants réponses participants comparés Notes correctes associée Graphe référence graphe référence fonction masse ainsi calculée chaque réponse contributeurs extraire ensemble critères hétérogènes permettant contourner différences entre nœuds proche notion signature nœuds introduite Jouili critères considérés soient mêmes particularité modélisation proposée graphes mêmes nœuds nombre attribut Ainsi comparer couples mesure expertise crowdsourcing attribut graphe référence attribut appartenant graphe comparer faire avons défini chaque graphe quatre critères représentant différentes erreurs possibles avons identifiées critères représentés fusionnés fonctions masse cadre discernement considéré représente assertion Expert expert cherchons ainsi mesurer croyance contributeur expert détermine ordre correct MNRUs fonction notes attribuées MNRUs Degré exactitude associée critère caractérisé différence position considéré entre référence réponse contributeur dissimilarité calculée distance Euclidienne profondeur rapport fonction masse correspondante critère donnée distance maximale entre nœuds Compte graphes considérés représente notes Degré confusion entre MNRUs critère mesure proportion nœuds distance point départD concerné dissimilarité Jaccard ainsi employé comparaison contenus ensembles ensemble nœuds graphe fonction masse associée donnée Cette masse représente valeur minimale Degré mauvais ordre précédent ensemble prédécesseurs mauvais ordre suivant ensemble successeurs participant considérer morceau meilleur autre contrairement attendu Ainsi critères mesurent erreurs inversion rapport précédent suivant définir degrés introduisons définition ensembles suivants respectivement ensemble prédécesseurs correctes PNCNi correctes ensemble successeurs correctes SNCNi correctes PredG1 PNCNi SuccG1 SuccG1 SNCNi PredG1 SuccG PredG respectivement ensemble successeurs ensemble prédécesseurs graphe partir définitions distances données équations PNCN2 SNCN2 reste masse associé ignorance masse associée ignorance également dérivée nœuds extrêmes prédécesseurs nœuds successeurs nœuds équations permettent calculer fonctions masse critère chaque couple nœuds respectivement graphe référence graphe correspondant réponse participant attribut étape suivante définit fonction masse graphe entier faisant moyenne fonctions masse nœuds calculées chaque critère ordre graphe nombre sommets obtenir fonction masse réponse considérée combinons fonctions masse quatre critères Finalement degré expertise donné calculant distance Jousselme entre fonction masse ainsi obtenue fonction masse catégorique élément expert Essaid Évaluation méthode situation réelle Historiquement Orange réalise tests évaluation subjective codeurs audio laboratoire tests consistent recruter auditeurs naïfs étant impliqués direc tement travaux évaluation qualité codage audio présenter mesure expertise crowdsourcing courtes séquences parole musique traitées selon différentes configurations codage demander évaluer qualité audio échelles adaptées tests déroulent salles traitées acoustiquement globalement environnement parfaite contrôlé méthodes laboratoire efficaces restent coûteuses peuvent avoir portée limitée quant représentativité résultats rapport utilisation services stimuli nombre limité exemple objectif ajouter approche crowdsourcing méthodes campagnes déployées plateforme crowdsourcing réalisées comparer sultats obtenus laboratoire Chaque campagne consistait réplique initialement réalisé laboratoire normalisation codeur G729EV laboratoire conditions solutions codage étaient considérées auxquelles ajoutaient conditions référence total douze conditions étaient évaluées travers extraits musicaux personnes recrutées réparties groupes Chaque groupe écoutait évaluait Human Intelligence étant ensemble séquences audio correspondant douze conditions tests présentées travers extraits musicaux différents Ainsi chaque contenait douze conditions conditions codage présentées ordre aléatoire extraits musicaux différent chaque Après chaque séquence audio auditeurs étaient invités noter qualité échelle Mauvaise Excellente campagnes crowdsourcing participants également répartis panels façon chacun puisse appartenir panel comme laboratoire Suivant expérimental laboratoire chaque panel étaient associés séquences audio évaluer échelle qualité Chaque faisait objet micro plateforme crowdsourcing Ainsi chaque participant pouvait faire entre panel différents autres panels participation participant prise compte avait terminé moins sachant pouvait cesser écoutes avant contrairement laboratoire instructions étaient présentées anglais écrit participants avant session apprentissage séquences audio devait également réalisée avant comme laboratoire campagnes ainsi menées considérant zones géographiques différentes première campagne travailleur anglophone pouvait participer travailleurs ayant participé cette campagne étaient majoritairement deuxième campagne limitait mêmes conditions appliquées participants appartenant Paneli écoutent mêmes morceaux campagnes degrés expertise calculés données laboratoire autre notes issues plateformes crowdsourcing données laboratoire résultats présentés intervalles degré expertise longueur figure obtenu personnes degré expertise supérieur seuil choisi comparaison données issues plateforme montrant ainsi fiabilité réponses personnes laboratoire intervalle contient personnes premier temps distributions ensembles panels données issues plateformes crowdsourcing représentées figure distribu tions notons petit intervalle permet ainsi déterminer seuil expertise prendre compte discriminer participants Participants intervalle expertise données laboratoire Distribution données degrés expertise varient intervalle large celui laboratoire premier facteur pouvant expliquer résultats serait manque sérieux grand nombre participants plateforme crowdsourcing autre conditions écoute environnement sonore casque parleur utilisé riables participant autre autre contrairement laboratoire peuvent influer qualité réponses participants travail avons souhaité imposer conditions expérimentation placer travailleurs contexte milier comparant distributions remarque petite différence entre mesure expertise crowdsourcing campagnes exemple intervalle expertise presque absent données campagne américaine personnes ensemble panels courbe grise alors intervalle contient participants courbe noire autre intervalle contient participants alors intervalle différences observées entre campagnes peuvent expliquer travers différences culturelles entre régions notamment grande proximité culturelle extraits musicaux choisis musique occidentale campagne américaine retenons comme seuils première analyse seuils proches sauts distributions participants retenus ayant degré expertise supérieur seuil considéré moyenne leurs réponses prise compte évaluation qualité audio comparons ainsi données issues pagnes plateformes crowdsourcing celles obtenues laboratoire selon seuils Comparaison courbes laboratoire crowdsourcing données fusionnées seuil expertise Comparaison courbes laboratoire crowdsourcing données fusionnées seuil expertise remarquons courbes obtenues laboratoire crowdsourcing premier seuil proches autres seuil Néanmoins courbes obtenues deuxième seuil montrent participants qualifiés perts selon critère réussi différencier premières conditions référence qualité connue Idéalement courbe premiers morceaux devrait droite respond MNRUs Cependant résultats expliqués comportements habituels retrouve données laboratoire plateformes proximité courbes montre intérêt réaliser évaluation plateformes crowdsourcing participants experts aient sélectionnés Conclusion discussion travail avons proposé approche originale calcul expertise participants évaluation subjective qualité audio travers tests écoute approche proposée fondée modélisation notations participants forme graphe Tenant compte données ordre préférence attendu connu avons développé mesure comparaison graphes Ainsi approche fondée quatre critères partir desquels quatre fonctions masse définies tenir compte imperfections possibles réponses participants partir fonctions masse degré expertise calculé chaque participant permettant ainsi considérer participants ayant degré expertise suffisant résultats comparant données issues campagnes crowdsourcing laboratoire montrent intérêt réaliser telles évaluations partir plateformes crowd sourcing cependant nécessaire évaluer correctement degré expertise considérer toutes réponses issues plateformes crowdsourcing approche veloppée travail évaluation degrés expertise permet écarter participants réponses pertinentes tâche évaluation qualité audio Références Kharoune Miklos Martin Characterization experts crowdsourcing platforms International Conference Belief Functions Kharoune Miklos Martin Yaghlane Caractérisation experts plate formes crowdsourcing Conférence Logique Floue Applications Dawid Skene Maximum likelihood estimation observer error rates using algorithm Journal Royal Statistical Society Dempster Upper lower probabilities induced multivalued mapping annals mathematical statistics Essaid Martin Smits Yaghlane distance based decision credal level Artificial Intelligence Symbolic Computation International Confe rence Seville Spain December Proceedings crowdsourcing Wired magazine Ipeirotis Worker evaluation crowdsourcing multiple workers mesure expertise crowdsourcing Ipeirotis Provost Machine learning spammer detection crowd sourcing HCOMP Proceedings SIGKDD Workshop Human Computation Modulated noise reference Technical Report Inter national Telecommunication Union Jouili Indexation masses documents graphiques approches structurelles thesis Université Nancy Jousselme Grenier Bossé distance between bodies evidence Information fusion Edmonds Hester Biewald Ensuring quality crowdsourced search relevance evaluation effects training question distribution Workshop Crowd sourcing Search Evaluation Philips Enterprise crowdsourcing learned worrying trust crowd Raykar Annotation models crowdsourced ordinal Journal Machine Learning Research Raykar Hermosillo Valadez Florin Bogoni Learning crowds Journal Machine Learning Research Shafer mathematical theory evidence Volume Princeton university press Princeton Smets combination evidence transferable belief model Smyth Fayyad Perona Baldi Inferring ground truth subjective labelling venus images Advances Neural Information Processing Systems Summary Crowdsourcing major economic issue outsources internal crowd digital subcontracting general public evaluation participants quality major issue crowdsourcing Indeed contributions controlled ensure effectiveness relevance campaign particularly interested small automatable tasks Several methods proposed solve problem applicable golden truth always known particularity propose method calculating degree expertise presence crowdsourcing method based belief function theory proposes structuring using graphs proposed approach assessed applied