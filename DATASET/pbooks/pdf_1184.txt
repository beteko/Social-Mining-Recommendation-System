Validation statistique cartes Kohonen apprentissage supervisé Prudhomme Stéphane Lallich Laboratoire Université Lumière avenue Pierre Mendès France 69676 Cedex France prudhomme lyon2 stephane lallich lyon2 Résumé apprentissage supervisé prédiction classe ultime largement attend bonne méthodologie appren tissage permette représentation données susceptible faciliter navigation utilisateur exemples aider choix exemples variables pertinents assurant diction qualité comprenne ressorts érents travaux montré aptitude graphes voisinage issus prédicteurs fonder telle méthodologie ainsi graphe voisins relatifs Toussaint Cependant complexité construction reste élevée données volumineuses proposons substituer graphes voisinage cartes Kohonen construites prédicteurs Après rappel principe cartes Kohonen apprentis supervisé montrons comment celles peuvent fonder stratégie apprentissage optimisée proposons ensuite évaluer qualité cette stratégie statistique originale étroitement corrélée erreur généralisation érentes expérimentations montrent faisabilité cette approche dispose alors critère sélectionner individus attributs pertinents clefs apprentissage supervisé cartes Kohonen validation tistique Position problème méthodes apprentissage supervisé variable catégorielle objet prédiction classe appartenance nouvel exemple partir échantillon exemples étiquetés prédiction étape procé apprentissage enrichie analyse exploratoire données préparer mieux donner intégrant éventuelles informations contextuelles telle perspective recours graphes voisinage apporte lution construit graphe voisinage prédicteurs exemple graphe voisins relatifs Toussaint Toussaint Menard lorie sommets graphe fonction classe appartenance trouver classe nouvel exemple insère celui graphe voisinage attribue classe majoritaire parmi voisins graphe Divers travaux proposé statistique poids arêtes coupées évalue capacité prédictive graphe voisinage permet sélection variables pertinentes détection Validation statistique cartes Kohonen apprentissage supervisé individus atypiques repérant impact individu variable capacité prédictive graphe Sebban Zighed Lallich Muhlenbach Zighed rapport méthode proches voisins graphes voisinage adaptent étendue prise compte proches voisins topologie locale statistique évalue capacité prédictive fortement erreur généralisation Leurs résultats généralisation moins aussi avantage fonder procédure navigation exemples culté complexité graphes voisinage construction graphe voisins relatifs Toussaint adaptés données volumineuses termes individus Plusieurs solutions possibles notamment diminuer algorithmique insertion nouvel exemple considé réelle construction graphe voisinage ensemble apprentissage acquise nitivement Clech construire graphe voisinage échantillon taille raisonnable Hacid avons choisi solution érente fondée cartes Kohonen conserver avantages graphes voisinage spatialisation formation apportée prédicteurs évaluation qualité prédictive cette information navigation exemples présentant moindre complexité Notations nombre individus nombre prédicteurs nombre modalités étiquette nombre classes nombre neurones matrice individus ligne correspond individu colonne prédicteur vecteur composantes indique étiquette chaque individu matrice terme général désigne poids neurone prédicteur vecteur composantes indique étiquette chaque neurone neurone ambigu neurone matrice terme général correspond nombre individus étiquette représente neurone matrice symétrique terme général neurone voisin neurone carte représente nombre voisins neurone indice neurone matching proche individu distc renvoie distance carte entre neurones chaque neurone carré distance carte entre neurones distance euclidienne entre centres carrés correspon Prudhomme Lallich distp fonction renvoie distance euclidienne entre poids rones dmaxd fonction normalise distance représente distance maximum entre neurones carte matrice symétrique terme général ppvij distc distc distc connectés sinon représente nombre neurones connectés neurone cartes Kohonen Organized Kohonen permettent apprentissage supervisé rapide individus représentation faire elles composent réseau neurones répartis uniformément voire dimensions Chaque neurone vecteur espace individus appelé vecteur poids apprentissage individus présentés successivement réseau chaque individu neurone proche Matching voisinage réseau ensemble rapprochent individu algorithme classique apprentissage individu instant résumer formule suivante cation poids neurone apprentissage décroît linéairement temps fonction voisinage étendue neurones autour début apprentissage neurones rapprochent fortement individus grand nombre neurones autour voisinage large grand suite ampleur cation nombre neurones décroissent Grâce algorithme obtient conservation topologie locale espace entrées individus proximité neurones correspond proximité espace départ complexité utilise multiple ensemble individus apprentissage choisit nombre neurones équivalent Vesanto détails algorithmes apprentissage supervisé rapides apprentissage supervisé simplicité cacité algorithme conduit érents auteurs adapter apprentissage supervisé présente principales approches Learning Vector Quantization proposés Kohonen couramment utilisés existe trois variantes trouver revue Validation statistique cartes Kohonen apprentissage supervisé Kohonen principe proche celui neurones étiquetés départ exemple algorithme Means garderont cette étiquette apprentissage calculé cation poids particularité faire intervenir comparaison entre classe individu celle classes identiques vecteur poids telle sorte rapproche individu contraire telle sorte éloigne apprentissage ectué classe nouvel individu égale celle modèle LASSO modèle LASSO proposé Midenent Grumbach particularité ajouter indicatrices classes prédicteurs calculer cette apprentissage ensuite réalisé manière classique phase prédiction nouvel individu présenté seulement partie vectorielle correspondant prédicteurs partir celle modèle recherche complète partie manquante nouvel individu vecteur indicatrices classe réalisant ainsi prédiction méthodes Kohonen Kohonen méthodes précédentes utilisent étiquette individus établir poids vecteurs prototypes rapprocher éloigner vecteurs autres regrouper fonction étiquette doivent représenter modèle LASSO étiquette manière prédicteurs établir position vecteurs espace entrées contribue grande cacité méthodes phase prédiction problème conservation topologie possible représenter topologie espace entrées puisque position vecteurs prototypes consiste simple projection espace celui carte modèle LASSO existe encore carte représentative espace entrées celle dépend prédicteurs étiquette contourner problème autres travaux séparé apprentissage phases première phase réalise construction fondant unique variables prédictives deuxième phase charge étiqueter neurones obtenus étiquetage fonction classe représentée neurone voisinage méthode Kohonen Zupan améliorée Kohonen Hopke érence entre méthodes réside fonction prédiction attribue étiquette nouvel individu terme apprentissage distingue neurones représentent individus ayant étiquette attribuée deuxième phase neurones vides ayant étiquette phase prédiction méthode Kohonen attribue étiquette nouvel individu représenté neurone fonction neurones voisins étiquette majoritaire voisi retenue problèmes découlent abord neurones voisins forcément proches voisins espace départ vecteur poids Prudhomme Lallich provoque perte information projection carte Ensuite existe indéterminés lorsque neurones voisins divisés équitablement entre érentes classes Kohonen fonde interprétation poids attribuer classe nouvel individu serait représenté ambigu étiquette retenue celle neurone voisin proche retenu termes distance euclidienne espace entrées comparai expérimentale méthodes entre elles Hopke apparaître méthodes Kohonen donnent mêmes résultats ailleurs clairement supérieurs méthode Kohonen résultats montrent possible ectuer apprentissage supervisé cartes Kohonen apprentissage garde propriétés préservation topologie dissocier projection prédicteurs carte prédiction Cependant méthode Kohonen validée données Kohonen nition méthodeKohonen types informations celles relatives neurones ambigus celles voisinage neurone carte proposons améliorer cette méthode fonction prédiction prend compte informations gardant interprétation poids méthode Kohonen entrée représentée neurone ambigu calcule indicateur quanti présence chaque classe pondérant distances poids neurones entrée région étend proches neurones entrée présentée prend valeur classe obtient indicateur maximum Lorsque cherche prédire étiquette vecteur entrée résumer principe fonction suivante maxh²K cbmui cbmui distp wbmui kbmui distp ppvbmui kbmui sinon Données paramétrage données proviennent univer Californie Irvine Blake Italian Olive Hopke Massart trouve tableau détail termes nombre prédicteurs classes instances chaque tableau indique nombre cycle apprentissage nb_appr dimensions utilisés toutes composées neurones carrés appren tissage quand réalisé algorithme classique section Expérimentations tester validité méthode Kohonen avons comparée méthode Kohonen données présentés tableau comparaison ectue résultats validation croisée repris Validation statistique cartes Kohonen apprentissage supervisé Prédicteurs Classes Instances Dimensions nb_appr Abalone 90000 Balance Scale 60000 Breast Cancer 90000 Glass Indent 10000 Haberman 20000 Ionosphère 20000 Italian Olive 45000 Liver 35000 Yeast 90000 Description bases hyperparamètres associés erreurs méthodes Kohonen Kohonen tableau partir carte étiquetée présente également erreurs obtenus bases arbres décisions algorithme implémenté Tanagra Rakotomalala résultats montrent grande cacité méthode Kohonen rapport Kohonen ensemble bases utilisation informations voisinage associées celles distances espace représentation voisins permet meilleur interprétation étiquetée outre résultats cette méthode comparables produit arbres décisions moyenne Kohonen contre autant favorables défavorables Kohonen méthode prédiction montre peuvent utilisées apprentissage supervisé bonnes conditions Mesures qualité supervisé suggérons stratégie apprentissage repose construction carte Kohonen issue prédicteurs abilité carte obtenue traction faite classe évaluée érents outils statistiques proposés notamment proposons évaluation capacité prédictive telle carte érentes statistiques montrerons expérimentalement section forte corrélation précision généralisation image poids arêtes coupées Lallich utilisé graphes voisi Prudhomme Lallich érentes statistiques fondées notion statistique cross product Mantel construite comme produit scalaire mesures proxi prédicteurs autre classe nition statistiques évaluer force entre proximité prédicteurs résumée carte proximité classe raisonner exemples neurones permet abstraire volumétrie exemples agissant exemples proximité prédicteurs entre exemples évaluée matrice terme général exemples représentés neurone sinon mieux prendre compte propriétés topologiques carte aussi utiliser matrice terme général représentés neurone distp wbmui wbmuj représentés neurones adjacents distc sinon proximité classe entre exemples évaluée matrice terme général exemples classe sinon neurones mesure proximité prédicteurs entre neurones matrice terme général distp ppvij sinon proximité classe entre neurones évaluée matrice terme général étiquette sinon distinguera ainsi trois statistiques nition indiquée dessous ijUij ijUij ailleurs utilise notations simpli catrices suivantes prendre valeur sommes terminant alors respectivement premiers dernier statistiques varient entre autant faibles liaison entre proximité suivant classe proximité suivant prédicteurs portée carte fortement positive pourra standardiser formant varie entre Signi cation statistiques savoir quelle mesure évaluation donnée hasard schéma aléatoire multinomial hypothèse nulle exemples Validation statistique cartes Kohonen apprentissage supervisé neurones étiquetés indépendamment suivant distribution probabilités désigne proportion exemples classe alors possible calculer value unilatérale gauche indique probabilité obtenir valeur aussi petite celle observée calcul simulation rapidement approximation normale impose calculer facile calculer trouve Lallich suivant calcul variance formule compliquée intervenir Expérimentations érentes statistiques abord testées bases présentées section tableau tableau donne leurs valeurs ainsi celles value associées erreur obtenu validation croisée carte méthode Kohonen analyse résultats montre abord value signi catives statistique Haberman statistiques samment robustes rendre compte qualité représentation faite terme apprentissage néanmoins value proches Cette statistique considère toute arête sommet étiqueté ambigu comme arête coupée value proche graphes voisinage résultent cartes Kohonen grand nombre sommets ambigus grand nombre arêtes coupées rapproche alors neurones auraient étiquetés indépendamment topologie induit valeur élevée value cause cette sensibilité neurones ambigus produit bases erreur généralisation élevé relativement nombre classes observe ensuite fortes corrélations entre érentes statistiques erreur Parmi elles faible celle issue statistique détail corrélations issues repris Comme prend compte individus étiquettes érentes représentés neurone tient compte information topologie locale étiquetée Cette information utilisée prend compte individus étiquettes érentes représentés neurones voisins suivant distance explique meilleure corrélation erreur statistique présente cient corrélation intermédiaire prend compte topologie locale travers graphe voisinage construit partir neurones carte revanche individus entrent calcul poids arêtes coupées graphe établit statistique certaine quantité information projection information relative distribution individus espace représentation Cependant complexité calcul statistique avantageuse surtout exemples grande taille celui faisant uniquement partir statistique Prudhomme Lallich value value value Moyenne Résultats bases statistiques value erreur généralisation Kohonen besoin exemples calculée toute façon cient corrélation inférieur autres statistiques proposées second temps avons testé capacité notre approche faire forte volumétrie données université Irwine Californie Blake permet générer aléatoirement données nombre individus évolue lesquels erreur généralisation connue appliqué Kohonen statistiques érentes bases Waves nombre individus variant également chronométré temps nécessaire apprentissage utilisées identiques change entre bases nombre cycle apprentissage égale nombre individus validation ectuée partir chier waves généré modèle tableau présente résultats obtenus montre abord erreur généralisation stable augmentation nombre individus environ temps nécessaire apprentissage croit quasi linéairement facteur comme nombre individus autre statistiques elles aussi stables légère diminution leurs valeurs mesure nombre individus croît value statistiques quand elles toujours nulles qualité apprentissage détériore accroissement nombre individus justi utilisation grand données statistiques proposées elles aussi adaptées relative stabilité regard accroissement nombre exemples montre elles robustes suivant taille échantillon permettent valider échantillon apprentissage grande taille Validation statistique cartes Kohonen apprentissage supervisé Taille value value value 10000 20000 40000 80000 160000 320000 640000 1280000 Résultats bases Waves statistiques value erreur généralisation Kohonen Corrélation erreur gauche droite Prudhomme Lallich Conclusion perspectives connaît qualités cartes Kohonen apprentissage supervisé notamment complexité linéaire suivant nombre exemples existence mesurant abilité aptitude fonder exploration données Lechevallier suggérons utiliser apprentissage supervisé synthétiser information apportée prédicteurs lorsque échantillon apprentis grande taille assurant ainsi bonne navigation exemples image graphes voisinage associons Kohonen procédure prédiction statistique ayant forte liaison linéaire erreur généralisation analogue complément cient détermi nation signi cation correspondant avons entrepris utilisation variations cette statistique fonder procédure détection exemples atypiques sélection variables Références Blake repository machine learning databases Cottrell Verleysen Statistical tools access reliability organizing Neural Network Clech Contribution méthodologique fouille données complexes Thèse doctorat informatique Université Lumière France Spatial processes models applications London Hacid Fouille données bases données complexes Mémoire Université Lumière France Hopke Massart Reference chemometrical methods testing Chemometrics Intelligent Laboratory Systems Kohonen organization topogically correct feature Biological Cybernetics Kohonen Learning vector quantization Neural Network Kohonen organizing Neurocomputing Lallich Mesure validation extraction connaissances partir données Habilitation diriger recherches Université Lumière France Lechevallier Construction super classes partir carte kohonen indicateurs qualité cette carte séminaire laboratoire inria talks Mantel detection disease clustering general regression proach Cancer Midenent Grumbach Learning associations organisation lasso model Neurocomputing Validation statistique cartes Kohonen apprentissage supervisé Muhlenbach Lallich Zighed Identifying handling mislabel instances Journal Information Intelligent Systems Rakotomalala Tanagra logiciel lyon2 ricco tanagra index Sebban Modèles théoriques reconnaissance formes architecture hybride machine perceptive Thèse doctorat informatique Université Lumière France Hopke Kohonen neural network pattern recognition method based weight interpretation Analytica Chimica Toussaint Menard algorithms computing planar relative neighborhood graph Methods Operations Research Proceedings Fifth Symposium Operations Research pages Vesanto Using mining Licentiate thesis Helsinki University Technology Helsinki Finland Zighed Lallich Muhlenbach Séparabilité classes Actes VIIIème Congrès Société Francophone Classi cation pages Zighed Lallich Muhlenbach statistical approach classes separabi Elomaa Mannila Toivonen editor Revue Applied Stochastic Models Business Industry pages Zupan Novic Gasteiger Classi cation multicomponent analytical olive using erent neural networks Analytica Chimica Summary supervised learning prediction class ultimate broader basis learning methodology expected enable representation order facilitate navigation within contribute choice examples attributes while ensuring structured understandable prediction Various studies shown called neighborhood graph predictors gives ground methodology relative neighborhood graph Toussaint However construction graph remains complex dimensionality propose substitute organized built predictors neighborhood graph After short reminder principles unsupervised learning analyze found optimized strategy learning propose original statistics narrowly correlated error generalization order assess level quality strategy Diverse experiments highlight feasibility approach therefore reliable criterion available select relevant examples attributes Keywords supervised learning Kohonen statistical validation