forage distribué données méthode simple rapide efficace Mohamed Aounallah Mineau Département informatique génie logiciel Pavillon Adrien Pouliot Université Laval Canada Mohamed Allah Mineau ulaval ulaval moaoa ulaval Personnel mineau Résumé article attaquons problème forage grandes bases données distribuées résultat modèle prédictif descriptif appelé classificateur faire proposons miner distance chaque données indépendamment regrouper modèles produits appelés classificateurs sachant chaque forage produira modèle prédictif descriptif représenté soins ensemble règles classification guider assemblage ensemble final règles union ensembles individuels règles coefficient confiance attribué chaque règle chaque ensemble coefficient calculé moyens statistiques représente confiance pouvons avoir chaque règle fonction couverture capacité appliquée correctement nouvelles données démontrons article grâce coefficient confiance gation simple classificateurs obtenir agrégat règles produit classificateur rapide efficace rapport niques existantes Introduction papier traite problème forage plusieurs bases données gigantesques graphiquement distribuées produire ensemble règles classification expliquent groupements données observés résultat forage classificateur aussi prédictif descriptif autres termes visons produire modèle permet seulement prédire classe nouveaux objets permet aussi expliquer choix prédictions croyons genre modèles basés règles classification devrait aussi facile comprendre humains également objectifs toutefois plaçons contexte impossible rapatrier toutes bases cause temps téléchargement cause impossibilité traiter ainsi agrégée littérature techniques forage distribué données prédictives criptives malheureusement nombreuses plupart entre elles tentent produire forage distribué données méthode simple rapide efficace classificateur forme ensemble règles couverture disjointe objet couvert seule règle montrerons article cette contrainte couverture disjointe nécessaire produire classificateur fiable Ainsi proposons technique simple objet couvert plusieurs règles relaxation cette contrainte couverture disjointe permet produire classificateur final rapide erreur celui souffre article procède comme section ensemble techniques agrégation modèles connues présentée section présen notre solution forage distribué données employant agrégation modèles basée coefficient confiance section présentons sultats expérimentations démontrent viabilité notre méthode section compare complexité asymptotique notre méthode celles rencontrées littérature présentons finalement conclusion travaux futurs Techniques existantes agrégation modèles présentons papier uniquement techniques développées forage distribué données Conséquemment ignorons volontiers système Ruler Fayyad Fayyad construit regrouper plusieurs arbres décision construits ensemble données système tralisé système apprentissage distribué Sikora développé cadre gestion systèmes information bâtir système apprenant distribué Distributed Learning System approche fragmentation Wüthrich utilise règles probabilistes outre ignorons techniques purement prédictives telles bagging Breiman boosting Schapire stacking Tsoumakas Vlahavas arbiter combiner Prodromidis algorithme algorithme Multiple Induction Learning initialement proposé Williams résoudre conflit entre règles conflictuelles définition dessous systèmes experts 1998a repris technique Williams arbres décision bâtis parallèle préalablement transformés règles outre étendu technique prendre considération autres types conflits proces agrégation proposé auteurs autre regroupement règles processus résolution éventuels conflits noter cette résolution conflits traite couple règles conflictuelles règles voient situation conflit quand leurs prémisses consistantes tandis elles produisent classes diffé rentes Williams appelé conflit lorsque conditions prémisses chevauchent partiellement 1998a appelé conflit quand règles nombre prédicats valeurs différentes associées conditions classent objets classe 1998b appelé conflit résolution conflits consiste spécialiser règles conflit conflits ajuster valeur condition borne conflits éventuellement fusionner règles conflit conflit certains Aounallah Mineau conflits nouvelles règles ajoutées basant ensembles traînement celles récupérer couverture perdue opération spécialisation système Distributed Learner technique Distributed Learner Provost Hennessy conçue implantée tirant avantage propriété cloisonnement invariant Provost nessy commence partitionner données entraînement ensembles disjoints assigne chacun machine fournit infrastructure communication entre différents apprenants nommé roulant chacun machine différente Quand règle répond critère évaluation ensemble données fonction évaluation règle constante devient candidate répondre critère évaluation global propriété cloisonnement invariant étendue garantit chaque règle satisfaisante ensemble données acceptable moins ensemble Lorsqu copie locale découvre règle acceptable envoie règle autres machines mette statistiques reste exemples règle répond critère évaluation global fonction évaluation principale constante signalée comme règle satisfaisante contraire statistiques locales remplacées statistiques globales règle rendue disponible spécialiser encore propriété cloisonnement invariant garantit chaque règle satisfaisante ensemble données trouvée Fusion ensembles règles générés parallèle travail présenté mélange derniers travaux présentés dessus autres termes travaux Williams 1998b Provost Hennessy Spécifiquement chaque règle créée associée mesure qualité basée précision ainsi nombre exemples couvre technique proposée utilisation Provost nessy proposent différence suppression règle espace règles considération lorsque règle classe toutes données différentes bases avère mesure inférieure seuil noter chaque règle voyage autre toute seule accompagnée valeurs nécessaires calculer mesure associée chaque règle Toutefois auteurs démontrent extrême propriété cloisonnement invariant risque satisfaite Ainsi suggèrent précision règles agrégées différente précision règles bâties ensemble entraînement entier outre auteurs soulignent conflits entre règles derniers peuvent résolus comme décrit 1998b Williams ailleurs traite nouveau conflit entre règles règle ayant intervalle conditions chevauchant intervalle deuxième règle règle générale créée combinant règles conflictuelles ajustant bornes intervalles forage distribué données méthode simple rapide efficace Discussion technique souffre plusieurs défauts abord processus résolution conflit spécialiser encore règles basant ensembles entraî nement règles classification règles générées peuvent exhiber faible pouvoir classification elles appliquées nouveaux objets surtout bases entraînement bruitées règles spécifiques ensemble entraînement cette méthode incapable généraliser puisqu regrou spécialiser encore règles conflit outre adaptation technique Williams traiter bases distribuées implique augmentation volume données échangées entre différents sites effet chaque règle voyage accompagnée index objets couverts autre conflit objets couverts règles conflit rapatriés entraînement résout conflits important inconvénient système temps exécution effet règle jugée acceptable donné passer autres sites mettre variables statistiques fonction leurs données autres termes toute règle acceptable classer toutes données autres sites Ainsi règle voyager travers sites autre classer données chaque règle jugée satisfaisante ensemble données celle spécialisée processus recommence nouvelle règle jugée localement acceptable clair processus risque gourmand temps exécution Quant système fusion règles générées parallèle système identique précédent différence toute règle générée donné traverse autres sites mettre variables statistiques Ainsi nombre règles voyageant entre différents sites important nombre règles transite système conséquent clair cette technique encore lente précédente technique agrégation modèles proposée construire notre classificateur proposons architecture basée agents logiciels cette types agents œuvre agents mineurs minent chaque données répartie agent collecteur responsable regrouper informations produites agents mineurs Tâches agent mineur tâche agent mineur décrite figure noter coefficient confiance règle calculé utilisant théorème limite centrale effet théorème stipule somme grand nombre variables aléatoires indépendantes identiquement distribuées distribution approximée Normale Ainsi comme classificateurs bâtis large volume données erreur règle calculé ensemble disjoint ensemble entraînement approximé Normale erreur erreur appliqué toute population écart erreur écart associés règle pouvons Aounallah Mineau agent mineur travaillant données faire Appliquer algorithme classification générant ensemble règles couvertures disjointes ensemble produit nombre règles Calculer chaque coefficient confiance Algorithme détaillant tâches agent mineur calculer intervalle confiance lequel retrouvons erreur comme constante choisie fonction degré confiance désiré coefficient confiance chaque règle déduit intervalle confiance avons défini comme étant moins erreur calculé znσEr autres termes moins erreur règle moins moitié largeur intervalle confiance erreur ainsi visons prendre compte Tâches agent collecteur agent collecteur quant tâche regrouper informations produites agents mineurs tâche détaillée algorithme figure pouvons algorithme agent collecteur passe globalement phases première phase phase principale consiste regrouper toutes règles règles Cette règles notre classificateur original deuxième phase optionnelle représente phase raffinement filtrage règles supprimer règles celles faible coefficient confiance autres termes supprimer règles après mesure confiance calculée statistiquement rappelons auront vraisemblablement pouvoir prédictif lorsque confrontées données nouvelles ensemble règles résultant cette étape classificateur ensemble comme classificateur ensemble représente agrégation classificateurs ensemble règles utilisé comme modèle aussi prédictif descriptif point prédictif classe prédite nouvel objet classe majoritaire prédite différentes règles couvrent pondérée leurs coefficients confiance Toutefois égalité pondérations proposons effectuer majorité simple revient déterminer classe votée majorité classificateurs noter contrairement identifié littérature appelons règles conflit seulement règles couvrent objet différemment plusieurs règles couvrent forage distribué données méthode simple rapide efficace central faire agent collecteur Étape principale créer nombre bases distribuées Étape optionnelle filtrage règles Éliminer règles ayant coefficient confiance inférieur seuil déterminer empiriquement Algorithme détaillant tâches agent collecteur objet prédisent classe considérons comme conflictuelles rares majorité simple risque aboutir égalité échéant choisissons classe majoritaire ensemble bases entraînement signaler objet couvert règles sachant nombre sites nombre règles exactement phase détermination coefficient confiance risque certains échouer défaut couverture conséquent règle question ignorée ailleurs regroupant ensembles règle apparaître classificateur seule occurrence règle retenue attribuant coefficient confiance moyenne coefficients confiance différentes occurrences point descriptif règles couvrent objet expliquent classe égalité majorité simple pondéré Comme système développé forage données autres termes comme support prise décision règles couvrant objet proposées utilisateur juger expertise pertinence présenter décideur règle expliquer classe objet avantages puisque celui large complète limites chaque classe rappelons outre apprentissage automatique limite définit séparation entre différentes classes généralement unique conséquent plusieurs règles produisant classe peuvent représentées hyperplans séparant différentes classes fournissant diverses données Expérimentation effectuer tests avons utilisé données tirés banque données Blake taille varie objets 45222 bases adult chess versus house votes ionosphere mushroom indians diabetes Wisconsin Breast Cancer Mangasarian Wolberg Wisconsin Diagnostic Breast Cancer subdivision bases simuler bases distribuées détaillée Aounallah Aounallah Mineau comparaison utilisons algorithme appliqué totalité données résultat ensemble règles représente idéal toutes données peuvent regroupées central résultats obtenus seulement titre référence supposons pratique possible regrouper algorithme aussi utilisé construire classificateurs erreur obtenus commençons regrouper ensembles règles créer classificateur original tableau représente erreur chaque ensemble intervalle confiance ainsi avant dernière colonne représente comparaison entre erreur ensembles trouvons Empire Améliore signifie statistiquement temps mieux point erreur classification dernière colonne indique valeur absolue cette différence indiquant statistiquement comparable tableau montre erreur comparable celui autres différence importante Toutefois excellent résultat pourrait conséquence bases distribuées riches informations vérifier avons appauvri bases données introduisant bruit inversant attribut classe1 objets Borne Borne Adult Chess Empire Empire erreur classificateur original comparés utilisant bases appauvries données différents bases départ bases appauvries chacune constatons erreur toujours aussi comparables ailleurs arrive produire meilleurs erreur statistiquement confiance mesure bruit augmente bases Quant erreur seuil optimal bases évalué empiriquement sensiblement mêmes comparables statistiquement confiance données noter toutes bases utilisées classes forage distribué données méthode simple rapide efficace nombre règles formant classificateur tableau représente nombre règles formant classificateur obtenu clair tableau classificateurs nombre règles sonnable certains inférieur nombre règles notre classificateur référence résultat encourageant puisque classificateurs difficiles faciles interpréter Adult Chess nombre règles formant chaque ensemble règles Évaluation asymptotique cette section comparons complexité asymptotique classificateurs présentés section faire notons taille maximale ensemble entraînement nombre attributs données nombre maximum valeurs attribut nombre maximum prédicats littéraux règle nombre maximum règles produites objets entraînement nombre sites taille maximale ensemble quelconque technique proposée technique proposée rappelons fonctionne phases phase distante complie agents mineurs phase centralisée achevée agent collecteur tâches agent mineur tâches agent mineur détaillées figure Globalement bâtir classificateur tâche calculer coefficient confiance chaque règle tâche tâche application algorithme connu ordre tâche résume calcul couverture chaque règle suivant nombre tests faire savoir règle couvre objet nombre prédicats règle déterminer couverture toutes règles nombre ayant objets ensemble total tâches agent mineur Aounallah Mineau tâches agent collecteur tâches agent collecteur détaillées figure Globalement regrouper toutes règles issues différents agents mineurs ensemble tâche extraire celles coefficient confiance inférieur certain seuil avoir ensemble tâche tâche considéré comme négligeable tâche nombre règles considérant nombre règles issues nombre sites cette tâche Ainsi total notre classificateur Puisque nombre sites constant terme remplacé celui négligé devant conséquent ordre autre agent mineur Ainsi temps regroupement filtrage règles présente asymptotiquement aucun surcoût rapport temps nécessaire produire parallèle classificateurs techniques existantes algorithme résoudre conflits Williams algorithme besoin rapatrier objets couverts règles conflit toutes règles issues provoquent conflits règles résoudre conflits récupérer objets couverts règles issues autres termes récupérer ensemble entraînement risque voire irréalisable hypothèses fixées départ savoir plaçons contexte impossible transférer toute données autre Ainsi comme quantité données transite autre bornée algorithme comparable autres algorithmes viole hypothèses apprentissage distribué conséquent ignoré durant notre comparai système simplifier comparaison supposons complexité algorithme utilisé construire ensemble règles celle algorithme utilisons notre technique dessus malgré après rapide Cette technique fonction évaluation chaque règle cette fonction évaluée ensemble indépendant ensemble entraînement celui calcul notre coefficient confiance dessus Lorsqu règle satisfait critère évaluation local envoyée autres sites mettre statistiques fonction leurs données Ainsi cette règle ayant prédicats classer objets autres sites nombre associé cette opération règle forage distribué données méthode simple rapide efficace toutes règles peuvent satisfaire critère évaluation local Ainsi mettre statistiques règles donné nombre chaque devrait classer règles autres sites Ainsi aussi ordre règle satisfait critère évaluation global renvoyée départ spécialisée encore notons cette opération nouvelle règle satisfait toujours critère évaluation local processus réitéré conséquent autre ordre règle classant données autres sites conclusion global cette technique ordre Fusion ensembles règles générées parallèle étude complexité cette technique sensiblement système puisqu exactement technique augmentée processus résolution conflit selon algorithme conséquent globalement complexité cette technique égale complexité technique précédente Comparaison complexité notre technique lorsque validation réalisée considérant échan tillons comme ensemble ordre complexité système ainsi technique fusion règles parallèle ordre Ainsi trois techniques sensiblement complexité asymptotique terme notre technique fonction taille ensemble système fonction taille ensemble entraînement Comme taille semble entraînement généralement importante taille ensemble notre technique asymptotiquement rapide système Conclusion objectif papier faire comparaison entre techniques existantes gation modèles forage distribué données version simplifiée notre technique Aounallah Mineau Aounallah autre faire avons présenté survol techniques agrégation modèles existantes comparables nôtre ainsi description version simplifiée notre technique expériences menées démontré notre technique performe point prédiction aussi mieux classificateur totalité données utilisé comme point référence ailleurs classificateurs toujours tailles comparables classificateur centralisé référence étude asymptotique démontre outre techniques asymptotiquement comparables rapides techniques existantes Aounallah Mineau conclusion avons démontré classificateur simple agréga classificateurs bases formés ensembles règles auxquelles attribué coefficient confiance démontre pouvoir prédiction taille raisonnable aussi rapide rapide techniques agrégation modèles existantes après Aounallah Mineau Aounallah rapide techniques échantillonnage apparaît notre classificateur représenter bonne forage bases données distribuées compétitif techniques existantes surcroît architecture multi agents utilisé parallélisation technique permettrait grâce hiérarchisation agents collecteurs encore adaptabilité grandes bases données applications servent données transac tionnelles commerce pourraient alors bénéficier expérimentations terrain venir résultats préliminaires présentés article encourageants technique proposée moins certaines expérimentations selon étude complexité faite section propose technique beaucoup simple celles proposées section Références Aounallah Mineau confidence produced disjoint databases statistically sound regroup rules IADIS international conference Applied Computing Lisbon Portugal Aounallah Quirion Mineau Distributed Mining Sampling niques Comparison Advances Artificial Intelligence Conference Society Computational Studies Intelligence Canadian Number Lecture Notes Artificial Intelligence London Ontario Canada Springer Verlag Aounallah Quirion Mineau Forage distribué données paraison entre agrégation échantillons agrégation règles Revue Nouvelles Technologies Information extraction gestion connaissances Blake repository machine learning databases mlearn MLRepository Breiman Bagging predictors Machine Learning extensible learning approach scalable accurate ductive learning thesis Columbia University Fayyad Djorgovski Skicat machine learning system automa cataloging large scale surveys Machine Learning Proceedings Tenth International Conference Mateo Morgan Kaufmann Fayyad Djorgovski Advances Knowledge Discovery Mining Chapter Automating analysis cataloging surveys Menlo California Press Press Chawla Bowyer 1998a Combining Decision Trees Learned Parallel Working notes forage distribué données méthode simple rapide efficace Chawla Bowyer 1998b Decision learning large International Conference Systems Cybernetics Volume Chawla Bowyer Learning rules distributed Workshop Large Scale Parallel Systems KDD99 Report Mangasarian Wolberg Cancer diagnosis linear programming Prodromidis Stolfo learning distributed mining systems Issues approaches Kargupta Advances Distributed Parallel Knowledge Discovery Menlo Cambridge Press Press Provost Hennessy Distributed machine learning Scaling coarse grained parallelism Proceedings Second International Conference Intelligent Systems Molecular Biology Provost Hennessy Scaling Distributed machine learning coope ration Thirteenth National Conference Artificial Intelligence Schapire strength learnability Machine Learning Sikora Computational Study Distributed Learning Informa Systems Research Tsoumakas Vlahavas Distributed Mining Large Classifier Eensembles Vlahavas Spyropoulos Proceedings Companion Volume Second Hellenic Conference Artificial Intelligence Thessaloniki Greece Williams Inducing Combining Decision Structures Expert Systems thesis Australian National University Wüthrich Probabilistic knowledge bases Transactions Knowledge Engineering Summary paper deals problem mining large distributed bases where model predictive descriptive called classifier produced propose independently database remotely gather produced models called classifiers knowing mining process produce predictive descriptive model represented needs classification rules order guide aggregation final which union individual confidence coefficient assigned coefficient computed statistical means represents confidence which according cover error prove paper thanks confidence coefficient aggregated which simple aggregation classifiers represents reliable classifier compared existing techniques