apprentissage topologique papier_court dviclassificateurs aléatoires topologiques graphes voisinage fabien djamel zighed laboratoire mendès france 69676 cedex france fabien lyon1 zighed lyon2 lyon2 résumé apprentissage supervisé méthodes ensemble leurs qualités méthodes référence domaine forêts aléatoires cette dernière repose partitionnements représentation selon frontières parallèles obliques conséquences cette façon partitionner espace représentation peuvent affecter qualité chaque prédicteur semblé cette approche améliorée libérait cette contrainte manière mieux coller structure topologique ensemble apprentissage article proposons nouvelle basée graphes voisinage perfor mances premières expérimentations aussi bonnes celles introduction mining particulièrement apprentissage supervisé recours combinaison ensemble prédicteurs principe consiste générer ensemble classifieurs selon plusieurs méthodes apprentissage données agréger ensuite prédiction principe commun nombreuses espace observations découpé régions manière quasi aléatoire comme proposent kleinberg kleinberg fradkin madigan selon règles générales fixées algorithme comme arbres décision comme breiman chaque région constitue ensuite classifieur local semble manière construites régions influer chaque classifieur individuel conséquent affecter classifieur agrégé proposons nouveau moyen construire telle méthode utilisation graphes voisinage cette méthode présente performances comparables forêts aléatoires considérées souvent comme performantes section suivante donner principales définitions formaliser méthodes semble prenant comme exemple forêts aléatoires section introduisons utilisation graphes voisinage section montrera premiers résultats comparés forêts aléatoires classificateurs aléatoires topologiques graphes voisinage concepts considère échantillon apprentissage composé individus décrits variables prédictives classe appartenance description individu classe place ainsi cadre problème apprentissage supervisé classes simplifier notations considérons exemple suivant variable classe binaire figure utiliserons exemple jouet illustrer différentes définitions ensemble points classes classifieurs simples problème apprentissage supervisé multiclasses individu représenté cherche prédire correctement classe parvenir cherche calculer distribution probabilité définition classifieur espace représentation dimension exemple classifieur application simplexe ordre nombre classes intéresserons particulièrement ensemble classifieurs pellerons classifieurs topologiques classifieurs utilisant informations proximité entre individus classifieur topologique classifieur topologique classifieur construit partir ensemble prentissage repose notion proximité première opéra classifier point associer voisinage ensemble apprentis dernier permettra calculer résultat grâce classifieur individuel local résultat tiendra compte voisinage différents exemples classifieurs topologiques peuvent trouvés littérature proches voisins voisins arbres décision graphes voisinage gabriel voisins relatifs arbre longueur minimale polyèdres delaunay zighed voisinage ensemble parties forment recou vrement ensemble apprentissage cette formée voisinages possibles individu classifier ainsi rattaché éléments cette fonction voisinage permet rattacher individu élément voisinages cette fonction permet associer point ensemble voisins seuls points voisins interviendront détermination classe classifieur local permet estimer localement distribution probabilité classes définition classifieur topologique formé triplet méthode ensemble principe méthodes ensemble générer classifieurs agréger effectue itérations toutes identiques itération génère nouvel ensemble apprentissage espace représentation exemple possible échantillonner données départ remise projetant données génère nouveau classifieur éventuellement rajoutant exemple sélection variables random forest agrège résultats obtenus exemple majorité simple random forest majorité pondérée exemple forêt aléatoire créations ensembles apprentissages échantillonage bootstrap ensemble départ voisinage lorsqu construit arbre engendre partition ensemble apprentissage constitue voisinage fonction voisinage quand nouvel individu présente facile localiser voisinage parcourant arbre racine noeud terminal induit également partition espace représentation comme figure différentes régions délimitées droites perpendiculaires classifieur local consiste alors prendre proportion chaque classe voisinage agrégation majorité simple figure propose arbre classification engendre partition régions utilisation graphes voisinage aucun moment forêts aléatoires avons exploité notion région géométrique terme aurions partitionner espace selon formes classificateurs aléatoires topologiques graphes voisinage yesyes partitionnement espace représentation arbre quelconques seule difficulté garder esprit mesure localiser région individu prédire classe devons struire voisinages fonction voisinage partitionnement graphes voisinage article sommes limités structures voisinages géométriques graphes gabriel graphiques montre données introduit graphe gabriel créations ensembles apprentissages échantillonnons données départ remise variables remise voisinage partir graphe gabriel suffit couper arrêtes relient sommets appartenant classe composantes connexes graphe réduit forment voisinages fonction voisinage définir notion attractivité partie individu utiliser propriété graphe gabriel attractivité serait individu anonyme raccroché composante attractivité grande agrégation voisinage chaque point étant attribut points classe agrégation plusieurs classifieurs avons utiliser comme pondération taille composante rattachement cardinal voisinage intérêts graphes voisinage forêts aléatoires partitionnement espace contraint utilisant coupures parallèles obliques obtient forcement polyèdres convexes zighed avons observé contraintes peuvent avoir effet négatif capacité général isation formes linéairement séparables telles spirales imbriquées performances meilleures graphes erreur voisinage graphe gabriel autre avantage notre approche struction graphes voisinage contraire celle arbre espace représen tation faire partir simple matrice distance similarité permet utiliser cette méthode apprentissage exemple issus sciences sociales lesquels parfois difficile trouver représentation évaluation évaluer intérêt graphes voisinage allons utiliser données premières expérimentations sommes limités données quantitat petit nombre classes avons mêmes tests utilisant forêts aléatoires selon version implémentée librairie randomforest wiener paramètres donnant meilleur résultat était généralement paramètres défaut dimension ntree chaque répété manière obtenir estimation erreur intervalle confiance méthodes intervalles confiances calculés risque erreur première espèce utilisant student résultats consignés tableau données gabriel forêt aléatoire classes intervalle intervalle confiance confiance waveform twonorm trinorm ringnorm sonar diabetes ionosphere letters musk2 comparaison plusieurs comparant résultats méthodes aperçoit performances basées graphes gabriel moyenne équivalentes forêts données gabriel meilleur forêts aléatoires équivalent reprises classificateurs aléatoires topologiques graphes voisinage conclusions travaux futurs venons proposer cadre permet unifier approches ensemble utilisant notion voisinage cadre large celui classifieurs aléatoires topologiques avons montré comment cette approche instanciée forêts aléatoires manière analogue graphes voisinage méthodes ensemble recourt meilleure exploitation structure topologique ensemble apprentissage ouvre pistes paraissent prometteuses effet utiliser situations espace représentation explicite seule matrice proximité connue faisons ainsi connexion méthodes noyaux références breiman random forests machine learning fradkin madigan experiments random projections machine learn proceedings ninth sigkdd international conference knowledge discovery mining random subspace method constructing decision forests transac tions pattern analysis machine intelligence kleinberg building projectable classifiers arbitrary complexity international conference pattern recognition volume kleinberg overtraining resistant stochastic modeling method pattern recog nition annals statistics kleinberg algorithmic implementation stochastic discrimination transactions pattern analysis machine intelligence wiener classification regression randomforest elliptic gabriel graph finding neighbors point application normal vector estimation computer aided design summary supervised machine learning ensemble methods known perform better single classifier methods reference method random forest method shatters feature space according hyperplans either parallel oblic consequencies partitionning might affect performances classifier believe approach could improved better exploiting topology dataset purpose neighbourhood graphs