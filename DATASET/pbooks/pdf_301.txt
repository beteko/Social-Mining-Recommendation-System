Apprentissage supervisé dépendances syntaxiques partir texte étiqueté plusieurs variantes légères Marie Arcadias Guillaume Cleuziou Edmond Lassalle Christel Vrain Orange avenue Pierre Marzin 22300 Lannion prénom orange Université Orléans Léonard Vinci 45067 Orléans Cedex prénom orleans GREYC Maréchal 14032 Cedex Résumé apprentissage dépendances tâche consistant établir partir phrases texte modèle construction arbres traduisant hiérarchie syntaxique entre proposons modèle intermédiaire entre analyse syntaxique complète phrase grammaire stochastique contexte traduisant relations dépendance entre catégories grammaticales phrase résultats rimentaux obtenus benchmarks attestés dépassent langues scores algorithme référence première scores obtenus français grande simplicité grammaire permet apprentissage rapide analyse presque instantanée Introduction structure dépendances phrase traduit hiérarchie syntaxique permet inférer sémantique applications liées structures dépendance multiples citer entre autres modélisation langages reconnaissance plications textuelles moteurs question réponse extraction information induction ontologies lexicales traduction automatique structure dépendances phrase gauche arbre nœuds tokens phrase désigné comme racine arbre général verbe laquelle attachés arbres couvrant portions contigües phrase arbre dépendances constitué relations orientées entre taxiquement faible dépendant modèle dépendances compromis intéressant entre analyse syntaxique classique complète représentation modèles apprentissage supervisé dépendances exigent nombre important exemples annotés travail fastidieux demande expertise linguiste essentielle remanié profondément chaque nouveau texte quantité textes annotés dépendances faible comparée variété types textes disponibles proposons approche supervisée demandant Apprentissage supervisé dépendances modèle original connaissance superficielle langue texte plaçons cadre Apprentissage Supervisé Dépendances obtenu aux_tps PONCT ponct souhaitait mod_rel Arbre dépendances référence gauche analyse grammaire formelle droite corpus journalistique américain Treebank propose version dépendances corpus donnant structures dépendances phrases Klein Manning furent premiers obtenir phrases moins corpus résultats meilleurs simple attachement chaque voisin droite arbres aléatoires nommé modèle Dependency Model Valence entrée algorithme constituée étiquettes grammaticales phrases modèle génératif lequel racine phrase générée ensuite chaque nouvelle génère récursivement dépendants gauches droits catégorie dépendant déterminée fonction direction gauche droite apprentissage probabilités modèle celles types dépendance favorisées effectué procédure classique maximisation espérance basée probabilités priori calibrées suivant critères linguistiques modèle riche intéressant initialisation paramètres modèle problème complexe essentiel demande innovation technique expert apprentissage connaissances linguistiques poussées expert construction syntaxique langue étudiée Apprentissage grammaire contexte proposons démarche incluant apprentissage grammaire contexte babiliste algorithme Inside Outside Young analyse phrases version probabiliste Jurafsky Martin appliquée cette suivie phase traduction arbre formel arbre dépendances rappelons définitions grammaires formelles référer exemple Jurafsky Martin Arcadias Inside Outside algorithme génératif considérer comme extension modèles Markov cachés permettant apprendre grammaires contexte probabilistes Alors apprennent probabilités règles dérivation calculs séquences précédant suivant position Inside Outside calculs séquences intérieur extérieur positions probabiliste algorithme analyse choisit parmi toutes analyses autori règles grammaire celle probable formalisme originalité notre méthode réside choix grammaire simple permettant exprimer dépendances entre phrase exemple phrase obtenu souhaitait obtenu dominant dépendent gauche droite dominant souhaitait arbre dépendances référence représenté Figure gauche Notre modèle associe chaque représenté étiquette grammaticale qualité dominant dominé rapport voisins analyser phrase modèle combine ensuite symboles groupes jusqu chaque trouve place arbre dépendances Figure droite considérons symboles terminaux symbole départ représentant dominants respectivement gauche droite enfin présentant dominés terminaux représentent différentes catégories grammaticales elles peuvent différer fonction langue outil étiquetage présentons grammaire étiquettes universelles règles production suivent forme normale Chomsky imposée Inside Outside contraintes imposons suivantes terminal majuscule dominer terminal minuscule auquel associé règle dérivation exemple exprime dominant gauche décomposer dominant gauche dominé droit terminal gauche associé gauche donne terminaux interdit nombreuses règles permet limiter taille grammaire gardant signification grammaire dépendances latéralisée position relative gauche droite importe règles Chomsky premier règles exprimant construction interne phrases parlons règles structure règles Chomsky second terminal celles lesquelles transmet information catégorie dominer voisins gauche droite exemple interdirons systématiquement français règles déterminant toujours dominé placé gauche variantes fonction structure langue considérée règles structure phrase peuvent correspondre forme intrinsèque phrases grammaire présentée nommée contient symbole départ terminaux règles structure phrase écrites façon binaire suivant forme normale Chomsky Apprentissage supervisé dépendances modèle original signification quatre terminaux témoigne différenciation essentielle entre rôles catégories grammaticales domineraient gauche droite français nombreux cette différenciation pertinente cependant contrer situations cette différenciation pertinente exemple adjectifs qualifiant gauche autre droite dominés avons envisagé version comportant trois terminaux avons conservé cette variante latéralisation dominés avons gardé terminal dominant latéralisé différences Grammaire dominant autorise importantes règles ternaires terminal règles entre latéralisé récursives dominant récursives variantes centré règles structure terminaux Différentes variantes grammaire formelle désigne termi majuscules choix formes implique vision binaire découpages phrase groupes imposée forme normale Chomsky pouvons cependant affranchir cette contrainte traduction règles ternaires règles binaires envisager ainsi structure ternaire suggérée phrases sujet gauche verbe centre complément droite continuité cette conservant rôles latéralisés dominants permettant aussi domination centrale latéralisée avons introduit symbole neutre variantes distinguent interdit autorise utilisation récursive symbole condui structures complexes dernier Tableau résume différentes variantes proposées calibrage modèles calibrés fonction langue corpus calibrage consiste sélectionner règles terminal linguis tiquement exemple français déterminant dépendra toujours situé droite pourquoi parmi règles seule règle conser expérimentations suivre calibrage réalisé observant chaque langue quelques arbres donnés comme référence treebanks dépendances Expérimentations résultats French Treebank Abeillé Barrier donne structure constituants groupes nominaux verbaux ainsi fonctions syntaxiques sujet objet nombreuses phrases issues articles journal Monde Depuis treebank converti Arcadias arbres dépendances Candito avons comparé arbres appris notre modèle donnés référence treebank Candito paraison avons utilisé score Unlabeled Attachment Score calcule ensemble phrases nombre dépendances correctes ponctuations scores différents fonction variantes grammaire obtenons titre comparaison obtenons score arbres générés aléatoirement observe variantes autorisent règles ternaires récursives groupe central dominant groupes latéraux dominés engendrent scores pratiquement identiques nettement supérieurs obtenus autres variantes suggèrerait structure jacente phrases journalistiques assez sophisti quées mieux capturée modèle complexe notre connaissance sommes premiers traiter cette tâche français Celle ayant largement abordée anglais autres langues partir conférence CONLL Buchholz Marsi avons confronté notre modèle référence Tableau résume résultats obtenus ainsi variante ayant engendré meilleur score résultats pouvent différer beaucoup variante autre celle judicieusement choisie fonction langue texte CONLL Aléatoire Variante Temps Catégories utilisée apprentissage corpus distinctes Allemand Anglais Bulgare Danois Espagnol Français Hollandais Japonais Portugais Slovène Suédois meilleurs scores obtenus comparés références données Spitkovsky treebank dépendances différentes langues proviennent Anglais Marcus français Candito Abeillé Barrier autres langues étant celles CONLL Buchholz Marsi Discussion conclusion temps apprentissage dépendent fortement volume données faiblement nombre catégories petit nombre règles structures grammaire permet cepen apprentissage raisonnable temps voire rapide petits corpus grammaire apprise analyse quasiment instantanée quelques secondes milliers phrases argue souplesse notre modèle rapidité œuvre Celui portable performant relativement autres tests révélé Apprentissage supervisé dépendances modèle original résultats peuvent encore améliorés considérant catégories grammaticales fines morpho syntaxe temps apprentissage ressent nécessairement améliorer encore notre modèle envisageons intégrer informations cales séquences catégories identiques puissent fonction vocabulaire interprétées arbres dépendances différents Remerciements remercions Johnson codes Inside Outside Marie Candito disposition treebank dépendance ainsi conseils Références Abeillé Barrier Enriching french treebank Lisbon Buchholz Marsi CoNLL shared multilingual dependency parsing Proceedings Tenth Conference Computational Natural Language Learning Candito Crabbé Denis Statistical french dependency parsing treebank conversion first results Jurafsky Martin Speech Language Processing Prentice Klein Manning Corpus based induction syntactic structure Models dependency constituency Proceedings Annual Meeting Young estimation stochastic context grammars using inside outside algorithm Computer Speech Language Marcus Marcinkiewicz Santorini Building large annotated corpus english treebank Computational linguistics Spitkovsky Alshawi Jurafsky Lateen unsupervised training multiple objectives applied dependency grammar induction EMNLP Summary Dependency learning about building model allows transforming textual sentences trees representing syntactical hierarchy between words sentence present intermediate model between syntactic parsing sentence words based light probabilistic context grammar allowing express dependencies between words sentence model tuned little respect learned language Experimentally could surpass scores reference attested benchmarks languages English Portuguese Japanese first results French corpora Learning parsing almost instantaneous