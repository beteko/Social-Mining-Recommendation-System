Microsoft EGC2004_Khiops méthode robuste partitionner valeurs attributs catégorielles Boullé France Télécom avenue Pierre Marzin 22300 Lannion France boulle francetelecom domaine apprentissage supervisez methods groupages attribut Modalités symbolique construct permettent nouvel attribut synthetic maximum conservant Valeur informationnelle initiale attribut diminuant Nombre Modalités proposons algorithme généralisation discrétisation Khiops1 groupages Problème Modalités algorithme CONTROLER Përmet Proposé priori Improving apprentissage robustesse significativement groupages Produits characteristic robustesse available statistique étudiant variations critère regroupements tableau lignes Contingence modélisant comportement algorithme statistique Khiops Expérimentations Intensifs Ontario permis approach valider Montré Ontario méthode groupages Khiops aboutIt groupages Performants qualité prédictive Nombre Faible Groupes Introduction Alors problème discrétisation largement étudié passé problème regroupement exploré profondément littérature Cependant réalité ensembles données exploration données existe nombreux regroupement valeurs attributs catégoriques étape traitement obligatoire problème regroupement consiste diviser ensemble valeurs attribut catégorique nombre groupes exemple plupart arbres décision exploitent méthode regroupement gérer attributs catégoriques augmenter nombre chaque arbre Zighed Rakotomalala réseaux neurones basées attributs numériques souvent utiliser codage binaire prétraiter catégorique attributs Lorsque catégories nombreuses schéma codage remplacé méthode regroupement problème nombreux autres algorithmes classification réseaux bayésiens régression linéaire régression logistique outre regroupement procédé usage général intrinsèquement utiles étape préparation données procédé extraction données méthodes regroupement peuvent regroupés fonction stratégie recherche meilleure partition critère regroupement utilisé évaluer partitions algorithme simple essaie trouver meilleurs bipartition catégorie contre autres approche intéressante consiste rechercher bipartition toutes catégories procédé avant séquentiel sélection dérivé Cestnik évalués Berckman brevets français 07006 16733 méthode robuste diviser valeurs Categorical Attributs algorithme glouton initialise groupe meilleure catégorie contre autres ajoute nouvelles catégories itérativement premier groupe Lorsque attribut classe valeurs Breiman proposé méthode optimale regrouper catégories groupes critère algorithme abord catégories fonction probabilité première valeur classe recherche meilleurs éclatés cette liste triée algorithme complexité temporelle nombre catégories idées présentées Lechevallier Fulton résultat probablement étendue trouver partition optimale catégories groupes valeurs classe utilisation algorithme programmation dynamique complexité temps général valeurs classe algorithme trouver regroupement optimal groupes dehors recherche exhaustive Cependant proposé approche basée means permet trouver partition localement optimale catégories groupes algorithmes arbres décision gèrent souvent problème regroupement heuristique gloutonne basée classification ascendante catégories algorithme commence groupe catégorie recherche meilleure fusion entre groupes processus répété jusqu aucune autre fusion améliorer critère regroupement algorithme CHAID utilise cette approche gourmande proche critère ChiMerge Kerber meilleures fusions recherchées réduisant minimum niveau confiance critère carré appliqué localement catégories elles fusionnées elles statistiquement similaires algorithme Quinlan utilise critère information évaluer attributs catégoriques regroupement critère favoriser attributs nombreuses catégories Quinlan proposé exploiter critère rapport divisant information entropie catégories critère carré également appliquée globalement ensemble catégories version normalisée valeur carré Tschuprow Cramer Ritschard comparer différents partitions méthode regroupement Khiops généralisation directe méthode discrétisation Khiops Boullé 2003a fusionner valeurs numériques adjacentes intervalles construction procédé groupement fusionne valeurs nominales groupes valeurs algorithme recherche heuristique gloutonne ascendante optimise critère carré appliqué ensemble intervalles groupes règle arrêt niveau confiance calculé statistiques carré méthode arrête automatiquement processus fusion niveau confiance épreuve indépendance entre attribut partitionné attribut classe diminue ensemble groupes résultant méthode regroupement fournit classificateur univariée élémentaire prévoit distribution valeurs classe chaque groupe appris méthode regroupement considéré comme algorithme inductif soumis overfitting appliquons méthode similaire celle développée méthode discrétisation Khiops apporter véritable contrôle surajustement principe analyser comportement algorithme regroupement organisme indépendant attribut explicatif attribut classe étudions statistiques variations valeurs carré fusion catégories proposons modéliser maximum variations processus regroupement complet algorithme ensuite modifié forcer toute fusion variation valeur carré inférieure variation maximale prédite notre modélisation statistique changement algorithme donne garantie probabiliste intéressant attribut indépendant seront regroupés groupe terminal attribut Boullé groupe compose moins groupes contient vraiment informations prédictives attribut classe confirmé expérimentalement reste document organisé comme section présente brièvement initiales Khiops regroupement algorithme section présente modélisation statistique algorithme réglage éviter surajustement article procède vaste évaluation expérimentale regroupement Khiops Méthode cette section rappelons principes carré présente algorithme regroupement Khiops description détaillée analyse trouvée Boullé 2003b carré Principes Notat Considérons attribut explicatif attribut classe déterminer elles indépendantes abord résumés tableau contingence comptés chaque paire valeurs attributs explicatifs classe valeur carré calculée partir tableau contingence après tableau notations fréquence observée valeur explicative Total valeur classe jième Fréquence totale observée valeur explicative Total fréquence observée valeur classe Nombre total observé fréquence Nombre valeurs attributs explicatifs Nombre valeurs classe totale Table contingence utilisée calculer valeur carré Laissez représentent fréquence attendue cellule attributs explicatifs classe indépendants valeur carré mesure ensemble tableau contingence différence entre fréquences observées fréquences attendues interprété comme distance rapport hypothèse indépendance entre attributs hypothèse nulle indépendance valeur carré soumis statistiques carré degrés liberté statistique permet rejeter hypothèse indépendance valeur carré niveau confiance valeur initiale algorithme carré dépend fréquences observées locales chaque ligne individuelle fréquences mondiales observées ensemble tableau contingence bonne méthode robuste partitionner valeurs attributs catégorielles critère candidat méthode regroupement statistiques carré paramétrées nombre valeurs explicatives rapport degrés liberté comparer groupes différents numéros groupe utilisons niveau confiance valeur carrée principe algorithme Khiops minimiser niveau confiance entre attribut explicatif groupés attribut classe biais statistiques carré valeur carré fiable tester hypothèse indépendance fréquence attendue cellule tableau contingence tombe dessous valeur minimale Copes algorithme cette contrainte traitement catégorie initiale remplit contrainte fréquence minimale inconditionnellement fusionnées groupe spécial procédé Khiops algorithme gourmand commence catégories initiales cherche ensuite meilleure fusion entre catégories algorithme répété jusqu aucune autre fusion diminuer niveau confiance complexité calcul algorithme réduite certaines optimisations Boullé 2003b existe différences principales entre algorithme Khiops initial algorithme CHAID similaire abord critère carré appliquée globalement partition entière algorithme Khiops alors appliqué localement groupes adjacents algorithme CHAID second algorithme Khiops arrête processus fusion lorsque niveau confiance augmente après meilleure fusion candidat alors algorithme CHAID arrête lorsque niveau confiance seuil utilisateur Analyse statistique algorithme algorithme Khiops choisit meilleure fusion entre toutes fusions possibles catégories itère processus jusqu règle arrêt remplie Lorsque attribut explicatif attribut classe indépendants ensemble résultant groupes devrait composé groupe signifie information prédictive attribut explicatif étudions comportement statistique algorithme Khiops initial attributs indépendants valeur carré soumis statistiques carré espérance variance connue étudions DeltaChi2 variation valeur carré après fusion catégories attributs indépendants cours processus regroupement grand nombre fusions évaluées chaque étape algorithme Khiops choisit fusion maximise valeur carré savoir fusion minimise valeur DeltaChi2 puisque valeur carré avant opération fusion règle arrêt remplie lorsque meilleure valeur DeltaChi2 grande Toutefois attributs indépendants processus fusion devrait poursuivre jusqu algorithme regroupement atteint groupe terminal grande valeur DeltaChi2 rencontrées cours algorithme fusion étapes décision alors acceptée allons essayer estimer cette valeur MaxDeltaChi2 attributs indépendants modifier algorithme forcer fusions cette limite atteint Statistiques valeurs MaxDeltaChi2 algorithme Khiops Concentrons lignes table contingence fréquences probabilités ligne valeurs classe Laissez Boullé probabilités valeurs classe toute table contingence valeur carré diminuer lorsque lignes fusionnées Définissons valeur DeltaChi2 comme variation valeur carré fusion DeltaChi avons prouvé indépendant attribut explicatif attribut classe valeurs valeur DeltaChi2 résultant fusion lignes mêmes fréquences asymptotiquement distribuée comme statistiques carré degrés liberté Boullé 2003b valeur MaxDeltaChi2 égale maximum valeurs DeltaChi2 rencontrées cours processus regroupement complet groupe terminal lorsque attribut groupé indépendant attribut classe processus discrétisation fusions contraintes adjacentes table contingence avons proposé Boullé 2003a formule analytique rapprocher statistiques MaxDeltaChi2 processus regroupement avons rapprocher statistiques MaxDeltaChi2 analytiquement Cependant avons montré Boullé 2003b statistiques MaxDeltaChi2 dépend paramètres nombre catégories initiales nombre valeurs classe précisément propositions suivantes conjectures vérifiés vaste expériences données synthétiques statistiques MaxDeltaChi2 indépendante taille échantillon statistiques MaxDeltaChi2 indépendante répartition catégories statistiques MaxDeltaChi2 indépendant distribution classe exemple évalué première conjecture ensembles données aléatoires catégories initiales classes équiréparties équiréparties avons recueilli valeurs MaxDeltaChi2 résultant processus regroupement complet données générés hasard Cette expérience répétée grand nombre tailles échantillons allant 200000 montré fonctions répartition valeurs MaxDeltaChi2 indépendantes taille échantillon genre expériences effectuée vérifier autres conjectures avons également prouvé propositions suivantes catégories classes Proposition catégories classes statistiques valeur MaxDeltaChi2 statistiques Quare degrés liberté Proposition équidistribuée catégories classes équiréparties moyenne valeur MaxDeltaChi2 asymptotiquement égale général statistiques valeur MaxDeltaChi2 modéliser expression mathématique comme celle méthode discrétisation Khiops avons choisi calculer expérimentalement moyenne écart MaxDeltaChi2 grand nombre paires paramètres analyse résultats montre comportement linéaire méthode robuste diviser valeurs Categorical Attributs rapport paramètres conforme propositions Cette observation permet utiliser table valeurs environ moyenne écart valeurs MaxDeltaChi2 compter interpolation linéaire entre valeurs calculées Enfin faisons dernière hypothèse confirmée évaluation expérimentale fonction répartition valeurs MaxDeltaChi2 approchée normale écart moyen standard détails simulation donnés Boullé 2003b conclure valeur MaxDeltaChi2 utilisée algorithme regroupement Khiops calculé raison interpolation linéaire moyenne écart trouvé tableau valeur calculée avant nombre donné catégories valeurs classe utilisant normale inverse valeur MaxDeltaChi2 déterminée sorte grande valeurs DeltaChi2 observées probabilité exemple robuste Khiops algorithme groupement algorithme robuste Khiops Initialisation Trier valeurs attributs explicatifs Créer groupe élémentaire chaque valeur Création groupe spécial traiter toutes catégories initiales remplissent contrainte fréquence minimale nécessaire fusionner groupe spécial catégorie reste moins fréquente Calculer valeur MaxDeltaChi2 nombre initial groupes valeurs classe Optimisation groupement répéter étapes suivantes Évaluer toutes fusions possibles entre paires groupes Rechercher meilleure fusion fusion continuer aussi longtemps conditions suivantes pertinente niveau confiance groupement diminue après fusion valeur DeltaChi2 meilleure fusion inférieure valeur MaxDeltaChi2 attributs indépendants regroupement devrait traduire groupe terminal probabilité donnée modélisation statistique algorithmes Khiops fournit valeur théorique MaxDeltaChi2 supérieure toutes valeurs DeltaChi2 fusions réalisées cours processus regroupement probabilité premier algorithme regroupement Khiops ensuite modifié forcer toutes fusions valeur inférieure DeltaChi2 MaxDeltaChi2 garantit comportement attendu algorithme probabilité attributs relation dépendance inconnue cette amélioration garanties algorithme lorsque attribut groupé constitué moins groupes attribut explicatif détient réellement informations concernant attribut classe probabilité supérieure conseillons laisser assurer résultats fiables regroupement impact algorithme Khiops initial limité évaluation règle arrêt conserve complexité calcul supra linéaire algorithme Boullé Expériences Dataset continue Taille nominale Classe majorité Attributs Attributs Valeurs Précision adulte 48842 Australian Coeur HorseColic ionosphère Champignon TicTacToe véhicule Waveform datasets notre étude expérimentale comparons méthode Khiops regroupement autres algorithmes regroupement supervisé critères performance prédictive nombre groupes évaluer performance intrinsèque méthodes regroupement éliminer biais choix algorithme induction spécifique utilisons protocole similaire méthode Zighed Rakotomalala chaque groupe considéré comme méthode inductive élémentaire prédit distribution valeurs classe chaque groupe appris avons choisi utiliser critère précision concentre uniquement valeur classe majoritaire différencier prédictions correctes faites probabilité prédictions correctes probabilité légèrement supérieure outre nombreuses applications notamment domaine commercialisation fondent notation instances doivent évaluer probabilité chaque valeur classe évaluer qualité prédictive groupes utilisons divergence Kullback Leibler Kullback appliqué comparer distribution valeurs classe estimée ensemble apprentissage groupes appris distribution valeurs classe observée ensemble valeurs initiales toutes méthodes testées catégorie donnée laissez probabilité valeur classe estimée ensemble apprentissage utilisation groupe contenant catégorie probabilité valeur classe observée ensemble seule catégorie divergence Kullback Leibler entre distribution estimée distribution observée évaluation globale qualité prédictive calculée comme moyenne divergence Kullback Leibler ensemble lisser distributions empiriques traiter probabilités utilisons estimateur Laplace autres approches définition mesures qualité ajustement exemple Ritschard Zighed méthode robuste partitionner valeurs attributs catégorielles problème regroupement problème critères tente compromis entre qualité prédictive nombre groupes classificateur optimal classificateur Bayes classificateur univariée attribut catégorique regroupement optimal faire expériences recueillons résultats qualité prédictive utilisant divergence Kullback Leibler nombre groupes avons recueilli ensembles données dépôt Irvine Blake chaque ensemble données moins quelques dixièmes chaque valeur classe attributs catégoriques valeurs augmenter nombre candidats attributs catégoriques regroupement attributs continus discrétisés traitement discrétisation supervision égale largeur tableau décrit ensembles données dernière colonne correspond précision classe majoritaire méthodes regroupement étudiés comparaison suivants Khiops méthode décrite présent document Initial Khiops version initiale méthode décrite article CHAID méthode regroupement utilisé méthode CHAID Tschuprow méthode regroupement décrit exemple Ritschard Ratio méthode regroupement utilisé méthode Quinlan Toutes méthodes basées algorithme avide raccorde manière itérative catégories groupes détermine automatiquement nombre groupes partition finale catégories méthode rapport seule méthode basée entropie autres méthodes utilisent critères carrés première méthode Khiops applique critère carré toute table contingence évalue partition niveau confiance méthode Khiops robuste améliore algorithme Khiops initial fournissant garanties contre surapprentissage méthode Tschuprow également basée évaluation globale table contingence utilise normalisation valeur carré Tschuprow niveau confiance évaluer partitions méthode CHAID applique critère carré localement rangées table contingence méthode CHAID niveau signification seuil carré correction Bonferroni appliquée avons réimplémenté groupement approches alternatives éliminer écart résultant différentes divisions validation croisée groupements effectuées attributs ensembles données utilisant stratifié validation croisée déterminer performances significativement différentes entre méthode Khiops méthodes alternatives statistiques différence résultats calculée hypothèse nulle cette valeur Student degrés liberté niveau confiance bilatéral réalisé rejeter hypothèse nulle Qualité Groupements tables ensemble résultats grandes imprimées présent document résultats qualité prédictive résumés tableau rapports chaque ensemble données moyenne divergences Kullback Leibler nombre victoires Khiops significatives pertes chaque comparaison méthode résultats normalisés utilisant divergence Kullback Leibler évalué lorsque aucun regroupement moyens moyens géométriques concentrer rapports performances entre méthodes testées Boullé résultats montrent différences significatives entre méthodes permettent classer méthodes testées premier groupe méthode méthode regroupement Khiops obtient meilleurs résultats suivi méthode initiale Khiops groupement méthode CHAID méthode Khiops obtient significativement meilleurs résultats méthode CHAID attributs groupés nettement moins résultats attributs deuxième groupe méthodes méthodes Ratio Tchuprow clairement surperformé trois principales méthodes exemple méthode Khiops dépasse méthode ratio attributs battu seulement attributs Dataset Khiops Khiops CHAID Tschuprow Ratio Adult australien Coeur HorseColic ionosphère champignons TicTacToe véhicule Waveform Synthèse Moyens qualité prédictive groupes nombre victoires significatives pertes données méthode Khiops rapport méthodes alternatives résumé critère qualité prédictive suggère classement suivant méthodes éprouvées Khiops initiale Khiops CHAID Tschuprow Ratio Taille groupement résultats numéro groupe résumées tableau différences importantes entre méthodes testées méthodes Ratio Tschuprow produisent petits groupes taille moyenne détriment faible qualité prédictive Parmi méthodes regroupement haute qualité méthode Khiops gagnant numéro groupe criteri suivie méthode Khiops initiale méthode CHAID groupes produits méthode Khiops toujours petit produits méthode CHAID différences importantes attributs méthodes Ratio Tschuprow obtiennent groupes petits moyenne résultats contrastés entre ensembles données quart attributs méthode Khiops obtient groupements nettement petite méthode ratio intéressant analyser profondeur résultats ensemble données forme environ moitié attributs attributs bruit inspection groupements révèle méthode robuste diviser valeurs Categorical Attributs Méthode Khiops robustes regroupement seule méthode identifie correctement attributs bruit groupements réduits groupe Dataset Khiops Khiops CHAID Tschuprow Ratio Adult australien Coeur HorseColic ionosphère Champignon TicTacToe véhicule Waveform Synthèse Moyens taille groupes nombre victoires significatives pertes données méthode Khiops rapport méthodes alternatives résumé critère numéro groupe suggère classement suivant méthodes éprouvées Tschuprow Ratio Khiops initiale Khiops CHAID critères analyse résultats mieux comprendre relations entre qualité prédictive taille groupes tirons figure moyens globaux résultats critères numéro groupe coordonnée qualité prédictive coordonnée titre comparaison présentons également résultats obtenus trois méthodes groupage alternative simple bipartition supervision catégories groupe contenant catégorie fréquente Valeur unique bipartition catégories catégorie contre autres sélectionnés critère carré fusion finale toujours possible exhaustive CHAID bipartition catégories obtenues algorithme CHAID forçant fusions jusqu partition contient groupes trois méthodes regroupement bipartition classés comme prévu critère qualité prédictive Tschuprow méthodes Ratio autorisés construire partition groupes obtiennent meilleurs résultats qualité prédictive méthode Exhaustive CHAID groupe méthodes efficaces Khiops initiale Khiops CHAID prend clairement avantage partitions plusieurs groupes Parmi méthodes principales méthode Khiops domine autres méthodes critères Enfin compte complexité calcul algorithmes celle algorithme optimisé Khiops Boullé tandis autres méthodes Cependant différence temps exécution mineur nombreux lorsque nombre valeurs catégoriques faible Groupe Nombre Khiops initiale Khiops CHAID Valeur unique Exhaustive CHAID Tschuprow Ratio FIGUE évaluation critères groupement éthodes numéro groupe critères qualité prédictive Conclusion principe méthode Khiops regroupement minimiser niveau confiance épreuve indépendance entre attribut groupé attribut classe cours processus bottom algorithme nombreuses fusions entre catégories effectuées variations produisent valeur carré table contingence raison modélisation statistique variations lorsque attribut explicatif indépendant attribut classe avons amélioré algorithme regroupement initial Khiops garantir groupes attributs indépendants réduits groupe Cette résistance attestés surapprentissage alternative intéressante approche validation croisée classique nombreuses expériences comparatives montrent méthode Khiops surclasse autres méthodes regroupement testées permet réduire considérablement nombre valeurs attributs catégoriques étape traitement exploration données gardant plupart performance prédictive monothétique Berckman Références Berckman Valeur regroupement arbres décision binaires Rapport technique Département Informatique Université Massachusetts Blake Blake référentiel bases données apprentissage machine mlearn MLRepository Irvine Université Californie Département information informatique Boullé 2003a Boullé Khiops discrétisation Méthode attributs continus résistance garantie bruit Actes troisième Conférence internationale apprentissage fouille données reconnaissance formes méthode robuste valeurs Partitionnement catégorielles Attributs Boullé 2003b Boullé Groupage facts Robuste symbolique attribut Khiops méthode technique France Télécom Breiman Breiman Friedman Olshen Pierre régression arbres Californie Cestnik Wadsworth International Cestnik Kononenko Bratko ASSISTANT outil connaissance explicitation utilisateurs sophistiqués Bratko Lavrac progrès apprentissage machine Wilmslow Royaume Sigma Press Optimal Partitionnement classification régression arbres Transactions modèle analyse intelligence artificielle Fulton Fulton Kasif Salzberg algorithmes efficaces trouver fractionnements façon multi arbres décision Actes Conférence mixte internationale Treizième intelligence artificielle Francisco Morgan Kaufmann technique exploration étudier grandes quantités données catégoriques Statistique appliquée Kerber Kerber ChiMerge discrétisation attributs numériques Actes Conférence internationale intelligence artificielle Kullback Kullback Théorie information statistique Wiley réédité Dover Lechevallier Lechevallier Recherche partition contrainte optimale totale ordre Rapport technique INRIA Préparation données exploration données Morgan Kaufmann Quinlan Quinlan Induction arbres décision Machine Learning Quinlan Quinlan Programmes apprentissage machine Morgan Kaufmann Ritschard Ritschard Zighed Nicoloyannis Maximisation association Regroupement lignes tableau Colonnes Croisé Ritschard Zighed Ritschard Zighed Modelisa tables Contingence induction arbre Extraction Gestion Connaissances Zighed Rakotomalala Zighed Rakotomalala Graphes induction Hermes Science Publications Résumé apprentissage machine supervisé partage valeurs également appelées regroupement objectif attributs catégoriques construction nouvel attribut synthétique conserve informations attribut initial réduit nombre valeurs article proposons nouvelle méthode regroupement Khiops généralisation algorithme discrétisation Khiops Cette méthode regroupement fournit garanties contre surapprentissage conduit ainsi groupes robustes Cette propriété découle modélisation statistique méthode Khiops permet affiner algorithme nombreuses expériences démontrent validité cette approche montrent méthode regroupement Khiops construit groupes grande qualité termes qualité prédictive petit nombre groupes