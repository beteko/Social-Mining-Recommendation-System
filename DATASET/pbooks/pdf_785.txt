actes_non_num 351rotes incrémental parallèle François Poulet Thanh Nguyen IRISA Texmex Campus Beaulieu 35042 Rennes Cedex francois poulet irisa irisa texmex people poulet index_fr LUSSI Télécom Bretagne Technopôle Brest Iroise 83818 29238 Brest Cedex telecom bretagne perso bretagne IRISA Symbiose Campus Beaulieu 35042 Rennes Cedex vhnguyen irisa irisa symbiose people nguyen Résumé présentons nouvel algorithme incrémental parallèle Séparateur Vaste Marge Support Vector Machine classification grands ensembles données utilisant processeur carte graphique Graphics Processing Units méthodes noyaux permettent construire modèles bonne précision nécessitent habituellement résolution programme quadratique requiert grande quantité mémoire temps exécution ensembles données taille importante présentons extension algorithme Least Squares proposé Suykens Vandewalle obtenir algorithme incrémental parallèle nouvel algorithme exécuté processeur graphique obtenir bonne performance faible résultats numériques ensembles données Delve montrent notre algorithme incrémental parallèle environ rapide significativement rapide algorithmes standards LibSVM Introduction algorithmes Séparateurs Vaste Marge proposés Vapnik méthodes noyaux permettent construire modèles précis deviennent outils classification données populaires trouver nombreuses applications comme reconnaissance visages catégorisation textes bioinformatique Guyon Cependant demandent résolution incrémental parallèle programme quadratique calcul moins complexité égale carré nombre individus ensemble apprentissage quantité mémoire nécessaire impossible utiliser grands ensembles données heure actuelle Lyman besoin permettre passage échelle traiter grands ensembles données machines standard méthodes heuristiques efficaces permettent améliorer temps calcul décomposant programme quadratique série petits problèmes Boser Chang Platt niveau œuvre méthodes apprentissage incrémental Cauwenberghs Poulet Mangasarian Poulet permettent traiter grands ensembles données solutions partielles chargeant successivement ensembles apprentissage mémoire avoir charger ensemble total algorithmes parallèles distribués Poulet Poulet utilisent machines réseaux améliorer temps exécution apprentissage algorithmes apprentissage actif Poulet Koller choisissent ensemble individus ensemble actif représentatif construction modèle algorithmes boosting Poulet basent échantillonnage théorème Sherman Morrison Woodbury Golub classifier simultanément grand nombre individus dimensions article présentons algorithme incrémental parallèle Least Squares classification grands ensembles données exemple carte graphique NVidia GeForce 8800GTX Notre point départ algorithme proposé Suykens Vandewalle algorithme obtient solution résolution système équations linéaires programme quadratique permet classifier beaucoup rapidement ensembles ayant grands nombres individus avons étendu algorithme manières avons développé version incrémentale pouvoir traiter grands ensembles données milliard individus utilisons carte graphique architecture massivement parallèle obtenir bonne puissance calcul faible performances algorithmes temps exécution précision évaluées grands ensembles données provenant Asuncion Newman Delve Delve comme Forest Covertype KDDCup Adult RingNorm résultats montrent version notre algorithme environ rapide version exemple efficacité classification ensemble données millions individus dimension classifiés classes seconde carte graphique NVidia GeForce comparé secondes nécessaires Intel avons aussi comparés résultats obtenus LibSVM Chang Joachims paragraphe présente brièvement algorithme paragraphe décrit algorithme incrémental permettant classification grands ensembles données paragraphe présentons version incrémentale parallèle quelques résultats paragraphe avant conclusion travaux futurs Quelques notations utilisées article vecteurs représentés matrices colonne produit scalaire vecteurs norme vecteur matrice représente points dimension Poulet Algorithme tâche classification binaire linéaire représentée figure individus dimensions représentés matrice leurs classes stockées matrice diagonale algorithme cherche meilleur hyperplan séparation données éloigné classe classe ramène maximiser marge distance entre plans supports classes support classe sépare individus classe autres autre minimiser erreurs individus mauvais support distances erreurs notées variables individu support alors algorithme revient programme quadratique marge optimal marge optimal linéaire classification données classes constante utilisée contrôler marge erreurs optimal obtenu résolution programme quadratique Ensuite classification nouvel individu obtenue signe peuvent utiliser autres fonctions classification comme exemple fonction polynomiale degré fonction Radial Basis Function fonction sigmoïdale passage linéaire linéaire simplement utilisant fonction noyau produit scalaire Cependant calcul solution moins ordre représentant nombre points peuvent traiter grands ensembles données incrémental parallèle algorithme proposé Suykens Vandewalle remplace contrainte inégalité égalité modifie également algorithme minimisant erreurs contrainte substituant fonction objectif programme quadratique obtenons alors problème optimisation calculons dérivées partielles donne système équations linéaires inconnues suivant réécrits forme système équations linéaires 1ETDe matrice diagonale identité dernier élément algorithme nécessite résolution système équations linéaires inconnues programme quadratique nombre dimensions ensemble données important capable traiter grand nombre individus milliard temps restreint machine standard résultats numériques montré algorithme obtient précision algorithmes références comme LibSVM algorithme beaucoup rapide exemple efficacité décrit Poulet classification classes milliard individus dimension seulement secondes standard Pentium Algorithme incrémental algorithme rapide efficace classification grands ensembles données nécessite charger totalité ensemble données mémoire effectuer classification grands ensembles données exemple milliard points dimension nécessite algorithmes apprentissage difficultés challenge grands ensembles données allons concentrer passage échelle algorithmes pouvoir traiter grandes quantités données machines standard algorithmes incrémentaux solution efficace traitement grands ensembles données évitent charger totalité données mémoire ensemble données traité instant solution partielle mesure Poulet suppose grand ensemble données décomposé blocs lignes algorithme incrémental simplement calculer solution système équations linéaires manière incrémentale simple supposons ensemble données traiter décomposé blocs lignes calcul incrémental solution système équations linéaires alors effectuer manière suivante 222111 eDEeDEDeE EEEEEE eDEEEI partir équations généraliser obtenir calcul incrémental ensemble données décomposé blocs lignes eDEEEI Entrée ensemble apprentissage blocs constante régler marge erreurs Apprentissage initialisation calcul TDiei résolution système équation obtient coefficients Classification nouvel individu basée signe Algorithme incrémental incrémental parallèle algorithme incrémental présenté tableau traiter ensembles données grandes tailles machine standard précision algorithme exactement celle algorithme original nécessite stockage mémoire petite matrice taille vecteurs taille entre étapes successives algorithme tests montré algorithme incrémental effectuer classification milliard individus dimension minutes compter temps lecture données Pentium Algorithme incrémental parallèle algorithme incrémental venons décrire traiter grands ensembles données simple exécute processeur avons étendu obtenir version parallèle Graphics Processing Durant dernière décennie Wasson développés processeurs spécialisés accélération graphique plusieurs avantages rapport architecture actuelle calcul intensif parallèle Parmi avantages citer meilleur transfert mémoire significativement meilleurs calculs flottant utilisation centaines unités parallèles calcul Single Instruction Multiple peuvent alternative intéressante cluster calcul intensif récents incluent nouvelles possibilités programmation peuvent utilisés calculs graphiques General Purpose comme simulations physique traitement signal calculs géométriques fouille données Entrée ensemble apprentissage blocs constante régler marge erreurs Apprentissage initialisation charge mémoire copie mémoire calcul TDiei copie mémoire résolution système équation obtient coefficients Classification nouvel individu basée signe Algorithme incrémental parallèle Poulet NVidia récemment sorti nouvelle carte graphique GeForce bibliothèque appelée NVidia Compute Unified Device Architecture architecture NVidia GeForce basée multi processeurs Chaque multi processeur comporte unités calcul total processeurs Chaque groupe processeurs partage cache mémoire Chaque processeur possède unité arithmétique Arithmetic Logic effectuer opérations flottants instructions exécutées Nvidia GeForce possède mémoire performances calcul GFLOPS transfert mémoire Cette architecture spécialisée profit calcul intensif massivement parallèle bibliothèque développée NVidia langage permet utiliser carte graphique calculs graphiques utilisée comme support exécution parallèle inclut pilote carte librairies mathématiques niveau usage graphique comprenant notamment CUBLAS NVidia Cublas Basic Linear Algebra Subprograms modèle application librairie CUBLAS création matrices vecteurs mémoire appel fonctions CUBLAS finalement récupération résultats machine transfert entre mémoire avons développé version parallèle algorithme incrémental bénéficier bonnes performances calcul faible implémentation parallèle incrémentale décrite tableau utilise librairie CUBLAS calculs matriciels architecture massivement parallèle programme utilisé importe quelle carte graphique compatible CUBLAS aujourd cartes différentes toutes NVidia utilisation CUBLAS parallélisation effectuée manière implicite ensemble données abord découpé petits blocs chaque étape algorithme incrémental données chargée mémoire transféré mémoire mémoire ensuite sommes EiTEi EiTDiei calculées parallèle Finalement résultats EiTEi recopiés mémoire mémoire résoudre système équations linéaires précision algorithme incrémental parallèle exactement celle algorithme original Quelques résultats expérimentation avons utilisé Intel carte graphique NVidia GeForce 8800GTX pilote NVidia version Linux Fedora avons développé versions algorithme incrémental parallèle bibliothèques CUBLAS librairie Lapack Dongarra bénéficier bonnes performances calcul matriciel résultats version comparés version Linux Fedora prend compte temps calcul temps nécessaire lecture données version temps transfert compte temps calcul inférieur présenté incrémental parallèle focalise tests grands ensembles données comprenant ensembles données Forest Cover Adult tableau aussi grands ensembles données utilisant programme RingNorm dimensions classes millions individus Classes Individus Dimensions Protocole Adult 48842 32561 16281 Forest cover 581012 495141 45141 Ringnorm 1000000 1000000 100000 Ringnorm 10000000 10000000 1000000 Description ensembles données Temps Précision ratio Adult Forest cover Ringnorm Ringnorm Résultats classification avons abord découpés ensembles données petits blocs lignes version avons varier taille traité chaque étape algorithme points jusqu occuper toute mémoire disponible comparer temps nécessaire chaque étape classification meilleurs résultats obtenus petite taille utilisant mémoire secondaire disque ensembles données découpés blocs lignes assurer meilleures performances résultats classification versions algorithme incrémental parallèle présentés tableau version moyenne rapide version ensemble données Forest Cover avons essayé effectuer classification LibSVM après jours calcul avions toujours résultat Cependant résultats publiés récemment montré algorithme effectué classification ensemble données secondes processeur Intel signifie notre version algorithme environ rapide ensemble données contient données réseau indiquant connexion réseau normale classe négative constitue attaque classe positive LibSVM exécuter manque mémoire effectué classification ensemble données précision secondes Pentium 800MHz alors notre algorithme effectue classification précision seulement secondes avère rapide Poulet résultats numériques montrent efficacité notre algorithme classification grands ensembles données avons notre algorithme était incrémental aussi décrémental particulièrement adapté fouille données ajouter nouvelles données supprimer anciennes données modèle alors partir étape précédente ainsi possible avoir importe quelle fenêtre temporelle données calculer modèle correspondant Adult Forest Cover Types Ringnorm Ringnorm Temps exécution versions Domingos Hulten listés critères algorithme fouille données suivre pouvoir traiter efficacement grandes quantités données prendre faible temps constant individu notre algorithme complexité linéaire nombre individus utiliser quantité mémoire constante quelque quantité données traiter mémoire nécessaire notre algorithme déterminée taille capable construire modèle lisant données traite chaque individu permettre obtenir modèle données moment construire modèle faisant somme importe moment prenant compte données traitées produire modèle équivalent algorithme aurait contraintes résultat obtient exactement celui version originale séquentielle quand données évoluent cours temps pouvoir faire évoluer modèle garder trace changements notre algorithme incrémental décrémental suivre aisément changement Notre algorithme vérifie critères listés garantit pouvoir traiter incrémental parallèle aisément grandes quantités données Conclusion perspectives avons présenté nouvel algorithme incrémental parallèle classification grands ensembles données processeurs graphiques principale étendre manières algorithme proposé Suykens Wandewalle avons développé version incrémentale classification grands ensembles données Notre algorithme évite charger ensemble données mémoire instant ensemble données mémoire modèle mesure traitement avons ensuite développé version parallèle algorithme incrémental basée processeurs graphiques bénéficier bonnes performances faible avons évalué performances précision temps calcul ensembles données Delve résultats montrent version notre algorithme environ rapide version avons aussi comparé algorithmes référence LibSVM autres algorithmes récents Notre version environ rapide LibSVM précision similaire avons aussi appliqué méthode algorithmes proposés Mangasarian collègues Newton Mangasarian Lagrangian Mangasarian Musicant mêmes propriétés algorithme nouvelles implémentations algorithmes parallèles efficaces classification grands ensembles données avons seulement utilisé processeur graphique expérimentations temps exécution rapide algorithmes actuels LibSVM amélioration évidente immédiate consister utiliser simultanément plusieurs processeurs graphiques avons montré version Poulet temps calcul était divisé nombre machines utilisé propriété version utilise alors temps calcul divisé 10000 rapport algorithmes courants actuels signifie tâche classification nécessitait année calcul effectuée heure voire moins dernières cartes graphiques sorties trois rapides celle utilisée amélioration significative possibilités algorithmes classification ouvrir nouvelles applications fouille données autre explorer extension méthode algorithmes linéaires Références Asuncion Newman Repository Machine Learning Databases mlearn MLRepository Poulet Boser Guyon Vapnik Training Algorithm Optimal Margin Classifiers Annual Workshop Computational Learning Theory Pittsburgh Pennsylvania Cauwenberghs Poggio Incremental Decremental Support Vector Machine Learning Advances Neural Information Processing Systems Press Chang LIBSVM Library Support Vector Machines cjlin libsvm Delve evaluating learning valid experiments utoronto delve Poulet Classifying Billion Distributed Algorithm International Conference Computer Science Research Innovation Vision Future Vietnam Poulet Mining Large Datasets Visualization ICEIS Entreprise Information Systems Miami Poulet Towards Dimensional Mining Boosting Visualization Tools ICEIS Entreprise Information Systems Porto Portugal Domingos Hulten General Framework Mining Massive Streams Journal Computational Graphical Statistics Dongarra Walker Lapack design overview object oriented extensions performance linear algebra Supercomputing Press Mangasarian Incremental Support Vector Machine Classification Mining Arlington Virginia Golub Matrix Computations Hopkins University Press Balti Maryland Guyon Applications clopinet isabelle Projects Joachims Training Linear Linear SIGKDD Lyman Varian Swearingen Charles Jordan information berkeley research projects Mangasarian finite newton method classification problems Mining Institute Technical Report Computer Sciences Department Wisconsin Mangasarian Musicant Lagrangian Support Vector Machines Journal Machine Learning Research NVidia Programming Guide incrémental parallèle NVidia Cublas Cublas Library Platt Training Support Vector Machines Using Sequential Minimal Optimization Advances Kernel Methods Support Vector Learning Schoelkopf Burges Smola Poulet Mining Large Datasets Support Vector Machine Algorithms Enterprise Information Systems Filipe Hammoudi Piattini Kluwer Academic Publishers Suykens Vandewalle Least Squares Support Vector Machines Classifiers Neural Processing Letters Incremental Learning Support Vector Machines SIGKDD Diego Koller Support Vector Machine Active Learning Applications Classification Machine Learning Stanford Vapnik Nature Statistical Learning Theory Springer Verlag Wasson NVidia GeForce graphics processor Technical Report Hardware Explored Classifying large using hierarchical clusters SIGKDD Summary present parallel incremental Support Vector Machine algorithm classification large datasets graphics processing units kernel related methods shown build accurate models learning usually needs quadratic program large datasets requires large memory capacity extend recent Least Squares proposed Suykens Vandewalle building incremental parallel algorithm algorithm graphics processors performance Numerical results Delve dataset repositories showed parallel incremental algorithm using about times faster implementation significantly faster times state algorithms LibSVM