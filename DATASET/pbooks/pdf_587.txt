critère Bayésien évaluer robustesse règles classification Dominique Boullé Orange avenue Pierre Marzin 22307 Lannion Cédex prenom orange ftgroup Résumé utilisation règles classification modèles prédictifs étudiée dernières années forme simple interprétable règles motifs populaires classifieurs combinant règles classification intéressantes selon mesure intérêt offrent bonnes formances prédictions Cependant performances classifieurs pendent mesure intérêt confiance accroissement seuillage trivial cette mesure déterminer règles pertinentes facile montrer règles extraites individuellement robustes article proposons nouveau critère évaluer bustesse règles classification données Booléennes Notre critère approche Bayésienne proposons expression analytique probabilité règle connaissant données Ainsi règles probables robustes critère Bayésien permet alors identifier paramètre règles robustes parmi ensemble règles données Introduction règles association Agrawal certainement partie motifs étudiés fouille données données binaires règle association pression forme corps conséquent ensembles attributs Booléens Intuitivement sémantique lorsqu observé attributs alors souvent observé aussi attributs principal intérêt règle pouvoir inférence inductive effet maintenant observe attributs alors probablement aussi observer attributs Lorsque attribut classe parle alors règle classification règles classification semblent propices tâches prédiction puisque objet décrit attributs alors proba blement classe récentes avancées extraction motifs donné naissance nombreux classifieurs règles pionniers Bringmann ensemble méthodes connues interprétabi performantes terme prédiction tâches classification supervisée Toutefois identifier moins verrous critère Bayésien évaluer robustesse règles classification paramétrage seuillage mesure intérêt utilisée étape cruciale autant triviale dilemme connu seuil fréquence minimum élevé génère moins règles aussi faible couverture données souvent moins pouvoir discriminant classes problème autre seuil fréquence génère grand nombre règles parmi lesquelles certaines faible fréquence peuvent erronées dilemme persiste seuillage mesures intérêt telles confiance estimation probabilité accroissement permet identifier motifs émergents fréquents classe données infréquents reste effet seuils élevés confiance accroissement génèrent petit nombre règles classification presque pures rares voire erronées combinées seuil fréquence alors seuils génèrent beaucoup règles intérêt limité Ainsi trouver compromis entre seuil fréquence mesure intérêt trivial instabilité mesures intérêt ensembles règles permettent bonnes prédictions facile montrer règles forte confiance émergentes individuellement robustes figure comparons valeurs confiance accroissement apprentissage règles extraites breast Asuncion Newman voyons clairement valeurs mesures instables entre phase apprentissage Ainsi bonne règle selon mesures révéler mauvaise mesures permettent identifier règles robustes train breast ACLIKE min_freq strong class rules Identity Growth train frequent emerging patterns Identity train breast ACLIKE min_freq strong class rules Identity Comparaison valeurs confiance accroissement appren tissage règles classification apprentissage breast Lorsque alors corrélation positive classe article proposons critère Bayésien approche Boullé permet identifier règles robustes manière naturelle paramé trage aucun reste article organisé manière suivante section contexte rappelle concepts approche étendons approche règles classification définissons notre critère Bayésien section rapporte expérimentations valident notre approche section faisons entre notre approche plusieurs travaux connexes Enfin section conclut brièvement avant ouvrir autres perspectives travail Boullé règles classification règles Définitions données binaires ensemble ensemble attributs Booléens ensemble classes relation binaire telle indique objet contient attribut Chaque objet labellisé unique classe règle classification expression forme itemset ensemble attributs classe fréquence itemset fréquence confiance accroissement freqr freqr ensemble données restreint objets classe freqr dénote fréquence relative freqr premiers auteurs classification supervisée règles association estiment règle potentiellement intéressante fréquence confiance accroissement supérieurs seuils définir Comme définir seuils souvent seuils décidés arbitrairement génère grand nombre règles ensemble règles extraites alors sélectionné traitement tenant compte couverture redondance corrélation choisissant meilleures règles Toutefois certains traitements nécessitent paramétrages triviaux supplémentaires article proposons suivre approche évaluer pertinence règles classification approche appliquée regroupement valeurs Boullé discrétisation Boullé régression Boullé encore arbres décision Voisine compromis entre précision formation prédictive fournie modèle robustesse obtenir bonne ralisation modèle point modèle règle classification choisir meilleur modèle règle approche Bayésienne utilisée cherche maximiser probabilité posteriori modèle règle sachant données appliquant théorème Bayes considérant probabilité données constante problème donné revient maximiser expression probabilité priori règle prior vraisemblance probabilité conditionnelle données sachant modèle règle Ainsi règle maximi cette expression règle probable issue données problème Notre critère évaluation logarithme négatif appelons règle calculer proposons nouvelle définition règle classification basée hiérarchie paramètres identifient manière unique règle Standard Classification Model règle standard classification model définie manière unique attributs corps règle chaque attribut corps valeur partie corps distribution classes corps corps critère Bayésien évaluer robustesse règles classification derniers points définition étendent définition classique règles sification effet attribut valeurs identifiants possibles Cette notion rapproche règles négations attribut corps Antonie Zaïane règles rejoignent aussi notion règles distribution récemment introduite Jorge conséquent telles règles distribution proba bilité ensemble classes classe unique exemple suivant illustre points Exemple règle Décrire corps telle règle consiste choisir attributs constituent corps choisir leurs valeurs Notons dériver facilement règle classification négations utilisant classe grande probabilité exemple utilisons notations suivantes définition priori règle critère Notations données binaires objets attributs classes règle telle notons attributs corps index valeurs participent corps nombre objets cellule corps nombre objets dehors cellule corps nombre objets classe cellule nombre objets classe cellule priori hiérarchique appuyons distribution priori modèles règles suivante nombre attributs corps uniformément distribué nombre donné attributs chaque ensemble attributs corps équiprobable valeur attribut donnée participer corps équiprobables distributions classes corps corps équiprobables distributions classes corps corps indépendantes Grâce définition espace modèles distribution priori appliquons théorème Bayes exprimer probabilité priori modèle probabilité données sachant modèle probabilité priori modèle règle abord considérons probabilité avoir attributs corps Consi dérant premières hypothèses priori hiérarchique nombre combinaisons serait candidat prior toutefois terme combinatoire symétrique ajouter nouveaux attributs accroît probabilité sélection Ainsi ajout variables pertinentes favorisé effet significatif vraisem blance modèle Préférant règles simples suggérons utiliser nombre combinaisons remise avons Boullé chaque attribut corps valeur participant corps règle choisie Ainsi avons selon hypothèse priori hiérarhique Considérant hypothèses apriori hiérarchique dénombrer distributions classes corps réduit calcul combinatoire avons terme vraisemblance probabilité données sachant modèle probabi observer données corps règle respectivement objets étant donnée distribution multinomiale avons obtenons ainsi définition complète règle logNX logNXj règle défini logarithme négatif probabilités cette trans formation Shannon entre probabilités longueur codage Ainsi comme capacité règle coder classes fonction attributs première ligne correspond choix nombre attributs attributs valeurs parti cipant corps règle seconde ligne correspond choix distribution classes corps dernière ligne vraisemblance construction règle obtenons théorème suivant Théorème Considérant priori hiérarchique Bayes optimal minimal ensemble Intuitivement règles faible probables meilleures Notons moindre petit ligne règles simples petit corps probables préférées conséquent règles fréquentes probables fréquentes ailleurs notion pureté règles apparaît dernière ligne règles fortes aussi moindre meilleures Comme règle dépend taille données définissons notre critère évaluation appelé level comme normalisation level level interprété comme compression critère Bayésien évaluer robustesse règles classification règle défaut corps Intuitivement gueur codage classes lorsqu aucune information attributs utilisée manière formelle logNj Ainsi level alors probable règle défaut Lorsque level alors utiliser expliquer données coûteux utiliser autres termes alors moins probable règle défaut intéressante règles intéressantes mises évidence lorsque level probables règle défaut règles level level alors considérée comme meilleure probable Notons particulier level signifie seule suffit caractériser exactement distribution classes Validation expérimentale cette section montrons expérimentalement confiance croissement généralement stables phase apprentissage phase candidats capturer notion robustesse règles classi fication level contraire stable mêmes conditions expérience level permet identifier naturellement règles robustes intéressantes Protocole expérimental réalisons expériences Données Objets Attributs Classes distribution breast credit credit diabetes meningitis sonar Description bases données bases données données meningite François brève description reportée table expérience train consiste diviser données ensembles pectant distribution classes mière apprentissage extrac règles selon seuils donnés fréquence confiance accroissement deuxième évaluer évolution valeurs mesures calculons parons aussi valeurs level règles extraites apprentissage utilisons prototype AClike extraire règles fréquentes confiance AClike trait itemsets fréquents libres Boulicaut corps règles telle utilisons aussi prototype consepminer Zhang extraire motifs fréquents émergents Boullé Résultats raisons limitations pages lisibilité reportons uniquement résultats quatre bases données marquées table croissement Notons obtenons mêmes observations conclusions autres bases critère confiance Données originales graphiques figure reportons évolution train valeurs acroissement chaque données comparons aussi valeurs level règles extraites remarquons généralement instable effet règle accroissement apprentissage avoir faible points éloignés droite identité confirme notre hypothèse accroissement comme confiance capturent notion robustesse contraire valeurs level stables points proche identité premières expériences montrent risqué reposer confiance accroissement faire prédictions stabilité level signe bustesse suite montrons expérimentalement règles level négatif significatives alors celles level positif intéressantes Données bruitées simuler présence bruit classe données breast ajoutons manière uniforme bruit attribut classe changement classe utili fonction AddNoise Witten Frank utilisons niveaux bruit moyen renouvelons expérience train chaque version artificiellement bruitée résultats reportés figure chaque niveau bruit extracteurs classiques réussissent extraire motifs potentiellement intéressants notons beaucoup moins règles extraites contextes fortement bruités Cependant expérience train montre encore instabilité mesures classiques cette instabilité autant grande lorsque contexte bruité effet plupart points règles dessous droite identité indique accroissement comme confiance optimistes peuvent mener mauvaises prédictions level stable contextes bruités aussi Notons plupart règles toutes niveau bruit level négatif contextes bruités elles probables règle défaut statistiquement significatives intuitif suite montrons expérimentalement level positif évidence règles intéressantes Règles level positif graphiques figure reportons valeurs appren tissage mesure basée entropie classe différence entre entropies conditionnelles règle défaut règle grand intéressante aussi comme nombre sauvegardés lorsqu compresse données utilisant Comme prévu figure règles level positifs rouge généralement intéressantes fortes valeurs règles level négatif intéressantes obtiennent faible score gauche graphiques critère Bayésien évaluer robustesse règles classification Travaux connexes discussions Notre approche issue approche croisée théorie Bayésienne principe Minimum Description Length Grünwald complexité Kolmogorov Vitányi propos principe Siebes propose approche extraction motifs basée principe auteurs cherchent extraire itemsets fournissent bonne compression données entre probabilités longueurs codage permet auteurs réécrire longueur codage itemset Ainsi meilleurs itemsets codage court compressent mieux données Leeuwen extension classification supervisée proposée principales férences approche suivantes utilisation apriori hiérarchique implique codage différent Siebes cherchent ensemble motifs compressent données alors notre critère défini règle Notons récemment Suzuki utilise aussi principe intégrer connais sances domaine forme liste décision processus extraction règles longueur codage liste décision extraire données enrichi connaissances domaine considérée comme mesure intérêt subjective propos robustesse level Contingency table classification montré stable expérimentalement Ainsi pouvons appuyer règles level positif puisque térêt règles confirmé notion robustesse étudiée récemment suggèrent nouvelle notion robustesse dépendante mesure intérêt utilisée seuil cette mesure Partant observation règle caractérisée trois valeurs table contingence fréquence corps fréquence cible nombre contre exemples table auteurs définissent robustesse règle distance Euclidienne normalisée entre règle limite règle minimise Cette approche capture notion robustesse toutefois paramétrage trivial supplémentaire nécessaire seuil robustesse propos redondance règle classification redondante rapport pouvoir discriminant selon mesure intérêt règle redondante utile Soient itemsets alors mesure basée fréquence redondant regrouper itemsets support classes équivalence unique grand itemset selon clusion ensembliste appelé itemset fermé petits itemsets libres littérature classifieurs motifs Baralis Chiusano préfèrent itemsets libres raisons simplicité critère level itemset fermé itemset fermé classe équivalence alors Boullé puisque nombre attributs favorise formaliser théorème suivant Théorème Soient itemsets alors préférable selon critère level level level Conclusion perspectives article présentons nouveau critère Bayésien level évalua règles classification données binaires approche level propose solution faiblesses identifiées approches existantes basées cadre fréquence confiance accroissement paramétrage trivial seuils mesures intérêt stabilité mesures level favorise compromis entre cision généralisation permet identifier naturellement règles intéressantes robustes technique paramétrage expériences menées confirment pertinence robus tesse critère travail level utilisé traitement sélectionner règles robustes partir ensemble règles confiantes émergentes prochaine étape approche constructive extraire directement règles level positif comme approche adaptée attributs numériques catégoriels autre étape visera étendre cadre règles quantitatives considérant discrétisation groupement valeurs Références Agrawal Imielinski Swami Mining association rules between items large databases Proceedings SIGMOD Antonie Zaïane associative classifier based positive negative rules Asuncion Newman machine learning repository archive Baralis Chiusano Essential classification Transactions Database Systems Boulicaut Bykowski Rigotti condensed representation boolean approximation frequency queries Mining Knowledge Discovery Boullé bayes optimal approach partitioning values categorical attri butes Journal Machine Learning Research Boullé bayes optimal discretization method continuous attributes Machine Learning Motwani Silverstein Beyond market baskets Generalizing associa rules correlations SIGMOD Press Bringmann Nijssen Zimmermann Pattern based classification unifying perspective workshop located critère Bayésien évaluer robustesse règles classification Efficient mining emerging patterns discovering trends diffe rences Proceedings Press Zhang Classification aggregating emerging patterns Proceedings Volume Springer François Crémilleux Robert Demongeot MENINGE medical consul system child meningitis study series consecutive cases Artificial Intelli gence Medecine Grünwald minimum description length principle Press Boullé probabilistic approach regression optimal bayesian partitioning Journal Machine Learning Research Jorge Azevedo Pereira Distribution rules numeric attributes interest Meyer Lenca Lallich measure robustness association rules Volume Springer Vitányi Introduction Kolmogorov Complexity Applica tions edition Springer Accurate efficient classification based multiple class association rules Proceedings Computer Society Integrating classification association mining Proceedings Press Shannon mathematical theory communication System Technical Journal Siebes Vreeken Leeuwen compress Suzuki Negative encoding length subjective interestingness measure groups rules PAKDD Leeuwen Vreeken Siebes Compression picks matter Voisine Boullé critère évaluation bayésienne construc arbre décision Witten Frank Mining Practical machine learning tools niques edition Morgan Kaufmann Zhang Ramamohanarao Exploring constraints efficiently emerging patterns large dimensional datasets Summary paper suggest criterion evaluation classification rules robustness binary labeled criterion arises Bayesian approach propose expression probability given probable rules rules robust Bayesian criterion derived defined expression allows robust rules given rules without parameter tuning Boullé Growth train breast CONSEP min_freq min_GR frequent emerging patterns Identity Growth train CONSEP min_freq min_GR frequent emerging patterns Identity breast CONSEP min_freq min_GR train level CONSEP min_freq min_GR train level Growth train credit CONSEP min_freq min_GR frequent emerging patterns Identity Growth train meningite CONSEP min_freq min_GR frequent emerging patterns Identity credit CONSEP min_freq min_GR train level meningite CONSEP min_freq min_GR train level Comparaison valeurs level apprentissage valeurs instables entre apprentissage phase alors valeurs level stables points proches droite identité confirme robustesse critère critère Bayésien évaluer robustesse règles classification Growth train noisy20_breast CONSEP min_freq min_GR frequent emerging patterns Identity Growth train noisy50_breast CONSEP min_freq min_GR frequent emerging patterns Identity noisy20_breast CONSEP min_freq min_GR train level noisy50_breast CONSEP min_freq min_GR train level Comparaison valeurs level contexte bruité apprentis règles considérées comme intéressantes révèlent instables traduit level négatif train breast CONSEP min_freq min_GR level level Identity train CONSEP min_freq min_GR level level Identity train credit CONSEP min_freq min_GR level level Identity train meningite CONSEP min_freq min_GR level level Identity Comparaison valeurs règles émergentes apprentissage meilleures règles probables level positif rouge généralement localisées droite graphique alors règles robustes level négatif proches origine