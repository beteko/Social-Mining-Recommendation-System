E33Prédiction défauts arbres végétal Grenoblois préconisations futures plantations Yelen Kevin Dalleau Malika Smail Tabbone LORIA yelen loria LORIA Université Lorraine kevin dalleau loria LORIA Université Lorraine malika smail loria Résumé décrivons article notre réponse analyse exploratoire données abord permis comprendre distri butions différentes variables détecter fortes corrélations avons défini variables supplémentaires partir variables données Plusieurs algorithmes classification supervisée expérimentés pondre tâche numéro performances évaluées lidation croisée permis sélectionner meilleurs classifieurs label multi label Autant tâche label multi label meilleur classifieur dépasse références environ avons également exploré tâche numéro règles association recher chées autre données enrichi connaissances telles données climatiques pluviométrie température données taxonomiques domaine botanique famille ordre super ordre outre données géographiques cartographiques exploitées outil visualisation partie données arbres Introduction tâches Grenoble abordées première tâche prédiction visant prédire arbres présentent défauts problème classification supervisée premier temps données analysées assurer corpus apprentissage exploitable possible second temps quelques algorithmes classification sélectionnés testés évalués données seconde tâche quant meilleure connaissance ainsi évolution végétal Grenoble contributions proposées nombre trois prise compte données climatiques données classification nique arbres recherche règles association outil visualisation arboricole Grenoblois logiciel libre offrant implémentation principaux algorithmes classifi cation utilisé travail Witten Frank programmes complémentaires écrits principalement ingénierie données Prédiction défauts arboricoles préconisations Analyse exploratoire données données fournies constituent corpus composé instances arbres décrites attributs Certains attributs décrivent arbre DiamètreArbreÀUnMètre Année DePlantation Espèce Genre_Bota emplacement Adr_Secteur Trottoir Fréquenta tionCible coordonnées géographiques informations établies occasion diagnostics AnnéeRéalisationDiagnostic NoteDiagnostic AnnéeTravauxPréconisésDiag Remarques présence localisation défaut Défaut Collet Houppier Racine Tronc derniers attributs constituent informations classe prédire cadre première tâche Nettoyage typage données première phase consisté coder façon systématique absence valeurs chaînes vides caractères spéciaux retirés attribut Remarques deuxième phase porté typage données fonction nature logiciel détecte types attributs partir leurs valeurs attributs nominal représente catégorie numérique conversions effectuées améliorer exploitabilité corpus Ainsi attribut Adr_Secteur figure leurs nombres compris entre relation ordre particulière transformé attribut nominal variables classe Défaut Collet Houppier Racine Tronc valeurs binaires transformées attributs nominaux permet appliquer programmes classification variable DiamètreArbreÀUnMètre transformée tribut numérique considérant centre intervalle distribution figure valeurs variable PrioritéDeRenouvellement nominales départ codifiées forme intervalles exemple valeur moins transformée intervalle Secteurs géographiques Grenoble Suppression attributs redondants attribut identifiant façon unique arbre supprimé avant applica programmes classification variable Sous_Catégorie codifiant variable Sous_Catégorie_Description supprimée variables Code_Parent Code_Parent_Desc aussi redondantes décrivent arbre station parente laquelle rattaché variables supprimées corpus raisons nombre valeurs distinctes important autre information station arbre étant nature géographique redondante variables Adr_Secteur ainsi coord_x coord_y Création attributs supplémentaires attributs créés aggrégation chacun attributs corpus premier attribut appelé EvolutionJsqDiag différence entre stade développe initial arbre stade développement diagnostic Autrement reflète évolution arbre plantation jusqu diagnostic calcule façon suivante EvolutionJsqDiag StadeDeDéveloppement StadeDéveloppementDiag valeurs variables StadeDeDéveloppement StadeDévelopementDiag étant codifiées entiers correspondant respectivement valeurs arbre jeune arbre adulte arbre viellissant différence positive nulle négative correspond alors évolu positive constante négative développement arbre second attribut appelé NbAnnéesAvantProchainDiag également différence mesure nombre années nécessité moins importante prochain nostic conséquence éventuels défauts ayant endommagé arbre définit façon suivante NbAnnéesAvantProchainDiag AnnéeTravauxPréconisésDiag AnnéeRéalisationDiagnostic avons vérifié attributs supplémentaires contribuent prédiction exemple règles classification données section Structuration attribut textuel attribut Remarques comporte texte libre décrivant informations notées arbres techniciens botanistes diagnostics Malheureusement valeurs valeurs uniques concernant arbre attribut difficilement exploitable distinguons trois façons considérer attribut valeurs attribut laissées telles quelles valeurs attribut transformées vecteurs utilisant filtre StringToWordVector logiciel filtre dictionnaire formé contenus texte remarques fréquence apparition ayant fréquence apparition minimale notre ensuite transformés attributs Chacun attributs contenir chaque remarque valeur selon cette dernière contienne attribut Finalement variable Remarques supprimée corpus chaque remarque termes composant texte remarque calculés somme valeurs forme valeur attribut numérique représentant importance remarque selon méthode pondération remarques longues composées termes rares privilégiées Prédiction défauts arboricoles préconisations Retour qualité données Globalement données bonne qualité puisque avons repéré erreurs saisie incohérences Certains attributs valeurs manquantes constitue forcément problème lorsque programmes classification capables accomoder données manquantes Distribution valeurs variable DiamètreArbreÀUnMètre Choix meilleurs classifieurs label multi label Méthodologie corpus préparé expériences classification peuvent menées triques évaluation fournies classifieurs référence exactitude précision micro macro rappel micro macro avons considéré problème classification multi label comme quatre problèmes classification label Quelques algorithmes classification supervisée expérimentés selon trois configurations différentes correspondant manière gérer attribut Remarques avons choisi tester algorithmes quatre catégories différentes Méthodes ensemble méthodes ensemble classification semblent tinentes raison nombre important instances données difficulté tâche prédiction localisation défaut programmes RandomForest BoostM1 procédant bagging boosting utilisés Breiman Freund Schapire Méthodes produisant modèle classification explicite méthodes classification produisant modèle explicite arbre décision règles classification utilisées façon complémentaire permettre experts domaine comprendre façon prédiction attributs programmes utilisés Quinlan Cohen Méthodes bayésiennes méthodes bayésiennes étant généralement performantes programmes classification NaiveBayes BayesNet testés Méthodes instances méthode proches voisins programme considérée privilégie approche locale classification oppose construction modèle global recherché autres méthodes plupart programmes classification utilisés paramètres défaut préconisés logiciel tableau dessous récapitule choix faits lorsque AdaBoostM1 classifier RandomTree RandomTree breakTiesRandomly confidenceFactor minNo optimizations Paramètres modifiés Résultats figures dessous décrivent résultats trois expériences problèmes classification label multi label mesure moyenne harmonique précision rappel scores obtenus validation croisée comparés rapport scores référence fournis scores surlignés dépassent scores référence scores police grande représentent expérience meilleure valeur chaque catégorie score guise éléments explicites classification présentons texte quelques règles construites programme prédiction présence défaut arbre nombres entre parenthèses correspondent nombres instances corpus apprentissage lesquelles règle applique nombres prédictions erronées NoteDiagnostic Arbre Davenir Incertain AnnéeRéalisationDiagnostic Défaut PrioritéDeRenouvellement PrioritéDeRenouvellement Défaut PrioritéDeRenouvellement NoteDiagnostic Arbre Davenir Incertain néeRéalisationDiagnostic NbAnnéesAvantProchainDiag coord_y 4224826 76743 Défaut PrioritéDeRenouvellement NbAnnéesAvantProchainDiag coord_x 1914782 38638 NoteDiagnostic Arbre abattre Défaut Prédiction défauts arboricoles préconisations DiamètreArbreÀUnMètre Sous_Catégorie_Description Arbre despaces ouverts NbAnnéesAvantProchainDiag coord_x 1914220 45606 coord_x 1913201 16333 Défaut DiamètreArbreÀUnMètre NbAnnéesAvantProchainDiag Sous_Catégorie_Description Arbre despaces ouverts TravauxPréconisésDiag Taille Défaut Exactitude Précision Rappel mesure Référence Expérience BayesNet NaiveBayes RandomForest AdaBoostM1 Expérience BayesNet NaiveBayes RandomForest AdaBoostM1 Expérience BayesNet NaiveBayes RandomForest AdaBoostM1 Résultats expériences classification label Comparaison classifieurs expériences interprétations examen résultats quantitatifs différents classifieurs construits semblent montrer formances variables expériences amélioration meilleures performances troisième expérience laquelle attribut textuel Remarques analysés agrégés nombre Néanmoins performances différents classifieurs trois expériences restent proches avons besoin assurer différences simplement erreurs estimation avons réalisé Student apparié comparer valeurs chaque métrique obtenues chaque classifieur répétitions validations croisées tests appliqués métriques exactitude mesure comme aggrégation précision rappel intervalle confiance abord avons testé significativité différences obtenues algorithme Random Forest trois données correspondant trois expériences selon traitement réservé attribut textuel Remarques avons utilisé comme baseline données brutes traitement champ textuel Comme tableau indique algorithme RandomForest donne meilleurs résultats statistiquement significatifs données expériences exactitude mesure intervalle confiance considéré Micro Macro Précision Rappel mesure Précision Rappel mesure Référence Expérience BayesNet NaiveBayes RandomForest AdaBoostM1 Expérience BayesNet NaiveBayes RandomForest AdaBoostM1 Expérience BayesNet NaiveBayes RandomForest AdaBoostM1 Résultats expériences classification multi label avons ensuite comparé performances algorithmes étudiés données brutes expérience résultats consignés tableau confirment algorithme RandomForest sente meilleurs résultats statistiquement significatifs exactitude mesure intervalle confiance considéré autres algorithmes considérés constatons également tests statistiques meilleure estimation métriques mesure exactitude faite grâce répétition validations croisées fournit résultats favorables présentés section précédente obtenus seule validation croisée Prédiction défauts arboricoles préconisations expérience expérience expérience mesure Exactitude dégradation statistiquement significative Résultats expériences classification label algorithme RandomForest trois données premier données baseline Algorithme mesure Exactitude RandomForest BayesNet NaiveBayes AdaBoostM1 dégradation statistiquement significative Résultats expériences classification label comparer algorithme RandomForest baseline autres algorithmes classification multi label avons comparé chaque classe perfor mances termes courbe mesure algorithme RandomForest autres algorithmes résultats montrent également aucun algorithme améliore façon significative performances algorithme RandomForest méthode ensemble classifieurs RandomForest celle fournit meilleur modèle prédiction problèmes posés classifieurs utilisés réaliser prédictions ensemble treize attributs prédictifs défaut suivants Adr_Secteur AnnéeDePlantation AnnéeRéalisationDiagnostic AnnéeTravauxPréconisésDiag Diamè treArbreÀUnMètre NoteDiagnostic PrioritéDeRenouvellement StadeDeDéveloppement TravauxPré conisésDiag NbAnnéesAvantProchainDiag coord_x coord_y Analyses exploratoires données décision répondre seconde tâche avons exploré trois pistes première consiste données corpus données externes climatologiques botaniques vérifier permet réaliser meilleure prédiction défaut localisations arbre deuxième consiste rechercher combinaisons fréquentes voire associations défauts certaines carac téristiques arbres dernière consiste visualiser données corpus enrichies données urbaines aider décideurs comprendre certains phénomènes Apport données externes classification supervisée données climatiques agrégées chaque arbre période comprise entre plantation diagnostic données relatives pluviométrie température ensoleillement prevision meteo données intégrées corpus expériences refaites meilleurs classifieurs expérience résultats classification label multi label respectivement décrits figures constate lègère amélioration rappel mesure AdaBoostM1 détriment diminution précision classifieurs somme apport information prédiction présence défaut considéré comme prédiction localisation défaut valeurs mesure augmentent légèrement Finalement intérêt prise compte données climatiques certes minime présent Exactitude Précision Rappel mesure Expérience référence RandomForest AdaBoostM1 Expérience données climatiques RandomForest AdaBoostM1 Résultats classifications label prise compte données climatiques Micro Macro Précision Rappel mesure Précision Rappel mesure Expérience référence RandomForest AdaBoostM1 Expérience données climatiques RandomForest AdaBoostM1 Résultats classifications multi label prise compte données climatiques données classification botanique recherchées données accessible tropicos permis associer genres botaniques présents corpus trois propriétés famille ordre super ordre genres botaniques ainsi agrégés familles ordres super ordres Comme données climatiques meilleurs classifieurs expérience figures illustrent résultats obtenus constatons malgré baisse performances classification label classifieur AdaBoostM1 présente meilleures performances conclusion apport données taxonomiques semble clair probablement cause certaine redondance données corpus espèce genre nique variété Recherche associations intéressantes focalisant ensemble intéressant caractéristiques arbres avons voulu explorer possibles associations présentes données susceptibles aider décideurs rapport choix plantation avons recherché règles association grâce programme Apriori Agrawal Srikant présentons après quelques exemples règles association support relativement modeste présentant bonne confiance avons également Prédiction défauts arboricoles préconisations Exactitude Précision Rappel mesure Expérience référence RandomForest AdaBoostM1 Expérience données classification botanique RandomForest AdaBoostM1 Classifications label exploitant données classification botanique Micro Macro Précision Rappel mesure Précision Rappel mesure Expérience référence RandomForest AdaBoostM1 Expérience données classification botanique RandomForest AdaBoostM1 Classifications multi label exploitant données classification botanique calculé mesure définie comme rapport entre probalité jointe parties gauche droite produit probalités parties Rappelons supérieur traduit corrélation positive entre parties règle caractère significatif association ensemble règles présentées Adr_Secteur Genre_Bota Populus Trottoir Défaut Adr_Secteur Genre_Bota Populus Trottoir Défaut Genre_Bota Populus Trottoir Variété Italica Défaut Adr_Secteur Genre_Bota Platanus Sous_Catégorie_Description Arbre voirie Trottoir Collet Houppier Adr_Secteur Espèce acerifolia Genre_Bota Platanus Sous_Catégorie_Description Arbre voirie Trottoir Collet Houppier Genre_Bota Platanus Collet Houppier règles permettent suggérer hypothèses intéressantes valider études poussées Ainsi règles montrent probabilité peuplier présenter défaut sachant planté trottoir secteur forte règle montre probabilité défaut houppier platane touché collet planté comme arbre voirie secteur proximité trottoir forte certaines règles validées botanistes chargés plantations peuvent tenir compte exemple évitant mauvaises associations entre secteurs variétés botaniques Visualisation contexte urbain arbres leurs défauts arbres étant plantés environnement urbain divers facteurs pourraient expliquer certains types défaut outil visualisation développé permettre visualiser contexte urbain arbres corpus outil requiert fichier format comprenant lattitude longitude présence défaut ainsi localisation défaut collet houppier racine tronc outil permet sélectionner défaut nombre arbres présentant défaut nombre arbres présentant défaut arbres alors affichés carte ville Grenoble figure représente capture écran outil lequel représentés arbres défaut racine parmi arbres défaut Capture écran outil visualisation arbres présentant défaut racine parmi arbres défaut outil présente avantages agissant vraie carte régulièrement fournit interface réaliste permettant techniciens botanistes mieux cerner situation végétal système échantillonnage permet étudier phénomènes petite échelle possibilité zoomer permet considérer étendue géographique territoire manipulation outil exemple permis faire quelques constats intéressants arbres défaut niveau tronc nombreux proximité grandes voies routes avenues boulevards arbres défaut niveau racine nombreux proximité intersections voies arbres défaut houppier nombreux lieux fréquentation publique importante parcs aires autres utilisation pourraient enrichir outil visualisation utilisation mulaire servirait support saisie divers critères sélection arbres afficher developers google documentation javascript Prédiction défauts arboricoles préconisations Conclusion avons répondu testant différentes méthodes fouille données avons jugées pertinentes complémentaires exploitation données fournies cadre tâches classifieurs construits semblent assez précis amélioration performances rapport référence relativement modeste éléments connaissance extraits semblent susceptibles apporter décideurs certaine compréhension phénomènes dégradation arbres milieu urbain pensons outil visualisation arbres contexte urbain pourrait gagner intégrer autres utilisation suggérés experts Références Agrawal Srikant algorithms mining association rules large databases Bocca Jarke Zaniolo Proceedings International Conference Large Bases September Santiago Chile Chile Morgan Kaufmann Kibler Albert Instance based learning algorithms Machine Breiman Random forests Machine Learning Cohen effective induction Prieditis Russell Machine Learning Proceedings Twelfth International Conference Machine Learning Tahoe California Morgan Kaufmann Freund Schapire Experiments boosting algorithm Saitta Machine Learning Proceedings Thirteenth International Conference Italy Morgan Kaufmann Quinlan Programs Machine Learning Morgan Kaufmann Witten Frank Mining Practical Machine Learning Tools Techniques Second Edition Morgan Kaufmann examination categorization methods SIGIR Proceedings Annual International SIGIR Conference Research Development Information Retrieval August Berkeley Summary describe paper response Challenge Exploratory analysis first understand distribution variables detect strong correlations defined variables combining dataset variables Several classification algorithms experimented first challenge Performances evaluated cross validation resulted selecting unilabel multilabel classifiers unilabel multilabel levels classifier outperforms reference scores approximately explored second challenge association rules searched other initial dataset enriched domain knowledge climate rainfall temperature taxonomic field botany Furthermore geographical cartographic visualisation representing trees