Classification actions humaines basée descripteurs spatio temporels Sameh Megrhi Azeddine Beghdadi Wided Souidène Institut Galilée Université Paris Sorbonne Paris avenue Clément 93430 Villetaneuse France Résumé article proposons nouveau descripteur spatio temporel appelé analyse reconnaissance actions vidéo principale enrichir descripteur Speed Robust Feature intégrant information mouvement issue optique Seuls points intérêts déplacement compte générer dictionnaire visuels robuste algorithme moyennes means dictionnaire utilisé cessus apprentissage reconnaissance actions méthode machines vecteurs supports résultats obtenus confirment descripteur proposé analyse scènes particulier reconnaissance actions méthode atteind précision recon naissance ordre équivalente performances descripteurs spatio temporels Introduction stockage distribution travers média numériques particulièrement inter données visuelles atteignent proportions gigantesques accéléré lisation outils capture éditions données numériques telles vidéo audio Cette masse données différentes modalités représente information capitale étapes identification événements décision nécessaire développer solutions automatiques analyser contenus numériques problématiques suscitent beaucoup intérêt depuis quelques années détection reconnaissance actions humaines séquences vidéo appelle action évènement caractérisé mouvements comportements anormaux rencontre exemple vidéo surveillance Bouttefroy détection actions trouve nombreuses applications telles indexation vidéo surveillance résumé vidéos citer quelques contexte recon naissance action représentation descripteurs vidéo moyen dictionnaire visuels domaine recherche actif Willamowski grouper ensemble objets exemple descripteurs visuels groupes sorte objets soient groupe cluster cemment algorithme moyennes largement utilisé construire Classification actions humaines basée descripteurs spatio temporels raison hautes performances simplicité Chaque vidéo ensuite représentée distribution visuels distributions servent paramètres entrée cessus apprentissage issue duquel classification actions obtenue Cependant telle approche difficulté réside souvent recherche liens plausibles entre entités perceptuelles interprétation scène contexte considéré important trouver moyen définir descripteurs riches information surtout corrélés actions souhaite identifier classer extraire descripteurs vidéo Mojarrad utilisé descrip teurs relatifs régions corps humain moyennant quelques hypothèses souvent difficiles satisfaire éviter problèmes Dollár choisi extraire descrip teurs locaux détectant cuboïdes locaux cette méthode produit visuels basés quantification suivant principe proposé Csurka veine Laptev Lindeberg proposé descripteur Points intérêts spatio temporels détecter cuboïdes Néanmoins limites méthodes mentionnées dessus concernent seulement difficulté trouver taille optimale cuboïde aussi temps calcul élevé surmonter problèmes proposons descripteur spatio temporel descripteur local proposé descripteur ensuite étendu espace spatio temporel montrons périmentalement efficacité cette contribution détection actions humaines réaliste sport proposée Rodriguez Approche proposée reconnaissance actions points intérêt localisés détecteur hessien proposé Beaudet ensuite extraits partir intégralité vidéos aprentissage extraits regroupés utilisant algorithme clustering moyennes clips vidéo représentés forme histogrammes distributions visuels Enfin étape apprentissage réalisée machine vecteurs supports Extention descripteur domaine temporel extension descripteur domaine temporel effectuée estimant optique proposé deniers montré algorithmes calcul optique fondés étape filtrage médian permettent obtenir optique stable voisinage important article point intérêt défini position instant trame effectue déplacement suivant direction suivant celle devient toutes expériences mention contraire supposons raison segmentation vidéo ensemble trames selon méthode Megrhi trajectoires vecteurs mouvement stables parallèles points intérêts seront négligés ensemble trames forment volume espace volume parallélipipède Ainsi trames parallélépipède direction représente direction mouvement vecteur mouvement calculé chaque Notre contribution consiste utilisation orientation mouvement position Megrhi caractériser mouvement utiliser vecteur direction généré calcul optique supposons vecteur mouvement espace défini comme intersection plans perpendiculaires respectivement extraire orientation projetons vecteur mouvement plans définir angle chaque projection premier angle αxentre optique angle entre vecteur mouvement arctan arctan chaque vecteur mouvement projeté plans selon lignes supports notées projection orthogonale centre parallélipipède formé ensemble trames lignes permet calculer distances entre centre lignes supportant vecteurs mouvement obtient alors Πarctan Πarctan Πarctan Πarctan dimensions Parallélipipède varie fonction nombre trames segmentées décrivent distances déplace point intérêt donné figure illustre projection centre parallélipipède plans projection vecteur mouvement plans adjacents Extraction génération nouveau descripteur réalisée fusion concaténa descripteur local dimension paramètres décrivant position Classification actions humaines basée descripteurs spatio temporels orientation chaque vecteur générés quantifiés visuels utilisant algorithme moyennes Chaque quence vidéo alors représentée histogramme fréquence visuels togrammes occurrences visuels résultent utilisés comme entrées classifieur Résultats expérimentaux tableau comporte Meilleures Moyennes Précisions différents ensembles détecteurs descripteurs ainsi Précision Moyenne reportée utilisant détecteur Hessien obtenu précision utilisant descripteur utilisant effet descripteurs mouvement local donnés histogrammes flots optiques caractérisent mieux action histogrammes gradient orienté décrivent apparence locale utilisation combinaison améliore précision reconnaissance action effet reporté explique moins précis caractériser information temporelle extension domaine temporel permis atteindre utilisant HOG3D Gabor orientation spatiale descripteur décrit informations apparence orientation temporelle extraite renseigne vitesse mouvement précision reste dessous résultats réalisés Laptev utilisant combinaison HOG3D Gabor Ainsi adoptons hypothèse pourrait génération différents utilisation différents détecteurs points intérêt utilisant combinaison détecteur Hessien proposons donne meilleurs résultats atteint précision surpassant descripteurs locaux spatio temporels effet descripteur combinaison information spatiale donnée information temporelle dérivée optique HOG3D Précision moyenne différentes combinaisons détecteurs descripteurs appli quées sport matrice confusion relative sport donnée tableau notons descripteur proposé donne résultats satisfaisants vidéos réalistes soulignons précisions faibles obtenues actions skate mouvements actions horizontaux résultat améliore mesure actions contiennent mouvements verticaux comme présentent mouvements rotation importants précisions entre swing proches ressemblance entre actions ensemble résultats prouvent notre méthode équivalente montre performances satisfaisantes sinon meilleures autres méthodes utilisant configuration Megrhi Matrice confusion reconnaissance actions utilisant Conclusion article avons proposé nouveau descripteur spatio temporel extension descripteur local domaine temporel extraction descripteur consiste détecter projeter espace exploitation originale orientation optique position descripteurs extraits intégrés finalement classés actions réalistes sport outre proposé démontre performances reconnaissance prometteuses cette précision environ effet reparamétrage optique permis décrire orientation trajectoire région intérêt ainsi position volume spatio temporel exploitation information relative orientaion garantit riance rotation position région intérêt extraite améliorer optimiser classification précision Ainsi classification robuste décalages pixels peuvent aboutir visuels Ainsi utilisant région intérêt partir optique coordonnées point intérêts obtenons compact Enfin résultats obtenus démontrent viabilité notre approche prouve sommes équivalents performances données imaginons nombreuses perspectives avenir importante appliquer méthode vidéos contenant actions complexes prévoyons également améliorer notre envisageons combiner autres descripteurs niveau différentes modalités Références Tuytelaars Speeded robust features Computer Vision Springer Beaudet Rotationally invariant image operators Proceedings Interna tional Joint Conference Pattern Recognition Bouttefroy Beghdadi Bouzerdoum Phung Markov random fields abnormal behavior detection highways Visual Information Processing EUVIP European Workshop Classification actions humaines basée descripteurs spatio temporels Csurka Dance Willamowski Visual categorization keypoints Workshop statistical learning computer vision Dollár Rabaud Cottrell Belongie Behavior recognition sparse spatio temporal features International Workshop Visual Surveillance Performance Evaluation Tracking Surveillance Maybank survey visual surveillance object motion behaviors Systems Cybernetics Applications Reviews Transactions Laptev Lindeberg Local descriptors spatio temporal recognition Spatial Coherence Visual Motion Analysis Springer Megrhi Souidène Beghdadi Spatio temporal human action cognition Pacific Conference Multimedia Mojarrad Dezfouli Rahmani Feature extraction human composition images segmentation method World Academy Science Engineering Technology Rodriguez Ahmed Action spatio temporal maximum average correlation height filter action recognition Computer Vision Pattern Recognition Conference Black Secrets optical estimation their principles Conference onComputer Vision Pattern Recognition Ullah Klaser Laptev Schmid Evaluation spatio temporal features action recognition British Machine Vision Conference Willamowski Arregui Csurka Dance Categorizing visual classes using local appearance descriptors illumination Chung Keller Activity analy summarization visualization indoor human activity monitoring Circuits Systems Video Technology Transactions Summary paper introduce spatio temporal descriptor order efficiently describe video context human action recognition fusion Speed Robust Feature original parameterization optical Video sequences represented Visual words former video representation which train support vector Machine action recognition detection observe leads relevant action recognition rates sport dataset