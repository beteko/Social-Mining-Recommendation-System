Apprentissage progressif modèles facteurs latents prédiction attributs réseaux sociaux attributs Cécile Bothorel Pascal Cheung STICC Département LUSSI Télécom Bretagne letran cecile bothorel telecom bretagne orange duckinh letran pascal cheungmonchan orange Résumé article intéressons problème prédiction attributs noeuds réseau social plupart techniques existantes problème techniques apprentissage ligne appropriés situations données massives viennent comme médias sociaux travail utilisons modèles facteurs latents prédire attributs inconnus noeuds réseau social proposer méthode mettre progressivement modèle prévision arrivée nouvelles données expériences véritable données médias sociaux montrent notre méthode rapide garantir performances acceptables rapport techniques progressives Introduction énoncé problème explosion médias sociaux Internet cours dernières années exploitation minière contenu médias sociaux devenu critique nombreux domaines défis exploitation médias sociaux savoir comment tirer parti information relationnelle exemple amitiés interactions entre utilisateurs médias sociaux attributs simultanément exemple intérêts utilisateurs textuelles toute autre information supplémentaire autre réside médias fournissent vastes continus données utilisant techniques apprentissage ligne devons regrouper toutes données disponibles passé jusqu jours Cette approche convient cette situation parce nouvelles données viennent taille ensemble données développe deviennent apprendre appliquer modèle cette approche saisir dynamique données anciennes données données récentes traitées uniformément article abordons défis introduisant méthode apprentissage progressif tâche prédire attributs acteurs sociaux réseau social problème nombreuses applications monde exemple prédire intérêts passe temps utilisant médias sociaux utilisateurs construisons graphique interactions entre utilisateurs médias sociaux enrichir graphique attributs définis nœuds Comme données noeuds liens arrivent comme cours permanent voulons modèles construction prédire périodiquement attributs inconnus nœuds formuler notre problème adoptons réseau attribut social réseau attribut sociale contient réseau social ensemble apprentissage incrémental réseaux sociaux attributs noeuds ensemble arêtes graphe social complété graphe bipartite appelé graphe attribut reliant noeuds sociaux noeuds attribut bords liens sociaux bords liaison nœuds sociaux nœuds attributs liens attributs existe types attributs entre noeud sociale noeud attribut positif possède attribut négatif savons entre chaînon manquant sommes intéressés problème prédire attributs nœuds nature positif négatif maillons manquants graphe attributs contexte apprentissage progressif contexte chaque temps avons instantané représente ensemble données noeuds liens disponibles partir passé jusqu comparaison instantané précédent nouveaux nœuds nouveaux liens nouveaux nœuds peuvent noeuds sociaux noeuds attributs expériences considérons comme seuls nouveaux nœuds sociaux raison limitation ensemble données constitué nouveaux liens viennent ajouté temps contient composants réseaux premier composant instantané second composant formulons notre problème apprentissage progressif comme supposons avons construit modèle prédire attributs noeuds temps notre problème mettre modèle nouvelles données noeuds liens prédire attributs noeuds inconnus temps passons revue modèles latents facteur matrice factorisation apprentissage section proposer approche apprentissage progressif techniques section présentons résultats expérimentaux encourageants section Enfin section concluons point certaines orientations prometteuses travaux futurs modèle facteur Latent matrice factorisation Comme indiqué précédemment approche apprentissage proposé présent document inspiré modèles facteurs latents Bartholomew longtemps utilisés statistiques apprentissage machine modèle statistique représente chaque instance données ensemble variables latentes Matrice factorisation considéré comme procédé modélisation facteur latent lequel variables latentes continues décomposer matrice données dimensionnelle matrices dimensions inférieures techniques également étendues gérer plusieurs matrices Singh Gordon introduit matrice collective factorisation traiter données relationnelles lesquelles existe nombreux types entités nombreux types relations entre entités chaque relation représentée matrice relationnelle tente cartographier entités espace commun latent factoriser simultanément plusieurs matrices relationnelles notre contexte problèmes avons matrices matrice adjacente réseau social matrice attributs désigné valeur binaire indiquant attribut positif négatif Utilisation minimise uiuTj uipTk ensemble liens sociaux ensemble liens attributs matrice constituée vecteurs latents noeuds sociaux manière similaire matrice constituée vecteurs latents noeuds attribut paramètre permet régler importance relative réseau social modèle troisième terme régularisation pénaliser modèles complexes grandes amplitudes vecteurs latents paramètre régularisation Yeung proposé autre extension relation appelée matrice régularisé factorisation exploite simultanément graphe social graphe attribut réduisant minimum mêmes notations équation QRRMF uipTk factorisation matrice attribut terme ajout larization terme appelé terme régularisation relationnelle permet minimiser distances entre nœuds sociaux connectés espace latent approche suppose acteurs sociaux connectés tendance avoir profils similaires Apprentissage progressif modèles facteurs latents contexte apprentissage progressif définis section avons besoin apprendre modèle prédiction caractéristiques latentes nœuds chaque temps approche apprentissage suggère apprenions caractéristiques latentes chaque temps utilisant ensemble instantané fonctions objectifs définis dessus équation équation Différente méthode apprentissage Procédé remental apprend modèle partir nouvelles données savoir réutilisation ancien modèle latent caractéristiques nœuds calculés temps précédent faire minimisons fonction objectif suivant respectivement ensemble noeuds sociaux ensemble noeuds attribut temps précédent respectivement vecteurs latents noeud sociale noeud attribut appris temps précédent paramètre modèle Cette fonction objective compose termes premier terme fonction objective graphique incrémental deuxième terme terme régularisation minimiser changements caractéristiques latentes mêmes nœuds entre temps réduisant minimum termes temps apprenons caractéristiques latentes nœuds nouvelles données Apprentissage progressif réseaux sociaux attributs caractéristiques latentes noeuds existants temps précédent facilement caractéristiques latentes existant seulement nouveaux liens connectent paramètre permet régler contribution modèle précédent modèle actuel termes optimisation adaptons Alternance moins Squared algorithme minimizeQ équation apprentissage orQinc équation apprentissage progressif algorithme résoudre moindre problème carré rapport caractéristiques latentes jusqu convergence complexité algorithme dépend linéairement nombre termes carré fonction objectif nombre total noeuds nombre liens autres termes algorithme apprentissage complexité linéaire rapport taille données apprentissage progressif optimisation uniquement données récentes gagner beaucoup termes calcul expériences Dispositif expérimental ensemble données utilisé expériences BlogCatalog recueillie utilisée BlogCatalog blogueur indiquer liens autres blogueurs outre présentation nouveau blogueur précise catégories parmi ensemble catégories prédéfinies intérêts blogueur déduit catégories blogs ensemble données contient petite parties ensemble réseau 10312 blogueurs 333983 relations entre blogueurs catégories chaque blogueur moyenne catégories intérêt pouvons construire ensemble données blogueurs acteurs sociaux catégories attributs Étant donné avons données construisons instantanés artificiels partir ensemble données statiques tester notre méthode apprentissage progressif construisons instantanés temps notre expérience considérons ajout nouveaux nœuds sociaux chaque temps ensemble noeuds attribut choisissons abord noeuds sociaux totaux construire instantané partir noeuds liens liens sociaux liens attributs concernent chaque étape temps prenons hasard noeuds sociaux totaux seuls nœuds encore prises ajoutons nœuds sociaux leurs liens sociaux construire nouvel instantané propos liens attributs supposons attributs nouveaux nœuds inconnus jusqu prochaine étape Notre objectif prédire attributs inconnus noeuds méthodes supplémentaires incrémental incrémental chaque étape comparons méthodes apprentissage supplémentaires approche apprentissage utilisant ensemble instantané chaque temps Trois méthodes apprentissage utilisés comparer apprentissage autre méthode appelée dimension sociale SocialDim cette méthode transformer réseau social caractéristiques noeuds utilisant algorithme clustering graphe chaque groupe également appelé appelé dimension sociale respond caractéristique former classificateur discriminante soutien Vector machine Cortes Vapnik utilisant fonctions démontré SocialDim surclasse autres méthodes connu classification réseau mesurer performances différentes méthodes prévision utilisons courbe Bradley chaque temps calculée partir prédiction blogcatalog scores véritables étiquettes liens manquants mesurons également temps calcul chaque méthode montrer empirique complexité notre méthode incrémentale propos choix paramètres avons observé performances méthodes relativement stables changements apprentissage apprentissage progressif avons produire résultats représentatifs chaque méthode notre expérience nombre facteurs latents laquelle atteignent leurs performances stables maximales Expérience résultats Temps étape SocialDim Batch incrémental incrémental temps Batch Batch SocialDim Batch incrémental Incremental temps apprentissage Performance temps apprentissage apprentissage progressif rapport apprentissage effectuons courses traçons moyenne chaque méthode chaque temps figure observons techniques apprentissage supplémentaires peuvent donner meilleures performances méthodes apprentissage toutes étapes temps Cette observation prévu cadre expérimental données Cependant donnent presque mêmes performances apprentissage apprentissage progressif différence dépasse autres termes pouvons apprendre progressivement modèle prédiction apprentissage partir aucune perte significative performances Lorsque compare voyons clairement mieux pouvons également performances techniques apprentissage supplémentaires éloignées celles méthode référence SocialDim différence figure montre temps apprentissage secondes chaque procédé testé juste toutes méthodes mises œuvre exécutées Matlab machine techniques apprentissage supplémentaires besoin apprendre modèle prédiction étape temps alors techniques apprentissage besoin cette étape étapes suivantes temps techniques supplémentaires toujours beaucoup petit temps apprentissage celui méthodes apprentissage apprentissage temps apprentissage augmente rapidement après chaque temps temps apprentissage SocialDim augmente moins rapidement celle encore rapport méthodes incrémentielles incrémental apprentissage réseaux sociaux attributs Conclusion Motivé défis exploitation minière médias sociaux avons proposé méthode apprentissage progressif alternatives inspirés testés problème prédiction attributs supplémentaires réseau social Notre algorithme apprentissage atteindre performances relativement bonnes rapport méthode référence basée dimension sociale méthode classification incrémentale travaux futurs allons tester notre approche progressive données réelles ruisseaux espérons notre méthode apprentissage progressif capturer dynamique données donner meilleures performances apprentissage considérons également extensions possibles modèles traiter données complexes médias sociaux exemple envisager autres types noeuds liens inclure attributs bords traiter liens dirigés Références Bartholomew Knott Moustaki Modèles variables Latent analyse factorielle approche unifiée Série Wiley Probabilités statistiques Wiley Bradley utilisation courbe évaluation algorithmes apprentissage machine Motif reconna Cortes Vapnik réseaux soutien vecteur apprentissage machine Yeung Relation régularisée matrice factorisation IJCAI IJCAI Morgan Kaufmann Publishers Singh Gordon apprentissage relationnel factorisation matrice collective procédant SIGKDD numéro Tirer parti réseaux médias sociaux classification Mining Knowledge Discovery Gupta Weninger cadre unifié mandation utilisant Walks Recom hasard ASONAM Computer Society Wilkinson Schreiber grande échelle parallèle filtrage collaboratif Netflix Actes conférence internationale aspects rithmic information gestion Springer Verlag travail intéressons Problème attributes prédiction Nœuds réseau social Plupart techniques ligne Adaptées situations where Données Arrivent massivement Comme médias sociaux travail utilisons variables Latentes Modèles versent tributs prédire Inconnus Nœuds réseau sociale proposer méthode verser incrémentalement Mettre modèle nouvelles Données questions Expérimentations médias sociaux Données montrent notre méthode couteuse temps Moins calculation performances ACCEPTABLES garantir techniques comparaison incrementales