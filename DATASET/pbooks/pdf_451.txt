Combinaison classification supervisée supervisée théorie fonctions croyance Fatma Karem Mounir Dhibi Arnaud Martin Unité Recherche Campus Universitaire Zarouk Gafsa Tunisie fatoumacy yahoo mounir dhibi ensta bretagne Université Rennes IRISA Edouard Branly 30219 22302 Lannion Cedex France Arnaud Martin rennes1 Résumé proposons article nouvelle approche classifica fondée théorie fonctions croyance Cette méthode repose fusion entre classification supervisée classification supervisée effet sommes problème manque données apprentissage applications résultats classification supervisée pervisée variables selon classificateurs employés résultats ainsi obtenus conséquent considérés comme incertains Notre approche propose combiner résultats types classifica exploitant complémentarité théorie fonctions croyance Celle permet tenir compte aspect incertitude imprécision Après avoir dresser différentes étapes notre nouveau schéma classification détaillons fusion classificateurs Cette nouvelle approche appli données génériques issues vingtaine bases données résultats obtenus montré efficacité approche proposée Introduction classification moyen utile organisation hiérarchisation données classification supervisée trouver groupes compacts séparés ensemble données affecter chaque observation étiquette classe matérialise appartenance celle classes dégagées souhaite pouvoir lement affecter toute nouvelle observation étiquette Cette situation rencontrée classification supervisée puisque observations disponibles étiquetées atteindre affecter nouvelle observation classe préexistante apprise données apprentissage problème contexte classification supervisée difficile puisqu aucune information fournie appartenance données telle telle classe Cette appartenance généralement déduite partir répartition spatiale points expliquée Campedel Indépendamment classification choix Combinaison crédibiliste classification supervisée supervisée méthode toujours problème donné effet existe approche timale importe données approche choisie résultats dépendants paramétrage souvent nécessaire méthode supervisé données apprentissage représentent toujours parfaitement réalité données question dégrader résultats classification particulier classes retenues apprentissage classification supervisée toujours pertinentes effet arriver classes soient oubliées encore étiquetage mauvaises conditions permettant distinction classes intéressantes classification supervisée positionnant problème puisqu déter classes venir classification supervisée confirmer infirmer choix classes initiales proposer classification classes ayant solution envisagée alors fusionner résultats donnés classification super visée supervisée tirer profit types méthodes répondre problème résultats types classification peuvent ainsi système fusion comme données hétérogènes imprécises incertaines combinaison offre conséquent utilisateur compromis entre méthodes précédents travaux réalisés fusion classifications concernent types fusion classifications supervisées exemple proposée restier Gançarski Gançarski Wemmert Wemmert Gançarski Masson Denœux supervisées exemple proposée Martin approches fusion classifications supervisés restent délicates absence information labels classes remarque aussi fusion entre supervisé supervisé réalisée propre classification supervisé était déployé faire apprentissage supervisé Guijarro Pajares Urszula Switek Prudent Ennaji article propose approche fusion améliorer résultats sification supervisée fondée théorie fonctions croyance Celle offre cadre théorique solide modéliser aspects incertitude imprécision notre problème classification permet gérer conflits entre approches supervisées supervisées effet modélise croyance évènement fonction appelée fonction masse travaille espace étendu hypothèses englobe toutes jonctions intersections possibles cadre discernement retenu section présentera classification supervisée supervisée section décrivons fusion informations cadre théorie fonctions croyance section mettons accent approche proposée finira étude expérimentale section Classification objectif classification identifier classes auxquelles appartiennent objets partir traits descriptifs attributs caractéristiques distingue essentiellement types classification supervisée supervisée Karem Classification supervisée Cette classification aussi appelée classification automatique clustering encore regroupement classification amené identifier populations ensemble données suppose dispose ensemble objets caractérisé ensemble descripteurs objectif cluste trouver groupes auxquels appartiennent chaque objet revient déterminer fonction notée associe chaque plusieurs éléments pouvoir affecter nouvelle observation classe observations disponibles initialement identifiées comme apparte telle telle population absence étiquette classe lourd handicap partiellement surmontable Seule analyse répartition spatiale observations permettre deviner véritables classes difficultés essentielles rencontre classification supervisée suivantes naturel reconnaître comme appartenant classe observations regroupées forte densité zones faible densité particulier attendre définition frontières entre classes sujette caution moins hasardeuse humain extraordinaire outil classification supervisée Malheureuse opérationnel données bidimensionnelles alors rencontre analyste couramment décrites dizaines variables avère reproduire performances humain espaces grande dimension exploit aujourd atteinte machines Parmi méthodes supervisées utilisées citons types approches centres mobiles means classification hiérarchique Classification supervisée contexte supervisé dispose exemples classe connue quetée données associées labels classes notés objectif alors apprendre modèle apprentissage règles permettent prédire classe nouvelles observations revient déterminer fonction partir descripteurs objet associe classe pouvoir aussi affecter toute nouvelle observation classe parmi classes disponibles revient trouver fonction associe chaque élément élément construit alors modèle classer nouvelles données Parmi méthodes supervisées proches voisins arbres décision réseaux neurones machines support vecteurs classificateurs Bayes Quelque classification confronté différents problèmes supervisé problème important manque données réaliser appren tissage disponibilité données inadéquates exemple incertaines imprécises empêche construction modèle correct classification supervisée délimi tation frontières entre classes toujours franche reconnaissable Indépendam classification données multi dimensionnelles encore dépendance méthodes classification paramètres initiaux comme nombre classes peuvent poser problèmes mesurer performance approches cherche trouver critères Combinaison crédibiliste classification supervisée supervisée qualité résultats Généralement avons recours indices appelle dices validité choisir indice adéquat données indice standard article proposons nouvelle approche surmonter problèmes classification Celle fondée fusion entre classification supervisée pervisée cadre cette fusion fondé théorie fonctions croyance présentons section suivante Fusion informations cadre théorie tions croyance fusion données informations faite selon niveaux processus classification données caractéristiques décisions concentrons troisième niveau approches fusion informations essentiellement fondées théories incertain modéliser finement imprécisions incertitudes Parmi celles théorie probabilités offre modélisation incertitude théorie ensembles flous imprécisions théorie fonctions croyance intéresse travail permet modélisation théorie fonctions croyance Dempster Shafer permet représenter imprécision incertitude travers fonctions fonction crédibilité fonction plausibilité fonctions dérivées fonctions masses définies ensembles single comme théorie probabilités permettant tenir compte imprécisions désigne fonction masse relative source définie valeur vérifiant contrainte suivante ensemble disjonctions possibles décisions classes notre contexte classification exemple décisions doivent exclusives nécessairement exhaustives choix fonction masse délicat Plusieurs approches proposées citons approches fondée modèle probabiliste Appriou autre trans formation distance Denœux fonction crédibilité donnée fonctions plausibilité représentent intensité laquelle doute donnée Karem complémentaire Plusieurs modes combinaison développés cadre théorie tions croyance importants combinaison conjonctive combinaison jonctive déclinées grand nombre opérateurs combinaison binaisons mixtes donne exemple combinaison conjonctive introduite Dempster reprise Shafer combine fonctions masse considérant intersections éléments comme rappelé Martin écrit façon générale fonctions masses obtient masses relatives chaque élément cadre discernement issue combinaison différentes sources alors calculer fonctions croyance plausibilité dernière étape reste celle prise décision choix décision disjonction choix faire maximisation critère critères multiples fondent essentiellement fonctions plausibilité crédibilité citons trois critères maximum plausibilité maximum crédibilité probabilité pignistique premier critère prend singleton donnant maximum plausibilité observation décidons critère optimiste puisque plausibilité singleton représente croyance aurions toutes masses disjonctions incluant étaient focalisées gleton deuxième critère choisit observation donne maximum crédibilité critère applicable seulement combinaison porte seulement singletons rarement rencontré sélectif précédent effet fonction crédibilité fournit croyance minimale décision celle obtenue toutes masses disjonctions incluant étaient focalisées cette décision autres compromis entre maximum plausibilité maximum crédibilité celui probabilité pignistique approche couple crédibilité plausibilité équirépartissant masses placées éléments différents singleton singletons composent Ainsi décision probabilité pignistique définie représente cardinal Ainsi critère maximum probabilité pignistique revient décider observation Combinaison crédibiliste classification supervisée supervisée critère conforme notion masse emploie contexte probabiliste présentons approche menée article Fusion crédibiliste classification supervisée supervisée plupart travaux réalisés fusion concernent classification supervi exemple Forestier Gançarski combinaison faite travers collaboration classifieurs processus compose trois étapes exécution initiale rallèle classifieurs raffinement résultats unification résultats seconde étape converger différentes classifications résolution conflits existants convergence faite grâce recherche conflits entre différentes classifications recherche faite résultats cherche correspondance entre classes clusters mesure similarité conflit entre résultats niveau quelques clusters résout fusion division résolutions conflits peuvent néfastes résultat global converger résultat contient seule classe englobe pixels image exemple consé quent choisit résolutions améliorent résultat global raffinement terminé fusionne classifications méthode fusion classification supervisée travail Martin comparaison faite entre plusieurs méthodes fusion classification images sonar décrites méthodes analyse texture fonds marins présentent zones sédiments homogènes peuvent apparenter textures carac térisation fonds marins problème difficile inexactitude appareils mesures multitude méthodes analyse solution choisie était fusionner classifieurs derniers composés perceptron multicouche approches traction texture fusion informations niveau niveau sorties numériques perceptrons sorties correspondant classes question valeur niveau sorties symboliques représentant classes affectées fusion était testée méthode approche possibiliste approche crédibiliste testée modèles distance probabilité calcul masses mentionner théorie fonctions croyance donne meilleurs résultats Concernant fusion types classification supervisée supervisée proches développées essentiellement utilisées déployer supervisé faire apprentissage supervisé Guijarro Pajares Urszula Switek Guijarro Pajares combinaison faite grâce approche décision floue multi critère Fuzzy multicriteria decision making approach fonctionnement nouveau classifieur selon étapes apprentissage classification Durant apprentis partition optimale construite partir données apprentissage partition nement grâce clustering nombre clusters automati quement jusqu tomber nombre optimal clusters validation partition grâce critère inertie intra classe somme erreurs carrées critère question Karem normalisé obtenir valeur comprise entre partition optimale trouvée nombre optimal classes ensembles passe estimation paramètres classifieurs restants Chacun classifieurs reçoit centres initiaux obtenus partition validée tenant compte nombre optimal clusters trouvé paramètres estimés classifieurs stockés Ensuite passe estimation compétences chacun calcule somme normalisée erreurs carrées certains calcule autres critère variance minimale relative Related minimum variance criteria obtient conséquent compétences chaque classifieur tenant compte ensembles nombre estimé clusters finie étape apprentissage passe classification chercher quelles classes appartiennent nouveaux vecteurs décision prise grâce binaison supports fournis chacun classifieurs leurs compétences travers méthodologie floue multi critères garde toujours nombre classes approche question considère critères bénéfice Critère1 Critère2 appli quant chacun certains classifieurs Critère1 tient compte degrés flous appartenance clusters probabilités sachant clusters existants utilisant fonctions densité probabilité critère Critère2 utilise distance euclidienne chacun centres calculés critères chacun seront pondérés poids tiennent compte performances classifieurs calculés étape apprentissage procède après construction table décisions performances normalisées tient compte critères Critère1 Critère2 calculés classifieurs question classes dégagées phase apprentissage sélectionne meilleure alternative vecteur classe parmi celles dégagées approche était appliquée images naturelles texturées images multi spectrales prises région Espagne approche menée article fusionne classifications améliorer résultat compose étapes principales première consiste appliquer sification supervisée supervisée séparément données seconde étape consiste fusionner résultats issus méthodes Ayant comme entrées notre processus fusion résultats issus sources différentes essaie mesurer précision chaque résultat théorie fonctions croyance calculer fonctions masses associées chacun premier obstacle rencontré choix modèle adéquat fonctions masses adoptera essentiellement modèle probabiliste Appriou choix simplicité usage probabilités fusion décisions singletons effet choix porté modèle distance rencontrait problème choix meilleure métrique dispose sources fournissant fonctions masses Chacune donne mesures relativement chaque observation objet chacun éléments cadre discernement ignorance composée ensemble classes construction fonctions masse classifieur supervisé utilisons modèle Appriou classification supervisée donne label observation avons fonctions masse suivantes éléments focaux αijRip Combinaison crédibiliste classification supervisée supervisée désigne classe réelle coefficient fiabilité classification pervisée classe probabilités conditionnelles estimées partir matrice confusion maxql supervisé censé octroyer masses classes question ignore supervisé sorties clustering clusters octroie masses alors mesurant similarités entre clusters classes similarité estimée calcul distances entre clusters classes calcul recouvrement entre effet distance entre renseigne parfaitement similarité entre avoir couples classes cluster classe ayant distance séparent séparées façon Généralement calcul mesure distance séparant centres classes surmonter blème calcule recouvrement classe considérée comme similaire cluster réciproquement recouverte totalité celui éléments commun similaire faire cherchera proportions classes chaque cluster Gançarski Wemmert Forestier Gançarski regroupements trouvés définissons fonctions masse affaiblit suite masses coefficient affaiblissement dépend points Ainsi affaiblir façon points point situé centre cluster considère comme représentant cluster question point situé frontière défini centre cluster masses calculées fusionner règle Dempster adopte comme critère décision maximum probabilité pignistique cherche notre problème singletons connus emploi classification supervisée Chaque pixel affecté classe précise Karem Etude expérimentale donnons cette section résultats obtenus notre approche fusion entre classification supervisée classification supervisée avons réalisé notre étude expérimentale différentes données issues bases données génériques objectif montrer performance méthode proposée conséquent fusion classification Notre expérience fondée trois méthodes supervisées means modèle mélange méthode supervisée proches voisins testée différentes valeurs allant commençons présenter bases montrons tableaux bonne classification trouvés bases données avant après fusion respectivement Kmeans modèle mélange Description bases données travail avons utilisés plusieurs types données données populaire domaine reconnaissance formes contient classes échantillons chacun Chaque classe réfère plante classe linéairement séparable autres autres linéairement séparables Haberman contient étude conduite entre versité Chicago étude survie patients opération chirurgicale cancer contient instances objectif cherché trouver status survie patient vivre mourir durant sensor readings contient mesures capteurs suivant gation robot mobile objectif dégager différentes directions prises robot aller droit tourner gauche droite échantillons tribués comme première classe contient échantillons deuxième classe contient échantillons troisième classe échantillons quatrième classe échantillons Expérimentation fixation nombre clusters testé nombre classes donné supervisé dépend utilisateur refixer validons notre travail méthode validation croisée itérons processus variant chaque ensemble apprentissage ensemble effet fusion remarquable niveau premier tableau effet atteint données sensor readings4 supérieur donnée Haberman abalone tableau sensor readings4 proche autres Combinaison crédibiliste classification supervisée supervisée Données Sensor readings Habeman Abalone Résultats obtenus nombre classes nombre clusters testé Nombre attributs bonne classification avant fusion bonne classification après fusion Données Sensor readings Habeman Abalone Résultats obtenus Kmeans nombre classes nombre clusters testé Nombre dattributs bonne classification avant fusion bonne classification après fusion Conclusion article propose nouvelle approche permettant fusion résultats classifica supervisée supervisée Cette approche originale fondée théorie fonctions croyance permet lever certaines ambiguïtés gérer conflits Chacune classifications supervisée supervisée montrent limites soient niveau méthodes niveau données testées approche proposée montré résultats courageants données génériques présent travail bases données complètes Celui étendu élargissement données envisagerait faire bases comprenant erreurs étiquettage envisagerons aussi images réelles telles images sonar images médicales ainsi approfondissement processus fusion autres méthodes Références Appriou Décision Reconnaissance formes signal chapitre Discrimination multisignal théorie évidence France Hermes Science Publication Campedel Classification supervisée Technical report Telecom Paris Denœux nearest neighbor classification based dempster shafer theory Transactions Systems Cybernetics Karem Données Sensor readings Habeman Abalone Résultats obtenus Modèle mélange nombre classes nombre clusters testé Nombre dattributs bonne classification avant fusion bonne classification après fusion Forestier Wemmert Gançarski Multisource images analysis using collabo rative clustering EURASIP Journal Advances Signal Processing Gançarski Wemmert Collaborative multi strategy classification application pixel analysis images Proceedings international workshop Multimedia mining mining integrated media complex Volume Guijarro Pajares combining classifiers through fuzzy ticriteria decision making approach Applied natural textured images Expert Systems Appli cation Martin Comparative study information fusion methods sonar images sification Proceeding International Conference Information Fusion Volume Martin conflit théorie fonctions croyance 10ème journées Francophones Extraction Gestion Connaissances Masson Denœux Clustering interval valued proximity using belief functions Pattern Recognition Clustering interval valued proximity using belief tions Masson Denœux Ensemble clustering belief functions framework International Journal Approximate Reasoning Prudent Ennaji Clustering incrémental apprentissage distribué système évolutif robuste Conférence Volume Urszula Switek Combined unsupervised supervised classification method Proceedings International Conference Knowledge Based Intelligent Information Engineering Systems Volume Wemmert Gançarski multi voting method combine pervised classifications Proceedings IASTED International Conference Artificial Intelligence Applications Volume Krzyzak Methods combining multiple classifiers their applica tions handwriting recognition Transactions Systems Cybernetics Combinaison crédibiliste classification supervisée supervisée Summary paper propose classification approach latter based fusion tween clustering classification types present limits dependance rameters learning availability uncertain mentioned drawbacks leads uncertain results approach combine results classification types using their complementarity throw belief functions theory treats aspects uncertainty imprecision present paper classification scheme After analyse fusion process approach applied generic issued twenty databases results usefulness proposed method