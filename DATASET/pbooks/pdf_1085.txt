approche multi agent adaptative simulation schémas tactiques aydano machado chevaleyre daniel zucker laboratoire informatique paris université paris boîte place jussieu 75252 paris cedex aydano machado daniel zucker poleia machado zucker lamsade université paris dauphine place maréchal lattre tassigny 75775 paris chevaleyre lamsade dauphine lamsade dauphine chevaley résumé papier consacré simulation réalisation automatique schémas tactiques groupe agents footballeurs autonomes jectif montrer peuvent apporter techniques apprentissage renforcement agents réactifs conçus cette tâche temps proposons plateforme architecture agents effectuer schémas tactiques relativement simples suite mettons œuvre algorithme apprentissage renforcement permettre agents faire situations complexes enfin série expérimentations montrent apporté agents réactifs utilisation algorithmes apprentissage introduction domaine sports équipe entraîneurs appel informatiques durant activité pédagogique particulier logiciels simulation enseigner joueurs améliorer tactique jusqu présent logiciels mettaient essentiellement entraîneur faire déplacer écran agents joueurs nécessitaient spécifier quasiment trame trame position agents entraîneur souhaitant montrer déploiement schéma tactique particulier effectuer important travail avant simulation puisse lancée rendre agents autonomes améliorer réalisme comportement capacité prendre décision allégerait travail entraîneur permettrait avoir spécifier schémas tactiques relativement abstrait comment agents joueurs déploieraient schéma intelligemment terrain notre objectif utiliser diverses techniques intelligence artificielle liorer autonomie agents devant déployer schéma spécifié entraîneur cette tâche considéré comme ensemble problème simulation sportive approche multi agent adaptative simulation schémas tactiques exemple robocup agents voient indiqués route suivre schéma tactique doivent pouvoir dévier croisent adversaire prend balle premier temps système multi agents construit lequel agents suivent comportement décrit règle avons montré quelques schémas comportements obtenus étaient parfois insuffisants agents autorisaient dévier suffisamment indications entraîneur faire adversaire ensuite avons implémenté algorithme apprentissage renforce permis agents comporter correctement échouaient système règles enfin avons plateforme logicielle intégrant différents algorithmes permettant entraîneur faire simulations aisément papier après avoir introduit schémas tactiques présentons essentielle résultats expérimentations algorithme apprentissage renforcement comparons différents schémas performances agents basés montrons particulier apprentissage converge rapidement malgré mension importante problème simulation schémas tactiques regardant sujet question avons trouvé principaux outils commerciaux travaux scientifiques représentants premier destinés professionnels football traitent effectivement schémas tactiques proposent solution simple déploie schéma tactique animation séquence positions prédéfinies utilisant techniques interpolation images objets trajec toire rectiligne entre positions successives résultat final animation qualité dépend intervalle entre chaque image intervalle augmente fiabi diminue cette approche laisse travail fastidieux répétitif utilisateur gramme prévoir décrire détail déplacement objets chaque instant particulier changement présente travail refaire robocup grand représentant deuxième projet pération international destiné encourager développement intelligence artificielle robotique autres domaines connexes point systèmes multi agents modèle footballistique robocup intéressant regroupe plusieurs caractéristiques environnement évolue dynamiquement nécessité agents communiquer coordonner attein leurs objectifs actuellement existe encore équipe utilisant déploiement schémas tacti joueurs football équipes suffisamment problèmes résoudre contraintes définitions imposées modèle question proposons solution inscrit premier professionnels sport simulation schémas tactiques comme robocup toutes contraintes déterminations avons utilisation méthodes apprentissage automatique conception agents évitant ainsi tâche complexe programmer comportements joueurs dotés faculté apprendre agents machado gagneront autonomie seront capables adapter adversaire environ nement entraînant agents jouer certains schémas tactiques entraîneur pourra velopper agents aptitudes particulières liées schémas exemple pourra créer défenseur mettant agent joueur attaquants ballon objectif apprendre récupérer ballon algorithme apprentissage avons choisi apprentissage renforcement parce agent apprend raction environnement avoir besoin exemples sections suivantes définirons récompenses agent devra découvrir processus essais erreurs action optimale effectuer chacune situations maximiser récompenses sutton modéliser problème utilisant apprentissage renforcement poser questions suivantes quelles actions peuvent effectuées agents quelle représentation environnement employer quelles récompenses donner espaces actions concerne espace avons choisi représentation basée distances comportements agents dépendent positions relatives rapport autres position absolue terrain caractéristiques distance entre objectif agent adversaire distance entre objectif agent distance entre agent objectif objectif distance entre agent adversaire distance entre agent distance entre agent adversaire proche adversaire distance entre agent ballon agent ballon quelle équipe ballon adversaire personne équipe agent sensé arriver objectif ballon distance entre agent compagnon adversaire angle1 entre compagnon existe description caractéristiques états utilisant comme comportements navigations primaires décrites ynolds avons actions suivantes déplacement point combine comportements unaligned collision avoidance aller point évitant collisions déplacement groupe point cette action permet joueur dépla restant proche groupe grâce comportement cohesion positionnement inspiré action positionner veloso combine comportements cohesion separation unaligned collision inverse aiguilles montre approche multi agent adaptative simulation schémas tactiques dance cette action déplacer agent stratégique temps proche compagnons adversaires évitant collisions marquage adversaire heuristique permet déterminer point proche adversaire situé entre ballon lequel joueur dirige interception ballon utilisons algorithme stone mcallester trouver temps nécessaire interception ballon cette information agent savoir aller attraper ballon autres actions également importantes utilisent comportements navigation lister faire passe prendre contrôle ballon renforcement définir récompenses manière facile avons déterminé ordre priorités abord réaliser schéma tactique arriver objectifs condi tions satisfaites ensuite perdre ballon enfin mettre ballon après priorités définies avons attribué valeurs comme récom pense situation récompense réaliser schéma réussir objectif perdre ballon ballon déplacement récompenses variation distance entre agent objective normalisé fonction évaluation avons fonction évaluer situation actuelle équipe rapport réalisation schéma tactique cette fonction somme évaluations indivi duelles joueurs équipe évaluer individuellement joueur prenons compte nombre objectifs réussis distance normalisée entre prochain objectif notée calculons valeur nombre total objectifs joueur évaluer équipe définissons fonction égale moyenne évaluations joueurs équipe expérimentation résultats interagir entraîneur réaliser expérimentations résultats avons réalisé plateforme comportant différents modules module interaction entraineur module apprentissage renforcement agents basés apprentissage renforcement avons implémenté autre agents comportement dérive système connaissances constitue approche classique ainsi comparant approches pouvons mesurer apporté algorithme apprentissage pendant expérimentations avons utilisé tableaux cases paramètres continus cases valeurs discrètes configurations utilisées résumées machado configuration epsilon alpha lambda gamma algorithme sarsa sarsa paramètres utilisés algorithme apprentissage avons commencé expérimentations schéma présenté équipe noire défenseurs utilise implémenté schéma détermine joueur arriver objectif ballon joueur arriver objectif ballon selon agent déplacer objectif faire attention ballon autre chercher équipe grise attaquants utilise apprentissage joueur objectif défini contre joueur arriver définie ballon souligner flèches uniquement illustratives entraîneur précise zones conditions joueur passer ballon prise compte schéma tactique déploiement schéma tactique graphe montre évolution apprentissage agents selon quantité épisodes abscisses notre fonction évaluation ordonnées configuration présentés episode evaluation apprentissage approche multi agent adaptative simulation schémas tactiques toutes configurations avons résultat final similaire montré agent objectif apprend chercher ballon sinon équipe adverse prendre ensuite faire passe coéquipier pouvoir accomplir tactique donné conclusion travaux futurs travail présenté montre comment approche adaptative simulation schémas tactiques œuvre résultats attendre quels apports autres solutions existantes allons poursuivre recherche variant composants architecture composants méthode apprentissage types agents mémoire intéressons notamment emploi techniques améliorer évolution coordination apprentissage étudions utilisation apprentissage imitation apprendre partir séquences vidéo numérisées accélérant apprentissage travers travail espérons ouvrir nouvelle approches mulation numérique milieu tactiques sportives contribuer conception nouveaux outils entraîneurs autres professionnels sport références matsubara hiraki frank soccer server research multi agent systems reynolds steering behaviors autonomous characters présenté developers conference gdc1999 california stone mcallester architecture action selection robotic soccer montreal quebec canada sutton barto reinforcement learning introduction press cambridge bradford veloso stone bowling anticipation collaboration agents study robotic soccer présenté summary paper about simulation tactical schemes group autonomous soccer agents shows advantages obtained apply reinforcement learning techniques group reactive agents designed firstly propose framework agent architecture carry simple tactical schemes implement reinforcement learning algorithm allow agents learn complex crowned situations finally results experiments showed confirm learn algorithm benefits success