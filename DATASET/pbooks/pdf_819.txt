Discrétisation fonctions continues rééchantillonnage Taimur Qureshi Zighed Université Avenue Pierre Mendès France 69676 Cedex France taimur qureshi abdelkader zighed lyon2 arbres décision verser largement utilisés classi ficateurs Générer partir ensemble Données construction Processus récursif partitionnement ensemble apprentissage Contexte tributs Continus discrétisés verser variables Alors discrétiser Ensemble Trouver Reportages points coupure papier montrons recherche bureaux points coupure méthode échantillonnage BOOTSTRAP conduit Comme Meilleurs Résultats Avons tested approach methods discrétisation Principales MDLPC Comme FUSINTER CONTRASTE Merge systématique Résultats Utilisant Meilleurs bootstrap exposons bureaux Ouvrons principaux Résultats pistes nouvelles construction arbres décision Introduction processus découverte connaissances partir ensemble données brutes avons abord prétraiter données éliminer bruit poignée manquant champs données Ensuite transformation données telles réduction nombre variables discrétisation attributs définis principal continu souvent réalisée ensuite fourni algorithme extraction données problèmes importants complexes exploration données relation processus transformation discrétisation consiste convertir données numériques forme symbolique discrète souligné qualité découverte connaissances partir ensemble données améliorée discrétisation parce beaucoup techniques découverte connaissances sensibles taille données termes complexité Ainsi choix technique discrétisation conséquences importantes modèle induction utilisé comme outre plages valeurs numériques assez facile fonctions évaluation poignée domaine nominal exemple versions originales machine populaire apprentissage gorithms peuvent utilisés données qualitatives Quinlan transformer nuous valeurs nents discrètes apprenant arbre décision nombreux algorithmes classification monde difficiles résoudre attributs continus discrétisées difficile intervalles Termine discrétisation attributs numériques nombre infini candidats procédure discrétisation simple divise plage variable continue intervalles égaux largeur égale intervalles fréquence Fayyad proposé algorithme pendent classe réduire nombre valeurs attribuées maintenant relation entre valeurs classe attribut méthodes classées discrétisation points différents rapport supervisé supervision statique dynamique global local directement contre incrémental méthodes surveillés utilisation informations classe processus discrétisation alors méthodes supervisées utiliser aucune mation classe disponible discrétisation supervisée seule méthode possible méthodes dynamiques exercent discrétisation valeurs continues durant processus classification tandis discrétisation méthodes statiques avant processus classification méthodes locales utilisent région locale espace instance alors méthodes globales utilisent espace méthodes comme FUSBIN MDLPC CONTRASTE commencent intervalle intervalles séparés processus discrétisation basées principalement binarisation ensemble données formation méthodes ascendantes comme FUSINTER fusion divisé complètement toutes valeurs continues intervalles attributs fusion processus discrétisation article concentrons types stratégies déterminer meilleurs points discrétisation fournir comparaisons termes qualité prévision Notre objectif trouver moyen produire meilleurs points discrétisation Auparavant diverses études réalisées estimer points discrétisation partir échantillons manière significative ensemble échantillons apprentissage utilisés approcher meilleurs points discrétisation ensemble population également valoir échantillon apprentissage approximation ensemble population sorte solution optimale construit ensemble échantillon nécessairement celle globale conduit terprétation utiliser approche échantillonnage déterminer meilleures distributions points discrétisation chaque point probabilité point discrétisation exacte ensemble population faisant essayons améliorer qualité discrétisation meilleure estimation points discrétisation ensemble population ainsi traiter problème discrétisation domaine statistique nouveaux résultats article montrons effectuant rééchantillonnage utilisant bootstrap déterminons meilleure estimation distribution points discrétisation ensemble population montré améliorer prédiction discrétisation atteint améliorons encore qualité moyen obtenu partir rééchantillonnage prédictions appliquant protocole sélection point discrétisation protocole sélectionne points coupe fonction certains critères exemple entropie distribution point fréquence amorçage échantillonnage obtenues partir rééchantillonnage améliore encore prédiction comparons prédiction différentes descendante stratégies ascendantes utilisant rééchantillonnage section exposons cadre discreti sation définir ensembles données utilisés calculs donnons illustration notre travail résultats appliquant méthodologie exemple ensemble données beaucoup coupé queue données Breiman comparons également plusieurs critères basés stratégie descendante ascendante comme comme fusion droit statistique FUSBIN FUSIN principe incertitude MDLPC basée information CONTRASTE prend compte homogénéité classes aussi densité points compte concluons observations déductions propositions travaux futurs Définitions cadre formulation Notations valeur attribut ligne réelle chaque exemple ensemble apprentissage valeur prise attribut attribut appelée variable endogène classe généralement symbolique exemple appartient classe avons supposons également connue échantillon apprentissage ensemble Ainsi essayons construire modèle telle sorte idéalement avons discrétisation Consiste diviser domaine attribut continu intervalles appelés points discrétisation déterminés tenant compte attribut particulier prédiction mesurons qualité discrétisation tenant compte prédiction calculé comme carte carte prédiction résultant discrétisation obtenue appliquant méthode échantillon application échantillon essai Ensemble données article utilisons ensembles données différentes premier utilise petit ensemble données individus correspondant problème classes représenté figure deuxième grand ensemble données utilisé comparaisons résultats ensemble données forme Breiman ayant individus attributs correspondent trois problèmes classe FIGUE points limites échantillon classes Résultats comparaisons Illustration utilisant exemple données figure Considérons ensemble données figure personnes ayant classes effectuons discrétisation FUSBIN chaque échantillon aléatoire amorçage taille générer échantillons figure donne répartition points discrétisation bootstrap échantillons aléatoires discrétisation obtenue partir bootstrap semblent généralisé défini quatre petits intervalles échantillonnage aléatoire distribution points semble définie grande région valeurs pensons outre cette différence augmente ensemble données devient grande verrons ensemble données Breiman avons également calculé prédiction moyen estimation valeurs moyennes chacun échantillons dessus avons trouvé amorçage échantillonnage aléatoire respectivement montrant échantillons bootstrap meilleures performances cette différence augmente encore complexité ajoutée taille population comme indiqué paragraphe suivant FIGUE distribution points discrétisation échantillons aléatoires bootstrap Ensuite améliorons qualité prévision introduisant notion protocole sélection point discrétisation protocole sélectionne points discrétisation partir distribution quence point donné comportant grande probabilité occurrence divise points critère exemple entropie satisfaite illustrer partir figure voyons point élevé bable prenons point diviser population certain critère entropie FUSBIN satisfaite continuons notre processus scissions obtenus manière descendante jusqu critère permet fractionnement encore points distribution fréquence choisi avons appliqué protocole amorce échantillons aléatoires sélec points discrétisation répartitions points fréquence respectivement avons calculé prédiction bootstrap Pling échan hasard démontre meilleure qualité discrétisation obtenue sélection bootstrap soutenons outre échantillonnage donne beaucoup variation prédiction savoir échantillons bootstrap prédiction varie difficile obtenir estimation généralisée points discrétisation population origine notre protocole permette obtenir points discrétisation définis donnent meilleure estimation points discrétisation origine Analyse résultats données signal Breiman cette section utilisons ensemble données ondes Breiman avons généré bootstrap échantillons aléatoires points chacune échantillon essai points partir échantillon vecteur éléments désignés étiquette avons répété processus décrit dessus ensemble données forme avons chaque variable ensemble données amorçage généré échantillons comme dessus Ensuite avons réalisé FUSBIN bootstrap échantillons aléatoires obtenu prédiction moyenne respectivement montrant meilleure formance échantillonnage bootstrap avons appliqué ensuite notre protocole point discrétisation sélection répartition points obtenus sélectionné meilleurs points utilisant critère FUSBIN méthodes échantillonnage avons trouvé prédiction points obtenus partir distribution amorçage valeur moindre échantillonnage aléatoire montrant quantité importante amélioration prédiction utilisant rééchantillonnage bootstrapping Enfin comparons FUSINTER FUSBIN CONTRASTE MDLPC fusion rééchantillonnage selon opératoire suivant méthodes comparer abord obtient points discrétisation échantillons bootstrap créer distribution points fréquence chaque variable utilisant notre protocole sélection MDLPC ChiMerge CONTRASTE FUSBIN FUSINTER MDLPC ChiMerge CONTRASTE FUSBIN FUSINTER calculées Résultats Différence prédiction moyen sélection points discrétisation fréquences distribution points appliquant critère méthode respective partir laquelle points discrétisation initiaux obtenus avons ensuite calcul prédiction points discrétisation sélectionnés chaque méthode rapport ensemble échantillon formons différence prédiction obtenus conclure meilleur significativement supérieure tableau présente comparaison termes différence moyens prédiction riables valeurs positives indiquent méthode rangée meilleur procédé colonne dehors méthode fusion résultats relativement pauvres toutes autres méthodes différences relativement petites Cependant parmi méthodes MDLPC semblait meilleur complexité beaucoup moins temps FUSBIN FUSINTER également complexité temporelle faible rapport CONTRASTE avait complexité quadratique devait compte lorsque nombre exemples devient élevé Conclusion échantillon apprentissage approximation ensemble population sorte sation optimale discreti construite ensemble unique échantillon nécessairement celui global optimal Rééchantillonnage donne meilleure estimation répartition points discrétisation termes parvenir répartition définie application notre protocole point discrétisation sélection distribution fréquence obtenue échantillonnage améliore considérablement qualité discrétisation prédiction approche solution globale optimale protocole lorsqu appliqué distribution point fréquence échantillons aléatoires obtenu améliorations beaucoup moins prédiction rapport bootstrap avons appliqué notre protocole après rééchantillonnage diverses méthodes exception fusion toutes autres méthodes offrent faibles variations termes prédiction MDLPC réalise meilleur FUSBIN réalise meilleure complexité temporelle point traitant beaucoup exemples Comme travaux futurs appliquerons cette approche discrétisation contexte arbres décision améliore performance globale temps réalisation cette approche répondre autres questions telles complexité temps également conduire appliquer éventuels points discrétisation contexte discrétisation floue douce arbres décision Références bibliographiques Zighed Rabaséda Rakotomalala Méthodes discrétisation Supervisé Mémorisation Encyclopédie sciences informatiques technologie vol40 Breiman Friedman Olshen Stone régression arbres Wadsworth International Francisco Wehenkel décision fondée qualité information Arbre Méthode Élagage Compte rendu Conférence internationale traitement information gestion sécurité fondée connaissance systèmes IPMUŠ92 Kerber Discrétisation attributs numériques Actes Confé rence nationale Dixième intelligence artificielle Press Cambridge Zighed Rakotomalala Rabaséda Procédé discrétisation attributs continus induction graphiques Actes Rencontres européennes Cyberne recherche système Fayyad Irani intervalle discrétisation attributs continu Apprécié classification apprentissage Actes Conférence internationale conjointe ficielle Intelligence Morgan Kaufmann Mateo Californie pp1022 Merckt arbres décision espaces attributs numériques Actes Conférence internationale conjointe intelligence artificielle Morgan Kaufmann Mateo Californie Mooney Duval Bootstrapping approche paramétrique statis tique Inference Série documents Université applications quantitatives sciences sociales Newbury Kusiak méthodes transformation fonctions exploration données Trans électronique fabrication emballages Hussain Discrétisation technique permettant Mining Knowledge Discovery Quinlan meilleure utilisation attributs continus Journal gence artificielle Intelli Recherche Flach Douce discrétisation améliorer décision continue Arbre induction Intégration aspects exploration données décision apprentissage pages notes atelier Septembre Résumé induction arbres décision largement utilisé générer classificateurs partir données formation processus division récursive espace données formation données valeur continuous attributs associés doivent discrétisées avance cours processus apprentissage générons points discrétisation effectuant rééchantillonnage ensemble données origine produire sélection points discrétisation utilisant notre sélection échantillonnage proto générons aussi points discrétisation échantillonnage aléatoire ordinaire calcule prédiction points discrétisation obtenus techniques échantillonnage rééchantillonnage processus répété utilisant différentes stratégies discrétisation mentionnées dessus Ainsi objectif article observer technique rééchantillonnage conduire meilleurs points discrétisation ouvre nouveau paradigme construction arbres décision