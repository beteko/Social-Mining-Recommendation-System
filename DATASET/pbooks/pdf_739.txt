actes_non_num 351rotes Construction descripteurs classer partir exemples bruités Nazha Selmaoui Dominique François Boulicaut Université Nouvelle Calédonie EA3791 EA3325 98851 Nouméa Nouvelle Calédonie nazha selmaoui dominique Université LIRIS UMR5205 69621 Villeurbanne France francois boulicaut Résumé classification supervisée présence bruit valeurs descripteurs avoir effets désastreux performance classifieurs pertinence décisions prises moyen modèles Traiter problème lorsque bruit affecte attribut classe étudié intéresser bruit autres attributs notre contexte travail proposons construction nouveaux descripteurs robustes lorsque exemples originaux bruités résultats expérimentaux montrent valeur ajoutée cette construction comparaison qualités obtenues précision lorsque utilise méthodes classification partir différentes collections descripteurs Introduction Lorsqu décrire ensemble objets moyen descripteurs valeurs derniers peuvent collectées façon moins fiable exemple lorsqu elles résultat processus complexe acquisition mesures classification supervi savons présence bruit exemples apprentissage avoir impact négatif performance modèles construits pertinence prises décisions associées existe types problèmes bruits problème bruit classe affectant uniquement attribut classe étudié dernières années Plusieurs approches proposées exemple élimination correction bruit encore pondération instances Rebbapragada Brodley contexte bruit attributs affectant uniquement attributs classe descripteurs moins traité trouvons travaux modélisation identification bruit Kubica Moore Zhang ainsi techniques filtrage nettoyer attributs bruités intéressons problème classification présence descripteurs tributs classe bruités précisément voulons apporter réponse question suivante comment construire modèles prédictifs robustes partir données attributs Booléens priori bruités Construction descripteurs classer partir exemples bruités proposons construction descripteurs robustes autant éliminer exemples bruités modifier valeurs attributs données apprentissage Cette approche combine avancées récentes domaines fouille motifs tolérants exceptions construction descripteurs autre concept itemsets fréquents tolérants bruit introduit permettre découverte motifs pertinents données booléennes bruitées synthèses ponibles comme exemple Besson Parmi extensions robustes étudiées Besson présente motifs généralisation concepts ensembles fermés tolèrent nombre borné erreurs colonne construits partir représentation condensée ensembles libres introduite licaut motifs libres coeur notre méthode construction descripteurs robustes construction nouveaux descripteurs basée motifs ensem blistes propriétés fermeture Selmaoui Cheng Garriga propositions récentes partent hypothèse ensembles attributs itemsets peuvent pertinents attributs seuls caractérisation classes pourvu puisse contrôler redondance collections travaillant propriétés fermetures justement donner cadre élimina redondance groupant motifs classes équivalence Notre proposition exploite avancées étapes notre processus comme indiqué Figure déroule manière suivante extrayons motifs redondants tolérants bruits basés représentation condensée approximative ensembles fréquents partir motifs construisons nouveaux descripteurs données processus appliquons algorithmes classiques classification supervisée exemple encore Naive Bayes Construction descripteurs robustes Noise Tolerant Feature Construction travaux rentrent cadre classification supervisée basée locaux motifs utilisés furent abord règles association motifs émergents2 Ramamohanarao synthèse récemment représentations condensées ensembles fréquents rares études classification tolérante bruit basée motifs locaux exploite motifs émergents Ramamohanarao reste article organisé comme based motif émergent fréquent relativement classe données fréquent reste données ratio fréquences relatives donne différentes catégories motifs émergents Selmaoui Section donne définitions nécessaires notre proposition détaillée Section Section décrit expérimentations discute résultats données Section conclut Définitions préliminaires données binaires ensemble transactions objets décrit ensemble attributs items Booléens Lorsque transaction contient objet possède propriété décrite attribut itemset simplement ensemble items fréquence itemset définie Objets Objets fréquent Définition règle association règle forte itemset libre règle association expression fréquence règle confiance entier turel règle forte règle association forme violée transactions transaction implique items libre existe règle forte entre ensembles propres Lorsque parle alors règles fortes itemsets libres ensembles libres règles fortes introduits Boulicaut définition représentation condensée approximative ensembles fréquents concept ensemble libres généralise clairement celui motif utilisé Bastide Reprenons présentation terme classes équivalence justement introduite Bastide Définition fermeture classe équivalence entier naturel fermeture itemset ensemble items Lorsque correspond opérateur fermeture connu pouvons aussi regrouper ensembles classe équivalence fermeture ainsi motifs libres équivalents nouveau notons lorsque retrouvons formalisation Bastide possible dériver règles fortes partir partir ensembles libres leurs fermetures effet règle forte constituée ensemble compris inclusion entre ensemble libre chacun éléments fermeture Besson combine itemsets libres leurs fermetures construire motifs appelés ensembles Définition ensemble fréquent ensemble ensemble fréquent ensemble libre fréquent Objets archive Construction descripteurs classer partir exemples bruités motif généralisation notion concept formel ensemble concept formel certaine tolérance exceptions Pensa paramètre détermine nombre erreurs borné colonne colonnes correspondant attributs fermeture suite allons décrire comment utilisées production nouveaux descripteurs robustes classes équivalence descripteurs pertinents réaliser tâches classification sommes intéressés règles fortes pertinentes contenues Figure présente exemple typique intéressante ensembles libres contiennent attribut classe fermeture contient attribut classe Ainsi dériver règles fortes potentiellement intéressantes concluent attribut classe intéressant classe équivalence fermeture Table contingence règle forte Information classes équivalence fermetures intéressantes Selon formalisation proposée Crémilleux Boulicaut règle forte caractérisation classe attribut classe corps minimal minimal existe autres règles fortes fréquentes telle savons Crémilleux Boulicaut ensemble règles fortes caractérisation renferme conflits inclusion égalité corps définition règles caractérisation basée confiance suffisante prédiction proposons utiliser également accroissement caractérisant motifs émergents pouvoir discriminant vient confronte fréquence relative règle classe rapport reste croissement défini rapport fréquences relatives suivant freqr freqr Selmaoui restreinte objets class Hébert Crémilleux auteurs placent cadre général mesures intérêt dites dépendantes elles dépendent fréquence corps règle nombre exceptions concordance principes suivants Lorsque augmente Lorsque augmente partir principes trouve Hébert Crémilleux résultat concernant bornes inférieures plusieurs mesures intérêt entre autres fonction effet table contingence règle forte Figure construction admet borne inférieure borne supérieure pouvons déduire borne inférieure mesures Après quelques déductions obtenons classe majoritaire Ainsi seuil fréquence donné ensembles fréquents libres fermeture contient attribut classe satisfait contraintes équations motifs émergents membres gauches règles conflictuelles suite considérons valeurs contraintes équations Notre processus construction descripteurs maintenant résumé gorithme procédure ExtractionMotifs Ligne extrait ensembles fréquents libres membres gauches règles fortes caractérisation Cette étape effectuée efficacement utilisant évolution simple prototype like4 prototype implémentation algorithme niveaux décrit Boulicaut profite monotonicité contraintes liberté fréquence extraire efficacement ensembles fréquents libres Comme intéressons ensembles minimaux fermeture contient attribut classe pouvons davan élaguer espace recherche éliminant ensembles ensembles sélectionnés niveau précédent Ensuite chaque devient nouveau descripteur attribut Ligne valeur transaction proportion attributs décrivent Items opérateur Objets obtenons alors veaux descripteurs valeurs numériques nombre attributs pensons codage tinent codage binaire effet codage numérique avons toujours possibilité discrétiser séparant domaine valeurs manière moins aussi pertinente celui imposé codage binaire Enfin Ligne nouvelle données décrite descripteurs numériques robustes prête étape apprentissage supervisé 4Disponible depuis liris turing Construction descripteurs classer partir exemples bruités Algorithme Construire nouvelle données partir descripteurs tolérants bruits entrée données binaires entiers positifs seuils fréquence erreurs sortie données descripteurs tolérants bruits begin1 ExtractionMotifs Items Expérimentations évaluer capacité notre processus construction descripteurs sister bruit attribut expérimentons données priori bruitées plusieurs versions bruitées dernières voulons apprendre modèles prédictifs pertinents partir exemples bruités ainsi expériences ensembles apprentis soumis bruit attributs ensembles validation restent propres Notre modélisation bruit consiste injection bruits aléatoires uniquement attributs classe ensemble apprentissage données introduire bruits indique chaque attribut chances valeur changer chaque transaction ensemble apprentissage attributs continus utilisons méthode discrétisation Fayyad Irani avant injecter bruit puisque intéressons bruit attributs Booléens partir données ainsi bruitée générons nouvelle données construisant nouveaux descripteurs Algorithme appliquons classifieurs Naive Bayes Notons étapes traitement ainsi résultats précision obtenus validation croisée grâce plateforme Witten Frank Résultats précision Tableau reportons résultats précisions classifieurs différentes versions bruitées améliorées données seuils fréquence utilisés chaque indiqués colonne indique fréquence absolue varie lorsque celui régulier colonnes rapportent précisions maximales obtenues parmi toutes valeurs testées entre parenthèses certaines fréquences absolues lesquelles précision meilleure données originales colonne Amélio reportons aussi amélioration précision processus ainsi moyenne niveau bruit table Selmaoui Amélio Amélio breast colic heart heart heart Moyenne Comparaison précisions données originales améliorées remarquons précision affectée niveau bruit croissant observons jusqu perte précision résultats expérimentaux montrent résiste presque toujours mieux bruits Construction descripteurs classer partir exemples bruités niveau extrême bruit données breast Wisconsin Notons amélioration précision souvent valeur unique seuil fréquence origine moins affecté bruit perte précision moins impor tante Ainsi amélioration processus moins flagrante significative versions données réalise amélioration précision entre elles Notons aussi amélioration précision données artificiellement bruitées moyenne rapport plupart réalise amélio ration niveau bruit pensons échec destruction complète bruit motifs originaux pertinents effet processus extraire assez ensembles libres pertinents caractériser objets restant génération bruit confusion entre motifs pertinents différentes classes Evolution précision fonction niveau bruit Figure reportons résultats précision fonction graphique niveau bruit courbe seuil fréquence droite constante représente précision Premièrement remarquons précision obtenue augmente cessairement façon monotone jusqu point maximal souvent meilleur classifieur données originales précision décroît brutalement choisit successivement meilleur motif construire noeuds ainsi arbre décision Ainsi ensembles extraits nécessairement utilisés arbre contraire utilise sembles extraits calcul produit approximations pourquoi précision décroît Notons comportement semblable autres données accentué lorsque niveau bruit augmente Deuxièmement lorsque niveau bruit augmente valeurs faibles engendrent précisions basses effet lorsque allons extraire motifs peuvent rares bruitées erronés abaisse fréquence valeurs intéressantes lesquelles meilleur différentes selon quantité bruit Étant donné seuil fréquence paramétrage nombre erreurs autorisées semble crucial suite donnons indications déterminer seuil Stratégie fixer paramétrage automatique seuil fréquence reste question ouverte Zhang travaux préliminaires seuil fréquence comment déterminer bonnes valeurs évolution mesures dépendantes telle mesure fonction intuitive connue Lorsque diminue augmente motifs respectant contraintes peuvent rares données bruitées Lorsque augmente motifs extraits deviennent aptes adapter bruit données apprentissage grandes valeurs elles seront moins pertinentes faible graphiques Figure reportons résultats Selmaoui niveau bruit niveau bruit niveau bruit niveau bruit niveau bruit niveau bruit niveau bruit niveau bruit Evolution précision fonction niveau bruit données Construction descripteurs classer partir exemples bruités niveau bruit niveau bruit niveau bruit niveau bruit Evolution précision ensemble apprentissage fonction différents seuils fréquence niveaux bruits précision apprentissage manière générale précision augmente jusqu stabilisation ralentissement croissance valeurs stabilisation intéressantes moins performant apporte amélioration significative Notons dépend niveau bruit données Puisque réels quantité bruit données connu priori proposons thode raisonnable accéder bonnes valeurs poser augmenter jusqu stabilisation ralentissement croissance précision données apprentissage Conclusion proposons processus original baptisé améliorer qualité tâches classification supervisée présence exemples apprentissage bruités combine avancées récentes domaines extraction motifs tolérants exceptions construction descripteurs améliorons description données initialement léennes grâce nouveaux descripteurs construits motifs ensemblistes pertinents robustes précisément partir ensembles fréquents libres leurs fermetures résultats expérimentaux montrent environnement bruité classifieurs Selmaoui culés moyen algorithmes classiques comme performants données améliorées données apprentissage originales proposons stratégie choisir valeurs pertinentes quantité bruit données perspectives travail nombreuses sommes restreints bruit attributs classe également possible étudier effet veaux descripteurs environnements attribut classe également soumis bruit autre pourrions considérer ensemble règles fortes caractérisation extraites comme corriger exemples bruités comme filtre éliminer exemples considérés comme bruités Remerciements travail partiellement financé contrat européen 516169 Bingo2 Références Bastide Taouil Pasquier Stumme Lakhal Mining frequent patterns counting inference SIGKDD Explorations Besson Pensa Robardet Boulicaut Constraint based mining fault tolerant patterns boolean Proceedings Volume Springer Boulicaut Bykowski Rigotti Approximation frequency queries means Proceedings Volume Springer Selmaoui Boulicaut parameter associative classifier Proceedings DaWaK Volume Springer Cheng Discriminative frequent pattern analysis effective classification Proceedings Computer Society Press Crémilleux Boulicaut Simplest rules characterizing classes generated delta Proceedings Springer Efficient mining emerging patterns discovering trends diffe rences Proceedings SIGKDD Press Ramamohanarao Noise tolerant classification emerging patterns Proceedings PAKDD Volume Springer Fayyad Irani Multi interval discretization continous valued attributes classification learning Proceedings IJCAI Morgan Kaufmann Garriga Kralj Lavrac Closed labeled Journal Machine Learning Research Selmaoui Boulicaut Feature construction based closedness properties simple Proceedings PAKDD Volume Springer Hébert Crémilleux Optimized mining through unified framework interestingness measures Proceedings DaWaK Volume Springer Construction descripteurs classer partir exemples bruités Kubica Moore Probabilistic noise identification cleaning Proceedings Computer Society Press Integrating classification association mining Proceedings Press Pensa Robardet Boulicaut Supporting cluster interpretation means local patterns Intelligent analysis Quinlan programs machine learning Francisco Morgan Kaufmann Ramamohanarao Patterns based classifiers World Rebbapragada Brodley Class noise mitigation through instance weighting Proceedings Volume Springer Selmaoui Leschi Boulicaut Feature construction delta samples Proceedings Volume Springer Zhang Ramamohanarao Noise tolerance based classifiers Proceedings AusAI Volume Springer Witten Frank Mining Practical machine learning tools niques edition Francisco Morgan Kaufmann Fayyad Bradley Efficient discovery error tolerant frequent itemsets dimensions Proceedings SIGKDD Press Dealing predictive unpredictable attributes noisy sources Proceedings Volume Sprin Zhang Zhang Computing minimum support mining frequent patterns Knowledge Information Systems Zhang Noise modeling associative corruption rules Proceedings Computer Society Press Class noise attribute noise quantitative study Artificial Intelligence Revue Summary training classifiers presence noise severely their performance differentiate class noise attribute noise earlier extensively studied while methods developed handle latter focus attribute noise consider robust feature construction based frequent fault tolerant pattern mining Indeed method based application independent strategy feature construction based called pattern which proposed earlier approximate condensed representations frequent experimental evaluation noisy training shows accuracy improvement using computed features instead original