articles assemblage estimation densité données application détection changement Alexis Bondu Benoît Grossin Marie Picard ICAME avenue Général Gaulle 92140 Clamart firstname Résumé dernières années quantité données traiter augmenté nombreux domaines application surveillance réseau cliquez données capteur réponses minières données traitement données massives paradigme permet traiter morceaux données volée surmonter stockage données détection changements distribution données question importante article propose nouveau schéma détection changement risation Résumés données entrée ensemble micro agrégats estimation distribution données exploitant micro estimation convergence entre distribution répartition référence courant estimé étape diagnostic grâce contribution chaque variable prédictive écart global entre distributions Notre schéma détection changement appliqué évalué données artificielles Introduction dernières années quantité données traiter augmenté nombreux domaines application réseau cliquez analyse données capteur extraction données indique algorithmes traitent tuples volée quand stocker traitement tuples aussi rapide possible permet gérer données débit problème important traitement données détecte changements distribution jacent généré tuples conception systèmes détection changement ordre général évolutive statistiquement pertinente grand changement distribution jacente interprétée différentes façons phénomène servi dérive naturellement raison changement contexte caché Widmer Kubat donnée explicitement facteur prédictif changement anormal système observé Distinguer question difficile nécessite expertise application article supposons expert connaît données observées prononcer interprétation changements détectés ensemble principales approches détection changement donnée Dries Dries Rückert Détection changements distribution tuples considérée comme hypothèse statistique implique échantillons tuples multidimensionnels problèmes étudiés littérature statistique tests Wolfowitz Smirnov généralisée terme tuple référence donnée émise partir entrée Estimation densité données ensembles données multidimensionnelles Friedman Rafsky suite approches fondées analyses proches voisins distance entre estimations densité Anderson point récemment statistiques fondées écart moyen maximal noyaux universels devenus populaires Gretton gamme travaux statistiques détection changement brusque Basseville Nikiforov Desobry article nouveau schéma détection changement proposé figure schéma composé quatre étapes successives section données entrée résumée algorithme micro clusters Cette première étape nécessaire raison élevé données entrée pratique toutes lignes peuvent traitées temps algorithme Denstream capacité résumer zones denses espace entrée oublier anciens tuples pondération fonction temps proposons moyen simple régler algorithme termes durées section nouvelle variante fenêtre Parzen proposé utilisé estimer distribution jacente données estimateur densité exploite résumé données entrée tuples Cette étape répétée périodiquement inférieur celui émission tuples partir données article montre comment distance entre répartition actuelle estimée distribution référence évaluée divergence Kullback Leibler Cette mesure permet envoyer alarme expert lorsque distributions significativement différentes dernière étape notre schéma consiste diagnostic donnée expert aider comprendre causes anomalie détectée contribution chaque variable distance globale entre distributions évaluée raison nouveau critère proposé Synopsis données entrée courant basée estimation détection DiagnosticEvents synopsis Densité Densité Clustering DenStream Addapted Parzen fenêtre estimateur divergence Kullback Leibler contribution chaque variable étape divergence section étape section étape section étape section schéma global détection changement distribution données entrée Enfin notre approche appliquée évaluée données artificielle section applications industrielles possibles travaux schéma futurs discutés section Summarization données entrée paradigme données tuples peuvent exhaustive stockées traitées raison élevé entrée Cette section présente récapitulation données entrée étape préliminaire traitement détection changement Notre approche exploite algorithme Denstream résumer données pondération fonction temps appliquée ensemble micro clusters Bondu données pondérées progressivement Tuples partir données pondérées fonction précisément tuples dénotées définis caractérisés vecteur Chaque tuple émise instant Tcurrent indiquant Tcurrent heure chaque tuple pondérée paramètre affaiblissement appartenant intervalle valeur importance données historiques rapport données récentes article représente nombre total tuples Tcurrent poids total données instant Tcurrent tuples avons correspondant temps écoulé entre émission dernières tuples hypothèse données constante poids total défini comme récursivement Cette série géométrique arithmétique converge micro ensemble objectifs micro résumer données entrée informations maintien distribution densité synopsis maintenu mémoire moment cluster micro défini poids correspond somme poids tuples appartenant cluster désignés centrale vecteur correspondant barycentre pondéré exemples wijxij rayon vecteur correspond écart pondéré distance euclidienne notée tuples augmente quand nouvelle ligne émise comme temps écoulé entre tuple considéré comme constant nouveau tuple affecté micro cluster proche ensemble micro agrégats maintenu raison Procédé ative poids micro maintenus étapes successives suivantes vieillissement micro agrégats augmentation poids micro cluster tuple affecté caractéristiques nécessaires maintenir centre rayon micro Zhang respectivement vecteur dimensionnel mémorisation chaque variable somme pondérée coordonnées respectivement somme coordonnées carré exemples appartenant micro cluster wijxij respectivement maintenus comme approche Denstream poignées approche Denstream types micro cluster correspondant différentes fonctions ensemble potentiel micro clusters désignés résume significative condition toujours satisfaite Estimation densité formation données partir données micro grappes dépassant poids minimal considérés comme représentant informations importantes ensemble aberrantes micro clusters désignés consiste tampon conservation informations négligeable données intuition suivante légère micro cluster poids minimal développer densité distri bution données train changer objectif conserver informations insignifiantes début détecter nouvelles zones denses données contraintes appliquées micro groupes micro poids diminue dessous poids minimum notée supprimés nouveau tuple fusionné micro groupe proche rayon inférieur écart maximum notée contraintes assurent micro clusters représentent zones denses espace tuples apparus récemment stratégie œuvre taille algorithme Denstream Cette stratégie réglementer espace mémoire nécessaire stocker ensembles micro clusters Comment paramètres termes durées supposons notre système détection changement proche exploitée expert connaît phénomènes intégrés données algorithme Denstream implique plusieurs paramètres peuvent difficiles régler expert paragraphe examen façon régler paramètres manière compréhensible expert connaît durée validité tuples capable mettre place période notée ΔHalfLivet paramètre affaiblissement déterminé second temps HalfLive démontrons paramètre représente poids minimal grappes délimitée comme ClusMin janvier λΔClusMaxt ΔClusMaxt temps arrivée nouveau tuple micro cluster reasonable garder statut potentiel micro cluster avons ClusMax obtient ClusMax ΔClusMint durée minimum temps maintenu micro cluster synopsis micro cluster avons ClusMin poids micro cluster inférieure égale poids total données avons ClusMin obtient ClusMin article adoptons choix auteurs définissent période taille comme minimum ΔClusMaxt considérons HalfLive donnés expert conditions exprimée comme ΔHalfLivet nouveau micro cluster lorsque écart maximal proche faisait micro cluster tuple Intuitivement valeur influences nombre micro agrégats potentiels maintenues mémoire accord question écart parce ensemble standard données entrée inconnue général article supposons écart global connu expert ajustée proportion écart global valeur périodiquement divisé Bondu Notations ensemble micro cluster potentiel ensemble micro cluster aberrant poids minimum micro cluster potentiel écart maximum micro cluster potentiel période élagage Répétez Obtenez point suivant partir données Procédure fusion Essayez fusion proche micro cluster nouveau rayon fusionner mettre Essayez fusion autre proche micro cluster nouveau rayon fusionner retirez tampon valeurs aberrantes créer nouveau Microcluster autre Créer nouvelle micro cluster insérer mémoire tampon valeurs aberrantes Procédure élagage taille Période écoulée alors chaque micro cluster faire Supprimer chaque micro cluster faire Supprimer jusqu données existe algorithme synthèse données approche Denstream estimation densité données estimation densité exploitant synopsis Cette section montre comment synopsis données entrée exploitée estimer densité données modifie estimateur densité fenêtre Parzen Parzen exploiter micro agrégats place tuples paragraphe présente fenêtre Parzen classique noyau gaussien paragraphe estimateur densité adaptée micro Parzen Windows Parmi large gamme modèles capables estimer densité données partir ensemble tuples fenêtre Parzen noyau gaussienne Shawe Taylor Cristianini avantage nécessiter quelques paramètres équation correspond sortie modèle prédictif estimation probabilité observer tuple fonction noyau évaluer proximité entre tuples cette fonction additionnée tuples pratique fonction noyau spécifié équation correspond sortie fenêtre Parzen pourvu noyau gaussien fenêtre Parzen implique paramètre écart noyau Gaussien figure illustre estimation estimateur fenêtres Parzen gaussiennes positionnés chaque tuple additionnés normalisés chaque tuple contribue estimation estimation densité fenêtre Parzen Contribution chaque exemple formation exemples formation figure Estimation distribution données raison fenêtre Parzen considérons écart noyau gaussienne constante toutes dimensions espace entrée Bondu Notre modifiées fenêtres Parzen paragraphe estimateur densité fenêtre Parzen adaptée exploiter ensemble micro tentiel tuples distribution approchée équation représente poids total données représente nombre micro agrégats potentiels résumant données représente poids micro groupe représente barycentre points pondérés appartenant micro groupe désigne écart points pondérés appartenant micro grappe représente paramètre planéité équation Chaque tuple observée censé probable ensemble tuples inobservée normalement distribué écart cette hypothèse variance totale donne variance micro cluster potentiel comme somme variance intra entre variance équation noyaux gaussiens positionnés centre chaque micro cluster potentiel Ensuite gaussiennes additionnés normalisés concerne nombre micro clusters potentiels poids total données écart exemples formation position centre valeur exemples formation poids estimation densité fenêtre Parzen Micro Cluster Influence poids micro estimation densité figure illustre estimation fenêtres Parzen modifiés cette figure ensemble tuples divisé micro agrégats potentiels rayon symbolisé ligne pleine horizontale poids symbolisés ligne pointillée verticale Estimation densité estimation données moins précis figure raison perte chaque emplacement tuple autre cette estimation prend compte poids chaque groupe estimation distribution change temps raison vieillissement micro aucun changement produit distribution jacente tuples diminution poids remplacés nouveaux estimation changeront contraire tuples remplacés micro cluster engendrer diminution poids alors changement estimation observée Changement détection diagnostic suppose anomalie produit résultats données entrée changement tribution distribution référence place après période apprentissage anomalies détecter expert examine données entrée assurer aucune anomalie cours cette période Ensuite estimation actuelle distribution comparée distribution référence raison divergence Kullback Leibler Hershey Olsen montre équation divergence Kullback Leibler propriétés statistiques intéressantes parti paramètres constatation modèle statistique maximisant probabilité analogue recherche paramètres réduisant minimum divergence Eguchi Copas divergence Kullback Leibler généralise tests statistiques classiques comme équivalente divergence Kullback Leigler entre distributions normales fonction premier terme développement Taylor divergence Kullback Leigler notre schéma détection changement alarme envoyée expert lorsque divergence entre distributions atteint seuil diagnostic requis expert donner réponse appropriée alarme objectifs phase diagnostic évaluation contribution chaque variable écart entre Ainsi expert informé facteur prédictif impliqués changement détecté contribution variables évaluée équation KLiminus divergence Kullback Leigler évalué après exclusion espace dimension variable Lorsque contribution variable évaluée KLlminus comparée somme KLminus variables contribution normalisée Contrib moins KLlminusΣk moins contribution chacun objectifs variables aider expert prononcer interprétation variation détectée pratique expert autorisé mettre distribution référence distribution actuelle changement détecté anomalie Cette constitue moyen possible prendre compte dérive naturelle phénomène observé Bondu Expériences cette section notre schéma détection changement appliqué données artificiel objectif évaluer capacité notre schéma détecter types changements différents changement moyenne distribution normale changement écart distribution normale Protocole expérimental données artificielle considérés partagent structure temporelle Chaque seconde tuple distribution jacente change temps figure montre comment distribution jacente évolue premiers tuples partir distribution initiale représente opération habituelle moment distribution référence place notre schéma détection changement commence Entre secondes distribution couchage déplace progressivement partir initial distribution modifié Ensuite tuples distribution modifiée Entre 10000 secondes distribution jacente progressivement retour initial Enfin tuples distribution initiale Répartition données Temps 12000 Distribution initiale référence place distribution modifiée Structure temporelle données artificielles expériences tuples définies distributions initial modifié définis Tableau données artificielles distributions normales désignées vecteur dimensions correspondant moyenne matrice covariance distribution initiale distribution modifiée données modification moyenne données changement écart Définition distributions initial modifiés données artificielles Notre schéma détection changement implique plusieurs paramètres doivent fixés avant expériences algorithme Denstream résument données entrée section paramétrée ΔHalfLivet 1000s paramètre planéité notre estimateur densité section Estimation densité données Résultats figure présente résultats expériences graphique gauche respectivement droit tableau indique détection changement moyenne respectivement écart distribution jacente décrite tableau cartes correspond horizontal temps commence quand Répartissez distribution référence correspond vertical écart entre référence distributions courant contribution chaque variable divergence également symbolisée couleurs FIGUE détection changements distribution données artificiels premier données artificielle implique changement moyenne distribution normale graphique gauche figure changement produit lorsque détecté effet augmentation divergence significative Entre secondes augmentation divergence maximum contributions estimer mouvement distribution jacente dimensions retour distribution initiale jacente 10000 relativement divergence maintient valeurs élevées jusqu diminue fortement après comportement expliqué temps nécessaire supprimer micro clusters potentiels inutiles résumé données entrée second données artificiel implique changement écart distribution normale graphique droite figure détection changement moins nette viously divergence varie fortement temps stabilisent divergence atteint faible valeur maximale Cependant première modification tribution jacent détecté divergence augmente partir Entre secondes divergence atteint valeur maximale compatible structure données entrée cours cette période contribution deuxième variable tendance importante première variable Enfin retour distribution initiale jacente détectée temps expériences montrent intérêt notre approche détection dérive progressive distribution jacente autres tests concluants effectués changements brusques temps latence court observée raison durée temps nécessaire créer nouveaux micro clusters potentiels remarque réglage paramètre affaiblissement sensible soulève dilemme entre réduction latence assurer détection signification statistique estimation distribution Réglage paramètre pourrait moins sensible pratique rythme changements connu avance expert Bondu Conclusion perspectives article propose nouveau schéma détection changement distribution jacente données Notre approche compose quatre étapes successives abord données entrée résumée ensemble micro agrégats algorithme Denstream ainsi données vitesse élevée traitée algorithme Denstream capacité résumer zones denses espace entrée oublier anciens tuples pondération fonction temps proposons moyen simple régler paramètres algorithme termes durées deuxième étape consiste estimation distribution jacente exploitant résumé données nouvelle variante estimateur fenêtre Parzen Parzen proposé Ensuite dérive distribution actuelle estimée évaluée rapport distribution référence divergence Kullback Leibler exploitée Hershey Olsen diagnostic donné nouveau critère évalue contribution chaque variable distance totale entre distributions pratique cette dernière étape pourrait utile comprendre causes anomalie détectée répondre manière appropriée Depuis notre schéma détection changement implique estimateur densité probabilité chaque tuple émise estimée fenêtre Parzen actuelle Cette information devrait exploitée détecter rapidement changements brusques distribution jacente supposant changement provoque émission séquence improbable tuples principale difficulté gérer dépendance temporelle tuples travaux futurs étudieront point autre aspect lequel travaillons quantification théorique informations perdues utilisant micro clusters tuples lorsque distribution données estimée poignées algorithme Denstream variance chaque micro cluster comme seule valeur scalaire représente perte information importante exemple matrice covariance tuples pourrait maintenue ligne chaque micro cluster œuvres FUTUR allons étudier maintien ligne matrice covariance moments statistiques élevés utiliser nouveaux éléments information estimer précisément répartition tuples Notre schéma détection changement favorablement évaluée données artificielle travaux futurs autres expériences évaluer influence dimension espace entrée capacité notre schéma détecter changements Enfin notre schéma appliqué données réelles particulier visons améliorer maintenance préventive centrales électriques grâce détection événements inhabituels manière générale notre schéma détection changement pourrait exploitée nombreux domaines applications exemple lancé vaste programme recherche gestion santé intégrée véhicules détecter automatiquement diagnostiquer prédire atténuer effets indésirables pendant aéronef Srivastava détection précoce anomalies données capteur représente intérêt communauté scientifique Références Anderson Titterington statistiques échantillons écarts entre mesurables fonctions densité probabilité plusieurs variables utilisant estimations densité noyau Journal multivariée Analyse Basseville Nikiforov détection changements abrupts théorie Applica Prentice Estimation densité données Desobry Support Vector Based détection ligne changements abrupts ICASSP Dries Rückert Adaptive Concept détection dérive Conférence Mining Eguchi Copas interprétation divergence Kullback Leibler lemme Pearson Neyman Journal Multivariate Analysis Ester densité regroupement données bruit evolv Conférence Mining Friedman Rafsky généralisations multivariées tests échantillons Wolfowitz Smirnov Annales statistique Gretton Borgwardt Rasch Schölkopf méthode noyau Sample problème Press Permutation tests égalité distributions milieu grande dimension Biometrika Hershey Olsen Approximation Kullback Leibler tween gaussiennes modèles Mélange ICASSP Conférence internationale acoustique Speech Signal Processing Volume Parzen estimation fonction densité probabilité Annales statistique mathématique Shawe Taylor Cristianini Méthodes noyau analyse modèle presse Universite Cambridge Srivastava extraction données théorie applications Paris Widmer Kubat apprentissage présence Concept Drift caché Contextes Machine Learning Zhang Ramakrishan Livny BIRCH clustering efficace données Méthode grandes bases données Sigmod Résumé Dernieres QUANTITE Années Donnees Traiter Augmentée considérablement applications Nombreuses fouille Données Répond Sives Données Traitements volée capacity requièrent reasonable stockage Detection density Changements probabilité question importantes article propose nouveau schéma Detection Compose changement Suivantes Quatre ÉTAPES résumé ensemble micro clusters estimation densité probabilité GRÂCE micro grappes estimation divergence between Estimée density instant courant density référence diagnos contribution estimant variables descriptif divergence separé globale densi Notre schéma détection changement FINALEMENT Evalue Appliqué Données artificiels