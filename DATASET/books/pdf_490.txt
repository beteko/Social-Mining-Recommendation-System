algorithme classification automatique données relationnelles multi francisco carvalho filipe lechevallier thierry despeyroux centro informatica freire cidade universitaria 50740 recife brésil inria paris rocquencourt 78153 chesnay cedex france lechevallier thierry despeyroux inria résumé classification automatique carvalho capable titionner objets prenant compte manière simultanée plusieurs trices dissimilarité décrivent matrices peuvent avoir générées utilisant différents ensembles variables fonctions dissimilarité cette méthode basée algorithme nuées dynamiques conçu partition prototype chaque classe découvrant dération pertinante chaque matrice dissimilarité optimisant critère adéquation entre classes leurs représentants pondérations changent chaque itération algorithme différentes chacune classes présentons aussi plusieurs outils interprétation groupes partition fournie cette nouvelle méthode exemples illustrent interêt méthode premier utilise données concernant chiffres manuscrits numérisés images binaires provenant second utilise ensemble rapports connaissons classification experte donnée priori introduction classification activité courante extraction connaissances sification organiser ensemble objets ensembles appelés clusters classes telle façon objets classe ressemblent quantifier cette ressem blance important définir cette dissimilarité entre objets partir leurs représentations représentation objet unique données appelées multi elles présentes plusieurs domaines bioinformatique keting cleuziou documents structurés exemple documents existe plusieurs blocs sections chacun interprété comme générale chaque matrice dissimilarité collaboratif pedrycz arriver consensus partition leclerc cucumel algorithme classification automatique données relationnelles multi matrices peuvent avoir générées utilisant distances différents ensembles riables article présente amélioration algorithme classification automatique décrit carvalho capable partitionner objets prenant compte manière simultanée plusieurs matrices dissimilarité décrivant influence poids différentes matrices dissimilarité étant identique chaque classe pertinence calculée déroulement algorithme apprentissage algorithme décrit texte conçu donner partition vecteur totypes chacune classes pondération chacune matrices dissimilarité optimisation critère adéquation entre trois éléments cette pondération diffé rente chaque classe algorithme algorithme nuées dynamiques données relationelles décrit lechevallier carvalho utilisant notion distance adaptative proposée diday govaert carvalho leche vallier cette version avons modifié étape représentation algorithme décrit carvalho proposons plusieurs outils interprétation classes partition fournies méthode étape représentation avons vecteur objets objet chaque chaque classe associe objet permet avoir comme étape pondération approche locale montrer utilité algorithme appliquons exemples utilisation premier concerne catégorisation automatique données concernant chiffres manus crits numérisés images binaires disponible machine learning repository décrits différents tableaux variables proposons aussi reprendre exemple présenté carvalho utilisait ensemble rapports lequel disposons classification experte cadre prototype classe était élément méthode classification plusieurs matrices dissimilarité cette section introduisons amélioration nouvel algorithme nuées namiques données relationnelles carvalho permet partitionner ensemble objets fonction description basée plusieurs matrices dissimila cette nouvelle version prototype défini comme individu comme vecteur individus ensemble exemples matrices dissimilarité donne dissimilarité entre objets matrice dissimilarité supposons vecteur vecteur prototype classe composantes appartiennent ensemble algorithme nuées dynamiques cherche partition classes vecteur prototypes correspondant representant classe carvalho pondération chaque matrice dissimilarité telle façon critère adéquation localement optimisé λkjdj lequel λkjdj dissimilarité entre objet vecteur prototype classe ramétrisé vecteur pondération poids matrice dissimilarité classe mesure dissimilarité locale entre objet prototype notre algorithme alterne trois étapes suivantes étape recherche meilleurs vecteurs prototypes cette étape partition classes matrice pondération pertinence fixés chaque classe recherche vecteur prototype minimise critère vecteur prototype possède composants objets obtenus argmin1 étape calcul meilleure matrice pondération cette étape partition vecteur prototypes fixés élément vecteur pondération minimisant critère contraintes calculé remarque objets classe proches composante totype rapport tableau dissimilarité grande valeur pondération étape construction meilleure partition cette étape vecteur prototypes matrice pondération fixés classe construite utilisant règle allocation suivante minimum unique affecté classe possède petit indice algorithme classification automatique données relationnelles multi facile montrer chacune trois étapes décroître critère algorithme démarre partition initiale alterne trois étapes jusqu conver gence cette convergence atteinte quand valeur critère stationnaire rapport algorithme initial carvalho utilisation vecteur totype permet optimisation prototype pondération localement groupe tableau dissilimarité critère convergence décompose selon tableaux dissimilarités selon groupes tableaux dissimilarité simultanément permet interpréter groupes rapports tableaux interprétation classes partition critère correspond critère appliqué partition seule classe outils interprétation classes partition basés décomposition critère parties correspond dispersion intra classes autre dispersion inter classes utiliserons approche chavent permet faire cette décomposition calcul dispersion inter classes impossible partition finale classes prototype vecteur pondération pertinence groupe supposons aussi prototype global vecteur dispersion globale partition définie comme étant λkjdj prototype global minimise dispersion globale composants calculés utilisant argmin1 dispersion globale décompose dispersion intra groupe donnée équation montrer facilement carvalho partir dispersion globale dispersion intra groupe décomposition adapter facilement indices interprétation groupes partition introduits chavent nouvel algorithme qualité globale partition finale indice proche indique partition meilleur qualité groupes homogènes qualité globale partition finale rapport chaque tableau dissimilarité donnée valeur proche indication bonne qualité partition rapport tableau dissimilarité comparaison montre pouvoir discriminant tableau dissimilarité supérieur pouvoir discriminant moyen tableaux dissimilarité application illustrer notre propos montrer utilité nouvel algorithme utilisons données premier concernent chiffres manuscripts numérisés second ensemble rapports classification chiffres manuscripts notre premier exemple concerne partitionnement données multiple features ponible machine learning repository données concerne chiffres manuscrits numérisés images binaires chiffres manuscrits individus décrits variables numériques variables partitionnées différents ensembles coefficients fourier décrivant forme caractères corrélations profil coefficients karhunen moyennes pixels fenêtres moments zernike caractéristiques morphologiques données formées classes priori individus chaque classe correspondant chiffre manuscrit initialement tableaux données considerés tableau individus crits toutes variables tableau mfeat autres tableaux individus décrits selon chacune différentes chaque ayant respectivement tableau mfeatfou tableau mfeatfac tableau mfeatkar tableau mfeatpix tableau mfeatzer tableau mfeatmor variables ensuite tableaux données relationnelles obtenues partir tableaux données moyen distance clidienne tableaux données relationnelles normalisés suivant dispersion totale chavent telle manière elles aient dispersion chaque dissimilarité tableau données relationnelles normalisée dispersion totale prototype global calculé suivant argmin1 notre algorithme classification appliqué abord tableau données tionelle mfeat ensuite simultanément tableaux données relationnelles mfeat mfeatfac mfeatkar mfeatpix mfeatzer mfeatmor correspondant différentes obtenir partition groupes algorithme déroulé algorithme classification automatique données relationnelles multi meilleur résultat critère adéquation selectionné notre comparer partitionnement obtenu façon automatique algorithme partition nement priori données classes critères comparaison choisis global erreur classification indice corrigé measure résultats valeurs indices measure obtenus partir partition finale donnée algorithme appliqué tableau données relationelle mfeat respecti vement valeurs mêmes indices obtenus partir partition finale donnée gorithme appliqué simultanément tableaux données relationnelles correspondant différentes respectivement tableau montre matrice poids pertinence tableaux données relationnelles groupes matrice poids pertinence tableaux dissimilarité groupes poids pertinence tableaux dissimilarités groupes mfeatmor mfeatzer mfeatpix mfeatkar mfeatfou mfeatfac tableaux montre matrice confusion groupes calculée partition finale matrice confusion classes chiffres manuscrits groupes carvalho exemple tableau dissimilarité mfeatmor pertinent définition groupes entre autre tableau dissimilarité mfeatfac poids pertinence presque aussi important celui tableau dissimilarité mfeatmor groupe qualité globale partition finale indice proche indique partition meilleur qualité groupes homogênes qualité globale partition finale rapport chaque tableau dissimilarité montré tableau valeur proche indication bonne qualité partition rapport tableau dissimilarités comparaison montre pouvoir discriminant tableau dissimilarité mfeatmor supérieur pouvoir discriminant moyen tableaux dissimilarité qualité globale partition rapport chaque tableau dissimilarité tableau dissimilarités mfeatmor mfeatzer mfeatpix mfeatkar mfeatfou mfeatfac tableau montre indice hétérogénéité indice qualité chaque groupe exemple groupe chiffre homogène tandis groupe chiffre celui meilleure qualité indice hétérogénéité indice qualité groupe groupe cardinal tableau montre indice jkjtkj donne qualité groupe tableaux dissimilarité valeur indice proche meilleure qualité groupe tableau dissimilarité comparaison entre indices donne tableaux dissimilarité carac térisent groupe exemple tableau dissimilarité mfeatmor caractéristique groupes tandis tableaux mfeatzer mfeatfac caractéristiques groupe chiffre classification rapports utilisée collection rapports activité produits différentes équipes recherche inria institut national recherche informatique automatique activités recherche inria organisées thèmes recherche thèmes algorithme classification automatique données relationnelles multi qualité groupes tableaux dissimilarité tableau dissimilarité groupes mfeatmor mfeatzer mfeatpix mfeatkar mfeatfou mfeatfac recherche correspondent structure organisationnelle permettent seule faciliter présentation activités inria évaluation choix thèmes recherche affectation différentes équipes thèmes prennent compte objectifs stratégiques institut proximité scientifique entre équipes aussi autres contraintes politiques comme volonté faire apparaître thématiques fortes certaines zones géographiques notre comparer partitionnement optenu façon automatique algorithme avons décrit présentation officielle décrirons comme experte donnée priori inria rapports activité rédigés anglais sources documents latex traduits façon automatique publié documents homogènes structure définie contient sections obligatoires autres optionnelles cette application considérons rapports activité équipes recherche inria portant année version rapports représentent total lignes source moctets données rapports sections sélectionnées décrire activité équipes recherche overall objectives scientific foundations dissemination results overall objectives décrit objectifs scientiques équipe alors section scientific foundations décrit fondements discipline ainsi matériel scientifique utile atteinte objectifs section dissemination contient activités ensei gnement implication communauté scientifique comités programme conférence éditoriale organisation séminaires workshop conférences partie results décrit principaux résultats avancées obtenus pendant année premier temps contenu rapports activité traité supprimer tains significatifs words texte passé lemmatiseur supprimer flexions remplacer chaque forme référence lemme forme canonique tables données feature tables construites chacune individus équipes recherche inria décrites fréquents catégories présents variables nombre fréquents section overall objectives scientific foundations dissemination results chaque carvalho cellule table donnée donne fréquence section concernée rapport activité concerné équipe recherche ensuite tables données relationnelles obtenues partir tables données feature tables moyen mesure dissimilarité dérivée coefficient affinité bacelar nicolau supposons chaque individu décrit variable tivaluée presentation modalités catégories individu décrit fréquence modalité dissimilarité entre paire individus donnée toutes tables données relationnelles normalisées suivant dispersion totale chavent telle manière elles aient dispersion chaque dissimilarité table données relationnelles normalisée dispersion totale prototype global calculé suivant argmin1 résultats notre algorithme classification appliqué simultanément tables données relationnelles presentation foundation dissemination bibliography obtenir partition nombre cluster donné algorithme roulé meilleur résultat critère adéquation selectionné détermination nombre approprié classes partition problème sique existe aucune bonne solution notre stratégie détermination nombre classes celle proposée logiciel consite sélectionner meilleur couple inertie intraclasse nombre classes comme diminution nombre classes augmenter inertie intra classe repérer important indice avoir partition bonne qualité coude repéré dérivées premières secondes silva dérivée première discrète nombre classe estdf dérivée seconde discrète lorsque retrouve dérivée usuelle partition classes retenue dérivée seconde maximale partition classes pourrait aussi retenue maximum local critère dérivée première dérivée seconde algorithme classification automatique données relationnelles multi cette partition clusters obtenues notre algorithme comparée gorisation classes équipes recherches données priori inria cette catégorisation classes connue priori suivante mathématiques appliquées calcul simulation algorithmique programmation logiciels architectures réseaux systèmes services calcul distribué perception cognition interaction sciences environnement catégories elles divisées categories sommes intéressés catégories premier niveau entre années laquelle porte analyse rapports classification faite inria certaines équipes recherche évoluées voire disparues cette raison seulement rapports seulement compte comparer classification automatique celle inria classification classes avons générée cohérente celle classes donnée priori demande quelques explications répartition donnée tableau répartition classification rapports thèmes clusters mathématiques appliquées calcul simulation architectures logiciels systèmes programmation algorithmique réseaux systèmes services calcul distribué perception cognition interaction sciences environnement matrice poids pertinence tableaux dissimilarité groupes poids pertinence tableaux dissimilarité classes overall objectives scientific foundations results dissemination 969026 979387 000909 052727 019705 934093 073774 977738 966223 068582 073115 902545 976156 993158 026519 004837 tableau montre clairement thème sciences vironnement artificiel réparti point vocabulaire utilisé clusters suivant traite aspects plutôt mathématiques plutôt cognitifs ainsi cluster pourrait labellisé simulation contrôle modélisation cluster traitement information classement différent expliquer aussi suivant veuille appuyer davantage aspect fondamental aspect application ainsi équipe signes classée groupe classifiaction experte quand regarde libellé français signes linguistiques grammaire algorithmique logique langue comprend rapport beaucoup parler algorithmes vocabulaire classe naturellement cluster proche thème carvalho mauvaise affectation provenir langage ambigüe commun disciplines différentes exemple équipe edelweiss classée cluster proche thème réseau cette équipe occupe effet réseaux réseaux sociaux matrice poids pertinence sections utilisées rapports présentée tableau conclusion article introduit nouvel algorithme classification capable partitionner semble objets tenant compte manière simultanée leurs descriptions relationnelles données plusieurs matrices dissimilarité matrices peuvent avoir générées utilisant différents ensembles variables différentes fonctions dissimilarité rithme exhibe partition prototype chacun clusters ainsi pondération pertinence chacune matrices dissimilarité optimisation critère quation mesure adéquation entre cluster représentant cette pondération pertinence change chaque itération algorithme diffère cluster autre plusieurs outils interprétation groupes partition fournies algorithme aussi introduit utilité algorithme montré utilisant données données concernant chiffres manuscrits numérisés images binaires résultats obtenus données selon plusieurs indices évaluation partition finale utilité indices interprétation algorithme donnent indications potentiel méthod rapports autre aussi bonne pertinence classification générée références bacelar nicolau affinity coefficient diday analysis symbolic speinger heidelberg chavent normalized means clustering hyper rectangles proceedings international symposium applied stochastic models analysis asmda brest france chavent carvalho lechevallier verde clustering methods interval computational statistics cleuziou exbrayat martin sublemontier cofkm centralized method multiple clustering ninth international conference mining miami silva analyse données évolutives application données usage thesis université paris dauphine carvalho csernel lechevallier clustering constrained symbolic pattern recognition letters carvalho lechevallier partitional clustering algorithms symbolic interval based single adaptive distances pattern recognition algorithme classification automatique données relationnelles multi carvalho lechevallier partitioning clustering algorithms based multiple dissimilarity matrices pattern recognition carvalho lechevallier utilisation matrices dissimilarité multiples classification documents extraction gestion connaissances alger algérie diday govaert classification automatique distances adaptatives informatique computer science lechevallier optimisation quelques critères classification automatique application étude modifications protéines sériques pathologie clinique thesis université paris leclerc cucumel concensus classification revue bibliographique mathématique sciences humaines pedrycz collaborative fuzzy clustering pattern recognition summary paper introduces improvement clustering algorithm carvalho partition objects taking account simultaneously their relational descriptions given multiple dissimilarity matrices these matrices could generated using different variables dissimilarity functions method which based namic clustering algorithm relational designed provided partition prototype cluster learn relevance weight dissimilarity matrix optimizing adequacy criterion measures between clusters their represen tatives these relevance weights change algorithm iteration different cluster another moreover various tools partition cluster interpretation furnished algorithm presented experiments demonstrate usefulness clustering method merit partition cluster interpretation tools first machine learning repository concerning handwritten numbers talized pictures second reports which expert classification given priori