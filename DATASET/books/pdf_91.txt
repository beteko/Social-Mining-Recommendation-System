28 1 RNTI E33Description interactive de l’intérêt de l’utilisateur via l’échantillonnage de motifs Moditha Hewasinghage Suela Isaj Arnaud Giacometti Arnaud Soulet Université François Rabelais de Tours LI EA 6300 Campus de Blois 41000 Blois prenom nom univ tours fr Résumé La plupart des méthodes d’extraction de motifs requièrent que l’uti lisateur formalise son intérêt avec une mesure d’intérêt et des seuils L’utili sateur est souvent incapable d’expliciter son intérêt mais il saura juger si un motif donné est pertinent ou non Dans cet article nous proposons une nou velle méthode de découverte de motifs interactive en supposant que seule une partie des données est intéressante pour l’utilisateur En intégrant le retour utili sateur de motifs proposés un à un notre méthode vise à échantillonner des mo tifs avec une probabilité proportionnelle à leur fréquence d’apparition au sein des transactions implicitement préférées par l’utilisateur Nous démontrons que notre méthode identifie exactement les transactions implicitement préférées par l’utilisateur sous réserve de la consistance de ses retours Des expérimentations montrent les bonnes performances de l’approche en terme de précision et rappel 1 Introduction La découverte de motifs est un outil puissant pour extraire des motifs intéressants au sein d’un jeu de données Néanmoins la plupart des approches reposent sur le paradigme de la recherche par requête qui peut être une contrainte à satisfaire ou une mesure à maximiser Il est difficile à l’utilisateur final d’exprimer explicitement son intérêt sous la forme d’une telle requête Pour cette raison l’extraction interactive de motifs van Leeuwen 2014 vise à cap turer cette requête en observant le retour de l’utilisateur au fur et à mesure que des motifs lui sont présentés La plupart des méthodes itèrent un cycle en trois phases Une phase d’extrac tion extrait des motifs pertinents Les premières itérations passées cette pertinence intègre les préférences apprises En effet une phase d’interaction glane les retours de l’utilisateur e g notation des motifs qui seront généralisés par une phase d’apprentissage en un modèle de préférence Dans ce contexte le choix du modèle de préférence s’avère déterminant pour bien identifier l’intérêt de l’utilisateur Par exemple le modèle du produit pondéré associe un poids à chaque item et considère alors le score d’un motif comme le produit des poids de ses items Bhuiyan et al 2012 Dans ce cas aucune distinction sur les transactions ne sera faite Les autres pro positions de la littérature associent à chaque motif un vecteur de caractéristiques Grâce aux retours de l’utilisateur certains vecteurs seront jugés plus pertinents que d’autres et l’apprentis sage de ce classement construira un modèle de préférence sur l’ensemble des motifs Rueping 285 Description interactive de l’intérêt de l’utilisateur via l’échantillonnage de motifs 2009 Dzyuba et al 2014 Dans cet article nous faisons l’hypothèse que les transactions sont divisées en deux parties les transactions préférées et les autres Ainsi l’utilisateur sou haite extraire les motifs qui décrivent ses transactions préférées Il s’agit en quelque sorte d’une généralisation de la découverte de contrastes qui vise aussi à caractériser une partie des tran sactions Mais dans notre cas la variable cible est découverte au cours de l’interaction Au delà de ce modèle de préférence cet article présente une méthode originale basée sur l’échantillonnage de motifs Grâce à cette technique nous montrons comment les préférences apprises peuvent être directement utilisées pour extraire les motifs à présenter à l’utilisateur Si les retours de l’utilisateur correspondent bien à son intérêt nous garantissons à la fois que les transactions préférées seront bien identifiées et que les motifs extraits décriront exactement ces transactions Enfin une étude expérimentale montre l’augmentation rapide du rappel en maintenant une bonne précision même si les transactions préférées sont peu nombreuses 2 Travaux relatifs L’extraction interactive de motifs van Leeuwen 2014 est un problème d’apprentissage bidirectionnel entre l’utilisateur et le système D’une part le système apprend les préférences de l’utilisateur à partir de ses retours sens “de l’utilisateur vers le système” D’autre part l’utilisateur apprend de nouvelles connaissances à partir du jeu de données à travers les motifs fournis par le système sens “du système vers l’utilisateur” Ce problème diffère donc de l’ap prentissage actif traditionnel Settles 2010 qui n’inclut pas le sens “du système à l’utilisateur” Cette distinction est importante Premièrement les requêtes demandées à l’utilisateur sont des motifs et non des transactions Dans la plupart des tâches d’apprentissage actif le retour de mandé par l’utilisateur porte directement sur les objets et non sur la généralisation de ces objets bien qu’il existe quelques exceptions notables Rashidi et Cook 2011 Bessiere et al 2013 Deuxièmement le choix de la requête présentée à l’utilisateur ne peut pas seulement viser à améliorer le modèle de préférence contrairement à l’apprentissage actif traditionnel Pour que l’utilisateur continue d’interagir avec le système ce dernier doit fournir des motifs intéressants à l’utilisateur i e du point de vue de ses préférences Troisièmement la requête présentée à l’utilisateur à chaque itération doit être calculée en quelques secondes pour maintenir une interaction satisfaisante Cette contrainte n’est pas forte dans l’apprentissage actif traditionnel puisque l’espace de recherche des requêtes est petit C’est beaucoup plus difficile d’extraire des motifs intéressants en un temps limité du fait de la grande taille de l’espace de recherche Un des défis de l’extraction interactive de motifs est donc d’extraire des motifs pertinents pour l’utilisateur sens “du système vers l’utilisateur” tout en améliorant son modèle de préfé rences sens “de l’utilisateur vers le système” En pratique les premières méthodes Xin et al 2006 Rueping 2009 ignoraient l’utilisation d’un critère pour favoriser la diversité des re quêtes qui aurait permis l’acquisition complète des préférences Une approche récente Dzyuba et al 2014 a néanmoins montré l’intérêt de tenir compte de la diversité à l’instar de l’appren tissage actif Ce travail a aussi montré l’importance de l’alétoire pour améliorer la diversité Ce besoin d’aléatoire justifie l’utilisation de l’échantillonnage de motifs Bhuiyan et al 2012 En plus de sa diversité intrinsèque nous montrons ici comment tirer parti des propriétés sta tistiques de l’échantillonnage pour contrôler l’erreur du modèle de préférences appris afin de mieux choisir les requêtes motifs extraits comme dans Giacometti et Soulet 2016 286 M Hewasinghage et al Un autre défi est d’extraire de nouveaux motifs à chaque itération en seulement quelques secondes afin de maintenir une interaction satisfaisante Ce besoin n’est pas rempli par les mé thodes traditionnelles d’extraction de motifs Ainsi les premières méthodes Xin et al 2006 Rueping 2009 étaient basées sur une extraction préliminaire et ensuite elles ré ordonnaient cette collection de motifs selon le critère mis à jour en tenant compte de l’évolution du modèle de préférence Cette approche par post traitement n’autorise pas la découverte de nouveaux motifs qui auraient été précédemment omis Plus récemment une approche par recherche en faisceau Dzyuba et al 2014 a été proposée pour extraire à chaque itération de nouveaux mo tifs qui maximisent le critère mis à jour combinant qualité et diversité dans ce cas Une telle approche reste lente et elle ne parvient pas toujours à trouver des motifs très diversifiés Dans ce contexte l’échantillonnage de motifs Bhuiyan et al 2012 est une technique attractive puis qu’elle donne un accès rapide à tous les motifs ayant une valeur non nulle par rapport au citère mis à jour garantissant une très bonne diversité Dans cet article nous adoptons une procédure aléatoire en deux étapes Boley et al 2011 dont la complexité est linéaire avec la taille du jeu de données 3 Formulation du problème Cette section formule en deux temps le problème de la description de l’intérêt de l’utili sateur en exploitant ses retours Auparavant nous rappelons des définitions préliminaires Soit I un ensemble de littéraux nommés items un itemset ou un motif est un sous ensemble de I Le langage des itemsets correspond à L = 2I Un jeu de données transactionnel D est un multi ensemble d’itemsets de L Chacune des observations de D est appelée transaction et ∆ représente l’ensemble de tous les jeux de données possibles La découverte de motifs tire avantage de mesures d’intérêt pour évaluer la pertinence d’un motif Plus précisément une mesure d’intérêt pour un langage L est une fonction définie de L ×∆ dans ℜ Typiquement le support d’un motif X dans un jeu de données D est la proportion de transactions de D qui contiennent le motif X supp X D = |{t ∈ D|X ⊆ t}| |D| 3 1 Description de l’intérêt de l’utilisateur En général on considère que tous les utilisateurs portent un même intérêt pour toutes les transactions Dans notre approche nous considérons que l’intérêt de l’utilisateur n’est pas le même pour toutes les transactions et évidemment différent pour chaque utilisateur Une partie des transactions dénotée par D1 est implicitement préférée par l’utilisateur par rapport aux autres transactions partie dénotée par D0 Par exemple le tableau 1 propose un jeu de données transactionnel avec 4 transactions t1 t4 décrites par 5 items A B C D et E où les transactions t1 et t2 appartiennent à D 1 car elles sont préférées par l’utilisateur L’échantillonnage de motifs Boley et al 2011 donne un accès au langage L en tirant des motifs selon une distribution p L → [0 1] qui est définie par rapport à une mesure d’intérêt m p = m Z où Z est une constante de normalisation Ainsi l’utilisateur a un accès rapide à l’ensemble des motifs du langage et ce sans paramètre excepté la taille potentielle de la réponse Dans notre contexte puisque l’utilisateur n’est pas intéressé par toutes les tran sactions de D mais seulement par un sous ensemble D1 de D nous ne voulons pas extraire l’échantillon de motifs par rapport à une mesure d’intérêt m évaluée sur D mais sur D1 En 287 Description interactive de l’intérêt de l’utilisateur via l’échantillonnage de motifs D Trans Items Préférence t1 A B E 1 t2 A B 1 t3 B C D 0 t4 C D 0 Connu par avance Inconnu TAB 1 Exemple jouet de jeu de données effet la mesure d’intérêt m évaluée sur D1 est plus appropriée car cela focalise l’extraction sur les motifs décrivant les transactions préférées de l’utilisateur Cependant les transactions préférées dans D1 ne sont pas connues par avance Nous formalisons notre problème ainsi Etant donné un jeu de données D contenant un ensemble inconnu de transac tions préférées D1 notre problème consiste à construire une séquence de motifs 〈X1 Xk〉 telle que la probabilité Pi X de tirer un motif X à l’étape i tend vers supp X D1 Z lorsque i tend vers +∞ où Z est une constante de normalisation Z = ∑ X∈L supp X D1 3 2 Interaction avec l’utilisateur Dans la formulation du problème ci dessus nous n’avons pas précisé comment parvenir à découvrir l’intérêt de l’utilisateur i e les transactions préférées D1 qui sont initialement in connues Comme en apprentissage actif une stratégie serait de demander directement à l’uti lisateur si certaines transactions sont intéressantes ou non pour découvrir la classe D1 Dans notre approche parce que le jeu de donnéesD peut être très large surtout par rapport à la taille réduite du jeu de données D1 nous préférons demander à l’utilisateur si un motif extrait est bien une généralisation des transactions préférées Plus précisément nous modélisons le retour de l’utilisateur par un oracle O qui est une fonction de L vers {0 1} Etant donné un motif X nous avons O X = 1 resp 0 si l’oracle donne un retour positif resp négatif pour un motif X Comme le retour utilisateur au sujet d’un même motif X peut changer durant le processus nous pouvons considérer que O est une variable aléatoire Dans cette configuration P 1 X représente la probabilité d’avoir un retour positif sachant le motif X quand l’oracle est consulté Par exemple P 1 AB = 1 signifie que l’oracle donne toujours un retour positif pour AB Maintenant nous devons faire le lien entre les retours de l’utilisateur sur les motifs et les transactions En général nous considérons qu’un utilisateur peut observer soit une transaction t ∈ D soit un motif X ∈ L soit une paire t X où X ⊆ t est une généralisation de t Dans cette configuration P t resp P X est la probabilité que l’utilisateur observe une transaction t ∈ D resp un motif X ∈ L De plus P t X est la probabilité que l’utilisateur observe conjointement une transaction t et un motif X En utilisant la formule des probabilités totales et la définition d’une probabilité conditionnelle nous avons P 1 t = P 1 t P t = ∑ X∈L P 1 t X P t = ∑ X∈L P t ×P X t ×P 1 t X P t = ∑ X∈L P X t ×P 1 X 288 M Hewasinghage et al en faisant l’hypothèse que l’oracle considère seulement le motif X pour déterminer son retour et pas la transaction t qui par la suite n’est pas montrée à l’utilisateur i e P 1 t X = P 1 X En fixant que P X t = 0 si X 6⊆ t nous obtenons finalement P 1 t = ∑ X⊆t P X t ×P 1 X 1 Cette équation montre comment les préférences de l’utilisateur sur les transactions peuvent être inférées de ses retours sur les motifs Cela montre aussi qu’il ne sera pas possible d’ap prendre les transactions préférées des retours sur les motifs si ces retours ne sont pas consis tants Par exemple si P 1 X = 0 pour tous les motifs X ⊆ t alors nous calculons que P 1 t = 0 que t soit une transaction préférée ou non Pour cette raison nous introduisons la notion de consistance de l’oracle par rapport aux transactions préférées D1 Définition 1 Consistance de l’oracle Etant donné un sous ensemble de transactions préfé rées D1 ⊆ D un oracle O est consistant avec D1 si et seulement si pour toute transaction t ∈ D nous avons soit P 1 t > 0 5 si t ∈ D1 soit P 1 t < 0 5 sinon Ainsi si le retour de l’utilisateur est consistant avec ses préférences le problème formulé dans la section précédente peut être résolu en estimant les probabilités P 1 t pour toutes les transactions de t ∈ D En effet si nous parvenons à estimer cette distribution alors il sera possible de tirer des motifs suivant leur support dans D1 Maintenant nous reformulons notre problème de la manière suivante Etant donné un jeu de données D contenant un ensemble inconnu de transactions préférées D1 et un oracle oracle O consistant avec D1 le problème consiste à construire en même temps — une séquence 〈w1 wk〉 de vecteurs de poids ωi définis de D vers ℜ tels que pour chaque transaction t ∈ D nous ayons limi→+∞ wi t = P 1 t et — une séquence 〈X1 Xk〉 de motifs Xi telle que si Pi X dénote la proba bilité de tirer le motif X à l’étape i alors limi→+∞ Pi X = supp X {t ∈ D|P 1 t > 0 5} Z où Z est une constante de normalisation 4 Apprentissage à partir de retours de l’utilisateur 4 1 Algorithme interactif de description des transactions préférées Dans le but de résoudre le problème posé dans la section 3 2 nous proposons d’utiliser une procédure aléatoire en deux étapes pour générer les motifs présentés à l’utilisateur Dans Boley et al 2011 les auteurs montrent comment échantillonner des motifs selon une distribution proportionnelle au support des motifs Dans notre approche nous proposons d’échantillonner des motifs suivant une distribution proportionnelle à leur support pondéré Plus formellement étant donné un jeu de données D et un vecteur de poids w D → ℜ le support pondéré du motif X dans D noté suppω X D est défini par suppω X D = ∑ t∈D X⊆t ω t ∑ t∈D ω t Il est facile de voir que si toutes les transactions de D 1 ont un poids de 1 et que toutes les autres ont un poids de 0 alors suppω X D = supp X D 1 289 Description interactive de l’intérêt de l’utilisateur via l’échantillonnage de motifs Algorithm 1 Echantillonnage de motifs selon un support pondéré Input Un jeu de données D et un vecteur de poids ω Output Un itemset tiré aléatoirement X ∼ suppω L D 1 Soient les poids ω′ définis par ω′ t = 2|t| × ω t pour tout t ∈ D 2 Tirer une transaction proportionnellement à ω′ t ∼ ω′ D 3 return un itemset tiré proportionnellement à la distribution uniforme u X ∼ u 2t L’algorithme 1 adapte la procédure aléatoire en deux étapes Boley et al 2011 pour générer des motifs avec une probabilité proportionnelle à celle de leur support pondéré Maintenant que nous savons comment tirer les motifs présentés à l’utilisateur nous devons montrer comment la probabilité P 1 t de chaque transaction peut être estimée Si les mo tifs présentés à l’utilisateur sont générés en utilisant l’algorithme 1 on a pour tout motif X P X t = 1|2t| Ainsi en utilisant l’équation 1 pour chaque transaction t ∈ D nous avons P 1 t = ∑ X⊆t P X t ×P 1 X = 1 |2t| ∑ X⊆t P 1 X 2 Pour estimer les probabilités P 1 t nous proposons la méthode détaillée par l’algo rithme 2 A chaque étape i cet algorithme commence par tirer un motif Xi ligne 4 se lon son support pondéré si = suppωi Xi D voir l’algorithme 1 Il est ensuite demandé à l’oracle ligne 5 si le motif Xi est intéressant ou non Alors en utilisant la séquence de retours de l’utilisateur 〈 X1 f1 s1 Xi fi si 〉 la pondération ω̄i+1 t est mise à jour pour chaque transaction t ∈ D afin d’approximer P 1 t ligne 7 Ensuite une estimation corrigée de P 1 t notée ω̃i+1 t est calculée à la ligne 8 en exploitant l’inégalité de Bennett Enfin une binarisation de ω̃i+1 t notée ωi+1 t est effectuée à la ligne 9 pour mettre à 1 resp 0 le poids d’une transaction très certainement préférée resp non préférée Le principe de l’intégration des retours utilisateur pour successivement calculer l’estimation moyenne de P 1 t son estimation corrigée puis enfin sa binarisation est détaillé dans la section suivante Algorithm 2 Echantillonnage interactif de motif Input Un jeu de données D et un oracle O 1 i = 1 et ω1 t = ω̄1 t = 0 5 for all t ∈ D 2 Soit F une séquence vide d’observations 3 repeat 4 Tirer un motif Xi de D selon suppwi 5 Ajouter le retour utilisateur Xi O Xi suppwi Xi D à la séquence F 6 for all t ∈ D do 7 ω̄i+1 t = ∑ Xj fj sj ∈F Xj⊆t fj sj ∑ Xj fj sj ∈F Xj⊆t 1 sj 8 Calculer l’estimation corrigée ω̃i+1 t de P 1 t en utilisant ω̄i+1 t 9 Calculer l’estimation binarisée ωi+1 t de ω̃i+1 t 10 end for 11 i = i+ 1 12 until L’utilisateur arrête le processus 290 M Hewasinghage et al 4 2 Intégrer les retours utilisateur à la pondération Estimation Soit une séquence de retours utilisateur F formée des triplets Xj fj sj où pour chaque motif Xj fj est le retour de l’utilisateur et sj est le support du motif au moment du tirage A partir de F une première estimation de la probabilité P 1 t est définie comme suit ω̄F t = ∑ Xj fj sj ∈F Xj⊆t fj sj ∑ Xj fj sj ∈F Xj⊆t 1 sj Intuitivement l’estimation calcule la proportion de retours positifs au sein de l’échantillon en pondérant le retour par sa probabilité de tirage De cette manière un motif qui a deux fois plus de chance d’être tiré a un poids deux fois moins important Avec ce biais de tirage des motifs cette pondération garantit que ω̄F t est une bonne approximation de P 1 t Propriété 1 Etant donnés un jeu de données D et une séquence de retours utilisateur F pour chaque transaction t ∈ D le poids ω̄F t converge vers P 1 t quand |F | tend vers l’infini En pratique cette propriété signifie que l’ajout de nouveaux retours tend à améliorer l’es timation de la probabilité P 1 t Cependant dans l’algorithme 2 comme le tirage d’un motif Xi dépend de l’estimation calculée à l’étape précédente cela peut provoquer des effets de bord Par exemple en faisant l’hypothèse que le motif X0 = ∅ soit initialement tiré et reçoive un retour négatif O ∅ = 0 l’estimation ω̄〈 ∅ 0 1 Z 〉 t de chaque transaction sera 0 1 Z 1 1 Z = 0 parce que l’ensemble vide est inclus dans chacune des transactions et la probabilité de le tirer est 1 Z Dans ce cas aucun motif ne pourrait être tiré à l’étape suivante Il ne serait alors pas possible d’améliorer l’estimation initiale faute de pouvoir obtenir de nouveaux retours Pour éviter cela il est essentiel de réaliser une correction statistique sur l’estimation Estimation corrigée L’idée est de bénéficier de l’estimation ci dessus en calculant un in tervalle de confiance qui borne la probabilité P 1 t Pour cela nous choisissons d’utiliser l’inégalité de Bennett Maurer et Pontil 2009 pour estimer l’erreur courante car elle est vraie quelque soit la distribution de probabilité Après k observations indépendantes d’une variable aléatoire r à valeur réelles dans l’intervalle [0 1] l’inégalité de Bennett garantit que avec une confiance 1 − δ la vraie moyenne de r est au moins r − ǫ où r et σ sont respectivement la moyenne et l’écart type observés dans l’échantillon et ǫ = √ 2σ2 ln 1 δ k + ln 1 δ 3k Nous utili sons ce résultat statistique afin de borner la vraie valeur de P 1 t à partir de la séquence F des retours utilisateurs Propriété 2 Bornes de P 1 t Etant donnés un jeu de données D une séquence de retours F et une confiance 1− δ la probabilité P 1 t de la transaction t est bornée ainsi max {0 ω̄F t − ǫ} ︸ ︷︷ ︸ infF t ≤ P 1 t ≤ min {ω̄F t + ǫ 1} ︸ ︷︷ ︸ supF t avec ǫ = √ 2σ ln 1 δ k+ ln 1 δ 3k où σ = √ ω̄F t − ω̄F t 2 est l’écart type de ω̄F t Cette propriété est importante car elle approxime l’erreur de notre estimation ω̄F Re prenons l’exemple précédent où le tirage de l’ensemble vide à la première itération donnait 291 Description interactive de l’intérêt de l’utilisateur via l’échantillonnage de motifs ω̄{ ∅ 0 1 Z } t = 0 pour chaque transaction t Dans ce cas les bornes inférieure et supérieure sont respectivement 0 et 1 Bien sûr la valeur ω̄F t est dans cet intervalle mais il est plus prudent de minimiser l’erreur ici 0 5 De manière générale pour estimer P 1 t nous pro posons finalement de prendre la valeur moyenne entre ces deux bornes en calculant ω̃F t = infF t + supF t 2 Cette estimation corrigée tend vers la probabilité P 1 t quand le nombre de retours uti lisateur augmente puisque les deux bornes tendent vers cette même probabilité Néanmoins même si l’oracle O est consistant avec D1 la probabilité P 1 t n’est pas égale à 1 pour une transaction préférée et 0 pour les autres Donc en utilisant cette estimation corrigée le tirage réalisé ne convergerait pas vers un tirage proportionnel au support dans D1 Binarisation de l’estimation La binarisation de l’estimation consiste juste à mettre un poids de 1 lorsqu’il est certain que la probabilité P 1 t est supérieure à 0 5 ou à l’inverse de mettre un poids de 0 si P 1 t est inférieure à 0 5 avec certitude Cette notion de certitude repose sur l’erreur estimée avec la propriété 2 ωF t =    1 si infF t > 0 5 0 si supF t < 0 5 infF t +supF t 2 sinon 3 Avec cette pondération si l’oracle est consistant avec D1 alors le poids d’une transaction préférée de D1 tend vers 1 et celui d’une transaction non préférée tend vers 0 De manière intéressante la diminution à 0 des transactions non préférées favorise le tirage d’autres tran sactions dont l’estimation n’est pas encore suffisamment affinée A l’inverse l’augmentation à 1 des transactions préférées défavorise le tirage d’autres transactions encore incertaines Ainsi la préoccupation de fournir des motifs pertinents à l’utilisateur est soutenue Grâce à l’utilisation de propriétés statistiques il est possible de conclure sur la bonne convergence de la méthode Théorème 1 Convergence Etant donnés un ensemble de transactions préférées D1 ⊆ D et un oracle O consistant avec D1 pour chaque transaction t ∈ D les poids ω̄i t et ω̃i t calculés par l’algorithme 2 convergent vers P 1 t quand i tend vers l’infini De plus ωi t converge vers 1 ssi t ∈ D1 sinon vers 0 quand i tend vers l’infini Par ailleurs les complexités temporelle et en espace de cette approche en O k|D||I| où k est le nombre de motifs tirés sont excellentes En effet les pondérations sont calculées incrémentalement en conservant un nombre fixe d’informations pour le numérateur et le déno minateur Il n’est pas nécessaire de conserver le détail de tous les retours de l’utilisateur 5 Expérimentations Dans cette section nous rapportons les évaluations expérimentales réalisées sur 6 jeux de données provenant de l’UCI Machine Learning repository archive ics uci edu ml le tableau 2 en donnant les principales caractéristiques Les jeux de données sont utilisés sans 292 M Hewasinghage et al D |D| |I| E[|D1|] |D| |D1min| D |D| |I| E[|D 1|] |D| |D1min| Abalone 4 177 28 10 9% 1 374 Mushroom 8 124 119 0 9% 3 646 Connect 67 557 129 0 23% 129 Sick 2 800 58 2 97% 450 Hypo 3 163 47 5 19% 1 035 Waveform 5 000 67 0 09% 1 662 TAB 2 Caractéristiques des jeux de données pré traitements particuliers un item correspondant généralement à un couple attribut valeur Notons enfin que par construction les motifs retournés par l’algorithme 1 ne peuvent contenir deux items portant sur le même attribut Protocole expérimental Pour chaque jeu de données D le sous ensemble D1 ⊆ D des tran sactions préférées est construit de deux manières différentes Pour les expériences sur la vi tesse de convergence les transactions préférées sont générées aléatoirement Un motif X est tiré aléatoirement avec une probabilité proportionnelle à son support dans D et D1 est définie comme étant les transactions contenant X i e D1 = {t ∈ D X ⊆ t} Pour chaque jeux de données 1 000 motifs et sous ensembles D1 sont générés aléatoirement et les différentes mesures reportées sont les moyennes arithmétiques des 1 000 expérimentations réalisées Pour les expériences sur l’influence de 1 − δ 1 000 expérimentations sont également réalisées où la classe minoritaire est le sous ensemble de transactions préférées La cardinalité de cet en semble noté D1min est précisée dans la dernière colonne du tableau 2 Nous utilisons un oracle déterministe modélisant un utilisateur pour lequel un motif est intéressant si sa fréquence d’apparition dans le sous ensembleD1 des transactions préférées est supérieure à sa fréquence d’apparition dans l’ensemble de toutes les transactions O X = 1 si supp X D1 > supp X D 0 sinon A chaque itération de l’algorithme 2 la qualité est évaluée avec trois mesures Precision Rappel et F mesure Elles comparent les transactions prédites comme préférées D par rap port aux transactions réellement préférées D1 Plus précisément on a Precision = TPTP+FP Rappel = TPP et F mesure = 2×Precision×Rappel Precision+Rappel où TP = |D ∩ D1| est le nombre de vrais positifs FP = |D ∩ D0| est le nombre de faux positifs et P = |D1| est le nombre de transactions préférées de D Par ailleurs sur une fenêtre glissante de longueur 50 nous mesurons la proportion P 1 de motifs présentés à l’utilisateur qui l’intéressent i e les motifs présentés qui sont évalués positivement par l’oracle Soit une séquence F = 〈 X1 f1 s1 Xk fk sk 〉 de k > 50 retours utilisateur on a P 1 = ∑k i=k−49 fk 50 Enfin sauf si indication contraire le niveau de confiance 1− δ est fixé à 90% Convergence de la méthode Le premier résultat important de la figure 1 est que la mesure de rappel est monotone croissante quel que soit le jeu de données De plus cette croissance peut être très rapide Pour trois des jeux de données Abalone Hypo et Sick la mesure de rappel dépasse 50% après moins de 50 itération et 70% après 200 itérations Elle dépasse même 90% pour 4 des 6 jeux de données après 500 itérations alors que la complexité du problème à résoudre est importante La troisième colonne du tableau 2 représente pour chaque jeu de données la taille relative moyenne de D1 sur les 1 000 itérations par rapport à la taille totale du jeu de données D On constate ainsi que la taille des sous ensembles de transactions D1 à identifier est toujours très faible par rapport à la taille totale des jeux de données 10 9% pour Abalone 5 2% pour Hypo et un peu moins de 3% pour Sick 293 Description interactive de l’intérêt de l’utilisateur via l’échantillonnage de motifs 0 0 2 0 4 0 6 0 8 1 0 200 400 600 800 1000 R e c a ll Number of iterations Abalone Hypo Mushroom Connect Sick Waveform 0 0 2 0 4 0 6 0 8 1 0 200 400 600 800 1000 P re c is io n Number of iterations Abalone Hypo Mushroom Connect Sick Waveform FIG 1 Evolution des rappel et précision avec le nombre d’itérations La convergence est plus lente pour deux des jeux de données Connect et Waveform Pour Connect le rappel dépasse néanmoins 90% après 1 800 itérations Enfin il dépasse 90% pour Waveform après 3 900 itérations Ces convergences plus lentes s’expliquent par une taille encore plus faible des sous ensembles D1 de transactions préférées à identifier Dans la troisième colonne du tableau 2 on note en effet que la taille relative des sous ensembles de transactions à identifier est de seulement 0 23% et 0 09% pour les jeux de données Connect et Waveform Ces pourcentages signifient qu’il s’agit en moyenne d’identifier par interaction de l’ordre de 150 transactions préférées sur 67 557 pour Connect et de l’ordre de 4 transactions préférées sur 5 000 pour Waveform La mesure de précision commence toujours par décroître avant d’augmenter Néanmoins la croissance de la mesure de précision débute après moins de 200 itérations pour 4 des jeux de données Abalone Hypo Mushroom et Sick et après environ 2 000 itérations pour deux autres jeux de données Enfin le niveau de précision final atteint reste satisfaisant pour tous les jeux de données au regard des excellents niveaux de rappel obtenus et de la difficulté d’identi fier avec des interactions un sous ensemble de transactions préférées de taille très faible L’évolution de la F mesure est présentée en figure 2 ainsi que le taux de motifs inté ressants P 1 présentés à l’utilisateur décrivant ses transactions préférées On constate une croissance monotone de ces taux pour tous les jeux de données la croissance est beaucoup plus lente pour Connect et Waveform et non visible sur les 1 000 premières itérations Pour les autres jeux de données ce taux reste très variable après 1 000 itérations entre 29% pour Sick et 63% pour Abalone En croisant ces taux avec la taille relative des ensembles de transactions préférées troisième colonne du tableau 2 on note que le taux de motifs intéressants présentés à l’utilisateur est d’autant plus important que cette taille relative est importante Impact du niveau de confiance Cette deuxième série d’expériences a pour objectif de mesurer l’impact du niveau de confiance dans la convergence de la méthode Pour rappel ce taux est utilisé pour estimer les bornes dans lesquelles se situent les probabilités P 1 t et réaliser une binarisation des probabilités estimées voir section 4 2 Les évolutions étant similaires sur les 6 jeux de données la figure 3 présente uniquement les résultats pour Mushroom Lorsque le niveau de confiance exigé augmente les bornes calculées pour corriger les poids estimés des transactions sont moins étroites Ainsi la convergence des poids est plus lente et leur binarisa tion est retardée Il en résulte une croissance plus lente du rappel lorsque le niveau de confiance 294 M Hewasinghage et al 0 0 2 0 4 0 6 0 8 1 0 200 400 600 800 1000 F − m e a s u re Number of iterations Abalone Hypo Mushroom Connect Sick Waveform 0 0 2 0 4 0 6 0 8 1 0 200 400 600 800 1000 P ro p o rt io n o f p o s it iv e f e e d b a c k Number of iterations Abalone Hypo Mushroom Connect Sick Waveform FIG 2 Evolution de la F mesure et du taux de motifs intéressants avec le nombre d’itérations 0 0 2 0 4 0 6 0 8 1 0 200 400 600 800 1000 R e c a ll Number of iterations Confidence 0 90 Confidence 0 95 Confidence 0 99 0 0 2 0 4 0 6 0 8 1 0 200 400 600 800 1000 P re c is io n Number of iterations Confidence 0 90 Confidence 0 95 Confidence 0 99 FIG 3 Précision et rappel suivant la confiance pour Mushroom est élevé Mais en contrepartie cette croissance plus lente du rappel est contrebalancée par une décroissance plus faible de la précision en première phase de convergence On notera que cette réduction de la décroissance de la précision peut être très significative i e de près de 10% sur les deux jeux de données en passant d’un niveau de confiance de 95% à 99% Pour finir on notera que si les mesures de rappel et précision évoluent différemment suivant le niveau de confiance tout particulièrement en début de séquence les rappel et précision tendent finalement vers des valeurs limites similaires les courbes se rapprochant en fin de séquence Ainsi l’influence du niveau de confiance sur les évolutions des mesures de rappel et précision constitue une piste intéressante pour analyser comment contrôler et accélérer la convergence de la méthode 6 Conclusion et perspectives Cet article présente une nouvelle méthode d’extraction interactive de motifs en exploitant l’échantillonnage de motifs Au delà de l’efficacité cette technique offre des garanties sta tistiques sur l’apprentissage des préférences et donc sur la convergence de l’approche Les 295 Description interactive de l’intérêt de l’utilisateur via l’échantillonnage de motifs expérimentations illustrent cette bonne convergence sur plusieurs jeux de données Le rappel de la méthode augmente rapidement et la précision reste raisonnable même si l’intérêt de l’uti lisateur ne porte que sur quelques transactions Le problème peut se généraliser facilement à d’autres mesures d’intérêt que le support On pense évidemment à une mesure pour identifier des contrastes entre D1 et D0 La modélisation de l’intérêt de l’utilisateur pourrait considérer une pondération non binaire et de manière plus ambitieuse cette pondération pourrait même être étendue aux items voire à l’ensemble des couples item transaction Remerciements Ce travail a été partiellement soutenu par le CNRS PEPS 2016 projet Préfute Références Bessiere C R Coletta E Hebrard G Katsirelos N Lazaar N Narodytska C G Quimper et T Walsh 2013 Constraint acquisition via partial queries In IJCAI’2013 pp 7 Bhuiyan M S Mukhopadhyay et M A Hasan 2012 Interactive pattern mining on hidden data a sampling based solution In Proc of the 21st ACM CIKM 2012 pp 95–104 ACM Boley M C Lucchese D Paurat et T Gärtner 2011 Direct local pattern sampling by efficient two step random procedures In Proc of the 17th ACM SIGKDD 2011 pp 582–590 Dzyuba V M v Leeuwen S Nijssen et L De Raedt 2014 Interactive learning of pattern rankings International Journal on Artificial Intelligence Tools 23 06 1460026 Giacometti A et A Soulet 2016 Frequent pattern outlier detection without exhaustive mining In Pacific Asia Conference on Knowledge Discovery and Data Mining pp 196–207 Maurer A et M Pontil 2009 Empirical bernstein bounds and sample variance penalization arXiv preprint arXiv 0907 3740 Rashidi P et D J Cook 2011 Ask me better questions active learning queries based on rule induction In Proc of the 17th ACM SIGKDD 2011 pp 904–912 Rueping S 2009 Ranking interesting subgroups In Proceedings of the 26th Annual International Conference on Machine Learning pp 913–920 ACM Settles B 2010 Active learning literature survey University of Wisconsin Madison 52 55 66 11 van Leeuwen M 2014 Interactive data exploration using pattern mining In Interactive Knowledge Discovery and Data Mining in Biomedical Informatics pp 169–182 Springer Xin D X Shen Q Mei et J Han 2006 Discovering interesting patterns through user’s interactive feedback In Proc of the 12th ACM SIGKDD 2006 pp 773–778 ACM Summary This paper proposes an interactive pattern mining method assuming that only some trans actions are interesting for the user By integrating his feedback our method aims at sampling patterns with a probability proportional to their frequency in these preferred transactions We demonstrate that our method accurately identifies the preferred transactions if user feedback are consistent Experiments show the good performances of the approach 296 