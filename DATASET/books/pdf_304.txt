Correction automatique de SVM pour dérivait classification des données Alexandra Degeest *, **, Benoît Frenay *, Michel Verleysen * * machine Learning Group, ICTEAM, Université Catholique de Louvain, Place du Levant 3, 1348 Louvain-la-Neuve, Belgique ** ISIB , Haute-Ecole Paul-Henri Spaak Rue Royale 150, 1000 Bruxelles, Belgique alexandra.degeest@uclouvain.be, degeest@isib.be Résumé. la dérive Concept est une caractéristique importante de flux de données réelles qui peuvent faire des techniques habituelles d'apprentissage de la machine deviennent rapidement inadaptés. Ce document porte sur le problème de la dérive concept soudaine des problèmes de classification pour lesquels des techniques standard peuvent échouer. A cet effet, le soutien des machines vectorielles (SVM) sont automatiquement corrigées pour faire face à un nouveau dériva soudain ensemble de données. Résultats sur des ensembles de données du monde réel avec plusieurs types de dérive brutale indiquent que la méthode est en mesure de corriger le SVM afin de mieux classer les nouvelles données après la dérive du concept, en utilisant une correction en fonction de la différence entre l'ensemble de données initial et le nouveau dérivé ensemble de données, même lorsque le nouvel ensemble de données est faible. 1 Introduction Concept dérive dans les flux de données du monde réel est une préoccupation standard. la dérive Concept se produit lorsque la distribution sous-jacente des données change au fil du temps. Il peut se produire de plusieurs façons: la dérive soudaine (modification brusque des données distribution statistique), la dérive progressive (période de temps où deux distributions différentes sont actifs), la dérive progressive (modification progressive des données distribution statistique) ou des contextes récurrents (réapparition périodique des différentes distributions statistiques) (Zliobaite, 2010). Cet article traite de la dérive soudaine. Les raisons pour lesquelles la dérive concept soudain se produit dans des ensembles de données sont nombreuses et diverses. À titre d'exemple, dans les applications industrielles, les données peuvent dériver soudainement en raison de l'entretien du moteur, car l'outil a été déplacé ou parce que les nouvelles données ont été recueillies par une autre personne. L'apparition de la dérive du concept dans les flux de données perturbe souvent les techniques habituelles d'apprentissage de la machine et, par conséquent, apporte la nécessité de développer de nouvelles techniques d'apprentissage ou d'adapter ceux qui existent déjà. machines à vecteurs de support (SVM) de sont un outil puissant, couramment utilisé pour la classification des données de grande dimension. Cependant, SVM peuvent rapidement devenir inutiles lorsque les données sont sujettes à la dérive du concept. L'objectif de cet article est de proposer une méthode pour corriger automatiquement le modèle SVM face à la dérive soudaine d'un problème de classification. L'objectif est double. Tout d'abord, l'objectif est de nous permettre d'utiliser le premier ensemble de données (avant la dérive) pour l'apprentissage du modèle, ce qui est particulièrement utile lorsque le second ensemble de données (après la dérive) est faible. Le deuxième objectif est de corriger la décision hyperplan de mieux classifier de nouveaux ensembles de données, même lorsque leur distribution statistique (un peu) diffère de la distribution du premier ensemble de données. Deux hypothèses ont été faites dans ce travail. Tout d'abord, les étiquettes des données sont inconnues dérivaient. En second lieu, le jeu de données est faible a dérivé - 311 - Correction automatique de SVM pour dérivait figure de classification des données. 1 - Des types structuraux de dérive concept, inspiré par Zliobaite (2010). par rapport au premier ensemble de données. L'article 2 est une brève revue de la littérature sur les différents types de dérive du concept. Le problème et la méthode proposée sont décrites respectivement dans les sections 3 et 4. La section 5 présente les résultats expérimentaux alors que la section 6 conclut le travail. 2 dérive Concept Concept dérive se produit lorsque la distribution des données change au fil du temps. Ce phénomène se produit fré- quently dans les flux de données du monde réel. Pour faire face à la dérive du concept, de nouvelles méthodes d'apprentissage de la machine doivent être développées ou techniques communes doivent être améliorées. Plusieurs aperçus approfondis sur la dérive concept ont été écrits (Zliobaite, 2010; Tsymbal, 2004). En consé- ING Zliobaite (2010) devraient être plus adaptées au problème lui-même, les techniques de dérive de concept, car trop d'études recherchent une réponse universelle à des dérives en général, ce ne sont pas opt assez iMAL. En effet, il existe plusieurs types de dérive concept (voir la figure 1), tels que la dérive soudaine, la dérive progressive, la dérive progressive et contextes récurrents (Zliobaite, 2010). Chaque type de dérive est associée à une classe spécifique des problèmes réels et a besoin d'une approche spécifique. Ce document fait face à des problèmes de dérive brutale; ceux-ci sont communs dans l'industrie et la médecine, par exemple. dérive brutale peut se produire en raison de l'entretien du moteur, le déplacement de la machine ou une modification non souhaitée dans des conditions environnementales. Par exemple, si un médecin enregistre un ECG à partir d'un premier patient lundi et d'un deuxième patient mardi, les conditions environnementales peuvent avoir changé (température, l'emplacement des sondes...). Les deux propriétés de jeux de données (distribution...) Sera différent, qui peut entraîner une dérive. Cependant, il serait vraiment intéressant de pouvoir utiliser l'ensemble de données à partir du premier ensemble de patients avec l'ensemble de données du deuxième patient, sachant combien il peut être difficile d'obtenir un ensemble de données de formation suffisamment grande. 3 Énoncé du problème Cet article traite du problème de la dérive concept soudaine des problèmes de classification. La principale question est « Comment garder et corriger un modèle M1, a appris la base de données D1, afin de l'utiliser pour évaluer un concept voguaient une autre base de données D2? » Deux hypothèses principales sont faites dans ce travail. La première est que les étiquettes du dérivé données D2 ne sont pas connus; ce qui correspond à des situations réalistes. Pour le premier jeu de données D1, avant la dérive, un spécialiste est disponible pour classer les résultats au cours des périodes de formation et de validation. Cependant, pour le deuxième jeu de données D2, après la dérive, par exemple, après un déplacement d'outil, aucun spécialiste est plus disponible et il serait trop coûteux d'appeler un expert pour donner les étiquettes chaque fois qu'il ya une légère dérive sur la distribution statistique. La seconde hypothèse est que le jeu de données a dérivé D2 est beaucoup plus faible - 312 - A. Degeest et al. que l'ensemble de données undrifted D1. Cela correspond également à une situation commune: après la dérive, le modèle doit encore bien performer, même si le nouvel ensemble de données D2 est uniquement composée de quelques cas. Il est donc intéressant de trouver une méthode qui fonctionne sur un petit ensemble de données non marqué. SVM sont déjà utilisés pour la détection de dérive concept (Campigotto et al, 2010;. Dries et al, 2009;.. Klinkenberg et al, 2000) et pour l'apprentissage progressif (Rüping, 1999). Le travail le plus proche de ce document, par Yang et al. (2007), utilise également SVM à face dérive brutale. La différence entre fonda- mentale Yang et al. (2007) et ce travail est que Yang et al. (2007) a besoin de données étiquetées dans l'ensemble de données a dérivé pour adapter le classificateur. En outre, il convient de noter que Yang et al. (2007) a besoin d'un pré-traitement consistant à sélectionner certains cas, dans l'ensemble de données, ce qui pourrait être risqué si l'ensemble de données est faible. L'originalité du procédé décrit dans le présent document est qu'il adapte le modèle directement hyperplan aux données dérivé non marquée, basée sur les distributions a dérivé et de données undrifted. Il n'y a pas besoin d'une sélection hasardeuse de données de D2, et il n'y a pas besoin d'étiquettes sur ces données dérivaient. Cela a l'avantage d'offrir une solution simple et rapide correction au modèle, une fois que les données ont dérivé. Il est rapide parce que le modèle n'a pas besoin d'être formé à nouveau; en particulier les méta-paramètres du modèle ne doivent pas nécessairement être sélectionné et validé à nouveau, après la dérive du concept, ce qui peut prendre du temps. 4 Support Vector Machine avec correction de données Drifted Cette section présente la principale contribution de cet article. Une méthode pour modèles SVM corrects face à la dérive soudaine est décrite. Pour les modèles de SVM corrects, la méthode utilise une correction en fonction de la différence entre l'ensemble de données initial et le nouvel ensemble de données dérivait. Que D1 représente l'ensemble de données undrifted avec des instances marquées et D2 le jeu de données sans étiquettes ont dérivé. Le modèle M1 apprend que SVM de D1. Les méta-paramètres du SVM sont sélectionnés par validation croisée. Ensuite, la classification des M1 sur D1 est évaluée. Sans modifier M1, le modèle est évalué sur le jeu de données D2 a dérivé, qui peut entraîner un taux d'erreur de classification plus grande, en raison de la dérive brutale. Le principe de l'algorithme de correction proposé est alors d'utiliser les valeurs de décision de M1 sur D1, appelé M1 (D1) et de M1 sur D2, appelé M1 (D2). Les valeurs de décision représentent les distances entre l'hyperplan de séparation et de chaque instance de l'ensemble de données. Chaque instance (x, y) des ensembles de données D1 est constitué d'un vecteur de particularité x ∈ Rn et une étiquette de classe y. Soit ω le vecteur de poids et b le seuil. La distance entre l'hyperplan et chaque instance de l'ensemble de données est ensuite | ωx + b | / || ω || où ωx + b est l'équation d'hyperplan, conduisant à la fonction de décision f (x) = signe (ωx + b). Avant la dérive, le hyperplan optimal est celui avec la marge maximale de séparation entre les classes de l'ensemble de données undrifted D1. Les valeurs de décision M1 (D2) représente la distance entre le même hyperplan, calculé sur D1, et chaque instance du jeu de données D2. Une fois que les valeurs de décision ont été calculées sur D1 et D2, les fonctions de densité de probabilité sont des estimations sur les deux ensembles. La figure 2 montre un exemple, avec une droite M1 (D1) et une ligne en pointillés pour M1 (D2). des fonctions de densité de probabilité des valeurs de décision sont utilisés parce qu'ils sont un moyen facile de caractériser un tracé à une dimension des différences entre les fonctions de densité de probabilité de M1 (D1) et M1 (D2). Lorsque les fonctions de densité de probabilité ont été estimés, la distance entre eux peut être mesurée. A cet effet, l'intégrale de la différence quadratique entre les deux fonctions de densité est calculée. L'étape suivante de la procédure consiste à modifier le modèle afin de mieux - 313 - Correction automatique de SVM pour dérivait classification des données figure. 2 - Méthode pour corriger un modèle SVM face dérive brutale; voir le texte pour plus de détails. adapter les données dans D2. A cet effet, les valeurs de décision M1 (D2) sont décalés par α (devenant M1’ (D2)) afin de minimiser la distance entre M1’ (D2) et M1 (D1). Décaler les ues de la décision équivaut à décaler l'hyperplan SVM perpendiculairement à lui-même, ou, de manière équivalente, pour décaler les données D2 dans la même direction. La valeur optimale de α est obtenu par une descente de gradient sur la distance entre les deux fonctions de densité de probabilité. Ce facteur de correction est ensuite utilisée pour corriger l'hyperplan SVM afin d'obtenir le modèle corrigé M1’ . L'application du nouveau modèle M1’ sur des données D2 devrait se traduire par des performances nettement améliorées par rapport à l'aide du modèle M1 sur D2. La nouvelle fonction de décision de M1’ est f »(x) = signe (ωx + b + α). La figure 2 décrit le procédé entier. Les flèches simples représentent l'utilisation des données undrifted D1 et les flèches en pointillés représentent l'utilisation de dérivé de données D2. 5 expériences Les expériences de cette section montrent que le déplacement du hyperplan SVM, basé sur un facteur tive CORREC- α, sans apprentissage supplémentaire, peut atteindre rapidement et de bons résultats face à la dérive soudaine, même sur un petit jeu de données D2 et l'absence de données marquées est disponible dans cet ensemble de données. Pour ces expériences, deux bases de données réelles, les oiseaux (Jacques et al., 2010) et Crabes (cloche Camp- et al., 1974) ont été utilisés. La première base de données Oiseaux se compose d'oiseaux de la même espèce avec différentes origines géographiques. Cinq variables morphologiques ont été mesurées sur 206 oiseaux de chaque espèce. A partir de ces variables, le modèle apprend à classer les oiseaux en deux groupes: les hommes et les femmes. La seconde base de données de crabes a 100 lignes et 6 colonnes, décrivant des 5 mesures morphologiques sur les crabes des deux sexes. Le modèle apprend aussi à classer les oiseaux en deux groupes: les hommes et les femmes. Sur ces bases de données, différentes amplitudes de dérive concept ont été artificiellement ajouté, afin de valider la méthodologie proposée. Base de données des oiseaux. Pour la première expérience, la taille de D2 a été limitée à 80 cas en D1 a gardé ses 206 cas. Les 80 cas de D2 ont été sélectionnés parmi e au hasard e deux classes (hommes et femmes) et la proportion initiale des classes ont été respectées. Sur ces cas, sept amplitudes différentes de dérive concept ont été ajoutés, à partir d'une très petite dérive à une modification importante des données. Pour chaque fonction, correspond la dérive (fixe) à 9, 18, 24, 26, 30, 36 et 47% de l'écart-type caractéristique. Figure 3 - 314 - A. Degeest et al. FIGUE. 3 - gauche: erreurs de classification pour plusieurs amplitudes de dérive sur les oiseaux (en haut) et les bases de données Crabes (en bas), avant la correction (gris) et après correction (noir) du modèle M1 sur le jeu de données a dérivé D2. A droite: les erreurs de classification pour plusieurs tailles de D2. montre l'amélioration des performances de classification après la correction de SVM a été AP- retors. Pour la seconde expérience, une amplitude fixe de la dérive a été fixé à une des caractéristiques de 20% assez réaliste l'écart-type D2. Huit différentes tailles de jeu de données D2 ont été utilisées: 24, 50, 80, 100, 120, 150, 180 et 206. La figure 3 montre que le pourcentage d'erreur de classification chute après la correction pour toutes les tailles d'ensembles de données. Crabes Base de données. Des expériences similaires ont été réalisées sur la base de données Crabes. Pour la première expérience, quatre amplitudes différentes de la dérive de conception ont été ajoutés à D2: 3, 6, 13 et 20% de l'écart-type caractéristique. La taille de D2 a été réglée sur 40 cas, tandis que D1 a conservé ses 100 instances. Les 40 cas de D2 ont été choisis au hasard parmi les deux classes et la proportion initiale des classes ont été respectées. La figure 3 montre qu'une amélioration bonne pourcentage après la correction a été obtenue pour toutes les amplitudes de dérive. Pour la seconde expérience, une amplitude fixe de la dérive a été maintenu 15% de l'écart-type des fonctions. Ensemble de données ont été utilisées plusieurs tailles de D2: 20, 40, 60, 80 et 100. La figure 3 montre que le pourcentage d'erreur de classification baisse après la correction pour chaque taille de données. 6 Conclusions Ce document propose une méthode pour corriger automatiquement la machine à vecteurs de support algo- rithme face à la dérive soudaine d'un problème de classification. Pour classer correctement la nouvelle sans étiquette dérivait données, la méthode proposée permet d'utiliser le modèle appris sur les données initiales (BE- - 315 - Correction automatique de SVM pour dérivait dérive antérieure de classification des données) et de corriger directement sa décision hyperplan en utilisant la distribution statistique des instances dérivé. Les expériences ont montré que le déplacement du hyperplan SVM, en fonction d'un facteur de correction, sans apprentissage supplémentaire ni validation méta-paramètres, peut obtenir des résultats simples et bons face à la dérive soudaine. Le concept de dérive CV Est caracteristique UNE des flux de importantes Les Donnees REELLES Qui peut les techniques RENDRE Vite de classiques d'apprentissage inadaptées la machine. Cet article du Traité concept de dérive les Dans soudain de classification where Problèmes les techniques classiques évincés peuvent échouer. A this fin, les SVMs visage Sont au automatiquement corrigés NEM de driftées Données soudainement. Les Résultats sur des Bases de données REELLES types de Avec la dérive Différents montrent Que la soudain is capable de méthode le SVM Corriger de better classificateur AFIN les après le Données nouvelles dérive, en juin correction Utilisant sur la basée l'ensemble difference between initial de Données et le NEM Drifte, si same-ci Celui est petit. - 316 -