ensembles de formation représentatifs pour la classification et la variabilité des distributions empiriques Saaid Baraty, Dan Simovici Université du Massachusetts Boston sbaraty@cs.umb.edu, dsim@cs.umb.edu Résumé. Nous vous proposons une nouvelle approche pour l'estimation de la taille des ensembles de formation qui sont nécessaires pour la construction de modèles valides dans l'apprentissage de la machine et l'exploration de données. Notre objectif est de fournir une bonne représentation de la population sous-jacente sans faire des hypothèses distributifs. Notre technique est basée sur le calcul de l'écart-type des statistiques χ2- d'une série d'échantillons. Lorsque les statistiques successives sont relativement proches, nous supposons que les échantillons produits représentent de manière adéquate la véritable distribution sous-jacente de la population, et les modèles tirés de ces échantillons se comportent presque aussi bien que les modèles tirés de l'ensemble de la population. Nous validons nos résultats par des expériences impliquant des classificateurs de différents niveaux de capacités de complexité et d'apprentissage. 1 Introduction L'estimation d'une taille échantillon qui permet la conclusion d'un bon modèle est une partie importante du processus d'apprentissage. Nous cherchons à déterminer la taille minimale d'un échantillon qui est très susceptible d'être un représentant de « juste » de la population sous-jacente. Les modèles tirés de ces échantillons se comportent presque aussi bien que les modèles appris sur la population entière et toute augmentation de la taille de l'échantillon entraînerait une augmentation négligeable de la qualité des modèles. Notre objectif est de déterminer la taille des échantillons qui sont suffisantes pour faire en sorte que ces échantillons représentent Adenova quately la population sous-jacente. Ces échantillons sont utilisés comme la formation de jeux pour les modèles comparables en con- construction définies par leurs performances à celles déduites de l'ensemble de la population, mais sont moins chers à construire. Les articles 2 et 3 décrivent en détail notre approche pour trouver la taille d'un échantillon d'un ensemble de données et une population respectivement. Le travail expérimental est présenté à la section 4. 2 Estimation de la taille d'un échantillon de données Soit U = {u1, u2,. . . , Un} un ensemble d'attributs. L'ensemble des états possibles pour ui d'attribut, Dom (ui), est supposé être fini et est communément appelé domaine ui. La notion de domaine d'attributs est étendue aux ensembles d'attributs de définition de l'ensemble Dom (V) pour l'ensemble des attributs V ⊆ U comme Dom (V) = Πv∈V Dom (v). - 299 - Estimation de la taille des ensembles de formation d'un ensemble de données de U est un D multi-ensemble de tuples t ∈ Dom (U). La multiplicité d'un membre de t D est la numberMD (t) qui est égal au nombre d'occurrences de tuple t en D. La taille de D | D | = Σt∈dom (U) MD (t). Laissez PU (t) indiquent la distribution de probabilité conjointe inconnue de U où t ∈ Dom (U). Définir le domaine λ-actif de U comme l'ensemble AdomU (λ) = {t ∈ Dom (U) | PU (t) ≥ λ}, où 0 ≤ λ <1 est un paramètre défini par l'utilisateur qui l'on se réfère sous le nom de seuil de valeur aberrante. Définition 2.1. NλS = (MS (t1),..., MS (tk)) est le vecteur de fréquence extraite du ple S pour λ de données. Si ELEM (D) -AdomDU (λ) 6 = ∅, nous ajoutons un tuple supplémentaire pour tenir compte des tuples consi- Ered comme des valeurs aberrantes, qui est, nous avons mis en k = m + 1 andMS (tm + 1) = | S | - Σm i = 1MS (ti); sinon nous fixons k = m. Étant donné que les tuples de l'échantillon S sont iid, nous pouvons considérer le vecteur de fréquence NλS pour un échantillon arbitraire S de taille fixe q de D en tant que vecteur aléatoire avec une distribution NλS ~ multinomiale (q, MD (t1) | D |,... , MD (tk) | D |), (1) où q = Σki = 1MS (ti) et MD (tk) = | D | - rk-1 i = 1 MD (ti). Définir les statistiques des c 2-de l'échantillon S pour le seuil des valeurs aberrantes λwith concerne la répartition cible de probabilité p = (p1,..., Pk) en tant que X 2S (λ, p) = Σki = 1 (MS (ti) -qpi) 2 QPI. Nous nous référons à X 2S (λ, p) que les statistiques de c 2, parce que si NλS ~ multinomiale (q, p1,..., Pk) puis, q → ∞, la distribution de la variable aléatoire X 2S (λ, p ) converge dans la distribution de χ2-distribution avec k- 1 degré de liberté (Pearson, 1900). Nous utilisons X 2S (λ, p) en tant que mesure de la proximité NλS est en représentant la distribution cible p. Comme nous augmentons l'échantillon s ize q, par la forte loi des grands nombres, X 2S (λ, p) devient plus petite. Notre but est d'estimer q, la taille d'un échantillon de données, de telle sorte que les vecteurs de fréquence extraites des échantillons de taille q sont susceptibles de représenter étroitement la distribution empirique de D pour les tuples qui ne sont pas X-valeurs aberrantes. Par conséquent, nous indiquons la répartition cible à la distribution empirique des données et définir χ2-statistiques des données d'échantillon S pour le seuil des valeurs aberrantes λ par rapport à la distribution empirique de la série de données D à être X 2S (λ, D) = kΣ i = 1 (MS (ti) - qmd (ti) | D |) 2 qmd (ti) | D | = | D | q kΣ i = 1 M2S (ti) MD (ti) - q. Laissez-S1,. . . , Sz être des échantillons z tracé à plusieurs reprises d'une taille fixe q de D. Etant donné un seuil λ on calcule X 2Si (λ, D) pour chaque Si suivi par ce procédé est résumé dans l'algorithme 1, où σq est l'écart-type entre les valeurs X 2Si (λ, D) pour différentes i. 3 Une estimation itérative de la taille d'un échantillon d'une population Nous appliquons notre approche d'estimer sans avoir un ensemble de données à portée de main de la taille d'un échantillon juste d'une population. Depuis PU (t) est inconnue, nous supposons que AdomU (λ) = {t1,. . . , Tm} pour un certain seuil λ des valeurs aberrantes. - 300 - S. Baraty et D. Simovici algorithme 1: Le pseudo-code pour trouver la taille d'un ensemble de formation suffisante ensemble de données D. Taille de l'échantillon de q du plus petit au plus grand faire prélever des échantillons de données de taille q: S1,. . . , Sz avec remplacement de jeu de données D; calculer l'écart type de séquence σq X 2S1 (λ, D). . . , X 2SZ (λ, D); sortie: taille de l'échantillon q tel que pour toute taille de l'échantillon v ≥ q on a σq ≈ σv Définition 3.1. Le vecteur de fréquence extraites d'un échantillon de la population de seuil des valeurs aberrantes λ est MλS = (MS (T1), MS (tk)...) Où, comme dans la définition 2.1, il y a deux cas: (1) si Dom (U ) -AdomU (λ) = 6 ∅ nous ajoutons un tuple supplémentaire pour compte pour les tuples considérés comme des valeurs aberrantes, qui est, nous avons mis en k = m + 1 andMS (tm + 1) = | S | - Σm i = 1MS (ti), et (2) sinon, qui est, si Dom (U) = AdomU (λ), nous avons ensemble k = m. Officieusement, on considère un échantillon de taille q en tant que représentant λ-équitable de la population si MλS / q se rapproche étroitement de vrai vecteur de distribution des tuples de la population AdomU (λ). Similaire à la section précédente, nous traitons MλS pour l'échantillon de la population arbitraire S de taille q comme vecteur aléatoire MλS ~ multinomiale (q, PU (t1),..., PU (tk)), où PU (tk) = 1 -Σ k-1 i = 1 PU (ti). Cependant, les probabilités d'unité centrale (ti) pour 1 ≤ i ≤ k sont inconnus. Par conséquent, on définit la probabilité aléatoire vecteur p = (p1,..., Pk) pour représenter l'apparition d'une distribution de probabilité à k dimensions en tant que véritable distribution sous-jacente de la population. Puis, p est représenté par l'espace de probabilité (Ω, P (Ω), f) de la probabilité k dimensions des vecteurs de dis- tribution où le Ω d'espace d'échantillon est une norme (k - 1) -simplex. On notera que X 2S (λ, p) est une variable aléatoire lui-même avec des valeurs dans R≥0. Nous rapprochons les statistiques de-c 2 un échantillon de la population par rapport à la vraie distribution sous-jacente de la valeur attendue conditionnelle de X 2S (λ, p) étant donné que nous avons un autre échantillon de la même taille de la même population à portée de main. Cet échantillon conditionné se rapproche de la forme de la distribution de probabilité de p (deuxième distribution de commande) si elle est suffisamment grand pour représenter sans biais de la distribution sous-jacente de la population. Laissez-S1,. . . , S2Z soit une séquence d'échantillons indé- pendants de taille q établis uniformément au hasard par le remplacement de la population sous-jacente. On calcule l'espérance conditionnelle de statistiques sur les c 2 (statistiques CEC) E [X 2Si (λ, p) | Sz + i] pour 1 ≤ i ≤ z. Cette statistique est utilisée comme substitut pour les statistiques réelles de-c 2 Si par rapport à la distribution cible PU. Ensuite, nous nous calculons l'écart-type entre les statistiques CECS de Si + i données Sz pour 1 ≤ i ≤ z. Si q est suffisamment grand, alors les distributions de probabilité capturées par les fréquences extraites de Si et Sz + i serait similaire à PU et, par conséquent, semblable à l'autre. Par conséquent, la variation dans les statistiques CECS est attendues d' d pour être petit. Ensuite, observer que P (S` | p) = Πk j = 1 p MS` (tj) j. Si nous supposons en outre l'avant, p ~ Dirichlet (μ1,..., Μk) pour μ1,. . . , Μk> 0, alors, on peut montrer que f (p | S`) suit la distribution Dirichlet, Dirichlet d'ordre k ≥ 2. Nous attirons (avec remplacement) échantillons aléatoires simples S1 (α1,, ak...) ,. . . , S2Z de taille q de l'OP, où | OP | est un multiple dépendant de domaine de q et plus la taille du pool d'observation est relative à q, le plus fiable est la conclusion du processus. E [X 2Si (λ, p) | Sz + i] est évaluée pour chaque i. Si l'écart-type entre les attentes conditionnelles est suffisamment faible et se stabilise à une certaine valeur de q, alors nous choisissons cette valeur de q comme seuil de la taille - 301 - Estimating tailles d'ensembles de formation d'échantillons équitables ou des ensembles de formation / évaluation adéquats. Dans le cas contraire, nous augmentons q et répétez le processus. Dans ce processus itératif, nous devrons peut-être élargir le bassin d'observation pour vous assurer qu'il est un multiple de q substantielle. Comme nous ajoutons de nouvelles observations à notre piscine, nous avons besoin de mettre à jour Adom OP U (λ), l'ensemble de tuples à considérer selon des valeurs aberrantes λ seuil, puis k, le ber de nom- dimensions de l'espace de probabilité. Notez que, nous élargissons la piscine d'observation OP, Adom OP U (λ) devient une approximation plus proche de l'ensemble AdomU (λ). Le docode suivant explique pseudotronc le processus de recherche de la taille d'un échantillon juste d'une population comme expliqué dans cette section. Algorithme 2: Le pseudo-code pour trouver la taille d'un ensemble de formation suffisante d'une popu- lation. foreach taille de l'échantillon q du plus petit au plus grand faire si ¬ (| OP | >> q) puis développez l'OP tel que | OP | q; évaluer Adom OP U (λ) et de trouver k en fonction de cet ensemble; prélever des échantillons indépendants de la taille q: S1, S2,. . . , S2Z (avec remplacement) à partir OP; calculer l'écart-type σq de séquence E [X 2S1 (λ, p) | T1],. . . , E [X 2SZ (λ, p) | Tz]; sortie:. Taille de l'échantillon q tel que pour toute taille v ≥ q nous avons σq ≈ σv 4 Résultats expérimentaux Dans la première expérience, nous avons utilisé l'algorithme 1 pour estimer la taille d'un échantillon de données de la Bank Marketing Data Set (Moro et al, 2011), qui contient 45, 211 références (voir la figure 1). Pour λ = 0, l'écart-type chute à son niveau minimal lorsque q est égal à environ 5, 000 si un échantillon de taille 5, 000 est très susceptible de présenter fidèlement l'ensemble des données qui est de la taille 45, 211. Pour λ = 0,00039 un échantillon de formation de taille 2, 000 est adapté. Dans l'expérience suivante, nous avons évalué notre approche pour déterminer la taille d'un échantillon d'une représen- tant la population que résumée dans l'algorithme 2 pour = 0,005. Nous avons simulé le processus de collecte d'observations à partir d'une population, afin d'élargir le bassin d'observation en générant synthétiquement tuples de quatre attributs en utilisant une distribution multinomiale avec des paramètres choisis au hasard, | dom (U) | = 24 et λ = 0 et nous avons exécuté l'algorithme 2 avec z = 1000. Pour chaque q, nous avons généré une centaine d'échantillons de taille q à partir d'un classificateur ensemble de données synthétiques et utilisé WEKA pour apprendre un voisin de k-plus proche (k-NN) à partir de chaque échantillon. Ensuite, nous avons évalué la performance de prédiction des classificateurs à l'aide d'un ensemble de test fixe de taille 10, 000 qui est assez grand pour représenter la distribution sous-jacente sans biais du domaine. L'écart moyen et standard du pourcentage de cas correctement classés (CCI) sont présentés dans la figure 2. Des résultats similaires ont été obtenus pour les réseaux bayésiens. D'autre part, des expériences avec des classificateurs bayésiens naïfs donnent des résultats très différents à la figure 3. L'amélioration du pourcentage moyen de la CCI en raison de l'augmentation - 302 - S. et D. Baraty Simovici FIG. 1 - écart-type des statistiques d'échantillons-c 2 de données par rapport aux changements de q échan- taille de PLE pour les données marketing de la Banque. Chaque courbe correspond à une valeur particulière de valeurs aberrantes seuil X énumérés dans la partie droite. FIGUE. 2 - Moyenne et STD la taille de l'échantillon pour 20 NN q est beaucoup plus faible que dans les cas précédents et la moyenne pourcentage de CCI atteint son maximum au format échantillon q = 2, 000 puis diminue légèrement à un niveau constant par la suite. Enfin, l'écart type du pourcentage de l'ICC converge vers zéro plus lent que les deux cas précédents. Ces différences sont dues au fait que les classificateurs de Bayes naïfs dépendent moins de la distribution de probabilité conjointe globale de classificateurs k-NN et les réseaux bayésiens en raison de l'hypothèse d'indépendance naïve. Les résultats expérimentaux montrent qu'il n'a pas de sens d'aller au-delà de la taille que nous déterminons ici, parce que l'amélioration que nous gagnons dans la performance est istent insignifiante ou inex-. Si la taille évaluée de l'ensemble de la formation est prohibitif, alors, nous pouvons être en mesure de réduire l'approximation de taille de l'échantillon en analysant dans le contexte d'un classificateur spécifique. Références Pearson, K. (1900), Sur le critère selon lequel un système donné des écarts par rapport à la probable dans le cas d'un système corrélative de variables est tel qu'il peut être raisonnablement supposer - 303 - Estimating tailles d'ensembles de formation FIG. 3 - L'écart moyen et standard du pourcentage de cas correctement classés pour bayésiens naïfs classificateurs ont surgi d'un échantillonnage aléatoire, Philosophical Magazine, Vol. 50, no. 302, ser. 5, pp. 157-175. Moro, S., Laureano, R. et Cortez, P. (2005), en utilisant Data Mining Bank Marketing Direct: Une application de la méthodologie CRISP-DM, Actes de la Conférence sur la simulation et la modélisation européenne, pp 117-121.. Le Portugal. Schmidtmann, I., Marteau, G., Sariyar, M. et Gerhold-Ay, A. (2009), l'évaluation des Kreb- de NRW Schwerpunkt couplage d'enregistrements, Rapport technique, IMBEI Nous proposons Résumé Une nouvelle approach l'estimation de verser la taille des ensembles d'ap- prentissage Qui sont nécéssaires verser des construct Dans l'Modèles d'extraction valides de connais- saices. Nous Visons à provide Une bonne représentation de l'ensemble de sans faire des Données de Hypothèses Répartition. Notre technique sur le is basée de l'écart calcul type des χ2-statistique d'échan- Une série d'tillons. When les statistiques Suivantes Sont proches Relativement, nous supposons Que les representent Échantillons Produits la vraie répartition adéquatement sous-jacente de la popula- tion, et les bureaux de Tirés Modèles se Échantillons bien also Presqu'île comportent les Qué sur l'APPRI Modèles ensemble de la population. Les Résultats semestriels Nous validons par des travaux expérimentaux involving Une des clas- sificateurs Variété. - 304 -