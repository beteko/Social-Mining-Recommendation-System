actes_non_num 351rotes résumé hybride données échantillonnage classification automatique nesrine gabsi fabrice clérot georges hébrail institut telecom telecom paristech barrault 75013 paris prénomauteur nomauteur telecom paristech france telecom avenue marzin 22307 lannion prénomauteur nomauteur orange ftgroup résumé grande volumétrie données générées systèmes formatiques hypothèse stocker totalité avant interrogation possible solution consiste conserver résumé historique répondre requêtes effectuer fouille données plusieurs techniques résumé données développées telles échantillonnage clustering selon champ requête résumés peuvent classés catégories résumés spécialisés résumés ralistes papier intéressons résumés généralistes notre objectif créer résumé bonne qualité toute période temporelle permet traiter large panoplie requêtes utilisons algorithmes clustream streamsamp consiste combiner tirer profit avantages chaque algorithme tester cette approche utilisons benchmark données réelles kdd_99 résultats obtenus comparés obtenus séparément algorithmes introduction existe actuellement plusieurs applications génèrent informations grande quantité applications issues domaines variés gestion trafic réseau lorsque volume données augmente devient coûteux stocker toutes données avant analyser judicieux adopter traitement volée informations nouveau traitement information émerge traitement données golab auteurs définissent données comme étant séquence items continue ordonnée arrivant temps débits importants plusieurs travaux babcock golab towne montrent systèmes gestion données adaptés applications essentiellement nature continue résumé hybride données ainsi volumétrie données transitent réponse besoins spécifiques applications traitent données plusieurs systèmes gestion académiques commerciaux développés stream arasu aurora abadi permettent exprimer requêtes continues évaluent mesure fenêtres ensembles finis babcock requêtes doivent spécifiées avant arrivée nouveaux besoins peuvent parfois apparaître après passage information système pourra répondre requêtes posées toutes données appelant aucun traitement définitivement perdues nécessaire certains conserver résumé données existe littérature nombreux travaux structures résumé gemulla lehner cormode garofalakis flajolet martin bloom structures dédiées tâche particu lière problématique article concerne résumés généralistes objectif fournir résultat approché importe quelle analyse données origine requête fouille posée instant présent fenêtre passé domaine encore récent existe travaux csernel aggarwal papier intéressons préservation terme données notre objectif élaborer résumé générique opérationnel plication généraliste évolutif adaptable variations bonne qualité repré sentatif origine toute période temporelle utilisons algorithmes streamsamp csernel clustream aggarwal tirer profit avantages approches créer résumé robuste respecte critères énoncés proposons papier méthode hybride permet résumer grands données numériques possible lancer résumé conçu requêtes obtenir réponses proches celles aurait obtenues présence totalité données résumés données nombreuses structures résumé développées certaines structures cation généraliste alors autres destinées particulier traitement intéressons papier résumés généralistes résumé généraliste après csernel résumé généraliste remplir quatre conditions répondre requêtes posées importe horizon temporel traiter large champ quêtes sélection médiane permettre analyses supervisées données arbres décision autoriser tâches analyse exploratoire classification autre façon définir résumé généraliste consiste réaliser organisation porelle série informations extraites données extractions peuvent réalisées biais solutions mémoires telles échantillonnage histogrammes gabsi solutions mémoires solutions mémoires permettent conserver résumés totalité données résumés portent dernières observations existe grandes opérations extraction information échantillonnage histogrammes échantillonnage échantillonnage technique directement issue statistiques ayant objectif fournir informations large population partir échan tillon représentatif celle techniques échantillonnages classiques toutes adaptées données effet elles nécessitent avoir intégralité sélectionner échantillon représentatif cadre données cette contrainte respectée nouveaux algorithmes échantillonnage développés vitter vitter introduit technique échantillonnage aléatoire incrémentale cette technique permet concevoir résumé totalité données existe techniques sophisti quées permettent maintenir échantillon aléatoire fenêtre glissante babcock objectif notre approche permettre interrogations passé lointain technique historisation selon principe babcock serait encontre objectif histogrammes technique histogrammes proche technique histogramme permet grouper données variable selon valeurs possibles chaque groupe surface construite correspond valeurs groupe taille proportionnelle nombre observations groupe solutions temporelles solutions temporelles permettent gérer cours temps informations produits techniques mémoires permettent archiver résumés couvrent intégralité espace borné fenêtres inclinées cette structure permet conserver résumés couvrant riodes temporelles tailles variables comme montre figure résumés taille constante étalent périodes temporelles durées variables courtes présent longues passé lointain structure fenêtres inclinées résumé hybride données systèmes clichés comme fenêtres inclinées cette technique permet tement efficace dimension temporelle objectif simple appuie sauvegarde instants réguliers système moment cliché cliché ainsi obtenu fournit informations traitement depuis lancement jusqu capture clichés ensuite conservés selon structure pyramidale comme montre figure cette structure privilégie instants récents rapport instants anciens proportionnellement temps nombre clichés conservés faible représentation clichés structure pyramidale clustream approche clustering clustream aggarwal algorithme robuste classification tomatique données numériques consiste construire résumé données forme ensemble micro classes évolutives clichés mémorisés gulièrement développer algorithme aggarwal inspiré algorithme birch zhang utilisant structure cluster feature vector cette structure conserve données statistiques résument ensemble éléments micro classe effectif total somme éléments chaque variable somme leurs carrés aggar aggarwal ajoute extension temporelle variables lorsqu nouvel élément arrive calcule distance rapport barycentre chaque micro classe ajoute classe proche ajout élément micro classe automatiquement appartenance élément classe mémorisée algorithme permet mémoriser cliché toutes micro classes clichés ensuite conservés selon structure pyramidale grâce propriétés mathéma tiques suivre évolution micro classes effectue opérations soustractions clichés obtenir contenu entre prises clichés cette technique permet fournir limite nombre clichés version résumé importe quelle section située entre prise clichés basant technique clustering couplée structure fenêtre ramidale clustream permet conserver clichés représentatifs données anciennes permet suivre évolution données cours temps cependant inconvénient traitement relativement lourd calculs distance lorsque débit élevé streamsamp streamsamp également algorithme résumé généraliste échantillonnage aléatoire données arrivée données échantillonnées gabsi placées échantillons taille lorsque atteint streamsamp échantillon ainsi début constitution ordre associé échantillon avance temps nombre échantillons constitués ordre augmente impossible mémoriser façon permanente échantillons réduire espace algorithme structure fenêtres inclinées lorsque nombre maximal échantillons ordre atteint fusionne échantillons ordre anciens nouvel échantillon taille couvre période temporelle grande affecté ordre construit échantillonnage toire ailleurs streamsamp permet exploitation analyse résumé traiter période temporelle échantillons appartiennent cette période concaténés pondérés façon conserver représentativité chaque élément échantillon final résumé conçu partir streamsamp particularité petit rapide élaborer dépend vitesse arrivée éléments cependant qualité résumé produit anciennes périodes temporelles dégrade effet anciens éléments poids croissant taille échantillon constamment conséquent échantillon contient éléments récents poids beaucoup faible éléments anciens derniers considérablement augmenter erreurs résultat requêtes utilisation fenêtres inclinées permet privilégier terme précision autre période passé récent approche hybride résumé généraliste article proposons nouvelle approche amélioration résumés néralistes cette approche intitulée approche hybride combine avantages streamsamp clustream évitant leurs inconvénients étant donné intervenir clustream données numériques considéré comme montre figure abord envoyé processus streamsamp permet conserver échantillons aléatoires lorsque échantillons présentatifs critères détaillés section envoyés cessus clustream respecter chronologie clustream avant envoi échantillons envoyer échantillons ordres supérieurs insertion échantillons élément élément respectant pondération passage processus autre aléatoire respecter certain nombre critères critères passage définis dessous permettent déterminer quand échantillon représentatif critères passage choix critères passage propriétés intrinsèques niques streamsamp guidé échantillonnage aléatoire clustream micro classes évolutives maintenir bonne qualité processus permet conserver résumé précis qualité premier critère variance surveille échantillonnage aléatoire entraine dégradation résumé streamsamp critère conservation centroides représentation clustream résumé hybride données approche passage streamsamp clustream critère variance notre objectif mesurer qualité représentation échantillon chaque variable revient étudier contrainte variance effet fusion échantillons période donnée donne moins individus étalent période durée représentation utilisé streamsamp ainsi moins moins précis moindre qualité échantillon bonne qualité permet répondre façon suffisamment précise requêtes posées pouvoir estimer agrégats nombre individus moyenne somme puisqu échantillonnage aléatoire étudier précision estimation agrégat revient calculer variance permet quantifier erreur relative estima utilisation critère variance permet fixer borne erreur relative revient fixer borne variance calculée échantillon théorie sondages erreur relative calculée comme valeur agrégat estimateur question posée concerne précision échantillon fusion échan tillons cherchons estimer erreur prendra exemple moyenne estimée partir échantillon notre sondage aléatoire simple obtenons ainsi probabilité échantillons fusionner échantillon résultant fusion estimateur moyenne calculé vraie moyenne vérifie inégalité suivante alors estime conservé échantillon bonne qualité erreur relative inférieure égale gabsi variance estimateur échantillon calculée comme taille échantillon taille population concernée critère conservation centroïdes notre approche passage cycle échantillon composé phases complémentaires première étape évolution échantillon streamsamp deuxième intégration échantillon processus clustream important prendre considération contraintes relatives chaque processus avons étudié section précédente contrainte fondement streamsamp contrainte variance suivant logique étudions conser vation centroïdes insertion échantillons clustream effet clustream permet regrouper éléments proches micro classe processus échantillonnage aléatoire entraîne dégradation résumé conséquence précision position centroides dégrade avons alors ajouté second critère conservation centroides respecter clustream conserver cette précision calculons chaque opération échantillonnage distance entre centroïde calculé partir échantillons fusionner centroïde calculé partir échantillon estimé distance entre inférieure seuil cette condition respectée processus échantillonnage arrêté passer clustream comme montre figure calculons partir individus centroïde estimons suite partir calculons partir échantillon vérifions suite inertie intra classe échantillon constitué partir expérimentations toutes expérimentations lancées ordinateur équipé processeur intel mémoire système exploitation windows professionnel algorithmes codés langage programmation évaluer efficacité notre algorithme avons comparé algorithmes clustream streamsamp expériences lancées données réelles network intrusion detection stream données préalablement utilisé évaluation clustream streamsamp correspond ensemble connexions enregistrées période semaines trafic réseau lincoln lequel avons expériences contient 500000 enregistrements variables numériques chaque enregistrement correspond connexion connexion appel service telnet variables utilisées expérimentations résumé hybride données calcul distance entre centroides variable count nombre connexions émises durant dernières secondes machine destinataire connexion courante variable srv_diff_host_rate pourcentage connexions faisant appel service connexion courante destinataires différents variable dst_host_srv_count nombre connexions ayant service destination connexion courante variable dst_host_diff_srv_rate pourcentage connexions desti nataire faisant appel services différents connexion courante variable dst_host_same_src_port_rate pourcentage connexions destination connexion courante utilisant étude variabilité étudier variabilité avons calculé moyenne variance chaque variable fenêtre glissante taille éléments résultats obtenus permis vérifier données utilisé stationnaire moments ordre données intéressant évaluer notre approche dégradation données streamsamp cette expérience consiste étudier dégra dation données streamsamp périodes temporelles anciennes avons étudié évolution estimation moyenne période temporelle 10000 avons lancé streamsamp chacune variables étudiées paramètres choisis façon garantir plusieurs opérations fusions streamsamp avons calculé différents instants observation erreur relative moyenne différents tirages existe estimation ainsi pourcentage tirages lesquels estimations peuvent effectuées figure montre résultats obtenus constatons chacune variables étudiées erreur relative moyenne gabsi streamsamp clustream approche hybride classes means instant prise cliché nombre clichés ordre paramètres expérimentations augmente nombre éléments traités représente dégradation perfor mances streamsamp cours temps erreur relative moyenne période 10000 différents instants observation performance approche hybride objectif cette expérience comparer formances notre approche rapport streamsamp clustream avons traité données évalué erreur relative moyenne estimation période temporelle 10000 avons répété tableau présente paramètres lesquels expérimentation lancées figure montre période temporelle assez ancienne 10000 évaluée approche hybride estime mieux moyenne streamsamp toutes variables étudiées ailleurs performances termes qualité estimation notre approche proches celles calculées clustream permet conserver moyenne exacte variables vitesse exécution figure montre performances termes temps exécution échelle logarithmique accomplies trois algorithmes clair streamsamp fournit meilleurs résultats comparé clustream approche hybride notre approche hybride lente streamsamp reste beaucoup rapide clustream ordre bascule comme montre figure enregistrements ordre bascule varie majorité enregistrements basculent clustream ordre impliquer passage forcé échantillons ordre supérieur anciens effet respecter chronologie clustream problème fusion détecté résumé hybride données erreur relative moyenne période 10000 observée 500000 entre échantillons ordre alors basculer échantillons anciens clustream vitesse exécution échantillons basculés chaque ordre clustream conclusion perspectives objectif article proposer nouvelle approche conception résumé données développer résumé généraliste bonne qualité toute période temporelle avons présenté stratégie passage algorithme streamsamp rithme clustream basant avantages chacune méthodes instant passage aléatoire propriétés intrinsèques techniques critères vérifié processus fusion échantillons stream arrêté échantillons envoyés clustream cependant avant envoyer échantillons abord faire basculer échantillons ordres supérieurs respecter chronologie clustream inconvénient cette approche condamnons échantillons passer processus alors vérifient encore critères passage travaux cours développer techniques permettant éviter inconvénient gabsi extension naturelle travail concerne intégration données qualitatives streamsamp problème utilisation variables catégorielles concernant clustream existe extensions traitent variables catégorielles hclustream sclope leong intégrer données qualitatives notre approche possible condition redéfinir paramètres tests transition références abadi carney çetintemel cherniack convey stonebraker tatbul zdonik aurora model architecture stream management journal aggarwal framework clustering evolving streams proceedings international conference large bases endowment arasu babcock cieslewicz motwani srivastava stream stanford stream management system stream management processing speed streams springer verlag babcock datar motwani widom models issues stream systems proceedings twenty first sigmod sigact sigart symposium principles database systems bloom space trade coding allowable errors commun cormode garofalakis sketching probabilistic streams sigmod proceedings sigmod international conference management csernel résumé généraliste données thesis ecole nationale supérieure télécommunications csernel clérot hébrail datastream clustering tilted windows through sampling knowledge discovery streams workshop flajolet martin probabilistic counting algorithms applications comput gemulla lehner sampling based sliding windows bounded space sigmod proceedings sigmod international conference management golab issues stream management sigmod wavelet synopsis streams minimizing euclidean error proceedings eleventh sigkdd international conference knowledge discovery mining koudas streams histograms procee dings thirty third annual symposium theory computing résumé hybride données leong keong sclope algorithm clustering streams categorical attributes technical report taylor condensative stream query language streams proceedings eighteenth conference australasian database darlinghurst australia australia australian computer society towne zuzarte window query processing joining streams relations cascon proceedings conference center advanced studies collaborative research vitter random sampling reservoir trans softw hclustream novel approach clustering evolving heteroge neous stream icdmw proceedings sixth international conference mining workshops washington computer society zhang ramakrishnan livny birch efficient clustering method large databases jagadish mumick proceedings sigmod international conference management montreal quebec canada press summary given large volume generated computer systems storing before querying possible solution summary history streams history answer queries perform mining summariz techniques already developed sampling clustering according scope applications these summaries classified categories specialized maries generalist summaries paper focuses generalist summaries objective create quality summary which covers period allows process range queries reported focuses algorithms clustream streamsamp order advantages benefits algorithm suggest their integration process approach kdd_99 benchmark results separately compared those obtained streamsamp clustream