Discrétisation des fonctions continues par rééchantillonnage Taimur Qureshi *, D.A.Zighed * * Université de Lyon 2 - Lab ERIC 5, Avenue Pierre Mendès France, 69676 Bron Cedex - France taimur.qureshi, abdelkader.zighed@univ-lyon2.fr CV. Les arbres de décision verser Sont largement utilisés des classi ficateurs Générer à partir d'un ensemble de Données. Le construction de l'Est Processus Une récursif de l'partitionnement ensemble d'apprentissage. Dans CE Contexte, les at- tributs Continus discrétisés fils. Il mio, les verser variables Alors each à discrétiser de l'Ensemble des Trouver Reportages des points de coupure. Dans papier nous montrons CE Que la recherche des bureaux des points de coupure par Une méthode de ré-échantillonnage, le BOOTSTRAP conduit Comme à des Meilleurs Résultats. Nous Avons tested this approach with the methods de discrétisation Principales MDLPC Comme, FUS- BIN, FUSINTER, CONTRASTE, Chi-Merge et les systématique- ment Résultats Sont en Utilisant le Meilleurs bootstrap. Nous exposons bureaux et Ouvrons principaux de Résultats pistes nouvelles Pour la construction d'arbres de décision. 1 Introduction Dans le processus de découverte de connaissances à partir d'un ensemble de données brutes, nous avons d'abord prétraiter les données pour éliminer le bruit et la poignée manquant champs de données. Ensuite, la transformation des données, telles que la réduction du nombre de variables et la discrétisation des attributs définis sur un do- principal continu, est souvent réalisée, qui est ensuite fourni à un algorithme d'extraction de données. L'un des problèmes les plus importants et complexes dans l'exploration de données est en relation avec le processus de transformation tel que discrétisation qui consiste à convertir des données numériques sous une forme symbolique ou discrète. Ku Siak [9] a souligné que la qualité de la découverte de connaissances à partir d'un ensemble de données peut être améliorée par discrétisation parce que beaucoup des techniques de découverte de connaissances sont très sensibles à la taille des données en termes de complexité. Ainsi, le choix de la technique de discrétisation a des conséquences importantes sur le modèle d'induction utilisé comme le CART [2]. En outre, les plages de valeurs numériques ne sont pas assez facile pour les fonctions d'évaluation à la poignée dans un domaine nominal; par exemple, les versions originales de la machine populaire apprentissage al- gorithms ID3 peuvent être utilisés que pour les données qualitatives et Quinlan [11] ont dû transformer les nuous en valeurs nents discrètes dans son apprenant l'arbre de décision C4.5. De nombreux algorithmes de classification du monde réel sont difficiles à résoudre, sauf si les attributs continus sont discrétisées. Il est difficile de les intervalles de- Termine une discrétisation des attributs numériques qui a un nombre infini de candidats. Une procédure de discrétisation simple, divise la plage d'une variable continue en intervalles égaux de largeur égale ou à des intervalles de fréquence. Fayyad et al. [6] a proposé un algorithme qui pendent classe de- réduire le nombre de valeurs attribuées en maintenant la relation entre les valeurs de classe et d'attribut. Liu et al. [10] méthodes classées de discrétisation de cinq points de vue différents: par rapport supervisé sans supervision, statique vs dynamique, global vs local, haut vers le bas vs bas vers le haut, et directement contre incrémental. méthodes ne font pas non surveillés utilisation des informations de classe dans le processus de discrétisation alors que les méthodes supervisées utiliser. Si aucune de mation de classe est disponible, discrétisation non supervisée est la seule méthode possible. Les méthodes dynamiques exercent une discrétisation des valeurs continues durant le processus de classification, tandis que la discrétisation des méthodes statiques avant processus de classification. méthodes locales utilisent la région locale de l'espace d'instance alors que les méthodes globales utilisent tout l'espace. Top-down méthodes comme FUSBIN, MDLPC et CONTRASTE [5-7] commencent par un intervalle et des intervalles séparés dans le processus de discrétisation et sont basées principalement sur la binarisation dans un sous-ensemble de données de formation. Bien que, les méthodes ascendantes comme FUSINTER [5] et Chi-fusion [4] divisé complètement toutes les valeurs continues des intervalles d'attributs et de fusion dans le processus de discrétisation. Dans ce article, nous nous concentrons sur ces deux types de stratégies pour déterminer de meilleurs points de discrétisation et de fournir des comparaisons en termes de taux de qualité et de prévision [1]. Notre objectif est de trouver un moyen de produire de meilleurs points de discrétisation. Auparavant, diverses études ont été réalisées pour estimer les points de discrétisation à partir d'échantillons. De manière significative, dans [1], un ensemble d'échantillons d'apprentissage sont utilisés pour approcher les meilleurs points de discrétisation de l'ensemble de la population, mais également valoir que l'échantillon d'apprentissage est une approximation de l'ensemble de la population, de sorte que la solution optimale construit sur un seul ensemble échantillon est pas nécessairement celle qui est globale. Cela conduit d'in- terprétation nous d'utiliser une approche de ré-échantillonnage [3] pour déterminer de meilleures distributions des points de discrétisation, où chaque point a une probabilité d'être le point de discrétisation exacte vers l'ensemble de la population. Ce faisant, nous essayons d'améliorer la qualité de discrétisation et une meilleure estimation des points de discrétisation de l'ensemble de la population, ainsi, traiter le problème de discrétisation dans le domaine statistique avec de nouveaux résultats. Dans cet article, nous montrons que en effectuant rééchantillonnage en utilisant bootstrap [8], nous déterminons une meilleure estimation de la distribution des points de discrétisation sur l'ensemble de la population, ce qui est montré améliorer le taux de prédiction de la discrétisation atteint. De plus, nous améliorons encore la qualité et le taux moyen de tion obtenu à partir rééchantillonnage prédictions en appliquant un protocole de sélection de point de discrétisation. Ce protocole sélectionne les points de coupe en fonction de certains critères (par exemple) de l'entropie de la distribution de point de fréquence d'amorçage de ré-échantillonnage obtenues à partir de rééchantillonnage n fois et améliore encore le taux de prédiction. De plus, nous comparons les taux de prédiction de différentes descendante et les stratégies ascendantes en utilisant rééchantillonnage. Dans la section 2, nous exposons le cadre de discreti- sation et de définir les ensembles de données utilisés dans nos calculs. En 3, nous donnons une illustration de notre travail et des résultats en appliquant la méthodologie à un exemple d'ensemble de données, puis à un beaucoup plus dé- coupé la queue, le jeu de données d'onde de Breiman [2]. Nous comparons également plusieurs critères basés stratégie descendante et ascendante comme dans [1], comme Chi-fusion basé sur le droit statistique χ2, FUSBIN et FUSIN- TER sur la base du principe d'incertitude, MDLPC basée sur le gain d'information et CONTRASTE que prend en compte l'homogénéité des classes et aussi la densité de points. En fin de compte, nous concluons avec des observations, des déductions et des propositions pour les travaux futurs. 2 Définitions et cadre et formulation Notations: (.) ​​Soit X une valeur d'attribut sur la ligne réelle <. Pour chaque exemple ω d'un ensemble d'apprentissage Ω, X (ω) est la valeur prise par l'attribut X (.) À ω. L'attribut C (.) Est appelée la variable endogène ou classe et est généralement symbolique et si un exemple appartient à une classe c, nous avons C (ω) = c. Nous supposons également que C (ω) est connue pour tout ω de l'échantillon d'apprentissage ensemble Ω. Ainsi, nous essayons de construire un modèle, noté Φ, de telle sorte que, idéalement, nous avons: (.) ​​C = Φ (X1 (), ..., Xp ().).). La discrétisation de X (.) Consiste à diviser le domaine Dx de l'attribut continu X (.), En k intervalles Ij, j = 1, ...., k, avec k ≥ 1. On note Ij = [dj-1 , dj] avec les d'js appelés les points de discrétisation qui sont déterminés en tenant compte de l'attribut particulier C (.). Taux de prédiction: Nous mesurons la qualité de discrétisation en tenant compte du taux de prédiction, qui est calculé comme suit: τj = carte {ω∈Ωt / C (ω) = C (ω)} carte {Qt} On note τjs les bon taux de prédiction résultant de la discrétisation de Xj obtenue en appliquant la méthode de l'échantillon q co S ou τjt par application sur l'échantillon d'essai Qt. Ensemble de données: Dans cet article, nous utilisons deux ensembles de données différentes. En premier lieu, on utilise un petit ensemble de données de 110 individus correspondant à un problème à deux classes représenté sur la figure 1. Le deuxième grand ensemble de données utilisé pour des comparaisons et des résultats est l'ensemble de données de forme d'onde de la Breiman [2] ayant 4590 individus et les 21 attributs X (. ), qui correspondent à une trois problèmes de classe. FIGUE. 1 - Runs Ri et points limites dj pour un échantillon de 2 classes "x" et "o". 3 Résultats et comparaisons 3.1 Illustration en utilisant l'exemple de données de la figure 1 Considérons un ensemble de données de la figure 1 de 110 personnes ayant deux classes. Nous effectuons discrétisation FUSBIN avec λ = 0,91 sur chaque échantillon aléatoire et d'amorçage de la taille 30 et de générer des 500 échantillons. La figure 2 nous donne la répartition des points de discrétisation de 500 bootstrap et des échantillons aléatoires. On voit que la discrétisation obtenue à partir bootstrap semblent être un peu plus généralisé et bien défini sur les quatre petits intervalles; 4,5 à 6, 6,5 à 9, de 12,5 à 14,5 et 22,5 à 27. Bien que, dans l'échantillonnage aléatoire, la distribution des points ne semble pas être mal définie dans une grande région de valeurs de 18 à 27. Nous pensons en outre que cette différence augmente que l'ensemble de données devient plus grande que nous verrons avec l'ensemble de données de Breiman. Nous avons également calculé le taux de prédiction moyen = 1100 mV à-dire Σ100 j = 1 τ v j par l'estimation des valeurs moyennes de chacun des échantillons ci-dessus 500. Nous avons trouvé les taux d'amorçage et d'échantillonnage aléatoire 22 et 21,1 respectivement montrant que les échantillons de bootstrap meilleures performances, avec cette différence augmente encore avec la complexité ajoutée et la taille de la population, comme indiqué dans le paragraphe suivant. FIGUE. 2 - distribution de points de discrétisation de 500 échantillons aléatoires et bootstrap. Ensuite, nous améliorons le taux de qualité et de prévision en introduisant une notion de protocole de sélection de point de discrétisation. Ce protocole sélectionne les points de discrétisation à partir d'une distribution de fré- quence point donné, comportant plus grande probabilité d'occurrence, et se divise sur ces points si un critère (par exemple l'entropie) est satisfaite. Pour illustrer, à partir de la figure 2, nous voyons que le point le plus élevé est bable pro- 25.5; si nous prenons ce point et de diviser la population si un certain critère (entropie FUSBIN) est satisfaite. Nous continuons notre processus sur les scissions obtenus de manière descendante, jusqu'à ce que le critère permet le fractionnement ou encore tous les points de la distribution de fréquence ont été al- prêt choisi. Nous avons appliqué ce protocole à la fois sur l'amorce et des échantillons aléatoires et il sélec- ted 6 sur 30 et 8 sur 36 points de discrétisation des deux répartitions de points de fréquence respectivement. Nous avons calculé le taux de prédiction que 22 pour bootstrap et 19,5 pour Pling échan- au hasard, ce qui démontre la meilleure qualité de discrétisation obtenue par sélection de bootstrap. Nous soutenons en outre que l'échantillonnage nous donne beaucoup de variation des taux de prédiction pour savoir échantillons bootstrap le taux de prédiction varie du 17 au 26 et donc, il est difficile d'obtenir une estimation généralisée des points de discrétisation de la population d'origine. Ici, notre protocole permette d'obtenir des points de discrétisation bien définis et donc, donnent une meilleure estimation des points de discrétisation d'origine. 3.2 Analyse et résultats à l'aide des données de signal de Breiman Pour cette section, nous utilisons l'ensemble de données d'ondes du Breiman. Nous avons généré 100 bootstrap et des échantillons aléatoires et cob co S; s = 1, ..., 100 des 300 points chacune et cot un échantillon d'essai de 4590 points. Pour tout ω partir de l'échantillon, on a un vecteur de 21 éléments désignés par (X1 (ω), ..., X21 (ω)) et une étiquette C (ω). Nous avons répété le processus décrit ci-dessus avec l'ensemble de données de forme d'onde. Nous avons pris chaque variable de l'ensemble de données et d'amorçage généré et des échantillons de dom ran- comme ci-dessus. Ensuite, nous avons réalisé FUSBIN à la fois les 100 bootstrap et des échantillons aléatoires et obtenu des taux de prédiction moyenne de 196 et 180 respectivement, montrant une meilleure formance per- avec un échantillonnage bootstrap. , Nous avons appliqué ensuite notre protocole de point de discrétisation de sélection sur la répartition des points obtenus et sélectionné les meilleurs points (en utilisant le critère de FUSBIN) des deux méthodes d'échantillonnage. Nous avons trouvé un taux de prédiction de 309 pour les points obtenus à partir de la distribution d'amorçage et d'une valeur moindre de 271 pour l'échantillonnage aléatoire montrant une quantité importante d'amélioration du taux de prédiction en utilisant rééchantillonnage (ou bootstrapping). Enfin, nous comparons FUSINTER, FUSBIN, CONTRASTE, MDLPC et Chi-fusion par rééchantillonnage. Cela se fait en deux par deux selon le mode opératoire suivant; Soit u et v les deux méthodes pour comparer. Tout d'abord, on obtient des points de discrétisation de 100 échantillons bootstrap et créer une distribution de points de fréquence pour chaque variable. Puis, en utilisant notre protocole de sélection, nous Diff dans Mean P-Rate MDLPC ChiMerge CONTRASTE FUSBIN FUSINTER MDLPC X 52,7 10,6 6,9 7,3 ChiMerge X -42,1 -45,4 -45 CONTRASTE X -3,7 -3,3 FUSBIN X 0,4 X FUSINTER TAB. 1 - calculées Résultats: Différence de prédiction taux moyen de sélection de points de discrétisation μuv de ces fréquences de distribution de points, en appliquant le critère de la méthode respective (à partir de laquelle les points de discrétisation initiaux ont été obtenus). Nous avons ensuite le calcul des taux de prédiction τjt des points de discrétisation sélectionnés de chaque méthode par rapport à l'ensemble de l'échantillon de test Qt. Nous formons la différence Γuv des deux taux de prédiction obtenus et conclure que u est meilleur que v si Γuv est significativement supérieure à 0. Le tableau 1 présente la comparaison en termes de la différence des moyens μuv des taux de prédiction de tous les riables va- . Les valeurs positives de μuv indiquent que la méthode de la rangée est meilleur que le procédé dans la colonne. En dehors de la méthode Chi-fusion dont les résultats sont relativement pauvres, toutes les autres méthodes ont des différences relativement plus petites. Cependant, parmi ces méthodes MDLPC semblait être le meilleur avec une complexité beaucoup moins de temps. FUSBIN et FUSINTER ont également eu une complexité temporelle plus faible par rapport à CONTRASTE qui avait une complexité quadratique qui devait être pris en compte lorsque le nombre d'exemples devient trop élevé. 4 Conclusion L'échantillon d'apprentissage est une approximation de l'ensemble de la population, de sorte que la sation optimale discreti- construite sur un ensemble unique de l'échantillon est pas nécessairement celui global optimal. Rééchantillonnage donne une meilleure estimation de la répartition des points de discrétisation en termes de parvenir à une répartition bien définie. L'application de notre protocole de point de discrétisation de sélection sur la distribution de fréquence obtenue par ré-échantillonnage, améliore considérablement la qualité de discrétisation et le taux de prédiction et donc, à l'approche d'une solution globale optimale. De plus, le même protocole, lorsqu'il est appliqué à la distribution de point de fréquence d'échantillons aléatoires, obtenu des améliorations beaucoup moins du taux de prédiction par rapport à bootstrap. Nous avons appliqué notre protocole (après rééchantillonnage) à diverses méthodes. À l'exception de Chi-fusion, toutes les autres méthodes offrent de faibles variations en termes de taux de prédiction. MDLPC réalise le meilleur et FUSBIN réalise la meilleure complexité temporelle, ce qui est un point clé en traitant avec beaucoup d'exemples. Comme les travaux futurs, nous appliquerons cette approche de discrétisation dans le contexte des arbres de décision, pour voir si elle améliore la performance globale ou non. Mais, en même temps, la réalisation de cette approche doit répondre à d'autres questions telles que la complexité du temps. Cela peut également conduire à appliquer les éventuels points de discrétisation dans le contexte de discrétisation floue ou douce [12] dans les arbres de décision. Références bibliographiques 1. D.A.Zighed, S.Rabaséda, R.Rakotomalala. Méthodes de discrétisation en ning Supervisé. Mémorisation en Encyclopédie des sciences informatiques et de la technologie, vol40, pp 35-50, 1998. 2. L.Breiman, J.H.Friedman, R.A.Olshen, C.J.Stone. Et régression des arbres. Wadsworth International, San Francisco, 1984. 3. L.Wehenkel. Une décision fondée sur la qualité de l'information Arbre Méthode Élagage. Compte rendu de la 4ème Conférence internationale sur le traitement de l'information et la gestion de la sécurité dans Un- fondée sur la connaissance des systèmes, IPMUŠ92 (1992). 4. R.Kerber. Discrétisation des attributs numériques. Actes de la Confé- rence nationale Dixième sur l'intelligence artificielle, MIT Press, Cambridge, MA, 1992, pp.123-128. 5. D.A.Zighed, R.Rakotomalala et S.Rabaséda. Procédé de discrétisation attributs continus dans l'induction des graphiques. Actes du 13e Rencontres européennes sur les tics Cyberne- et recherche sur le système, 1996, pp.997-1002. 6. U.M.Fayyad, K.Irani. mult i-intervalle discrétisation des attributs continu Apprécié pour la classification d'apprentissage. Actes de la 13e Conférence internationale conjointe sur ficielle Intelligence ar-, Morgan Kaufmann, San Mateo, Californie, 1993, pp1022-1027 7. T.Van de Merckt. Les arbres de décision dans les espaces d'attributs numériques. Actes de la 13e Conférence internationale conjointe sur l'intelligence artificielle, Morgan Kaufmann, San Mateo, Californie, 1993, pp 1013-1021. 8. Mooney, C Z Duval, R D (1993). Bootstrapping. Une approche non paramétrique statis- tique Inference. Série de documents de l'Université Sage sur les applications quantitatives des sciences sociales, 07-095. Newbury Park, CA: Sage. 9. A. Kusiak. méthodes de transformation des fonctions dans l'exploration de données. IEEE Trans. sur l'électronique fabrication d'emballages, 24 (3): 214-221, 2001. 10. H. Liu, F. Hussain, C. L. Tan, et M. Dash. Discrétisation: Une technique permettant. Data Mining et Knowledge Discovery, 6 (4): 393-423, 2002. 11. J. R. Quinlan. Une meilleure utilisation des attributs continus dans C4.5. Journal of gence artificielle Intelli Recherche, 4: 77-90, 1996. 12. Y. Peng et P. Flach. Douce discrétisation pour améliorer la décision continue Arbre à induction. Intégration des aspects de l'exploration de données, aide à la décision et méta-apprentissage, pages 109-118, les notes de l'atelier ECML / PKDD'01, Septembre 2001. Résumé induction des arbres de décision a été largement utilisé pour générer des classificateurs à partir des données de formation par un processus de division récursive la l'espace des données. Dans le cas de la formation sur les données d'une valeur continuous-, les attributs associés doivent être discrétisées à l'avance ou au cours du processus d'apprentissage. Nous générons points de discrétisation en effectuant rééchantillonnage sur l'ensemble de données d'origine, puis produire une sélection de points de discrétisation en utilisant notre sélection de ré-échantillonnage col proto-. Nous générons aussi des points de discrétisation par échantillonnage aléatoire ordinaire et on calcule le taux de prédiction des points de discrétisation obtenus à l'aide à la fois les techniques d'échantillonnage et rééchantillonnage. Ce processus est répété en utilisant les différentes stratégies de discrétisation mentionnées ci-dessus. Ainsi, l'objectif de cet article est d'observer si la technique rééchantillonnage peut conduire à de meilleurs points de discrétisation, ce qui ouvre un nouveau paradigme pour la construction d'arbres de décision.