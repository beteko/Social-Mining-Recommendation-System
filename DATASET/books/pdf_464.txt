 Extraction de séquences fréquentes avec intervalles d’incertitude Asma Ben Zakour Sofian Maabout Mohamed Mosbah Marc Sistiaga LaBRI Université Bordeaux 1 CNRS FRANCE maabout labri fr mosbah labri fr 2MoRO Solutions Bidart FRANCE marc sistiaga 2moro fr asma ben zakour 2moro fr Résumé Lors de l’extraction des séquences la granularité temporelle est plus ou moins importante selon les besoins des utilisateurs et les contraintes du do maine d’application Nous proposons un algorithme d’extraction de séquences fréquentes par intervalles à partir de séquences à estampilles temporelles dis crètes Nous intégrons une relaxation des contraintes temporelles en introduisant la définition de "séquences temporelles par intervalles" STI Ces intervalles re flètent une incertitude sur les occurrences précises des évènements Nous forma lisons ce nouveau concept en exhibant certaines de ses propriétés et nous menons quelques expériences afin de comparer qualitativement nos résultats avec une autre proposition assez proche de la nôtre 1 Introduction L’extraction de séquences fréquentes ESF a été introduite par Agrawal et Srikant 1995 comme une extension de leur algorithme A Priori Agrawal et Srikant 1994 qui calcule les ensembles fréquents Lors de l’ESF la chronologie d’occurrence des événements est plus ou moins importante selon la nature des connaissances à extraire En effet il est parfois néces saire de relaxer les contraintes de chronologie afin d’extraire des informations utiles Dans cet article nous proposons de fusionner des évènements consécutifs et proches temporelle ment en un ensemble d’évènements simultanés dont l’estampille temporelle n’est plus discrète mais exprimée par un intervalle temporel Cet intervalle représente une incertitude sur les ins tants exacts des occurrences des évènements regroupés Ce regroupement est contraint par la taille de la fenêtre glissante fixée par l’utilisateur Ce travail est réalisé dans le cadre d’un projet industriel Il s’agit d’anticiper des opérations de maintenance des équipements aéro nautiques Par exemple considérons un historique d’utilisation d’avions Vi désigne le vol i et Mj désigne l’opération de maintenance j Soit S = {S1 S2} un ensemble de séquences avec S1 = 〈 0 V1 1 V2 2 V3 5 M1 〉 et S2 = 〈 0 V1 1 V3 2 V2 6 M1 〉 En fixant un support minimal à 2 et une taille de fenêtre glissante égale à 1 notre approche retourne la séquence 〈 [0 0]V1 [1 2]V2 V3 [5 6]M1 〉 qui traduit les faits suivants Lorsque le vol V1 est effectué V2 et V3 ont lieu dans n’importe quel ordre entre une et deux unités de temps après V1 i e dans l’intervalle [1 2] Par la suite la réparation M1 est effectuée dans l’inter 173 Extraction de séquences fréquentes avec intervalles d’incertitude valle [5 6] après le vol V1 Ainsi les regroupements des événements V2 et V3 se font au prix d’une imprécision sur la chronologie de leurs occurrences Les techniques proposées dans la littérature nous décrivons quelques unes dans Section 2 ne permettent pas d’extraire ce type d’informations Par exemple pour les mêmes séquences et une contrainte de support équivalente l’algorithme GSP présenté dans Srikant et Agrawal 1996 extrait la séquence suivante 〈 V1 V2 V3 M1 〉 Cette séquence représente la même série d’évènements fréquents que celle retournée par notre approche mais ne donne aucune information temporelle Elle est interprétée comme suit Le vol V1 est effectué il est suivi par les vols V2 et V3 qui sont effectués dans n’importe quel ordre dans un intervalle de lar geur 1 ces derniers sont eux mêmes suivis par la tâche M1 Vu le manque d’information temporelle concernant les enchainements des évènements cette séquence est difficilement ex ploitable par un expert qui cherche à anticiper les applications de futures réparations sachant que grâce à cette anticipation d’importantes économies peuvent être réalisées en réduisant le temps d’immobilisation des avions La section suivante présente un état de l’art succinct sur l’ESF Nous insistons surtout sur la différence de notre approche vis à vis de celles qui exploitent des intervalles temporels Ensuite nous donnons les définitions formelles et les propriétés des séquences que l’on cherche à extraire La Section 4 décrit le processus d’extraction qui est une modification de l’algorithme PrefixSpan Pei et al 2001 Nous terminons par une expérimentation permettant de comparer notre approche avec une technique de la littérature en l’occurrence GSPM de Hirate et Yamana 2006 et une conclusion avec quelques perspectives 2 État de l’art Plusieurs travaux ont porté sur le regroupement d’évènements et l’extraction de séquences fréquentes par intervalles Pham et al 2009 permettent le regroupement de certains évène ments en utilisant une notion de fenêtre glissante Ce regroupement se fait lors d’une phase de pré traitement des données sur lesquelles un algorithme d’extraction est par la suite exécuté Cependant les éléments regroupés sont associés à une estampille temporelle discrète la plus petite des estampilles des évènements du groupe Un choix arbitraire qui n’est nullement mo tivé si ce n’est des considérations de simplification et qui de plus constitue une perte d’infor mation Ce faisant le nombre de séquences obtenues est plus grand que le nombre de séquences initiales une même séquence peut donner lieu à plusieurs regroupements différents Se pose alors le problème de l’interprétation du support d’une séquence Aussi l’algorithme TCLW pour Time Constraints LevelWise présenté dans Masseglia et al 2009 applique un regrou pement d’évènements a travers l’application d’une fenêtre glissante et intègre des contraintes sur la distance qui sépare deux transactions successives Cependant les motifs extraits ne pré sentent pas d’estampillage temporel ce qui réduit les possibilités de leur exploitation Partant de données initialement estampillées par des intervalles d’autres travaux ont été proposés afin d’en extraire les séquences fréquentes Il est important de noter que toutes les approches citées ci dessous considèrent l’intervalle estampille associé à un évènement comme représentant une durée tout au long de laquelle l’évènement a lieu Ce qui les distingue de notre approche où l’on considère l’intervalle comme une incertitude sur le moment exact lors duquel l’évènement a lieu Giannotti et al 2006 extraient des séquences avec un algorithme à la A Priori Ils identifient dans un premier temps les séquences fréquentes indépendamment des 174 A Ben Zakour et al estampilles Par la suite pour une séquence extraite ils intersectent les intervalles temporels estampilles de ses occurrences pour obtenir une nouvelle suite d’intervalles qui lui sont as sociés Guyet et Quiniou 2011 représentent les estampilles temporelles d’une séquence sous forme d’hyper cube dont les axes sont les évènements de la séquence La similarité entre deux séquences est exprimée en fonction du volume de l’intersection de leurs hypercubes respectifs Grâce à cette similarité les auteurs regroupent les séquences Un représentant d’un groupe i e une séquence est extrait si le groupe en question est assez dense Wu et Chen 2007 et Chen et al 2010 utilisent la théorie des intervalles d’Allen 1983 qui identifie treize rela tions entre deux intervalles Un algorithme d’extraction à la PrefixSpam Pei et al 2001 est appliqué sur des séquences à estampille temporelle par intervalles Le résultat de ces deux approches consiste en un ensemble de relations fréquentes entre évènements et non pas des séquences avec des estampilles associées aux transactions On note cependant le travail de Hi rate et Yamana 2006 qui comme l’approche que nous présentons considère des séquences à estampilles temporelles discrètes en entrée et extrait des séquences fréquentes par intervalles Les auteurs utilisent une fonction par paliers qui s’apparente à une fenêtre non glissante Ainsi des évènements très proches temporellement peuvent se retrouver dans des groupes différents du fait de l’application des paliers Par ailleurs l’on distingue essentiellement deux techniques adoptées par les algorithmes d’ESF La première s’apparente à A priori et a été utilisée dans par exemple Srikant et Agrawal 1996 Giannotti et al 2006 Rabatel et al 2009 La seconde utilise une stratégie diviser pour régner par réductions progressives de l’espace de recherche et sélection d’un ensemble de séquences 1 fréquentes pour la construction des séquences de longueur k à partir d’une séquence de longueur k − 1 exemple Hirate et Yamana 2006 Pei et al 2001 Chen et al 2010 Fournier Viger et al 2008 Wu et Chen 2007 et Guyet et Quiniou 2008 Cette dernière s’avère moins coûteuse en parcours des données donc en temps de calcul C’est pour cette raison que l’algorithme que nous proposons s’inscrit dans cette deuxième catégorie Il est inspiré de PrefixSpan utilisé dans Pei et al 2001 3 Notations et définitions Dans un premier temps nous définissons les séquences temporelles à estampilles discrètes telles qu’elles sont énoncées dans plusieurs travaux traitant l’ESF à partir de séquences tem porelles Hirate et Yamana 2006 Fournier Viger et al 2008 Pei et al 2001 Soit ω = {e1 e2 ek} un ensemble d’évènements Une transaction est un ensemble d’évè nements simultanés Une séquence temporelle est une séquence de transactions ordonnées chronologiquement A chaque transaction est associée une estampille temporelle Une sé quence temporelle S notée S = 〈 t1 I1 t2 I2 tn In 〉 avec n ∈ N où ∀1 ≤ i ≤ n Ii est une transaction et ti est son estampille temporelle Une base de séquences temporellesD est une collection de séquences S où chacune est identifiée par un identifiant unique id_sequence Le support d’une séquence S dans une base de séquences D est noté supportD S Il cor respond au pourcentage de séquences de D qui contiennent S S est fréquente dans D si et seulement si son support est supérieur ou égal à un seuil minimal minsupp fixé par l’utilisateur Nous définissons maintenant les séquences temporelles par intervalles Nous rappelons que ces séquences associent aux transactions des intervalles représentant une incertitude des 175 Extraction de séquences fréquentes avec intervalles d’incertitude occurrences des évènements d’une transaction Par exemple soit S = 〈 [m M ] I 〉 et que I = {e} une transaction contenant le seul évènement e Intuitivement S relate le fait suivant e se produit à un moment ponctuel entre les instants m et M Définition 1 Séquence temporelle par intervalles STI Soit ω = {e1 e2 ek} un en semble d’évènements Une séquence temporelle par intervalles STI S de longueur n est no tée S = 〈 [m1 M1] I1 [m2 M2] I2 [mn Mn] In 〉 où [mi Mi] Ii est une tran saction à estampille temporelle sous forme d’intervalle telle que – Les estampilles des transactions d’une séquence sont relatives à l’occurrence de son premier évènement mi = mi −m1 et Mi =Mi −m1 – ∀1 ≤ i ≤ n mi ≤ temps_occurrence ej ≤Mi pour tout ej ∈ Ii – Une séquence temporelle par intervalles est cohérente si pour deux transactions succes sives Ii et Ii+1 on a mi ≤ mi+1 et Mi ≤Mi+1 Exemple 1 Soit S1 = 〈 [0 1] A [2 2] BC 〉 une STI elle exprime le fait suivant A se produit avec une occurrence ponctuelle dans l’intervalle [0 1] et B et C se produisent simulta nément au plus tôt une unité temporelle après l’évènementA et au plus tard deux unités tempo relles après S2 = 〈 [0 3] A [1 2] B [2 5] C 〉 n’est pas une STI cohérente puisque la borne supérieure du second intervalle est inférieure à la borne supérieur du premier intervalle 2 � 3 Concernant les séquences temporelles à estampilles discrètes les transactions sont associées à un instant temporel ponctuel pendant lequel les évènements ont lieu Il n’y a donc aucune incertitude sur le moment de leurs occurrence On peut donc dire que chaque séquence tem porelle à estampille discrète S = 〈 t1 I1 tn In 〉 peut être transformée en une STI dont la largeur des intervalles est nulle l’incertitude est nulle elle est donc notée STI S = 〈 [m1 M1] I1 [mn Mn] In 〉 avec ∀1 ≤ i ≤ n mi =Mi = ti Afin d’adapter les délais temporels des séquences aux besoins spécifiques d’extraction et de formulation des contraintes temporelles sont considérées Ces contraintes permettent de fixer un seuil maximal d’incertitude de réguler les espacements entres les transactions successives d’une séquence et d’en fixer une longueur minimale et maximale Soit SI une STI de longueur n SI satisfait les contraintes temporelles mingap maxgap min_whole_interval max_whole_interval et la fenêtre glissante ws si et seulement si ∀ 1 ≤ i ≤ n – Gap régule les distances temporelles minimale et maximale entre deux transactions suc cessives mingap ≤ mi −Mi−1 ≤ maxgap – Whole_interval régule la longueur minimale et maximale d’une séquence min_whole_interval ≤ |m1 −Mn| ≤ max_whole_interval – Fenêtre glissante permet de regrouper des évènements de transactions successives dans une même transaction en leur associant un intervalle temporel Elle fixe sa largeur in certitude maximale |Mi −mi| > ws 176 A Ben Zakour et al Exemple 2 Soit SI = 〈 [0 1] A [2 3] BC [6 10] D 〉 une STI et les contraintes tempo relles mingap et maxgap respectivement égales à 2 et 3 SI ne satisfait pas mingap puisque m2 −M1 = 2− 1 = 1 ≤ 2 Par contre SI satisfait maxgap puisque pour toutes ses transac tions successivesmaxgap est satisfaite m2−M1 = 2−1 ≤ 3 m3−M2 = 6−3 ≤ 3 Pour une taille de fenêtre égale à 3 SI ne respecte pas la taille de la fenêtre puisque M3 −m3 = 10 − 6 3 D’autre part pour une fenêtre égale à 4 la contrainte est respectée par tous les intervalles de la séquence Ces contraintes régulent l’effet du paramètre temporel dans une STI ils gèrent la distance minimale respectivement maximale entre deux transactions successives pour que la corré lation i e la mise en relation des co occurrences entre elles soit significative et que deux transactions trop proches mingap respectivement trop éloignées maxgap ne soient pas reliées La taille de la fenêtre gère le regroupement des évènements et régit l’incertitude sur leurs occurrences La contrainte whole_interval régule la longueur de la séquence afin que la corrélation de toutes les transactions de la séquence soit significative Dans ce qui suit nous définissons un opérateur ♦ pour regrouper des transactions succes sives d’une séquence À partir d’une position j ♦ joint des transactions qui se succèdent dans une STI S en appliquant une fenêtre dont la taille fixe l’espacement temporel maximal entre la première et la dernière transaction du groupe Le résultat est une séquence dont les transac tions contiennent l’ensemble des évènements joints et ont pour estampille temporelle l’union des intervalles des transactions regroupées Définition 2 Soient une STI SI = 〈 [m1 M1] I1 [m2 M2] I2 [mn Mn] In 〉 un entier j ≤ n et une taille de fenêtre ws On définit l’opérateur ♦ws tel que ♦ws SI j = SI ′ = 〈 [m′1 M ′1] I ′1 [m′2 M ′2] I ′2 [m′n M ′n] I ′k 〉 – où ∀1 ≤ i � j [m′i M ′i ] I ′i = [mi Mi] Ii – ∃ 1 6 lj 6 lj+1 li 6 lk−1 6 n tel que – I ′j = ∪ lj p=jIp I ′ i = ∪lip=li−1+1Ip I ′k = ∪ ln p=lk−1+1 Ip – m′j = mj M ′ j =Mlj m ′ i = mli−1+1 M ′ i =Mli m ′ k = mlk−1+1 M ′ k =Mn – |mj −Mlj | 6 ws |mli−1+1 −Mli | 6 ws |mlk−1+1 −Mn| 6 ws Exemple 3 Soit SI = 〈 [0 2] A [1 2] B [3 5] C [4 6] D 〉 et une taille de fenêtrews = 3 alors♦3 SI 1 = 〈 [0 2] AB [3 6] CD 〉 Les évènements des deux premières respecti vement des deux dernières transactions sont regroupés et les intervalles qui leurs sont respec tivement associés sont fusionnés car les deux fusions sont autorisées par la fenêtre 2−0 6 3 respectivement 6− 3 6 3 Notons que ♦3 SI 2 = SI En effet lorsque le regroupement commence à la deuxième position les intervalles de la deuxième et de la troisième transactions ne peuvent être fusionnés puisque leur union est trop large par rapport à la taille de la fenêtre ws Finalement ♦3 SI 3 = 〈 [0 2] A [1 2] B [3 6] CD 〉 et ♦3 SI 4 = SI Nous définissons maintenant l’opérateur ︷︸︸︷ ♦ ws qui pour une STI de longueur n et une taille de la fenêtrews fournit un ensemble de STI’s L’opérateur applique la fenêtre sur une séquence en la faisant glisser et envisage toutes les possibilités de fusion des transactions successives 177 Extraction de séquences fréquentes avec intervalles d’incertitude Intuitivement ︷︸︸︷ ♦ fait glisser la fenêtre de regroupement et fournit l’ensemble de toutes les séquences condensées combinaison de regroupement des transactions proches qui peuvent représenter la séquence de départ C’est l’ensemble des résultats des applications de ♦j sur une n séquence pour des valeurs de j dans [1 n− 1] Définition 3 Soit SI = 〈 [m1 M1] I1 [mn Mn] In 〉 et ws une taille de la fenêtre Alors ∀1 ≤ i � n et SIi = ♦ws SI i on définit ︷︸︸︷ ♦ ws comme suit ︷︸︸︷ ♦ ws SI = {SI1 SI2 SIn−1} Exemple 4 Soit la séquence SI = 〈 [0 2] A [1 2] B [3 4] C [4 6] D 〉 et une fenêtre ws = 3 Alors ︷︸︸︷ ♦ 3 SI = {〈 [0 2] AB [3 6] CD 〉 〈 [0 2] A [1 4] BC [4 6]D 〉 〈 [0 2] A [1 2] B [3 6]CD 〉} La séquence < [0 2] AB [3 4] C [4 6] D > n’est pas incluse dans le résultat par contre 〈 [0 2] AB [3 6] CD 〉 est induite de la précé dente À ce stade nous pouvons définir la relation d’inclusion entre deux séquences temporelles par intervalles Intuitivement une séquence temporelle par intervalles SI contient une autre séquence par intervalles SI ′ ssi les évènements de chaque transaction de SI ′ sont contenus dans une ou plusieurs transaction s de SI et que l’intervalle de la transaction de SI ′ implique celui de la transaction de SI L’ordre des transactions doit cependant être respecté Définition 4 Soient SI = 〈 [m1 M1] I1 [mn Mn] In 〉 SI ′ = 〈 [m′1 M ′1] I ′1 [m′k M ′ k] I ′ k 〉 et une taille de la fenêtre ws SI ′ contient SI notée SI ′ w SI ssi – ∃ 1 6 ld1 6 lf1 6 ld2 6 lf2 6 ldk 6 lfk = n – ∃ 1 6 i1 6 i2 6 in 6 k – I ′i1 ⊇ t lf1 p=ld1 Ip I ′ iu ⊇ t lfu p=ldu Ip I ′ in ⊇ tnp=ldnIp – [0 Mf1 −md1 ] ⊇ [0 M ′i1 −m′i1 ] [ mdu −Mf⊇ u−1 Mfu −md u−1 ] ⊇ [ m′iu −M ′i u−1 M ′iu − m′i u−1 ] [ mdn −Mf n−1 Mfn − mf n−1 ] ⊇ [ m′in −M ′f n−1 M ′in −m′d n−1 ] Exemple 5 Soient les SI1 = 〈 [0 2]A [3 4] B [5 6]C 〉 SI2 = 〈 [0 4]AB 〉 et SI3 = 〈 [0 2]A [3 6]BC 〉 SI1 w SI2 puisque [0 4] implique [0 2] et [3 4] et SI1 w SI3 Cepen dant SI1 6w SI4 = 〈 [0 3]A [2 6]BC 〉 puisque [0 2] + [0 3] Propriété 1 Soientws une taille de fenêtre S une séquence temporelle à estampilles discrètes et SI une STI S contient SI si et seulement s’il existe SI ′ ∈ ︷︸︸︷� ws STI S et SI ′ ⊇ SI ⊆ est l’inclusion classique entre séquences e g Agrawal et Srikant 1995 Après avoir défini les STI et l’opérateur d’inclusion nous pouvons redéfinir la notion de support d’une séquence temporelle par intervalles dans une base de séquences temporelles à estampilles discrètes Nous considérons que le support d’une STI dans une base de séquences est le nombre de séquences de la base qui la contiennent au moins une fois Définition 5 Le support d’une STI SI dans D est défini par suppD SI = |{S ∈ D | S w SI}| Pour des besoins de simplification suppD SI sera noté supp SI 178 A Ben Zakour et al 4 Extraction de STI Cette section décrit le procédé d’extraction de séquences temporelles par intervalles fré quentes à partir de séquences temporelles à estampilles discrètes L’algorithme que nous pro posons est appelé STI PS pour séquences temporelles par intervalles PrefixSpan il utilise une fenêtre glissante afin de regrouper progressivement des évènements proches en respectant la taille de la fenêtre et les ramener à une même transaction Un tel regroupement permet d’unifier des occurrences d’évènements distincts et leur associe un intervalle temporel qui ba laye l’ensemble des instants d’occurrences initiaux de chacun Notre algorithme applique une approche pattern growth Pei et al 2001 qui utilise une méthode de recherche verticale de séquences basée sur la projection de la base Dans un premier temps l’ensemble des 1 séquences évènements fréquents est extrait Il est noté L1 = {S S = 〈 [m = 0 M = 0] e 〉 supp e > minsupp} Ensuite l’extraction conti nue récursivement par construction des k + 1 séquences à partir d’une k séquence A chaque itération i on applique deux étapes – une nouvelle projection de la base de séquences D′ est associée à chaque 1 STI de L1 L1 étant identifiée dans l’espace de recherche associé à la récursion i − 1 D′ repré sente ainsi l’espace qui contient les éventuelles continuations de la séquence construite à l’itération i− 1 – La seconde étape consiste à identifier l’ensemble des 1 STI à partir de D′ et à associer à chaque évènement fréquent l’intervalle qui représente son estampille temporelle Chaque 1 STI identifiée est concaténée à la séquence extraite à l’itération précédente i−1 pour construire une nouvelle i séquence Dès lors une nouvelle itération est exécutée Le procédé est arrêté si l’une des deux conditions suivantes est satisfaite 1 Lorsque la pro jection est vide étape 1 ou 2 lorsqu’aucune 1 STI n’est identifiée étape 2 Tout comme GSPM Hirate et Yamana 2006 STI PS applique le principe de projection présenté ci dessus Cependant il s’en distingue par la considération de la fenêtre glissante à deux niveaux 1 la sélection d’évènements fréquents et 2 la projection de l’espace de recherche Pour la sélection d’évènements fréquents l’application de la fenêtre glissante inter vient en associant des occurrences décalées d’un même évènement Ces occurrences doivent appartenir à une même fenêtre Cette modification permet de calculer la fréquence d’un évè nement en appliquant la relaxation temporelle contrôlée par la taille de la fenêtre Exemple 6 Pour la séquence SI = 〈 [0 0]A 〉 un support égal à 2 ws = 2 et la projection d’un espace de recherche D sur SI D|SI = {〈 1 B 2 CD 〉 〈 2 D 3 B 4 F 〉} deux évènements fréquents sont relevés [1 3]B [2 2]D En effet la séquence [1 3]B permet de dire que dans l’espace de recherche l’évènement B est fréquent et que ses occurrences varient sur 2 unités temporelles 3− 1 par rapport aux occurrences de A Concernant la projection des espaces de recherche par un évènement fréquent l’application de la fenêtre permet de prendre en considération l’aspect glissant Nous définissons la projection de façon à ce qu’elle prenne en considération une exploration en arrière des évènements Cette exploration est restreinte à la taille de la fenêtre Une telle projection considère le désordre local à la taille de la fenêtre des évènements proches Afin d’éviter l’extraction multiple d’une même séquence de longueur k à partir d’un motif SI de longueur k − 1 le retour rétroactif ne considère pas les évènements qui ont déjà été traités pour extraire des fréquents de longueur k à partir de SI Nous définissons ainsi la projection d’une séquence comme suit 179 Extraction de séquences fréquentes avec intervalles d’incertitude Définition 6 Soient un ensemble d’évènements triés ω = {e1 e2 em} une séquence tem porelle S = 〈 t1 I1 tn In 〉 et une 1 STI [m M ] er Supposons qu’il existe j 1 ≤ j ≤ n tel que er ∈ Ij et tj ∈ [m M ] Nous avons alors – Le préfixe S par rapport à [m M ] er est la sous séquence de S qui précède e dans S Il est noté wprefixe S er tj = 〈 t1 I1 t2 I2 tj Ij 〉 – Le suffixe de S par rapport à [m M ] er est la sous séquence de S qui peut être consi dérée comme la continuation de [m M ] er wsuffixe S er [m M ] = 〈 tk I ′k tp I ′p \ {er} tu I ′u tn In 〉 telle que 1 tp ∈ [m M ] 2 er ∈ Ip 3 tk 6 ti − ws et tk−1 6 ti − ws 4 tu 6 ti + ws et tu+1 6 ti + ws 5 I ′l = Il \ {e1 e2 e r−1 } Soit D une base de séquences temporelles et α = 〈 [m M ] I 〉 une 1 séquence fréquente La projection de D par SI est définie par D|α = {SI | SI = wsuffix S I [m M ] S ∈ D} et [m M ] i v S Exemple 7 Dans l’exemple précédent si on considère l’évènement fréquent [1 3]B la sé quence extraite devient SI = 〈 [0 0]A [1 3]B〉 La projection définie par notre approche permet de considérer tous les éléments autour du dernier évènement de SI Elle fournit l’es pace de recherche suivant D|SI = {〈 1 CD 〉 〈 −1 D 1 F 〉} Dans cet espace l’évène ment [−1 1]D est fréquent puisque D apparait dans les deux séquences et ses estampilles sont proches relativement à la taille de la fenêtre 1 − −1 = 2 6 2 ce qui permet de construire le motif SI ′ = 〈 [0 0]A [2 2]D [1 3]B〉 qui sera représenté par la séquence SI ′ = 〈 [0 0]A [1 3]BD〉 Pour l’extraction du motif 〈 [0 0]A [2 2]D 〉 l’évènement B n’est pas pris en compte dans le retour arrière afin de ne pas extraire deux fois la séquence SI ′ Cette section a présenté STI_PS un algorithme d’extraction de STI’s fréquentes en utilisant la méthode pattern growth L’algorithme extrait les k + 1 séquences à partir de k séquences en réduisant à chaque itération la taille de la base Les intervalles temporels sont instaurés par l’application d’une fenêtre glissante à deux niveaux de l’algorithme l’identification d’évène ments fréquents et la projection de la base 5 Expérimentation Cette section présente une comparaison des séquences extraites par l’algorithme STI PS avec celles obtenues par GSPM l’algorithme présenté dans Hirate et Yamana 2006 Les deux algorithmes sont basés sur prefixSpan Ils se distinguent par le fait qu’ils utilisent des méthodes 180 A Ben Zakour et al différentes pour regrouper les transactions En effet GSPM se base sur une fonction par pal lier qui s’apparente à une fenêtre non glissante alors que notre algorithme utilise une fenêtre glissante Pour que la comparaison ait un sens à chaque fois qu’on fixe la valeur de la fenêtre glissante ws pour notre algorithme on fixe la fonction pallier de GSPM à f t = b1 wsc Nous donnons ci dessous un exemple expliquant le fonctionnement de GSPM et renvoyons le lecteur à Hirate et Yamana 2006 Exemple 8 Considérons la base de séquences {S1 = 〈 0 A 1 B 2 C 3 F 4 B 6 G 〉 S2 = 〈 0 A 1 C 2 B 3 D 4 F 5 G 〉} un support minimal minsupp = 2 une fe nêtre glissante ws = 2 et une fonction par paliers f t = bt 2c Les intervalles associés par GSPM seront donc de la forme [2× f t 2× f t + 1 [ L’algorithme extrait d’abord les 1 séquences fréquentes suivantesA B C F etG l’estampille de toutes ces 1 séquences corres pond à l’intervalle nul En considérant la séquence B la projection de la base fournit les sé quences suivantes {S′1 = 〈 1 C 2 F 3 B 5 G 〉 S′′1 = 〈 2 G 〉 S′2 = 〈 2 F 3 G 〉} A partir de cet ensemble le motif [2 4[ F est identifié Il est considéré comme fréquent car 1 F apparaît dans S′1 et S ′ 2 et 2 dans les deux cas f t = bt 2c = 1 Pour l’intervalle associé on applique [2 f t 2 f t + 1 [ ce qui donne [2 4[ Dans la même projection G apparaît dans 3 séquences Dans S′′1 et S ′ 2 on a f t = 1 alors que dans S ′ 1 on a f t = 2 Ainsi seule [2 4[ G est extraite [4 6[ G n’est pas considérée comme fréquente Les deux algorithmes sont développés en JAVA en utilisant une version 1 de prefixSpan présentée dans Fournier Viger et al 2008 Ils sont implémentés sur une machine Windows 7 64 Intel R Core TM 3 CPU 2 40 GHz Avec 3 GO RAM Nous comparons les séquences extraites par les deux méthodes en utilisant des données synthétiques Les séquences contiennent 7 évènements différents et se caractérisent par un écart moyen entre les transactions de 3 unités temporelles et une longueur moyenne de 15 tran sactions par séquences Lors de l’extraction les contraintes mingap respectivement maxgap min_whole_interval et max_whole_interval sont fixées à 0 resp 1 0 et 15 La base de sé quences utilisée contient 12 séquences Nous avons délibérément choisi des jeux de données de petite taille car nous fondons notre étude non pas sur les temps d’exécution mais plutôt sur les résultats obtenus et plus précisément sur les nombres de séquences extraites Dans cet article notre objectif est de valider notre approche en vérifiant si les résultats extraits sont in téressants dans le cadre de l’application que nous ciblons En effet vu que notre approche est plus tolérante vis à vis de la chronologie des évènements il est naturel de s’attendre à ce qu’on extraie plus d’informations La Figure 1 illustre les résultats obtenus en faisant varier les dif férents paramètres Pour chaque combinaison des valeurs des paramètres nous avons mesuré le nombre de séquences extraites par les deux méthodes De plus pour chaque algorithme nous avons calculé les séquences maximales à partir des résultats obtenus Les figures 1 a resp 1 b 1 c 1 d illustrent les variations des tailles des résultats sous différentes valeurs de regroupement Elles montrent que le nombre de séquences extraites par STI_PS est beaucoup plus important que ceux obtenus par GSPM Ceci est expliqué par l’application de contraintes temporelles plus souples En effet la fenêtre glissante regroupe les transactions de proche en proche et permet d’avoir toutes les combinaisons possibles de groupement mais aussi d’extraire des séquences plus longues Aussi le retour en arrière lors de la projection permet de prendre en compte plus d’évènements et certains y voient leur support augmenter Le tableau 1 illustre 1 philippe fournier viger com spmf index php 181 Extraction de séquences fréquentes avec intervalles d’incertitude a WS=1 f t = bt 1c b WS=3 f t = bt 3c c WS=5 f t = bt 5c d WS=7 f t = bt 7c FIG 1 – Comparaison du nombre de séquences extraites en faisant varier le support la taille de ws et la largeur du palier de la fonction le détail des nombres de séquences extraites par les deux méthodes pour une valeur de regrou pement variable et un support égal à 0 4 Notons que lorsque les deux méthodes fournissent des séquences de même longueurs correspondance de la figure 1 a dans le tableau 1 les séquences maximales extraites par notre approche sont moins nombreuses que celles obtenues par GSPM Ce cas de figure est illustré dans l’exemple 9 Cependant lorsque les séquences de STI_PS sont plus longues que celles retournées par GSPM les maximales sont plus nombreuses et leur nombre est majoritairement représenté par des motifs de longueurs supérieures aux sé quences maximales extraites par GSPM Notons enfin que le nombre de séquences maximales extraites par notre approche reste comparable à celles de GSPM Exemple 9 Si l’on reprend l’exemple 8 on peut vérifier que les plus longues séquences maxi males que GSPM extrait sont 〈 [0 0[ B [2 4[ F 〉 〈 [0 0[ G 〉 〈 [0 0[ A 〉 〈 [0 0[ C 〉 Celle extraite par STI_PS est 〈 [0 2] ABC [3 4] F [5 6] G 〉 Si on considère la séquence 〈 [0 0[ B [2 4[ F 〉 extraite par GSPM elle traduit le fait que F apparaît dans l’intervalle [2 4[ après B La séquence 〈 [0 2] ABC [3 4] F [5 6] G 〉 obtenue par STI_PS exprime entre autres le fait que F apparaît dans l’intervalle [3 − 2 = 1 4 − 0 = 4] après B Vu que [1 4] contient [2 4[ on peut donc dire que la séquence maximale extraite par notre approche inclut toutes les séquences maximales extraites par GSPM et ce en tolérant plus d’incertitude 182 A Ben Zakour et al ws GSPM maximaux STI PrefixSpan STI PS maximaux 1 L1 = 13 L2 = 21 L3 = 1 L1 = 17 L2 = 39 L3 = 14 L2 = 21 L4 = 14 3 L1 = 9 L2 = 12 L3 = 5 L1 = 7 L2 = 53 L3 = 96 L4 = 26 L5 = 3 L3 = 30 L4 = 26 L5 = 3 5 L1 = 9 L2 = 13 L3 = 2 L1 = 7 L2 = 55 L3 = 133 L4 = 75 L5 = 9 L6 = 1 L3 = 26 L4 = 42 L5 = 13 L6 = 1 7 L1 = 9 L2 = 19 L3 = 3 L1 = 7 L2 = 51 L3 = 115 L4 = 88 L5 = 21 L6 = 4 L3 = 24 L4 = 29 L5 = 12 L6 = 4 TAB 1 – Nombre de i séquences Li extraites en fonction de la variation de la taille de ws et un support égal à 0 4 6 Conclusion Cet article présente STI PS un algorithme d’extraction de séquences en appliquant une fenêtre glissante qui permet une relaxation des contraintes temporelles La fenêtre regroupe des évènements de transactions voisines de proche en proche permettant de considérer plu sieurs combinaisons des données lors de l’extraction L’algorithme est appliqué à une base de séquences à estampilles discrètes et en extrait des séquences fréquentes à estampilles tem porelles par intervalles L’estampille par intervalle représente une incertitude temporelle sur le moment d’occurrence des évènements de la transaction L’ampleur de cette incertitude est régulée par la taille de la fenêtre glissante Comparée à la solution proposée dans Hirate et Ya mana 2006 notre approche permet d’extraire un plus grand nombre de séquences De plus certaines des séquences que nous obtenons sont plus longues que celles extraites par GSPM Les futurs travaux porteront dans un premier temps sur l’optimisation de l’extraction des mo tifs maximaux En effet il n’est pas efficace de d’abord extraire tous les motifs et ensuite ne retenir que les maximaux Dans un deuxième temps nous comptons valider notre approche dans le cadre d’une application réelle Il s’agit de pronostiquer l’occurrence de pannes dans des systèmes complexes à partir de données d’utilisation par le biais des séquences que nous obtenons Références Agrawal R et R Srikant 1994 Fast algorithms for mining association rules in large data bases In Proceedings of VLDB conference Agrawal R et R Srikant 1995 Mining sequential patterns In Proceeding of ICDE confe rence IEEE Computer Society Press Allen J F 1983 Maintaining knowledge about temporal intervals Communications of ACM 26 832–843 183 Extraction de séquences fréquentes avec intervalles d’incertitude Chen Y C J C Jiang W C Peng et S Y Lee 2010 An efficient algorithm for mining time interval based patterns in large database In Proceedings of the 19th ACM international conference on Information and knowledge management Proceedings of CIKM conference pp 49–58 Fournier Viger P R Nkambou et E M Nguifo 2008 A knowledge discovery framework for learning task models from user interactions in intelligent tutoring systems In Proceeding of the 7th Mexican International Conference on Artificial Intelligence pp 765–778 Giannotti F M Nanni D Pedreschi et F Pinelli 2006 Mining sequences with temporal annotations In Proceedings of the 2006 ACM symposium on Applied computing SAC ’06 pp 593–597 ACM Guyet T et R Quiniou 2008 Mining temporal patterns with quantitative intervals In Proceedings of The 4th International Workshop on Mining Complex Data IEEE Computer Society Guyet T et R Quiniou 2011 Extracting temporal patterns from interval based sequences In Proceedings of IJCAI conference pp 1306–1311 Hirate Y et H Yamana 2006 Generalized sequential pattern mining with item intervals JCP Journal of Computers 1 3 51–60 Masseglia F P Poncelet et M Teisseire 2009 Efficient mining of sequential patterns with time constraints Reducing the combinations Expert Syst Appl 36 2 2677–2690 Pei J J Han B Mortazavi Asl H Pinto Q Chen U Dayal et M Hsu 2001 Prefixspan Mining sequential patterns by prefix projected growth In Proceedings of ICDE conference pp 215–224 Pham Q K G Raschia N Mouaddib R Saint Paul et B Benatallah 2009 Time sequence summarization to scale up chronology dependent applications In Proceedings of CIKM conference pp 1137–1146 Rabatel J R Bringay et P Poncelet 2009 So mad Sensor mining for anomaly detection in railway data In Proceedings of Industrial Conference on Advances in Data Mining pp 191–205 Srikant R et R Agrawal 1996 Mining sequential patterns Generalizations and performance improvements In Proceedings of EDBT conference pp 3–17 Wu S Y et Y L Chen 2007 Mining nonambiguous temporal patterns for interval based events IEEE Trans on Knowl and Data Eng 19 742–758 Summary Sequential patterns mining has been used in several domains We note that time granularity is more or less important regarding the application domain In this paper we propose a frequent interval time sequences ITS extraction technique from discrete temporal sequences using a sliding window approach in order to relax time constraints The extracted sequences offer an interesting overview of the original data by allowing a temporal leeway on the extraction process We formalize the ITS extraction under classical time and support constraints and conduct some experiments on synthetic data for validating our proposal 184 