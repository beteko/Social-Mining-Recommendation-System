classification données catégorielles maximisation spectrale modularité lazhar labiod younès bennani lipade university paris descartes saints pères 75006 paris france email prénom parisdescartes université paris avenue baptiste clément 93430 villetaneuse prénom paris13 résumé papier présente algorithme spectrale maximiser critère modularité étendu classification données catégorielles evidence connexion formelle entre maximisation modularité sification spectrale présente particulier problème maximisation modularité forme problème algèbrique maximisation trace développons ensuite algorithme efficace trouver partition maximisant critère modularité résultats expérimentaux montrent efficacité notre approche introduction classification automatique méthode apprentissage supervisé permettant partitionnement ensemble observations classes méthodes classification automatique conduisent partition population initiale groupes disjoints selon critère choisi priori individus groupe aient entre maximum affinité individus groupes différents aient entre minimum affinité classification automatique largement étudiée apprentissage automatique bases données statistique divers points mesure modularité utilisée récemment classification graphes kempe newman girvan white smyth papier montrons critère modularité formellement etendu classification données catégorielles développons ensuite procédure spectrale efficace trouver partition optimale maximisant critère modularité résultats expérimentaux montrent efficacité notre approche première contribution papier introduction mesure modularité étendue classification données tégorielles deuxième contribution présentation problème maximisation mesure modularité étendue forme problème maximisation trace reste papier organisé comme section introduit quelques notations défini tions section présente mesure modularité étendue discussions connexion maximization spectrale modularité spectrale problème maximization modularité procédure optimisation posée décrites section section montre résultats expérimentaux enfin section présente conclusions certains travaux futurs définitions notations ensemble données objets décrit ensemble attributs variables catégorielles chacun ayant catégories respectivement désigne nombre total catégories toutes variables chaque variable catégorielle décomposée collection variables indicatrices chaque variable considérons valeurs correspondent naturellement nombres variables binaires telles chaque seulement prend jieme valeur ainsi matrice données exprimée comme collection matrices terme général objet possède catégorie sinon matrcie disjonctive dimensions écrit extension mesure modularité classification données catégorielles cette section explique comment adapter mesure modularité classification données catégorielles graphe modularité modularité mesure récemment utilisée mesurer qualité classifica graphes immédiatement attention considérable comme témoignent articles newman girvan agarwal kempe maximisation mesure modularité exprimée forme problème programmation linéaire nombres entiers étant donné graphe matrice binaire symétrique chaque entrée existe arête entre noeuds entre noeuds matrice contenant toutes formations graphe souvent appelée matrice adjacence trouver partition ensemble noeuds ensembles homogènes conduit résolution programme linéaire variables bivalentes suivant matrice relation équivalence nombre total arêtes liens degré objet modularité évalue densité arêtes classes façon relative densité atten indépendance entre extrémités arrêtes prend valeurs entre labiod valeurs positives quand classes arêtes observées pendance extrémités arêtes critère partition triviale seule classe chaque noeud isolé classe extension intégration priori intégration priori consiste combinaison directe graphes obtenus partir toutes variables ensemble données graphe avant appliquer algorithme apprentissage prenons matrice chaque entrée considérée comme matrice poids associée graphe chaque arête poids analogie mesure modularité classique définissons extension comme poids total degré objet maximisation spectrale modularité normalisée critère modularité pondéré cardinalités classes signifie classe faire petite quand touchée valeurs aberrantes ainsi définissons nouveau critère modularité normalisée comme matrice binaire partition ensemble classes matrice diagonale chaque élément diagonal correspond cardinalité classe partition connexion spectrale cette section donnerons interprétation spectrale problème maximi sation critère modularité exploitant quelques propriétés algèbriques relation équivalence appliquons suite relaxation spectrale problème miser critère modularité normalisée connu grande valeur propre matrice pondérée vecteur dimension appropriée toutes valeurs valent vecteur associé simon jordan applicant maintenant décomposition spectrale matrice obtient ainsi ukλku soustraire vecteur propre trivial correspondant grande valeur propre donne ukλku considérons maintenant maximization spectrale modularité vecteurs propres principaux deetdetde ukλku cette matrice multipliée constante 1etde impact position maximum critère modularité exactement matrice présente partie donnée critère modularité equation autre probléme maximisation modularité étendue formaliser forme probléme algèbrique maximisation trace contrainte orthogonalité matrice partition cilement vérifier matrice orthogonale matrice identité ordre matrice utilisée critère modularité exprimé termes grands vecteurs propores matrice similarité après résolution décomposition spectrale obtient vecteurs propres associés grandes valeurs propres ainsi définir matrice dimensions kieme vecteur propre vecteurs retenus normalise chaque colonne cette matrice telle programme dessus équivalent spectral problème maximisation critère modularité normalisée algorithme proposé appelé spectcat commence calcul premiers vecteurs propres ignorant vecteur trivial algorithme intégre entrée espace euclidien décomposition spectrale matrice larité applique algorithme clustering géométrique principales étapes algorithme spectral utilisé décrites après algorithme1 algorithm spectcat input matrice similarité nombre classes output matrice partitions définir comme étant matrice diagonale trouver vecteurs propres définir matrice partir partitionner lignes classes utilisant exemple kmeans affecter object classe seulement ligne correspondante matrice affectée classe expérimentation validation étude performance réalisée évaluer notre méthode cette section décrivons expériences résultats avons testé notre algorithme réelles obtenues partir référentiel machine learning repository comparer performances autres algorithmes clustering utilisant pureté mesurer qualité résultat clustering effectuons comparaisons bases asuncion newman soybean small mushroom congressional votes labiod hayes balance scale evaluation audiology description synthétique bases données utilisées donnée tableau description bases données bases données objects attributes classes soybean small mushroom congressional votes hayes balance scale evaluation audiology analyse résultats avons étudié clustering trouvé quatre algorithmes notre algorithme spectcat modes standard algorithme representative algorithme modes avons servé plupart algorithmes clustering nécessitent nombre clusters comme paramètre entrée alors expériences avons varier chaque données nombre clusters allant nombre classes chaque données chaque nombre clusters pureté clustering différents algorithmes comparée comme méthode proposée approche spectrale adapté données catégorielles avons comparé performances algorithme proposé autres algorithmes classification données catégorielles tableau clair performance méthode proposée repose principe classification spectrale donne résul meilleurs semblables autres approches signifie approche proposée améliore pureté clustering disparités performances spectcat rapport différents algorithmes expliquer structure interne données savoir nombre modalités variable effectif chaque modalité cavité matrice données mesure pureté modes representatives weighted modes spectcat bases données modes representatives modes spectcat soybean small mushroom congressional votes hayes balance scale evaluation audiology données balance scale méthode proposée efficace plupart valeurs méthode proposée donne moins résultats algorithme representative autres spectcat produit clusters haute pureté comme indiqué figure gauche données spect donne résultats comparables moins rapport autres algorithmes résultats donnés figure droite maximization spectrale modularité mesure pureté différent nombre clusters gauche balance scale droite conclusions perspectives papier avons étudié maximisation spectrale modularité sification données catégorielles avons proposé approximation spectrale matrice modularité équivalent spectral problème maximisation modularité procédure efficace optimisation présentée résultats expérimentaux obtenus utilisant différentes bases données réelles montrent notre méthode fonctionne effica cement notre méthode facilement étendue cadre spectral général permettant combiner multiples ensembles données hétérogènes références agarwal kempe modularity maximizing graph communities mathematical gramming journal machine learning research francis michael jordan learning spectral clustering application speech separation european physical journal xiaofeng hongyuan chris horst simon aggregation scaled principal component space technical report ernest orlando lawrence berkeley national laboratory berkeley newman girvan finding evaluating community structure networks physical review white smyth spectral clustering approach finding communities graphs pages summary paper propose spectral based clustering algorithm maximize extended modularity measure categorical maximization extended modularity shown trace maximization problem spectral based algorithm presented search partitions maximizing extended modularity criterion