détection singularités temps combinaison apprentissage automatique sémantique basés spark badre belabbess musab bairat jeremy olivier innovation 95870 bezons france prénom 77454 france prénom paris introduction apprentissage automatique contient ensemble puissant approches aider détecter anomalies manière efficace cependant représente processus lourd règles strictes multitude tâches telles analyse nettoyage données réduction dimension échantillonnage sélection algorithmes appropriés réglage précis hyper paramètres notre système spécifiquement conçu simplifier processus lourd accélérer déploiement solution temps notre système identifier anomalies grand réseau potable leader national expert domaine découverte telles irrégularités réseau préoccupation critique écologique financier volume perdue monde généré perte milliards milliards euros reste difficilement identifiable raison nature souterraine réseau recherches approfondies menées experts anomalies peuvent identifiées utilisant mesures pression débit envoyées capteurs spécifiques dispersés réseau canalisations architecture système conçu traiter données massives dynamiques statiques architecture distribuée tolérante pannes objectif principal pouvoir traiter massifs données temps lancer modèles intensifs appren tissage automatique répondre besoins système distribué robuste scalable faible latence avons notre conception architecture lambda archi tecture résout problème fonctions calcul lourdes données temps décomposant problème trois couches couche batch couche vitesse couche service scénario général commence stockage données détection singularités temps historiques horodatées forme séries temporelles analyse cache données massives nécessite système fichiers distribué robuste récupérer données rapidement système utilise cluster hadoop première phase traitement batch cependant plupart données brutes doivent toyés augmenter précision identification singularités étapes succèdent système infère données manquantes techniques interpolation maximi sation espérance ensuite techniques réduction dimensions permettent réduire taille dataset initial unité modélisation distribuée appliquera plusieurs modèles séries temporelles trouver valeurs aberrantes saisonnalité chronologie valeurs aberrantes seront utilisées classer attributs selon probabilité occurrence anomalie modèles étant appliqués attributs mieux classés réduisant ainsi considérablement temps traitement cette méthode permet allocation données dynamique optimisant taille paquets données transférés entre moteur spark cette allocation données gérée unité sémantique profitant atouts ontologies après avoir converti données réduites générateur requêtes continues sparql sélectionnera graphique taille minimale utilisant ontologie conçue utilisation actuel sélectionner algorithme respondant profil ingérés utilisons ensemble complexe règles telles interdépendance variables profil distribution données estimation complexité traitement résultats trouvés seront envoyés système messagerie apache kafka mettra attente messages manière ordonnée exposés outil visualisation enfin système appuie annotations utilisateur lancer nouvelle boucle itération stockera signatures chaque anomalie validée contributions système proposé évolutif permettant détection anomalies temps mélange techniques apprentissage automatique approche sémantique appuyant profil données historiques système utilise ensemble règles hiérarchiques sélectionner meilleur algorithme adapté usage estimons premier système visant automatiser processus complet apprentis automatique depuis nettoyage données lancement modèles appropriés tâches effectuées cours processus généralement effectuées manuellement experts besoin connaissance suffisante domaine application prentissage automatique général utilisant capacités environnement distribué traiter données massives véloces notre système propose trouver automatiquement algorithme pouvant meilleurs résultats terme précision temps exécution summary using machine learning solve complex cases generally cumbersome costly error prone process system remove burden process demonstrate machine learning tasks automated