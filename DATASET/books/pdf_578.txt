reconnaissance actions modélisation mouvement yassine benabbas lablack thierry urruty chabane djeraba université lille1 telecom lille1 ircica haute borne 56950 villeneuve yassine benabbas lablack thierry urruty chabane djeraba résumé article propose approche utilisant modèles direction magnitude mouvement détecter actions effectuées êtres humains séquences vidéo mélanges gaussiens mises estimés partir orientations magnitudes vecteurs optique calculés chaque scène paramètres modèles estimés grâce algorithme apprentissage ligne actions reconnues grâce mesure distance bhattacharyya permet comparer modèle séquence donnée modèles créés partir séquences apprentissage approche proposée évaluée ensembles vidéos contenant actions variées exécutées aussi environnements intérieur extérieur introduction reconnaissance actions sujet particulièrement complexe domaine vision ordinateur consiste classification automatique actions activités réalisées individu séquence vidéo reconnaissance actions cruciale nombreux domaines comme vidéo surveillance interaction homme machine indexation vidéos objectif système reconnaissance actions reconnaitre actions simples courante vidéo marcher répondre téléphone sauter partir vidéos référence actions répondent modèles mouvements simples effectués seule personne durant temps court certaines approches détectent actions partir images fixes tandis autres recours vidéos stéréoscopiques maillages ganesh bajcsy article traitons séquences vidéo enregistrées caméras monoculaires elles permettent détecter actions combinant informations spatiales temporelles johansson intérêt vidéos monoculaires résulte elles couramment utilisées moins gourmandes ressources économiques article présente méthodologie permet reconnaître actions basant analyse mouvement sujets organisé comme travaux antérieurs passés revue section décrivons ensuite notre approche section détaillant phases principales construction modèles reconnaissance reconnaissance actions modélisation mouvement action approche proposée évaluée ensembles données résultats périmentaux rapportés section concluons proposons plusieurs pistes travaux futurs section travaux antérieurs durant dernières années nombreuses approches reconnaissance actions proposées elles décrites études bibliographiques poppe turaga techniques classées fonction méthode représentation images algorithme classification action comme représentation images calcul caractéristiques partir images tient compte dimension temporelle généralement vecteurs tique caractéristiques spatio temporelles comme cuboïdes dollar caractéristiques hessiennes willems descripteur suite représenter séquence vidéo fathi calculent descripteurs apprentissage classificateurs boost partir caractéristiques niveau alors messing calculent trajectoire points mouvement certains descrip teurs laptev hog3d kläser esurf étendu willems basés analyse spatio temporelle locale points mouvement meilleures méthodes représentation images celles discernent efficacement actions classes différentes exécutent temps classification action mécanisme permet classifier action effectuée utilisant classificateur comme mauthner organizing huang processus gaussien 2009b fonction distance modèle discriminant hidden conditional random field champ aléatoire conditionnel caché zhang effectuer tests comparer différentes approches bases vidéos telles laptev lindeberg activities daily living activités quotidienne messing utilisées descripteurs spatio temporels locaux récemment popularité dévelop avérés efficaces cadre reconnaissance actions humaines 2009a modèles inspirés descripteurs proposés permettent extraire principales orientations magnitudes mouvement attribuent variance poids histogrammes calculés partir fréquence observation vecteur mouvement proposons approche originalité utilisation modèles direction magnitude représenter actions passer détection membres corps humain effet appuie vecteurs optique caractéristiques permettant construire modèle associé séquence estimé temps notre approche extrait magnitudes orientations mouvement principales chaque scène avons choisi représentation dense échantillonnage offre meilleurs résultats 2009a actions ensuite détectées biais mesure distance appliquée entre modèle associé séquence référence celui associé séquence requête séquence requête séquence vidéo cherche reconnaitre action benabbas description approche détecter actions réalisées seule personne proposons approche principales étapes illustrées figure étapes divisées phases principales construction modèles permet quantifier mouvement partir vecteurs optique estimer modèle directionnel modèle magnitude intégralité séquence reconnaissance action permet reconnaitre action vidéo parant modèle modèles séquences vidéo référence biais mesure distance séquence vidéo calcul optique modèle directionnel détection regroupement données circulaires modèle magnitudes regroupement données circulaires allocation vecteurs blocs construction modèles modèles référence modèle requête mesure distance action reconnue reconnaissance action etapes approche phase construction modèles phase recon naissance action construction modèles construire modèle séquence vidéo commençons extraire semble points intérêt chaque image avons utilisé détecteur points tomasi tomasi permet trouver coins possédant valeur propre élevée considérons également vidéos traitées position reconnaissance actions modélisation mouvement conditions éclairage permettent obtenir grand nombre points intérêt pouvant facilement détectés suivis après avoir défini ensemble points intérêt suivons leurs déplacements images suivantes grâce vecteurs optique utilisons implémenta bouguet bouguet algorithme suivi lucas kanade avère rapide efficace gérer points trouvant proximité image résultat ensemble vecteurs mouvement vecteur défini origine orientation magnitude étape suivante consiste diviser scène grille blocs chaque vecteur mouvement associé correspond selon origine taille blocs influe précision système étudiée section algorithme regroupement données circulaires ensuite appliqué orienta tions vecteurs optique chaque ensemble distributions circulaires associées appelé modèle directionnel figure montre construction modèle directionnel associé action answerphone modèle directionnel action answerphone image courante vecteurs optique modèle directionnel associé séquence vidéo article regroupons données circulaires utilisant mélange mises ainsi probabilité obtenir orientation rapport définie formule suivante représente nombre mélange avons choisi empiriquement correspondre quatre points cardinaux respectivement poids benabbas angle moyen paramètre concentration distribution mises direction paramètre concentration possède fonction densité probabilité suivante intervalle fonction bessel modifiée première espèce ordre définie analogie regroupons magnitudes vecteurs optique chaque grâce mélanges gaussiens ensemble mélanges gaussiens estimés représente modèle magnitude ainsi probabilité magnitude rapport définie façon suivante respectivement poids moyenne variance sienne nombre gaussiennes expérimentations chaque image mettons paramètres mélanges gaussiens grâce approximation means décrite kaewtrakulpong bowden utilisons également estimer paramètres mélange mises adaptant rithme gérer données circulaires prenant compte inverse variance paramètre dispersion annotons dessous modèle séquence respectivement modèle directionnel modèle magnitude associés séquence figure montre modèles directionnels magnitude quelques séquences vidéo issues reconnaissance action modèle séquence vidéo calculé détectons action correspondant cette séquence requête fonction vidéos référence actions détectées parant modèle séquence requête modèles associés séquences référence utilisant mesure distance action associée modèle ayant distance petite rapport modèle séquence requête retenue soient ensemble séquences leurs modèles respectifs séquence requête modèle distance entre séquence référence définie correspond norme matrices contiennent distances entre chaque élément modèles directionnel reconnaissance actions modélisation mouvement echantillon images modèle directionnel modèle magnitude échantillon images modèles direction magnitude associés modèles magnitude chaque élément défini formule suivante ydistd représentent poids variance mises associés modèle directionnel distd distance bhattacharyya entre mises définie équation suivante distd benabbas distd comprise entre cette équation calculée grâce cette solution forme fermée distd respectivement angle moyen paramètre disper distribution autre mesure distance étudiée benabbas analogie définissons chaque élément équation suivante ydistm représentent poids gaussienne modèle magnitude distm distance bhattacharyya entre gaussiennes définies solution forme fermée suivante distm respectivement moyenne variance gaussienne expérimentations résultats démontrons cette section efficacité notre approche sembles vidéos portant variété actions quotidiennes matrices confusion présentées suivies effets taille blocs nombre classes actions performances système efficacité reconnaissance actions vidéo laptev lindeberg vidéos faible résolution images niveau pixels regroupant actions effectuées plusieurs personnes cette contient vidéos environnement intérieur extérieur personnes portent tenues vestimentaires différentes divisons ensemble données ensembles comme suggéré schuldt schuldt ensemble apprentissage contient séquences référence personnes ensemble contient séquences requête personnes ensemble apprentissage comporte personnes person01 person16 ensemble comporte personnes person17 person25 utilisons blocs taille quelques exemples actions ainsi matrice confusion indiqués notre approche aboutit résultats satisfaisants trois premières actions reconnaissance actions modélisation mouvement vidéos lorsque personne immobile revanche notre système assimile tions jogging action actions diffèrent légèrement vitesse longueur foulée ayant orientation similaire boxing handclapping handwaving walking running jogging boxing handclapping handw aving alking running jogging résultats ensemble données échantillon actions matrice confusion utilisant answerphone chopbanana dialphone drinkwater eatbanana eatsnack lookupinphonebook peelbanana usesilverware writeonwhiteboard answerphone chopbanana dialphone drinkw eatbanana eatsnack lookupinphonebook peelbanana usesilverware writeonw hiteboard résultats échantillons actions matrice confusion utilisant blocs pixels vidéo activities daily living activités quotidienne messing vidéos haute définition pixels regroupant actions courantes quotidien peelbanana usesilverware answerphone effectuées benabbas personnes différentes suivons protocole leave notre expérimenta prenons compte séquence séquence requête toutes autres comme séquences référence phase reconnaissance action cette cédure effectuée toutes séquences moyenne résultats calculée chaque classe action figure présentons matrice confusion obtenue cadre notre approche cette vidéos approche obtient précision moyenne blocs taille pixels résultat satisfaisant toutefois action peelbanana confondue actions eatsack usesilverware elles comportement initial similaire consiste ramener objet depuis potager étude comparative comparons notre approches autres utilisant bases vidéos présentons leurs précisions tableau méthode approche proposée historique vitesses messing points intérêt spatio temporels laptev cuboïdes spatio temporels dollar comparaison bases vidéos avère approches basées descripteurs spatio temporels locaux dollar laptev historique vitesses messing aboutissent meilleurs résultats notre système dernier recours vitesse points intérêt descripteurs niveau cependant notre système performant combine informations relatives magnitude mouvement orientation rapport caractéristiques laptev notre modèle scène simile principales orientations magnitudes prend compte mouvements soumis bruit chaque mélange renvoie orientations moyennes variances poids correspondants tandis descripteurs calculent histo grammes gradients orientés optiques moins précis notre approche notamment efficace utilisation vidéos haute résolution appuie information mouvement exacte néanmoins souffre manque précision vidéos basse résolution etude nombre classes actions taille blocs étudions influence taille blocs nombre classes action ensemble ainsi avons répété expérience chaque élément ensemble ensembles actions actions suivantes handshaking reconnaissance actions modélisation mouvement boxing handwaving walking running jogging avons respectivement tions graphes figure montrent précision notre système chaque ensemble graphe obtenu blocs taille pixels tandis graphe rouge correspond blocs taille pixels précision atteint lorsque actions combinées correspondant actions trotter courir marcher souligne difficulté différencier vitesse chaque action cadre vidéos basse résolution expériences montrent également augmenter taille blocs réduit précision globale système cependant temps traitement aussi diminué ailleurs augmentation nombre séquences référence allonge durée traitement combinaisons actions taille taille block 10x10 boxing handclapping handwaving walking running jogging influence taille blocs combinaison actions précision conclusion avons présenté système reconnaissance actions performant modèles direction modèles magnitude mouvement avons extrait teurs optique séquences vidéo acquérir modèles statistiques orienta magnitude mouvement résultat modèle séquence vidéo estime principales orientations magnitudes blocs scène avons utilisé mesure distance détecter action comparant modèle séquence requête modèles référence appuyant orientation magnitude mouvement notre approche aboutit résultats prometteurs comparés autres approches notamment vidéos haute définition ainsi travaux futurs orienteront amélioration flexibilité notre approche rapport ajout suppression classes action reconnaissance actions applications temps remerciements projet soutenu projet européen midas multimodal inter faces disabled ageing society midas 07008 projet canada comportements anormaux analyse détection alerte benabbas références human action recognition videos using kinematic features multipleinstance learning transactions pattern analysis machine intelligence tpami benabbas lablack ihaddadene djeraba action recognition using direction models motion international conference pattern recognition bouguet pyramidal implementation lucas kanade feature tracker descrip algorithm intel corporation microprocessor research dollar rabaud cottrell belongie behavior recognition sparse spatio temporal features international workshop visual surveillance performance evaluation tracking surveillance fathi action recognition learning level motion features international conference computer vision pattern recognition ganesh bajcsy recognition human actions using optimal control based motor model workshop applications computer vision huang human action recognition using recursive organizing longest common subsequence matching international workshop applications computer vision johansson bergstrom epstein jansson perceiving events objects lawrence erlbaum associates kaewtrakulpong bowden improved adaptive background mixture model realtime tracking shadow detection european workshop advanced video based surveillance systems kläser marszałek schmid spatio temporal descriptor based gradients british machine vision conference laptev lindeberg velocity adaptation space interest points inter national conference pattern recognition laptev marszałek schmid rozenfeld learning realistic human actions movies international conference computer vision pattern recognition lucas kanade iterative image registration technique application stereo vision international joint conference artificial intelligence ijcai mauthner bischof instant action recognition scandina conference image analysis messing kautz activity recognition using velocity histories tracked keypoints international conference computer vision poppe survey vision based human action recognition image vision computing schuldt laptev caputo recognizing human actions local approach international conference pattern recognition reconnaissance actions modélisation mouvement tomasi features track internatioal conference computer vision pattern recognition turaga chellappa subrahmanian udrea machine recognition human activities survey transactions circuits systems video techno ullah kläser laptev schmid 2009a evaluation local spatio temporal features action recognition british machine vision conference leckie 2009b action recognition multi feature fusion gaussian process classification international workshop applications computer vision willems tuytelaars efficient dense scale invariant spatio temporal interest point detector european conference computer vision efficient human action detection using transferable distance function asian conference computer vision zhang action categorization modified hidden conditional random field pattern recognition summary paper proposes approach direction magnitude models perform action recognition videos captured using monocular cameras mixture distribution computed motion orientations magnitudes optical vectors location video sequence sequence model which composed direction model magnitude model created circular circular clustering human tions recognized distance metric based bhattacharyya distance compares model query sequence models created training sequences posed approach validated using public datasets indoor outdoor environments resolution videos