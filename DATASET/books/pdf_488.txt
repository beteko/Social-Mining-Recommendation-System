Topologiques et décomposition Heuristique pour la haute vitesse Clustering de réseaux complexes Faraz Zaidi *, Guy Melançon ** * Institut Karachi d'économie et de la technologie (KIET) Korangi Creek, Karachi, 75190, Pakistan faraz@pafkiet.edu.pk ** CNRS UMR 5800 LaBRI & INRIA Bordeaux - Sud Ouest 351, cours de la Libération, 33405 Talence cedex, FRANCE Résumé guy.melancon@labri.fr. Avec la croissance exponentielle de la taille des données et des réseaux, dé- veloppement des techniques nouvelles et rapides pour analyser et explorer ces réseaux devient une nécessité. De plus, l'émergence de propriétés échelle du monde libre et petits dans les réseaux du monde réel a stimulé beaucoup d'activité dans le domaine de l'analyse du réseau et l'exploration de données. Clustering reste une technique fondamentale pour explorer et organiser ces réseaux. Un problème défi est de trouver un algorithme de classification qui fonctionne bien en termes de qualité de clustering et est efficace en termes de complexité de temps. Dans cet article, nous vous proposons un algorithme de clustering rapide qui combine des heuristiques avec une décomposition topologiques pour obtenir un regroupement. Le algo- rithme que nous appelons topologiques et décomposition Heuristique pour Clustering (TDHC) est très efficace en termes de complexité temporelle asymptotique par rapport à d'autres algorithmes existants dans la littérature. Nous présentons également un certain nombre d'heuristiques pour compléter l'algorithme de clustering qui augmente la vitesse du processus de regroupement en maintenant la haute qualité de regroupement. Nous montrons l'efficacité de la méthode de classification proposée sur les différents ensembles de données du monde réel et comparer ses résultats avec des algorithmes de clustering bien connus. 1 Introduction La plupart des systèmes du monde réel prennent la forme de réseaux où un ensemble de noeuds et des arêtes peut être utilisé pour représenter ces réseaux. Les exemples incluent les réseaux sociaux, les réseaux métaboliques, web alimentaire, les réseaux de transport (Newman (2003)). Clustering reste une technique importante vers une meilleure exploration et de l'organisation de ces réseaux. En termes de réseaux représentant des données réelles du monde, un cluster peut être défini comme un groupe de noeuds qui sont semblables ou connectés dans un certain sens prédéfini et différent des noeuds appartenant aux autres groupes (Schaeffer (2007)). La détection des grappes a une large gamme d'applications dans divers domaines. Par exemple, dans les réseaux sociaux, le regroupement pourrait nous conduire vers une meilleure compréhension des interactions qui ont lieu entre les personnes ou pour les réseaux biologiques, une application utile de regroupement est dans l'identification de biomarqueurs dans un réseau d'interaction protéine-protéine. - 83 - Décomposition topologiques pour grande vitesse clustering Différentes mesures ont été étudiées pour classer ces réseaux. Deux de ces classifications ont gagné beaucoup d'intérêt lorsque les réseaux présentent petit monde (Watts et Strogatz (1998)) et l'échelle libre (Barabási et Albert (1999)) dispose. Ces caractéristiques rendent les réseaux complexes et le problème cluster difficile. Voici quelques exemples de réseaux qui sont à la fois libre à grande échelle et petit monde en même temps sont le réseau de l'auteur (Newman (2001)) et The Movie Network Acteur (Watts et Strogatz (1998)). Une autre question importante qui doit être pris en compte lorsque le développement d'algorithmes de regroupement de ces réseaux est le temps complexité de la taille croissante de ces réseaux, il est BE- presque impossible d'utiliser des algorithmes de clustering lents. Il existe des algorithmes dans la littérature résoudre le problème de clustering pour les vastes réseaux complexes, mais un compromis existe tween Clustering Précision BE- et le temps de complexité. Il est donc évident que des algorithmes plus rapides sont nécessaires pour obtenir le regroupement à grande vitesse, ainsi que une grande précision pour gérer les grands réseaux. La motivation de ce travail vient du fait que la distribution de niveau de noeud de réseaux du monde réel ne sont pas des nœuds aléatoires, plutôt différents ont des degrés divers. Spécialement avec la pré- sence d'un comportement sans échelle, beaucoup de nœuds ont tendance à avoir quelques connexions alors que quelques noeuds dominent la connectivité réseau avec un grand nombre de connexions. Ces réseaux forment une seule composante connexe, mais une analyse attentive suggère que les noeuds ayant un degré élevé, jouent un rôle important dans le maintien l'ensemble du réseau connecté. En utilisant une décom- position des réseaux topologiques en fonction du degré, nous proposons un nouvel algorithme de clustering qui est très efficace en termes de complexité de temps et performe aussi bien que les algorithmes existants en termes de de clustering la qualité du regroupement produit. Nous présentons également des heuristiques à grande vitesse qui aident à réduire la taille du réseau dans le temps de doublure en termes de nombre de nœuds. Tout au long de cet article, nous utilisons le terme de réseau pour faire référence à un graphique simple, et non orienté non pondérée représentée par Me G. Nous représentons le nombre de noeuds par n et le nombre d'arêtes par m. Le reste du papier est organisé comme suit: La section 2 porte un certain nombre d'algorithmes de clustering présents dans la littérature. Dans la section 3, nous expliquons les détails de la décomposition topologique. Nous avons ensuite introduit l'algorithme de TDHC dans la section 4. Dans la section 5, nous présentons des ensembles de données du monde réel utilisées pour l'expérimentation. Nous comparons les résultats de l'algorithme de TDHC avec des algorithmes existants dans la section 6, pour finalement conclure à la section 7. 2 travaux connexes De nombreuses approches différentes ont été proposées pour découvrir les clusters dans les réseaux complexes. Par exemple, Girvan et Newman (Girvan et Newman (2002)) bord utilisé intermédiarité pour produire un algorithme de classification hiérarchique de division. L'idée de base est d'identifier les bords intra du cluster par rapport aux bords inter-munitions. Les bords se trouvant entre les groupes auront une place centrale de BE- tweenness plus élevé par rapport aux bords d'un cluster. L'algorithme de clustering supprime les bords avec une grande place centrale betweenness pour identifier les clusters et recalcule la place centrale betweenness. L'algorithme donne de bons résultats dans la détection des clusters, mais souffre d'une grande complexité du temps. La pire complexité temporelle de cas est donnée par O (M2N). Bien que pratiquement l'algorithme tourne plus vite que son pire des cas, mais il a encore une complexité de temps en raison de la lation cal- de centralité intermédiarité à chaque itération puisque dans chaque itération, le nombre total de noeuds sont divisés par un certain facteur avant de recalculer la centralité betweenness . Wu et al. (Wu et al. (2004)) introduisons une structure à plusieurs mailles pour regrouper les grands réseaux. L'algorithme de clustering utilise centralité Betweenness et le degré de noeud pour identifier un ensemble de - 84 - noeuds représentatifs et Zaidi Melançon. Tous les autres nœuds sont assignés les noeuds représentatifs les plus proches pour obtenir des grappes. Le processus d'agglomération est répétée pour obtenir une classification hiérarchique qu'ils appellent à plusieurs niveaux de maillage. A chaque niveau, l'utilisateur choisit un facteur de ramification qui détermine le nombre de grappes pour ce niveau. Ce nombre pourrait ne pas représenter le nombre réel de clusters dans l'ensemble de données telles qu'elles sont déterminées par l'utilisateur sans l'utilisation d'une mesure heuristique ou statistique. La complexité globale de l'algorithme est donnée par O (M2N). Boccaletti et al. (Boccaletti et al. (2007)) proposent une méthode de classification basée sur les propriétés de dispersion de synchronisation des oscillateurs de phase. A partir d'un état entièrement synchronisé du réseau, un changement dynamique dans les poids des interactions qui conservent des informations sur la distribution de betweenness original, donne une classification hiérarchique progressive qui détecte pleinement les communautés denses. Etant donné que le calcul initial de betweenness prend O (n2), les échelles de l'algorithme quadratique comme le nombre de noeuds augmente. Newman (Newman (2004)) présente un algorithme plus rapide regroupement hiérarchique agglomératif qui est basé sur une fonction de qualité appelée modularité Q. L'algorithme se joint à plusieurs reprises des communautés par paires, en choisissant à chaque étape, la jointure qui entraîne le plus grand in- pli de Q. la complexité temporelle de l'algorithme est donnée par O ((m + n) n) échelles quadratiquement en termes de nombre o f noeuds dans le graphe. Une classe importante d'algorithmes de regroupement appelé algorithmes Spectral Clustering ont suscité un intérêt considérable (Spielman et Teng (1996)). Le plus grand avantage de ces algorithmes est qu'ils sont capables de détecter des clusters sans une forme spécifique par rapport aux algorithmes classiques tels que k-means. En outre, ils sont bien adaptés pour les réseaux de grande taille ainsi. Mais ces algorithmes sont adaptés que des ensembles de données où les graphiques de similarité sont rares (Luxburg (2007)). Pour les graphiques ayant des propriétés libres d'échelle, où quelques noeuds sont reliés à un bon nombre de nœuds, les résultats sous forme de graphiques de similarité non rares. Un exemple du type de graphiques que nous avons avec petit monde et les propriétés libres d'échelle est illustré à la figure 1 (a). Le graphique est aménagé à l'aide d'une force dirigée algorithme (Hachul et Jünger (2005)). Ces algorithmes sont bien connus pour mettre des nœuds plus dense, plus proches les uns des autres et peu connectés noeuds distants les uns aux autres. De la figure, il est tout à fait clair que l'algorithme ne parvient pas à le faire avec petit monde et l'échelle des graphiques libres en raison de la présence de noeuds de degré élevé. Un autre retour de tirage des algorithmes de classification spectrale est que les résultats dépendent fortement du choix des paramètres initiaux et différents paramètres peut entraîner des changements importants dans le regroupement (Luxburg (2007)). Sélectionner- ing paramètres corrects, l'utilisateur doit être bien au courant sur les données et les grappes à générer qui peut être problématique. modéliser un réseau Wu et Huberman (Wu et Huberman (2004)) sous la forme d'un circuit électrique et l'algorithme de regroupement est basé sur la notion de chutes de tension sur les réseaux. L'idée est que chaque bord est considéré comme une résistance entre deux noeuds. En résolvant les équations de Kirchhoff (Alexander et Sadiku (2008)) la valeur de tension peut être obtenue pour chaque nœud. En utilisant cette valeur de tension, la communauté du nœud peut être déterminée. Bien que la durée totale de fonctionnement de l'algorithme est O (m + n), mais l'algorithme doit être répété un certain nombre de fois pour obtenir une certaine précision. Un autre algorithme qui donne de bons résultats en termes de temps d'exécution est basé sur une méthode heuristique qui optimise la modularité (Blondel et al. (2008)). L'algorithme n'utilise pas la modularité normalisée qui est considérée comme un défaut (Fortunato et Barthélemy (2007)). Des algorithmes efficaces pour les réseaux de clusters avec seulement de petites propriétés du monde ont été proposés comme (Auber et al (2003). van Ham et van Wijk (2004)). Ces systèmes fonctionnent bien - 85 - Décomposition topologiques pour Clustering haute vitesse si la topologie du réseau suit les petites propriétés du monde, mais ne parviennent pas à effectuer dans la pré- sence de propriétés libres d'échelle. Cela est dû au fait que dans un réseau sans échelle, quelques nœuds dominent les connexions ensemble des réseaux et rend difficile d'identifier les grappes. 3 topologiques décomposition des graphiques Dans cette section, nous décrivons une méthode introduite plus tôt par les auteurs (Zaidi et Melançon (2010)) pour détecter la présence de noeuds connectés à forte densité dans un réseau relativement rapide. La méthode est basée sur une technique de décomposition qui exploite le fait que des noeuds ayant un degré élevé sont responsables de maintenir les réseaux de grande taille, comme une seule composante connexe. Pour décomposer le réseau en plusieurs composantes, Maxd-Degree induite sous-graphes (Maxd-DIS) sont réalisés où Jmax-DIS est un sous-graphe induit construit par Ering consi- que les noeuds ayant un degré au plus d dans le graphique G. Mathématiquement pour un graphe G (V, E) où V est un ensemble de noeuds et E est un ensemble d'arêtes, la Maxd-DIS est défini comme G '(V', E ') de telle sorte que V' ⊆ V et E '⊆ E et ∀u ∈ V ', degG (u) ≤ d, où d peut avoir des valeurs comprises entre 0 et le degré de noeud maximal possible pour un réseau. On construit pour d = Maxd-DIS {0, 1, · · ·, MaxDeg} pour obtenir un ensemble de graphiques (G0, G1, · · ·, GMaxDeg). Construction d'un Maxd-DIS peut être réalisé en O (n) et si elle est répétée pour toutes les valeurs possibles de niveau de noeud, le procédé peut être réalisé en O (n * MaxDeg) temps où MaxDeg est le degré maximum possible d'un noeud dans le graphique G. Prenons l'exemple du réseau d'Auteur représenté sur la figure. 1. L'ensemble du réseau est représentée sur la Fig. 1 (a), alors que la figure 1. ( b) représente une petite partie étant porté où les noeuds encerclés représentent les noeuds connectés à forte densité ou plus précisément cliques. Fig. 1 (c) et (d) montrent des parties de la Max3-DIS et Max5-DIS dessinées à l'aide d'un algorithme dirigé de force (Hachul et Jünger (2005)). Dans ces deux chiffres, il est assez facile de détecter visuellement les cliques ou les noeuds connectés à forte densité. L'inspiration de l'algorithme de clustering vient de cette visualisation. Fig. 1 (c) et (d) montrent clairement que les noeuds sont déconnectés en l'absence de noeuds de degré élevé et ces composants déconnectés peuvent être facilement identifiés comme des sous-graphes. Nous soutenons que ces sous-graphes, le problème des clusters trouver peut être simplifiée en tant que problème de comptage de nombre d'arêtes et le nombre de noeuds dans un composant connecté. Calculer une composante connexe est un problème qui peut être résolu en O (n + m) temps. De même, le comptage des noeuds et des arêtes peut aussi tourner dans le temps linéaire. En gardant à l'esprit que n et m peut être très faible en fonction de la valeur de d choisie, cette étape va assez vite alors le pire des cas, car il n'y a qu'un nombre limité de noeuds et des arêtes dans Maxd-DIS par rapport au graphique complet G . 4 Méthode proposée Clustering: TDHC de la décomposition topologique, l'idée de construire un algorithme de regroupement est assez intuitif. Etant donné que dans ces sous-graphes, nous pouvons identifier l'ensemble des noeuds qui sont connectés à forte densité à l'autre dans le temps rapide, ils peuvent être regroupés pour former des amas. Ainsi, un algorithme de classification hiérarchique peut être construit qui calcule la Maxd-DIS pour faire varier les valeurs de d et les groupes à forte densité de noeuds connectés. La notion de la définition est-densité traitée plus loin dans cette section. Le nombre d'itérations ne dépendent pas de n ou m de G mais d'un facteur de degré maximum d'un noeud peut avoir dans G. En plus de la détection de noeuds connectés à forte densité par l'intermédiaire - 86 - Zaidi et Melançon FIG. 1 - Co-Authorship réseau (a) Tout le réseau (b) Mise au point sur une petite portion (c) Une partie de Max3-DIS (d) Une partie de Max5-DIS Maxd-DIS, nous introduisons également plusieurs heuristiques qui permettent d'optimiser les performances du algorithme en cluster. Notez que les heuristiques améliorent que la vitesse de convergence de l'algorithme à un cluster unique, et l'algorithme de base peuvent être exécutées sans utiliser ces heuristiques. Toutes ces étapes sont très efficaces en termes de complexité de temps et sont discutés ci-dessous. Lavabo à l'aide de K-Sink Fonctionnement: On définit l'opération K-Sink comme suit: Les noeuds ayant un degré 1 dans un réseau donne à penser qu'ils ne sont connectés à un seul noeud. Nous fusionnons les noeuds de 1 degré dans leurs voisins créant un nouveau nœud pour chaque fusion. Les nœuds de 1 degré fusionné dans les voisins sont appelés les Plombs. Les noeuds dans lequel les noeuds de 1 degré sont appelés se fondre les dolines. Cette opération est justifiée parce qu'un noeud 1 degré ne peut pas être mis en cluster avec un autre nœud comme il est simplement connecté à un seul nœud. Nous appelons cette opération, une opération 1-évier et il est illustré sur la Fig. 2 (a) lorsque le noeud 2 est le platine et le noeud 1 est le doline. Si deux noeuds ont un degré 1 et sont reliés les uns aux autres, ce qui signifie qu'ils sont déconnectés du reste du réseau et dans ce cas, soit du noeud peut être choisi pour être le platine et l'autre comme la doline. De même on définit une opération 2-Sink, considérons deux noeuds, le noeud d'exemple 2 et le noeud 3 à la fois, ayant un degré 2 (Fig. 2 (a)). Ils sont reliés les uns aux autres et à un autre noeud par exemple du noeud 1, avec un degré plus élevé, les noeuds 2 et 3 peuvent être sinked dans le noeud 1 car ils ne sont reliées l'une à l'autre ou noeud 1. Cette opération est illustrée à la Fig. 2 (a) et nous appelons cette opération 2-Sink comme type A. Tout comme dans le cas de 1-Sink, si nous trouvons un ensemble de nœuds chaque degré ayant exactement égale à 2 et reliés les uns aux autres, ce qui signifie qu'ils ne sont pas Conne DECT au reste du graphe, dans ce cas, un nœud quelconque peut être choisie pour être la doline et les deux autres noeuds à la platine. Un autre type d'opération 2-Sink, type B, est quand un noeud de degré 2, - 87 - Décomposition topologiques pour Clustering haute vitesse Fig. 2 - (a) l'opération K-Sink illustré avec une évier et les opérations 2-évier. (B) l'opération de serrage, où les noeuds 1 et 2 get déconnectée en laissant les autres noeuds connectés à forte densité. est reliée à deux autres noeuds de degré supérieur à 2. Indépendamment du fait que ces deux noeuds de haut niveau sont reliés les uns aux autres ou non, le noeud de degré deux ne peut être regroupé avec l'un de ces deux noeuds. Ce que nous faisons est simplement mis le nœud de deux degrés avec le voisin ayant un plus haut degré et de créer un avantage entre ce groupe et l'autre voisin. Pour la mise en oeuvre de l'algorithme, nous utilisons seulement 1 évier et opérations 2 évier AL- bien que l'idée peut être généralisée aux nœuds de puits jusqu'à une constante K. Les deux 1-évier et opérations 2-évier peut être effectuée en temps O (n). Mais une mise en œuvre généralisée au fonctionnement des entreprises in- K-Sink ne sera reste plus linéaire et puisque notre objectif est de maintenir la complexité temporelle limitée par une fonction linéaire ou aussi proche que possible d'une fonction linéaire, nous évitons d'utiliser une opération généralisée K-Sink . L'ordre dans lequel ces K-Sink opérations ont été formés per- est important, où le premier nous effectuons une opération 1-Sink, suivi d'un type A et type B Opérations 2-évier. Ensuite, l'opération de type A 2-Sink est répété finalement suivie d'une opération 1-évier. Rememeber, dans la plupart des réseaux du monde réel, la distribution des degrés de nœud est pas aléatoire, mais est exponentielle. Et il y a beaucoup de noeuds avec un faible degré de nœud et à seulement quelques noeuds avec un haut degré de nœud. L'idée de base l'opération K-Sink est desinged pour regrouper ces nœuds rapidement, étant que si un nœud est connecté à un seul nœud, il doit être mis en cluster immédiatement avec ce nœud. Nous répétons que cette heuristique est tout à fait logique et n'affecte pas la qualité du regroupement, à moins que les clusters singleton sont autorisés à générer, ce qui pourrait ne pas être intéressant pour un expert du domaine à analyser. Degré maximum Induced sous-graphe: L'étape suivante de l'algorithme est de créer un Maxd- DIS avec une petite valeur de d. En raison de cette faible valeur, le réseau peut se briser en plusieurs composants déconnectés les uns des autres comme représenté sur la Fig. 1 (c) et (d). Serrage: Déconnexion Connecté nœuds Librement: Après avoir obtenu le Maxd-DIS, nous effectuons une opération que nous appelons serrage. Nous examinons les noeuds ayant une degré dans cette sous-graphe et l'on enlève simplement les bords de connexion 1 degré noeuds du sous-graphe induit comme représenté sur la Fig. 2 (b). Ce processus nous aide à faire les composants connectés trouvés dans le sous-graphe plus dense. De plus, comme il est certain que les 1 noeuds degré dans les Jmax-DIS font réellement appartiennent au cluster du nœud avec lequel il est connecté, cette étape permet de garantir que les noeuds sont uniquement affectés à des clusters auxquels ils appartiennent. L'étape peut être facilement effectuée en temps O (n) où n peut avoir des petites valeurs par rapport à l'ensemble du graphe G. Calcul des composantes connexes: Une fois que nous avons la Maxd-DIS, on calcule tous les composants connectés dans le sous-graphe. Nous utilisons un algorithme de recherche première largeur (BFS) - 88 - Zaidi et Melançon à partir d'un nœud et itérer ses voisins pour trouver le composant connecté, il appartient. Une fois que nous avons identifié les noeuds connectés au noeud de départ, nous remettons en marche le BFS à partir d'un noeud qui n'a pas encore été visités. Les pistes de l'algorithme en O (n + m) temps. Le regroupement des composants plus dense: La dernière étape consiste à regrouper les composants connectés qui sont connectés les uns aux autres à forte densité. Nous expliquons comment évaluer si le Ponent ciales est assez dense plus loin dans cette section. Une fois que nous avons trouvé les composantes com- dans le sous-graphe, nous regroupons ces nœuds dans le graphique G. connectés dense Nous remplaçons ce groupe de noeuds avec un seul nœud G. bords multiples reliant cette nouvelle cl uster noeud à d'autres noeuds sont supprimés pour faire en sorte que le graphique reste simple. Nous considérons que des composants de taille supérieure à 2 noeuds à être regroupés ensemble. Clustering Algorithm: Maintenant que nous avons expliqué toutes les étapes nécessaires, la décomposition ical Topolog- et heuristiques pour Clustering (TDHC) est présenté comme algorithme 1. L'algorithme commence par le calcul d'un MaxD2-DIS pour rechercher des triangles représentant trois nœuds et reliés les uns aux autres. Pour les noeuds ayant un degré 1, ils se sinked à l'étape 1-évier et donc on n'a pas besoin d'exécuter l'algorithme de MaxD1-DIS. On notera que dans l'algorithme, lorsque l'étape est réalisée sur G, la taille de G en termes de nombre de noeuds diminue en tant que noeuds à l'intérieur de G sont regroupés à des groupes de formulaires. Algorithme 1 TDHC algorithme d'entrée G (V, E) d ← 2 incrément ← 1 tandis que Number_of_Nodes (G)> 1 do K-évier (G) G '= Create_Maxd-DIS (G) de serrage (G') Calculate_Connected_Component (G ') Group_Densely_Connected_Component (G ') d ← d + incrément fin tandis que toutes les étapes de traitement ont une complexité en temps linéaire comme indiqué dans les sections précédentes. Le nombre d'itérations nécessaires pour converger vers une solution ne dépend plus du nombre de nœuds ni les bords, mais le degré maximal d'un nœud peut avoir. De plus, comme dans l'algorithme donné, nous avons choisi un incrément de 1 à chaque itération, dans ce cas, l'algorithme exécute la plupart du temps d. Le choix de la valeur de l'incrément variable dépend de l'utilisateur, qui peut être augmentée en fonction de la façon dont les résultats varient en fonction de cette valeur. Un moyen de valeur d'incrément moins élevé nombre d'itérations, mais les risques dans les composants moins denses trouvés. À l'heure actuelle, nous avons maintenu la valeur d'incrément à 1, mais nous avons l'intention d'expérimenter avec ce paramètre dans l'avenir pour étudier la variation de la qualité des grappes produits. La complexité du temps de cas moyen de l'algorithme complet peut être exprimé AsO (d * (m + n)) où d est le degré maximal d'un noeud dans le graphique G. Une observation importante de l'algorithme de regroupement est qu'il utilise à la fois le Divisive que ainsi que Ascendante approches graphiques du cluster. La partie vient de division du fait que nous construisons degré sous-graphes induits - 89 - Décomposition topologiques pour grande vitesse Clustering et la partie est représentée agglomératif lorsque nous nœuds de cluster pendant le fonctionnement K-Sink et le regroupement des composants plus dense. Aplatissant les clusters: La classification hiérarchique ainsi produit peut avoir plusieurs pôles avec 2 ou 3 noeuds en raison de l'opération K-Sink expliqué précédemment. Nous analysons simplement récursive par différents groupes pour supprimer ces grappes de petite taille et de les fusionner en groupes de plus grande taille. Pour produire un regroupement partitionnel (à plat), en utilisant le même algorithme, tout ce que nous devons faire est de remplacer la condition dans l'algorithme où nous voulons converger vers un seul nœud par le nombre de groupes que nous voulons obtenir dans le réseau. Une fois que nous arrivons à ce numéro, nous pouvons aplatir la hiérarchie pour obtenir un regroupement partitionnel. Nous avons utilisé cette même approche pour comparer les résultats de l'algorithme de TDHC avec les autres algorithmes de regroupement. Densité Fonction: Il existe plusieurs définitions de la façon de calculer la densité d'un graphique (Melançon (2006)). Par souci de simplicité, nous utilisons le noeud de rapport de bordure (n / m) pour désigner la densité du graphe. Melançon (2006)) fait valoir que la densité d'un graphique varie en fonction du domaine d'application donnant des exemples du monde réel. Pour l'algorithme de regroupement proposé, nous utilisons une fonction de densité pour déterminer à quel point un ensemble de noeuds est connecté à l'autre. Sur la base des arguments et des exemples fournis dans (Melançon (2006)), nous soutenons que nous ne pouvons pas avoir un ensemble de valeurs de densité générique comme seuil pour décider si un ensemble de noeuds est assez connecté ou non. En outre, la question de savoir si un ensemble de noeuds sont connectés assez bien pour être en cluster, dépend non seulement de la densité de l'ensemble graphique, mais sur la structure sous-jacente du réseau ainsi. Pour résoudre ce problème, nous PROP Ose une fonction de densité flottante à-dire, nous proposons un ensemble de fonctions à partir de valeurs de densité élevée à des fonctions progressivement moins denses. L'idée est d'essayer de trouver des communautés très denses en premier lieu, pour toutes les valeurs possibles de la Maxd-DIS, puis remplacer la fonction de densité avec une fonction moins dense. Nous commençons par chercher le nombre maximum d'arêtes possibles pour un ensemble de noeuds et finissent par se retrouver à la recherche du nombre minimal d'arêtes possibles pour un ensemble de noeuds à connecter. Nous cluster un ensemble de noeuds si le nombre d'arêtes m est égal à: m = n (n-1) / 2 m ≥ n (n-1) * 0,9 / 2 m ≥ n (n-1) * 0,6 / 2 m ≥ n (n-1) * 0,4 / 2 m ≥ (1,5 * n) - 0,5 m ≥ n l'ensemble des équations représentent une diminution progressive de la densité de noeuds bord requis pour un groupe de noeuds à considérer comme suffisamment dense pour être regroupés. Bien que l'idée en utilisant l'équation flottante peut effectuer le nombre d'itérations nécessaires pour regrouper l'ensemble des données, mais il nous assure que les grappes trouvées seraient denses. Ceci est le seul paramètre de contrôle qui est requis par l'algorithme proposé et varie d'un ensemble de données à l'autre. La complexité globale de l'algorithme reste le même que le nombre de gammes d'équations d'une valeur constante de 2 à 6. 5 ensembles de données Expérimentation: Le premier ensemble de données est le réseau copaternité de scientifiques travaillant sur la théorie des réseaux et des expériences ( Newman (2006)). Le deuxième ensemble de données est un ensemble de données de mappage de réseau qui se compose de trajets à partir d'un hôte de test vers d'autres réseaux sur l'Internet contenant ING rout- et des informations d'accessibilité (www.opte.org). Depuis le Divisive Clustering algorithme a une complexité de temps, nous considérons qu'un sous-ensemble des données réelles avec 1049 nœuds et - 90 - Zaidi et Melançon 1319 bords. Le troisième ensemble de données est un réseau d'interactions de protéine utilisée par (Gavin (2002)). Les données sont disponibles sur le site Web (http://dip.doe-mbi.ucla.edu/dip) et contient 1246 nœuds et 3142 arêtes. noeuds déconnectés (80 nœuds) ont été retirés à partir des données. Le choix de ces ensembles de données sont basées sur les critères que tous ces réseaux appartiennent à une classification différente des réseaux tels que décrits dans la littérature (Newman (2003)). Le réseau auteur représente un réseau social de la collaboration, le réseau Internet représente un réseau technologique et le réseau de protéines représente un réseau biologique. Tous ces réseaux ont une exponentielle (pas nécessairement suivant une loi de puissance) de distribution de degré. Le coef ficients Clustering du réseau auteur est 0,74 et la longueur du trajet moyen est 6,04, celle du réseau Internet est de 0,005 et 6,42, et enfin pour le réseau de protéines est de 0,23 et 4,89 respectivement. Clustering algorithmes: à se regrouper ces ensembles de données, nous utilisons deux connu regroupement algorithmes de l'algorithme Bissectrice K-Means (. Steinbach et al (2000)) et l'algorithme de clustering Divisive basé sur le bord Centralité (Girvan et Newman (2002)) . Le choix de ces algorithmes est basée sur les critères que ces algorithmes ne tentent pas d'optimiser ou d'influencer l'algorithme de classification en fonction de la densité ou une autre mesure de qualité de cluster par rapport à d'autres algorithmes présents dans la littérature comme (Newman (2004 )). En outre, ils sont connus pour bien performer pour un certain nombre d'ensembles de données du monde réel (Girvan et Newman (2002)). Nous utilisons également la force Clustering algorithme proposé par (Auber et al. (2003)). L'algorithme a été montré que de bons résultats pour l'identification des composants connectés à forte densité que les clusters. Cluster d'évaluation Metrics: Pour évaluer la qualité de la mise en grappes produits, nous utilisons les mesures suivantes. La modularité (Q) (Newman et Girvan (2004)) (Q métrique) est une métrique qui mesure la fraction des arêtes dans le réseau que des bords de connexion au sein de la collectivité, moins la valeur attendue de la même quantité dans un réseau avec la même communauté divisions, mais les connexions aléatoires entre les sommets. Si le nombre d'intérieur communautaire arêtes est pas mieux que aléatoire, nous obtenons Q = 0. Les valeurs approchant Q = 1, est le maximum, indique la structure communautaire forte. La seconde métrique utilisée par Auber et al. (Auber et al. (2003)) est appelée MQ métrique. Il se compose de deux facteurs où le premier terme contribue au poids positif représenté par la valeur moyenne de densité de bord à l'intérieur de chaque grappe. Le second terme contribue en tant que poids négatif et représente la valeur moyenne de densité de bord entre les grappes. Enfin, la densité relative (RD) (Mihail et al. (2002)) d'un groupe calcule le rapport de la densité de bord à l'intérieur d'une grappe à la somme des densités de bord à l'intérieur et l'extérieur de ce groupe. La RD finale est la somme moyenne des ces différentes densités relatives pour tous les groupes. 6 Résultats et discussion Comme le montrent les sections précédentes du temps de cas moyen de l'algorithme de complexité est O (d * (m + n)), mais en réalité, les pistes de l'algorithme beaucoup plus rapide que son cas en moyenne. Ceci est parce que les progrès de l'algorithme, les noeuds sont regroupés en grappes et la taille du réseau devient plus petit. Nous comparons les résultats de l'algorithme de clustering avec TDHC (Girvan et Newman (2002), Newman (2004), et al Auber (2003).) Au tableau 1. A partir des différentes valeurs, il est tout à fait clair que l'algorithme de TDHC performe aussi bien que les autres algorithmes de regroupement. Bien que l'utilisation de la métrique RD, ses performances ne sont pas aussi bon que l'autre groupement algorithmes de. Ces différences mettent en évidence le comportement des diverses mesures d'évaluation des clusters présents dans la littérature. Néanmoins, compte tenu de la complexité temporelle de TDHC par rapport à la - 91 - Décomposition topologiques pour grande vitesse Clustering Auteur Internet protéine algorithme MQ Q RD MQ Q RD MQ Q RD Div. Clus. 0,77 0,63 0,32 0,53 0,79 0,69 0,31 0,63 0,49 Bis. K-Means 0,77 0,63 0,41 0,42 0,59 0,58 0,41 0,33 0,31 Force 0,26 0,23 0,50 0,83 0,35 0,55 0,52 0,16 0,29 0,82 0,42 TDHC 0,42 0,55 0,85 0,49 0,38 0,44 0,23 TAB. 1 - Résultats de Divisive Clustering basé sur la distribution Edge (Div Clus..), Bissectrice K-Means (Bis K-Means.) Et des algorithmes de clustering force avec l'algorithme de TDHC. FIGUE. 3 - linéaire Durée de l'algorithme de TDHC avec l'augmentation de la taille du graphique. d'autres algorithmes, les résultats empiriques montrent de TDHC que l'algorithme donne de bons résultats sur des ensembles de données dif- férents. Nous ne prétendons pas que notre algorithme produit de meilleurs résultats de qualité pour différents types de réseaux et techniques d'évaluation du cluster, mais nous montrons que notre algorithme fonctionne aussi bien que d'autres algorithmes. La contribution majeure de l'algorithme est la faible complexité temporelle asymptotique qui nous permet d'exécuter l'algorithme pour les réseaux de grande taille. La figure 3 montre le temps d'exécution de l'algorithme TDHC pour les graphes de taille croissante en termes de nombre de nœuds. Les graphiques ont été produits en utilisant le modèle de génération de réseau artificiel pour petit monde et graphiques libres d'échelle en utilisant le modèle de Klemm et Eguiluz (2002). L'analyse de l'algorithme, nous essayons d'exploiter deux caractéristiques importantes des réseaux, la distribution des degrés et le coefficient de clustering. La décomposition topologiques utilise le fait que les réseaux du monde réel ne sont pas une distribution uniforme de degré, ainsi la décomposition contribue à briser le réseau en plusieurs composants. Et d'autre part, les réseaux ayant un haut coefficient de classification représentent la présence de noeuds connectés à forte densité du réseau, qui peuvent être regroupées pour former des grappes. L'idée de la fonction flottante de densité fonctionne bien pour les réseaux qui n'ont pas haut coefficient de clustering (Voir réseau Internet) que nous essayons de nœuds de groupe qui sont connectés moins denses. Les résultats montrent que l'algorithme fonctionne bien pour les différents types de réseaux. 7 Conclusion et futures recherches Dans cet article, nous avons utilisé heuristiques et une technique basée sur la position topologique du réseau décom- pour développer un algorithme de clustering à haute vitesse. La faible asymptotique - 92 - Zaidi et complexité temporelle de l'algorithme Melançon ouvre de nouveaux horizons au domaine de l'analyse du réseau et le regroupement. Comme le montrent les résultats, les exécute algorithme proposé, ainsi que d'autres algorithmes existants en termes de précision, mais en grande partie sur les pose en termes de complexité de temps. De cette étude, il y a beaucoup de questions qui doivent être examinées plus en détail et présente de nouvelles opportunités stimulantes de recherche. Par exemple l'opération K-Sink comme un utilitaire important de réduire la complexité des réseaux libres d'échelle et les regroupant basée sur cette opération uniquement. Les Jmax-DIS comme une décomposition importante de petits réseaux mondiaux pour le regroupement. Nous avons l'intention d'effectuer une étude approfondie en utilisant la position topologique présentée et décom- attendre à trouver de nouveaux résultats intéressants. Références Alexander, C. et M. Sadiku (2008). Principes de base des circuits électriques. McGraw-Hill. Auber, D., Y. Chiricota, F. Jourdan et G. Melancon (2003). visualisation multi-échelles des petits réseaux mondiaux. En InfoVis '03: Actes du Symposium IEEE sur la visualisation de l'information, pp 75-81.. Barabási, A. L. et R. Albert (1999). Emergence de mise à l'échelle dans les réseaux aléatoires. ence fiques 286 (5439), 509-512. Blondel, V. D., J.-L. Guillaume, R. Lambiotte, et E. Lefebvre (2008). déploiement rapide des communautés dans les grands réseaux. J. Stat. Mech. 2008 (10), P10008 +. Boccaletti, S., M. Ivanchenko, V. Latora, A. Pluchino et A. Rapisarda (2007). La détection de modularité complexe des réseaux par le regroupement dynamique. Physical Review E 75. Fortunato, S. et M. Barthélemy (2007). limite de résolution dans la détection de la communauté. Ings Proceed- de l'Académie nationale des sciences 104 (1), 36-41. Gavin (2002). organisation fonctionnelle du protéome de levure par une analyse systématique des complexes de protéines. Nature 415 (6868), 141-147. Girvan, M. et M. E. J. Newman (2002). Structure communautaire dans les réseaux sociaux et biologiques. Proc. Natl. Acad. Sci. USA 99, 8271-8276. Hachul, S. et M. Jünger (2005). Dessin grands graphes avec un algorithme multi-niveaux sur le terrain-potentiel. Graphique Dessin, 285-295. Klemm, K. et V. M. Eguiluz (2002). De plus en plus des réseaux sans échelle avec un petit comportement mondial. Physical Review E 65, 057102. Luxburg, U. (2007). Tutoriel sur la classification spectrale. Statistiques et informatique 17 (4), 395-416. Melançon, G. (2006). Juste combien denses graphiques denses dans le monde réel ?: une note méthodologique. Dans BELIV '06: Proc. de l'atelier AVI 2006 sur le temps et les erreurs au-delà, pp. 1-7. Mihail, M., C. Gkantsidis, A. Saberi et E. Zegura (2002). Sur la sémantique des topologies Internet, gitcc0207. Rapport technique, College of Comp., Institute of Georgia Tech., États-Unis. Newman, M. E. (2001). réseaux de collaboration scientifique. je. la construction du réseau et les résultats fonda- mentaux. Phys Rev E Stat Nonlin matière molle Phys 64 (1 Pt 2). Newman, M. E. et M. Girvan (2004). La recherche et l'évaluation de la structure des communautés dans les travaux Net-. Phys Rev E Stat Nonlin matière molle Phys 69 (2 Pt 2). - 93 - pour Décomposition topologiques haute vitesse Clustering Newman, M. E. J. (2003). Structure et fonction des réseaux complexes. SIAM Review 45, 167. Newman, M. E. J. (2004). algorithme rapide pour la détection de la structure des communautés dans les réseaux. Physical Review E 69, 066133. Newman, M. E. J. (2006). Trouver la structure des communautés dans les réseaux utilisant les matrices de vecteurs propres. Physical Review E (statistiques, non-linéaire, et physique de la matière souple) 74 (3). Schaeffer, S. E. (2007). Graphique en cluster. Computer Science Review 1 (1), 27-64. Spielman, D. A. et S.-H. Teng (1996). travaux de partitionnement spectraux: graphes planaires et maillages éléments finis. Dans Au Symposium IEEE sur les fondations de l'informatique, pp. 96-105. Steinbach, M., G. Karypis et V. Kumar (2000). Une comparaison des des techniques de classification des documents. Rapport technique, Département des sciences informatiques et en génie, Univ. du Minnesota. van Ham, F. et J. van Wijk (2004). La visualisation interactive des petits graphiques du monde. En InfoVis 2004. Symposium IEEE sur la visualisation de l'information, pp. 199-206. Watts, D. J. et S. H. Strogatz (1998). Les dynamiques collectives des réseaux « petits monde ». La nature 393, 440-442. Wu, A. Y., M. Garland, et J. Han (2004). Exploitation minière réseaux sans échelle en utilisant géodésique cluster- ment. Dans KDD '04: Proc. de SIGKDD, pp. 719-724. Wu, F. et B. A. Huberman (2004). Trouver les communautés dans le temps linéaire: Une approche de la physique. Le Journal européen pour la physique B 38, 331-338. publication informelle. Zaidi, F. et G. Melançon (2010). Identification de la présence des communautés dans les réseaux complexes par décomposition et topologiques des composants Densités. En EGC 2010, Extraction et Gestion de Connaissance, volume E-19, RNTI. 163-174. Avec l'résumé de la Exponentiel Accroissement des taille et des réseaux Données, il DEVIENT né- cessaire de develop des techniques et nouvelles d'analyse et rapides d'exploration de bureaux réseaux. De plus, l'Émergence de petit monde du Propriétés et Graphes sans les réseaux Dans échelle du monde un réel STIMULE l'activité grandement Dans le domaine de l'analyse de l'exploitation d'et réseau des Données. Le Regroupement technique Fondamentale Une demeure verser ex plorer et organisateur bureaux réseaux. La Consiste à Difficulté Trouver un algorithme de regroupement Qui bien en Fonctionne Termes de qualité de et Qui Regroupement en Soit Termes de Efficace de temps Complexité. Dans this article, nous proposons un algorithme de regroupement rapide Qui combinent cer- Taine heuristiques with a verser obtain Décomposition un topologique regroupement. L'al gorithme nous appelons Que et Heuristiques Décomposition topologique verser Regroupement (TDHC) est tres en Annoter de Efficace Complexité de temps asymptotique aux Autres algorithmes comparé Dans la litérature existant. Nous introduisons un also Heuristiques D'Nombre de postes verser l'Agenda item algorithme de la accroit Qui Regroupement du Processus de vitesse en regroupement la haute qualité Maintenant du regroupement. Nous montrons de la l 'efficacité de méthode sur proposed Regroupement de Données Différentes séries du monde et nous comparons réel SES Résultats Avec des algorithmes de bien connus regroupement. - 94 -