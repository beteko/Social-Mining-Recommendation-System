 actes_non_num\351rotes pdf Détection de séquences atypiques basée sur un modèle de Markov d’ordre variable Cécile Low Kam Anne Laurent Maguelonne Teisseire I3M Univ Montpellier 2 CNRS Pl Eugène Bataillon Montpellier France cecile lowkam math univ montp2 fr LIRMM Univ Montpellier 2 CNRS 161 rue Ada Montpellier France {laurent teisseire} lirmm fr Résumé Récemment le nombre et le volume des bases de données séquen tielles biologiques ont augmenté de manière considérable Dans ce contexte l’i dentification des anomalies est essentielle La plupart des approches pour les extraire se fondent sur une base d’apprentissage ne contenant pas d’outlier Or dans de très nombreuses applications les experts ne disposent pas d’une telle base De plus les méthodes existantes demeurent exigeantes en mémoire ce qui les rend souvent impossibles à utiliser Nous présentons dans cet article une nouvelle approche basée sur un modèle de Markov d’ordre variable et sur une mesure de similarité entre objets séquentiels Nous ajoutons aux méthodes ex istantes un critère d’élagage pour contrôler la taille de l’espace de recherche et sa qualité ainsi qu’une inégalité de concentration précise pour la mesure de similarité conduisant à une meilleure détection des outliers Nous démontrons expérimentalement la validité de notre approche 1 Introduction Un outlier est défini dans Hawkins 1980 comme "une observation qui s’écarte telle ment des autres qu’elle est susceptible d’avoir été générée par un mécanisme différent" Ces dernières années la détection d’outliers a été étudiée pour des types de données très divers En effet les applications associées à la découverte d’anomalies sont très nombreuses dans des domaines aussi variés que la détection de fraudes ou l’analyse de séquences biologiques Parmi elles les bases d’ADN et de protéines ont fait l’objet de nombreuses études pour une meilleure compréhension des phénomènes biologiques par exemple par l’extraction de motifs Ferreira et Azevedo 2007 La perspective d’identifier des anomalies peut alors compléter les propositions actuelles Mais effectuer cette recherche demeure problématique puisque les outliers sont rares par définition De plus ils ne doivent pas être confondus avec le bruit inhérent à tout jeu de don nées Néanmoins certaines propositions existent et nous pouvons citer celles fondées par ex emple sur des tests de discordance sous l’hypothèse d’une distribution de probabilités des observations donnée dans le cadre univarié ou multivarié Barnett et Lewis 1994 D’autres Détection de séquences atypiques se basent également sur la notion de distance afin de détecter les anomalies dans le cas de données multidimensionnelles Knorr et Ng 1998 Toutefois ces méthodes ne sont pas adaptées à certaines bases biologiques qui sont partic ulières par leur structure séquentielle et leur taille importante L’enjeu est alors de sélectionner un modèle approprié Une approche très efficace pour la découverte d’anomalies dans de telles bases a été proposée dans Sun et al 2006 Elle se fonde sur un modèle d’arbre de suffixes et l’introduction d’une mesure de similarité Mais cette méthode peut être très exigeante en mé moire et nécessite une base de séquences typiques pour construire un modèle Nous proposons donc dans cet article d’étendre cette approche afin de pallier ces inconvénients En particulier nous utilisons un critère d’information qui sélectionne un modèle adéquat et parcimonieux En ce qui concerne la mesure de similarité nous obtenons des bornes plus précises au delà desquelles les séquences sont considérées comme atypiques Ceci permet une meilleure détec tion des anomalies dans la base considérée 2 Extraction d’anomalies dans les bases séquentielles Dans cette section nous décrivons une approche pour l’extraction d’anomalies dans les bases séquentielles Nous considérons des bases de données de séquences de la forme s = s1 s` de ` lettres On note PT s la probabilité de s dans la base Pour 2 ≤ i ≤ ` PT si|s1 si−1 = P T s1 si P T s1 si−1 est la probabilité que si suive s1 si−1 L’hypothèse sur laquelle se base l’approche de Sun et al est que les séquences d’ADN ou de protéines possè dent une propriété de "mémoire courte" Ron et al 1996 il existe un entier 1 ≤ K ≤ i − 1 tel que PT si|s1 si−1 = P T si|si−K si−1 1 Autrement dit la valeur de la séquence au temps i ne dépend que desK valeurs précédentes Il s’agit d’une propriété de Markov d’ordreK Elle est dite d’ordre variable car K n’est pas fixé Une représentation usuelle d’un tel modèle est un arbre de suffixes où chaque noeud a pour parent son plus grand suffixe Dans un tel arbre chaque feuille représente une mémoire de la chaîne de Markov associée Ce modèle est à l’origine de nombreuses applications telles que la classification en familles des séquences de protéines Bejerano et Yona 1999 En effet il permet d’estimer la probabilité de chaque sous séquence de la base 2 1 Arbre Probabiliste des Suffixes Supposons que nous avons un ensemble S de séquences sur un alphabet fini Σ Un arbre probabiliste des suffixes ou Probabilistic Suffix Tree PST est un arbre des suffixes classique muni de probabilités conditionelles associées à chaque noeud Ron et al 1996 Plus précisé ment chaque noeud est associé à une séquence s de la base Il contient le nombre d’occurences de s dans la base et un vecteur de longueur |Σ| des probabilités conditionnelles PT σ|s pour tout σ ∈ Σ Comme la taille de l’arbre augmente de façon exponentielle avec la longueur des mémoires il est élagué A cet effet une longueur maximale L est fixée pour l’arbre Et les noeuds de fréquence faible sont également élagués étant considérés comme négligeables C Low Kam et al e 0 7 0 3 0 5 0 5 0 01 0 99 0 67 0 33 b 23 aa 2 ba 12 a 15 bab 3 bba 9 bbb 6 aba 7 bb 14 ab 19 abb 5 0 35 0 65 0 2 0 8 0 45 0 55 0 9 0 1 0 5 0 5 0 7 0 3 aab 1 FIG 1 – Un exemple de PST sur l’alphabet binaire Exemple 2 1 La figure 1 montre un PST construit sur l’alphabet {a b} On pose une longueur maximale L = 3 Il s’agit de l’ordre maximum de la chaîne de Markov On fixe également la fréquence minimale des séquences dans la base à 4 Les noeuds aa aab et bab sont alors élagués car ils sont rares Une fois l’arbre construit les probabilités conditionnelles associées à ses noeuds sont util isés pour estimer la distribution de chaque séquence puisque pour toute séquence s = s1 s` PT s1 s ̀ = P T s`|s1 s`−1 × ×P T s2|s1 ×P T s1 Exemple 2 2 En utilisant le PST de l’exemple précédent PT aabb = PT b|aab ×PT b|aa ×PT a|a ×PT a = PT b|ab ×PT b|a ×PT a|a ×PT a = 0 50×0 80×0 20×0 35 2 Une fois la probabilité de chaque séquence calculée une mesure de similarité est introduite afin de distinguer les observations atypiques 2 2 Mesure de similarité et théorie de l’information Dans Sun et al 2006 pour chaque séquence s = s1 s` la mesure de similarité SIMN est définie par SIMN s = 1 ` log PT s1 s` 3 Afin de pouvoir estimer la similarité de n’importe quelle nouvelle séquence les probabilités du PST sont lissées La mesure SIMN est normalisée et n’est donc pas biaisée par la longueur de la séquence De plus sous certaines hypothèses SIMN possède une intéressante propriété asymptotique supposons que les séquences sont générées par une source d’information Cela signifie qu’elles sont à valeurs dans un alphabet fini et qu’elles ont une distribution stationnaire qui ne varie pas au cours du temps Rappelons aussi que l’entropie d’une variable aléatoire est une mesure de régularité Ash 1990 Cette notion s’étend facilement au cas de deux variables ou plus les concepts de distri bution jointe et conditionnelle menant à ceux d’entropie jointe et conditionnelle L’incertitude d’une source d’information est alors définie comme la limite de l’entropie conditionelle Détection de séquences atypiques Supposons enfin que les séquences de la base S ont été générées par une unique source d’information alors d’après le théorème de Shannon McMillan Shannon 1948 sous la condition d’ergodicité de la source −SIMN converge vers l’incertitude de la source Une preuve de ce résultat se trouven dans Ash 1990 Ainsi quand ` est grand SIMN s de vrait être près de l’incertitude de la source si s a réellement été générée par elle Sinon SIMN s sera loin des similarités des autres séquences Par conséquent l’inégalité de concen tration de Bienaymé Tchebycheff est utilisée pour déterminer des bornes au delà desquelles les séquences sont susceptibles d’être des anomalies Mais cette inégalité est moins performante pour les points éloignés de la moyenne qui sont précisément les outliers potentiels Dans Sun et al 2006 des expérimentations sur des bases de protéines sont menées avec succès Mais elles reposent sur une connaissance préliminaire de séquences typiques puisque seules celles ci sont utilisées pour construire le PST En effet tout d’abord un modèle est construit sur une base de séquences puis les auteurs déterminent si de nouvelles séquences sont des outliers par rapport à ce modèle Cependant dans notre approche nous souhaitons extraire directement les anomalies de l’ensemble des séquences puisque nous ne connaissons pas les séquences typiques Donc bien que la méthode présentée dans cette section soit très efficace pour mettre en évidence les différences de structures entre les familles de protéines elle échoue lorsque l’on souhaite identifier les outliers parmi une base de séquences De plus bien qu’en partie réduite par un élagage selon la fréquence la taille de l’arbre demeure problématique Par conséquent notre proposition a pour but l’amélioration de l’approche de Sun et al 2006 Et plus particulièrement dans cet article nous déterminons si une séquence s est un outlier étant donnés une base S et un seuil t 3 Vers une approche plus générique Dans cette section nous détaillons notre approche Plus précisément nous introduisons – Un élagage supplémentaire de l’arbre avec un critère d’information conduisant à une découverte systématique des anomalies grâce à un modèle adéquat et réduit – L’utilisation d’une inégalité de concentration exponentielle pour la mesure de similarité résultant en des seuils plus précis et ainsi en une meilleure séparation entre outliers et séquences typiques Nous adoptons les mêmes hypothèses de mémoire courte et de stationnarité et nous consid érons également le cas d’une alphabet Σ fini 3 1 Elagage du PST avec le critère d’information d’Akaike Nous avons vu dans la section 2 qu’un PST peut être élagué en deux étapes – Une longueur de branche maximale L est fixée Tout noeud situé au delà de L dans l’arbre est élagué – Tout noeud pour lequel la fréquence de la séquence associée est inférieure à un seuil donné est élagué En plus de ces deux procédures dans Ron et al 1996 un PST est construit de la façon suivante un noeud est ajouté à l’arbre s’il diffère statistiquement de son père Un critère basé sur l’information de Kullback Leibler est utilisé à cet effet L’information ou distance de Kullback Leibler est parfois appelée entropie relative et représente l’information perdue C Low Kam et al quand une distribution est utilisée pour approximer une autre Burnham et Anderson 1998 La statistique d’erreur pour une lettre σ et une séquence s est définie dans Ron et al 1996 par Err σs s = PT σs × ∑ σ′∈Σ P T σ′|σs log P T σ′|σs P T σ′|s Si Err σs s est supérieur à un seuil donné le noeud correspondant à σs est ajouté à l’arbre Ainsi l’information supplémentaire apportée par un fils à son père peut être mesurée Comme l’information de Kullback Leibler originelle est pondérée par la probabilité de σs les noeuds correpondant aux séquences dont les probabilités d’obervation sont faibles sont élagués qu’ils différent ou non de leur père Etant rares ils sont considérés comme néglige ables Dans Sun et al 2006 seul ce dernier critère est appliqué Mais ce qui est vrai à un niveau de l’arbre ne l’est pas nécessairement aux niveaux suivants les distributions pouvant différer à une profondeur supérieure Par conséquent tous les descendants potentiels de chaque noeud élagué sont aussi testés Exemple 3 1 Considérons à nouveau l’arbre binaire de la figure 1 On fixe le seuil à 0 1 Err abb bb = 0 001 et Err abb bb = 0 Les noeuds abb et bbb sont alors élagués puisque leurs vecteurs de probabiliés conditionnelles sont similaires à celui de leur père et qu’ils n’apportent donc aucune connaissance supplémentaire La méthode d’élagage ci dessus n’est pas utilisée dans Sun et al 2006 Par conséquent afin de réduire davantage la taille de l’arbre nous utilisons un critère appelé An Information Criterion AIC et introduit dans Akaike 1973 Ce critère permet de trouver un compromis entre l’ajustement d’un modèle aux données et sa complexité Soit L la fonction de vraisem blance d’un modèle et k le nombre de ses paramètres Alors ce critère est défini comme suit AIC = 2k−2 logL L’AIC est relié à l’information de Kullback Leibler Il se base également sur la vraisemblance et contient un terme supplémentaire afin de corriger le biais d’estimation asymptotiquement Ce critère permet de comparer la distance de deux modèles potentiels em boîtés du "vrai" modèle inconnu puis de choisir le plus proche voir Burnham et Anderson 1998 pour plus de détails Ainsi dans un ensemble de modèles candidats nous choisissons celui pour lequel l’AIC est le plus faible En pratique l’AIC peut être peu performant si le nombre de paramètres est élevé par rapport à la taille de la base de données Ce problème est notamment soulevé dans Sugiura 1978 Par conséquent le critère d’information du second ordre est défini dans Hurvich et Tsai 1989 par AICc = AIC + 2k k + 1 n − k − 1 4 où n est la longueur totale des données L’AICc est adapté quel que soit le nombre de paramètres du modèle Pour cela nous utilisons toujours cette version corrigée dans nos applications Nous appliquons ce critère en deux étapes Tout d’abord notonsML le modèle de Markov d’ordre fixe L Nous choisissons le meilleur modèle au sens du critère parmi l’ensemble {ML L ≥ 0} Ainsi une longueur maximale pour l’arbre est fixée Ensuite nous appliquons le même critère à chaque niveau père fils soit Mp le modèle basé sur le père et Ms celui basé sur ses fils alors ∆AICc = AICc Mp − AICc Ms exprime la différence entre ces deux modèles Nous ajoutons tous ses fils à un père si cette différence est significative Burnham et Anderson 1998 Sinon nous n’ajoutons aucun des fils à leur père Ainsi nous obtenons un modèle de Markov d’ordre variable Nous introduisons le critère d’Akaike corrigé dans l’algorithme proposé dans Sun et al 2006 Nos expérimentations Détection de séquences atypiques montrent que la taille de l’arbre diminue considérablement avec ce nouveau critère et que la qualité de discrimination est améliorée En résumé non seulement notre modèle possède un fondement statistique mais il nous permet aussi de réduire le nombre de noeuds dans l’arbre Dans la littérature le critère d’Akaike est souvent associé à un autre critère connu appelé critère d’information de Bayes BIC Il a été introduit dans Schwarz 1978 La différence entre les deux critères concerne le terme de correction puisqueBIC = log n k−2 logL où n est la longueur totale des données Comme le sujet de notre travail n’est pas la comparaison de ces deux critères nous nous bornons à remarquer qu’ils sont employés à des fins différentes le but de l’AIC est de parvenir au meilleur compromis entre biais et variance alors que le mod èle sélectionné par le BIC converge vers le "quasi vrai" modèle le modèle parmi l’ensemble des candidats qui est le plus proche du vrai Nous utilisons les deux critères et obtenons des résultats comparables Une fois ce modèle sélectionné les probabilités conditionnelles du PST sont utilisées afin de calculer SIMN s pour chaque séquence s de S 3 2 Des bornes plus précises pour la concentration de SIMN Dans la section précédente nous avons vu comment les mesures de similarités sont cal culées à partir du PST Puis pour détecter les outliers dans la base l’inégalité de Bienaymé Tchebycheff est utilisée dans Sun et al 2006 soient E SIMN et V SIMN l’espérance et la variance de la variable aléatoire SIMN Alors P{|SIMN−E SIMN |≥ t} ≤ V SIMN t2 pour tout t > 0 Les outliers sont les séquences dont la similarité se trouve loin des autres en dehors des bornes définies ci dessus Mais bien que satisfaisante pour les points proches de la moyenne cette inégalité est connue pour être peu adéquate pour les observations loin de la moyenne i e les outliers potentiels Pour ces derniers les inégalités de concentration de type exponentiel sont particulièrement adaptées Nous nous intéressons en particulier à l’inégalité de Bennett 1962 Théorème 3 1 SoientX1 X` des variables aléatoires réelles indépendantes et centrées et telles que |Xi| ≤ c avec une probabilité de un Soit S` = ∑` i=1 Xi et σ 2 = 1 ` ∑` i=1 V Xi Alors pour tout t > 0 P {S` > t} ≤ exp − `σ2 c2 h ct `σ2 5 où la fonction h est définie pour u ≥ 0 par h u = 1 + u log 1 + u − u Nous considérons les variables Xi = log PT si|s1 si−1 1 ≤ i ≤ ` Elles sont bornées puisque les probabilités conditionnelles de l’arbre sont lissées Comme l’inégalité de Ben nett est de type exponentiel nous obtenons des résultats de concentration plus précis pour la mesure de similarité En effet nos expérimentations montrent qu’en ce qui concerne la détec tion d’outliers les bornes obtenues avec l’inégalité de Bennett sont meilleures que celles issues de l’inégalité de Bienaymé Tchebycheff C Low Kam et al 4 Expérimentations et analyse Afin de valider notre approche expérimentalement nous avons considéré la base de don nées Bateman et al 2000 qui contient environ 9300 familles de protéines sur l’alphabet des acides aminés de taille 20 Pfam est connue pour couvrir de nombreuses familles de protéines Ferreira et Azevedo 2007 Nous utilisons le logiciel R Team 2006 muni du package Bio3D Grant et al 2006 pour lire les données dans le format FASTA Dans Sun et al 2006 il a été judicieusement observé qu’une bonne mesure de similarité devrait détecter la différence de structure entre deux familles Pour cela un PST est construit sur une famille et les similarités de chaque séquence sont calculées afin d’obtenir des bornes Ensuite le même arbre est utilisé pour le calcul des similarités des membres des autres familles afin de savoir combien d’entre eux se trouvent à l’extérieur des bornes Nous avons mené des expérimen tations similaires en comparant les résultats obtenus avec ou sans élagage selon l’AIC et en utilisant les inégalités de Bienaymé Tchebycheff et de Bennett Toutes ces méthodes nous donnent des résultats satisfaisants ce qui suggère que tous les modèles de Markov d’ordre raisonnable fonctionnent bien à cet effet Cependant notre but ici est de détecter quels sont les outliers parmi un ensemble de séquences sans savoir quels membres sont typiques et devraient donc être utilisés pour construire l’arbre Nous considérons alors la famille HCV_core de la base Pfam qui compte plus de 3000 membres auxquels nous ajoutons quelques séquences appartenant à la famille NADHdh Dans cet article nous présentons les résultats obtenus pour de tels jeux de données Le premier que l’on note D1 contient 30 séquences issues de la famille NADHdh soit environ 1% de la base Le deuxième jeu appelé D2 contient 300 séquences de NADHdh représentant 10% environ du total Nous construisons un PST sur ces jeux de données et vérifions si la mesure de similarité distingue bien les séquences atypiques elles devraient être de la famille NADHdh Tout d’abord nous sélectionnons le modèle global l’ordremaximal de la chaîne deMarkov en utilisant l’AICc et le BIC Nous considérons quatre modèles de Markov d’ordre crois sant {ML 0 ≤ L ≤ 3} Le tableau 1 montre les résultats obtenus pour D1 D’après les deux Modèle AICc BIC M0 10 2 × 10 5 10 2 × 105 M1 6 4 × 10 5 6 4 × 105 M2 1 6 × 10 5 2 9 × 105 M3 3 2 × 10 5 5 5 × 105 TAB 1 – Critères d’information pour des modèles de Markov d’ordre 0 à 3 critères nous choisissons le modèle d’une chaîne de Markov d’ordre 2 correspondant au score le plus faible Intéressons nous aux histogrammes des similarités obtenues avec M0 M1 M2 et M3 La figure 2 montre une estimation de la distribution des similarités des séquences typ iques et atypiques selon le modèle utilisé M2 sépare le mieux les deux groupes de mesures de similarité et donc une inégalité de concentration adéquate devrait permettre de pouvoir identifier les outliers parmi les données comme nous le verrons plus tard Au contraire les autres modèles laissent les deux groupes "déborder" l’un sur l’autre ce qui rend la distinction difficile Nous voyons ainsi que le modèle le plus complexe de la liste n’est pas adéquat pas Détection de séquences atypiques FIG 2 – Comparaison des modèles de Markov d’ordre 0 à 3 plus qu’un modèle trop simple tel que M0 Le choix du modèle doit se faire sur la base d’un critère approprié Procédonsmaintenant à la deuxième étape de notre stratégie d’élagage Nous avons vu dans la section 3 qu’une fois la profondeur maximale pour l’arbre trouvée nous pouvons également utiliser le critère localement pour chaque noeud Nous élaguons le PST selon l’AICc au niveau local et obtenons un histogramme similaire à celui du modèle M2 figure 3 L’arbre possède désormais 312 noeuds au lieu de 368 Comme les anomalies sont mises en évidence de manière comparable et que le coût de calcul du critère local est important il s’agit d’une somme sur tout l’alphabet la question de l’utilité de cette seconde étape se pose Cependant lorsque l’on a affaire à de très grands alphabets il peut être souhaitable de sélectionner un modèle de Markov niveau par niveau sans avoir d’abord à fixer une profondeurmaximale puis construire tout l’arbre et enfin élaguer les noeuds le cas échéant Nous construisons donc le PST sur la même base mais en utilisant le seul critère ∆AICc ce qui signifie que nous ne fixons pas de longueur maximale pour les mémoires Le PST ainsi obtenu possède 515 noeuds seulement pour une profondeur maximale de 3 et montre la même efficacité pour détecter les outliers comme le montre l’histogramme de la figure 4 En résumé lorsque nous élaguons l’arbre des suffixes avec ce seul critère local nous obtenons un modèle parcimonieux et qui détecte bien les anomalies Cependant il est habituellement recommandé de d’abord sélectionner un modèle global Burnham et Anderson 1998 Cette approche doit donc être utilisée avec précaution Une fois que le modèle a été choisi nous cherchons à obtenir des bornes pour déterminer si une observation est un outlier par rapport à un seuil donné Pour cela sous le modèle M2 nous appliquons l’inégalité de Bennett avec les seuils correspondants à la réelle proportion C Low Kam et al FIG 3 – Histogramme obtenu en utilisant le critère local pour L = 2 FIG 4 – Histogramme obtenu en utilisant le critère local sans profondeur maximale d’anomalies dans D1 et D2 Puis nous comparons ces bornes à celles obtenues avec l’inégalité de Bienaymé Tchebycheff avec un seuil de 11% comme il est recommandé dans Sun et al 2006 ce qui revient à fixer la borne à 3 écarts type de la moyenne Nous obtenons les résultats des tableaux 2 et 3 qui contiennent les pourcentages d’anomalies extraites pour chaque base selon chaque méthode Pour le premier jeu de données les deux inégalités mènent à des résul Inégalité Seuil Vrais Faux Bienaymé Tcheb 0 11 100 0 0 3 Bennett 0 01 100 0 0 5 TAB 2 – Pourcentages de vrais et faux outliers hors des bornes pour D1 Inégalité Seuil Vrais Faux Bienaymé Tcheb 0 11 5 0 0 7 Bennett 0 10 100 0 4 0 TAB 3 – Pourcentages de vrais et faux outliers hors des bornes pour D2 tats similaires Cependant le seuil utilisé pour l’inégalité de Bennett a plus de sens puisqu’il correspond à la proportion d’outliers de D1 Mais en général il est impossible de savoir à l’avance combien il y a de séquences atypiques dans la base Toutefois un histogramme tel que ceux de la figure 2 donne une indication Pour le deuxième jeu de données l’inégalité de Bennett est clairement plus performante que celle de Bienaymé Tchebycheff pourtant à un seuil très proche Pour D2 de meilleurs résultats pourraient être obtenus en changeant le seuil de l’inégalité de Bienaymé Tchebycheff d’autant plus que les 3 écarts type n’ont pas de fondement théorique En effet la figure 5montre les bornes obtenues par les inégalités de Ben nett et de Bienaymé Tchebycheff pour les mêmes seuils La ligne en pointillés représente la similarité la plus grande des outliers Nous voyons qu’elle correspond à un seuil de 0 06 pour l’inégalité de Bennett et de 0 29 pour celle de Bienaymé Tchebycheff Par conséquent nous pourrions utiliser cette dernière avec ce seuil pour détecter les anomalies Cependant le seuil de l’inégalité de Bennett correspond à l’intuition que l’on peut avoir à propos de ces outliers puisqu’il nous informe que leurs similarités auraient eu moins de 6% de chances de se trouver en dehors des bornes si elles avaient été typiques Détection de séquences atypiques FIG 5 – Bornes pour les deux inégalités de concentration pour tous les seuils FIG 6 – Mesures de similarité pour les séquences typiques les vrais et les faux out liers Seuils Nombre de noeuds Outliers non détectés 5 1318 0 37 10 782 0 03 15 603 0 0 TAB 4 – Résultats avec un critère d’élagage basé sur la fréquence pour D1 Le pourcentage de vrais outliers détectés est optimal Les résultats pour les fausses anoma lies est très correct moins de 4% cependant quelques séquences typiques demeurent en de hors des bornes par exemple 17 par l’inégalité de Bennett pour D1 Cela représente le coût de la bonne performance de l’inégalité pour les vrais outliers Pour remédier à ce problème nous recommençons le même processus de contruction et d’élagage de l’arbre mais sur une base réduite dont les vrais et faux outliers ont été enlevés Ensuite nous regardons à quel point les observations mises à l’écart sont mises en évidence par le nouveau modèle Les similarités des faux outliers excepté une seule séquence sont maintenant beaucoup plus proche de ceux des séquences typiques alors que les similarités des vrais outliers se détachent clairement La figure 6 illustre ce résultat pour D1 Finalement l’élagage du PST avec le critèreAICc couplé à une inégalité de concentration adaptée donne des résultats satisfaisants Mais dans Sun et al 2006 un critère d’élagage basé sur la seule fréquence était utilisé On peut donc se demander s’il ne pourrait pas mener à une détection comparable Le tableau 4 montre les résulats d’un tel élagage pour D1 et une profondeur d’arbre L = 4 en utilisant l’inégalité de Bennett au seuil 1% Pour des seuils in férieurs à 15 tous les outliers ne sont pas détectés Pour un seuil supérieur à 15 toutes les anomalies sont en dehors des bornes mais l’arbre peut être plus grand que celui obtenu en élaguant avec le critère d’information En résumé cette méthode mène à des résultats compa rables et parfois même meilleurs pour la taille de l’arbre Cependant aucune information sur le seuil n’est donnée pourtant ce dernier dépend de la taille de notre jeu de données du nombre C Low Kam et al d’anomalies et de la structure même des séquences En effet pour D2 en fixant le seuil de fréquence minimale à 15 et en utilisant l’inégalité de Bennett au seuil 10% 66% des outliers ne sont pas détectés La qualité de la détection est donc très variable alors que l’élagage selon un critère d’information permet d’identifier systématiquement les outliers Dans cette section nous avons présenté les résultats de notre approche sur des bases de protéines Notons que nous avons également mené des expérimentations aussi efficaces sur d’autres familles de la base Pfam et obtenu des résultats également pertinents 5 Conclusion et perspectives Dans cet article nous avons proposé une méthode pour détecter des anomalies dans les bases de séquences Nous avons déterminé si une obervation est atypique selon une base S et un seuil t Notre approche est une extension de celle de Sun et al 2006 elle consiste à con struire un arbre de suffixes sur la base et à utiliser une mesure de similarité En effet lorsque les données sont générées par une unique source d’information la convergence de cette mesure vers l’incertitude de la source nous assure qu’elle est appropriée Cependant à la fois la taille de l’arbre et l’extraction exacte des outliers demeuraient problématique Par conséquent nous avons étendu cette méthode à travers un élagage supplémentaire de l’arbre grâce au critère d’information d’Akaike afin de réduire sa taille et d’améliorer le modèle et à par l’utilisation de l’inégalité de concentration de Bennett afin de borner plus précisément la mesure de sim ilarité Ces ajouts ont permis une détection plus efficace car systématique des anomalies En effet la qualité de la discrimination a été améliorée alors que la taille de l’arbre est contrôlée Pour nous en assurer nous avons testé notre méthode sur des bases de séquences de protéines Ainsi nous avons posé des bases pour la détection d’anomalies dans un cadre plus général afin de permettre l’extension de notre méthode à des structures de données plus complexes telles que les motifs séquentiels dans les séquences de données Agrawal et Srikant 1995 Remerciements Nous remercions le Pr AndréMas pour ses conseils avisés Merci égale ment à Yoann Pitarch pour son aide pour les expérimentations Références Agrawal R et R Srikant 1995 Mining sequential patterns In P S Yu et A S P Chen Eds Eleventh International Conference on Data Engineering Taipei Taiwan pp 3–14 IEEE Computer Society Press Akaike H 1973 Information theory as an extension of the maximum likelihood principle In F Petrox B N Caski Ed Second International Symposium on Information Theory pp 267–281 Ash R 1990 Information Theory Dover Publications Barnett V et T Lewis 1994 Outliers in Statistical Data John Wiley Bateman A E Birney R Durbin S R Eddy K L Howe et E L Sonnhammer 2000 The pfam protein families database Nucleic Acids Res 28 263–266 Détection de séquences atypiques Bejerano G et G Yona 1999 Modeling protein families using probabilistic suffix trees In S Istrail P Pevzner et M Waterman Eds Proc 3rd Ann Conf ComputationalMolecular Biology RECOMB Lyon France pp 15–24 ACM Press Bennett G 1962 Probability inequalities for the sum of independent random variables Journal of the American Statistical Association 57 33–45 Burnham K P et D R Anderson 1998 Model Selection and Inference A Practical Information Theoretic Approach Springer Verlag Telos Ferreira P G et P J Azevedo 2007 Chapter vi Deterministic motif mining in protein databases In F Masseglia P Poncelet et M Teisseire Eds Successes and New Directions in Data Mining Grant B A Rodrigues K ElSawy J McCammon et L Caves 2006 Bio3d An r package for the comparative analysis of protein structures Bioinformatics 22 2695–2696 Hawkins D 1980 Identification of Outliers Chapman and Hall Hurvich C M et C L Tsai 1989 Regression and time series model selection in small samples Biometrika 76 2 297–307 Knorr E M et R T Ng 1998 Algorithms for mining distance based outliers in large datasets In Proc 24th Int Conf Very Large Data Bases VLDB pp 392–403 Ron D Y Singer et N Tishby 1996 The power of amnesia Learning probabilistic au tomata with variable memory length Machine Learning 25 2 3 117–149 Schwarz G 1978 Estimating the dimension of a model Annals of Statistics 6 2 461–464 Shannon C 1948 A mathematical theory of communication Bell System Technical Jour nal 27 379–423 and 623–656 Sugiura N 1978 Further analysis of the data by akaike’s information criterion and the finite corrections Communications in Statistics Theory and Methods 7 13–26 Sun P S Chawla et B Arunasalam 2006 Mining for outliers in sequential databases In Proc 6th SIAM Int Conf Data Mining pp 94–105 Team R D C 2006 R A Language and Environment for Statistical Computing Vienna Austria R Foundation for Statistical Computing ISBN 3 900051 07 0 Summary Recently biological sequential databases have increased in both size and number In this context identifying the outliers is essential To extract them most of approaches use a sample of known typical sequences to build a model However such a database is not often at hand Besides the existing methods remain greedy in terms of memory usage In this paper we pro pose a new approach based on a variable order markov model and on a measure of similarity We add to existing methods a pruning criterion to control the size of the search space and its quality and a sharp inequality for the concentration of the measure of similarity to better sort the outliers We prove the feasability of our approach through a set of experiments 