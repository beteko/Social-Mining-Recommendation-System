 Grille bivariée pour la détection de changement dans un flux étiqueté Christophe Salperwyck Marc Boullé Vincent Lemaire Orange Labs 2 Avenue Pierre Marzin 22300 Lannion prenom nom orange com LIFL UMR CNRS 8022 Université de Lille 3 Domaine Univ du Pont de Bois 59653 Villeneuve d’Ascq Cedex Résumé Nous présentons une méthode en ligne de détection de changement de concept dans un flux étiqueté Notre méthode de détection est basée sur un critère supervisé bivarié qui permet d’identifier si les données de deux fenêtres proviennent ou non de la même distribution Notre méthode a l’intérêt de n’avoir aucun a priori sur la distribution des données ni sur le type de changement et est capable de détecter des changements de différentes natures changement dans la moyenne dans la variance Les expérimentations montrent que notre méthode est plus performante et robuste que les méthodes de l’état de l’art testées De plus à part la taille des fenêtres elle ne requiert aucun paramètre utilisateur 1 Introduction De nombreux acteurs de l’informatique doivent faire face à l’arrivée massive de données Les plus connus sont Google et Yahoo avec le traitement des logs pour la publicité en ligne Facebook et Twitter qui modélisent les données provenant de leurs centaines de millions d’uti lisateurs les opérateurs téléphoniques pour la gestion de réseaux de télécommunications La volumétrie de ces données continue de croître rapidement et les quantités ne sont plus compa tibles avec l’utilisation de la plupart des méthodes hors ligne qui supposent de pouvoir accéder à toutes les données Dans ces conditions il est préférable de traiter les données à leur passage ce qui impose d’y accéder une seule fois et dans leur ordre d’arrivée On parle alors d’un accès sous la forme d’un flux de données En classification supervisée on appelle concept P C|X la probabilité conditionnelle de la classe C connaissant les données X Les flux de données peuvent ne pas être stationnaires et comporter des changements de concept si le processus qui génère les données varie au cours du temps Dans ce cas le modèle de classification supervisée doit être adapté au fur et à mesure que le concept change Cet article propose une nouvelle méthode de détection de changement basée sur l’obser vation des données du flux Notre méthode utilise deux fenêtres et permet d’identifier si les données de ces deux fenêtres proviennent ou non de la même distribution Elle est capable de détecter les changements de diverses natures moyenne variance sur la distribution des Grille bivariée pour la détection de changement données conditionnellement ou non aux classes Notre méthode a l’intérêt de n’avoir aucun a priori sur la distribution des données ni sur le type de changement De plus à part la taille de la fenêtre elle ne requiert aucun paramètre utilisateur Cet article présente tout d’abord dans la section 2 les approches existantes de l’état de l’art auxquelles l’approche proposée sera comparée La section 3 présente notre méthode de détec tion ainsi qu’une validation expérimentale sur des données artificielles La section 4 montre comment notre méthode de détection peut être utilisée au sein d’une méthode de gestion de la dérive de concept La dernière partie conclut cet article 2 Etat de l’art des méthodes de détection L’état de l’art sur la gestion de la dérive de concept est abondant Bifet et al 2009 Žlio baite 2010 Les méthodes de gestion de la dérive peuvent se diviser en plusieurs familles détection de changement ensemble de classifieurs pondération des données selon leur ancien neté Le but de cet article étant de présenter une nouvelle méthode de détection l’état de l’art présenté ici se focalise donc sur la famille des méthodes de détection de changement Le but de la classification supervisée sur flux de données est d’optimiser les performances du classifieur Dans ce cas l’état de l’art peut encore être divisé en deux familles – méthodes sans classifieur les auteurs s’intéressent directement aux distributions d’inté rêt du flux de données P X P C P X|C – méthodes avec classifieur les auteurs s’intéressent à la performance liée à P C|X d’un classifieur D’un point de vue bayésien cela revient à détecter les variations d’une des quantités de la formule suivante P C|X = P C P X|C P X avec – P C la proportion des classes dans les données – P X la probabilité des données – P X|C la probabilité conditionnelle des X connaissant la classe C A notre connaissance il n’existe pas de méthodes permettant de détecter directement les varia tions dans la distribution jointe P X C La méthode proposée dans cet article ayant vocation à détecter les changements sur les trois termes mentionnés ci dessus on présente dans les sous sections suivantes une brève description des méthodes de l’état de l’art testées de façon comparative dans cet article 2 1 Méthodes sans classifieur Les méthodes sans classifieur sont essentiellement des méthodes basées sur des tests statis tiques qui sont utilisés pour détecter un changement entre différentes fenêtres d’observations Test t de Welch Le test t de Welch est une adaptation du test t de Student qui s’applique à deux échantillons de tailles N1 et N2 Ce test permet de tester statistiquement l’hypothèse d’égalité de deux moyennes X1 et X2 avec deux échantillons de variances inégales s21 et s22 Ce test a pour formule t = X1 − X2 √ s21 N1 + s 2 2 N2 On utilise le test t de Welch pour tester l’hypothèse nulle suivante les moyennes de deux populations sont égales Ce test retourne une p value qui permet de rejeter ou non l’hypothèse nulle C Salperwyck et al Test de Kolmogorov Smirnov Le test d’hypothèse de Kolmogorov Smirnov est utilisé pour déterminer si un échantillon suit bien une loi donnée ou bien si deux échantillons suivent la même loi Ce test est basé sur les propriétés des fonctions de répartition empirique Nous utiliserons ce test pour vérifier si deux échantillons suivent la même loi Soient deux échan tillons de tailles N1 et N2 possédant respectivement les fonctions de répartition empirique F1 x et F2 x La distance de Kolmogorov Smirnov est définie de la manière suivante D = max x |F1 x − F2 x | L’hypothèse nulle stipulant que les deux échantillons proviennent de la même distribution est rejetée avec une confiance α si √ N1N2 N1 +N2 D > Kα Kα se retrouve à l’aide des tables de Kolmogorov Smirnov MODL P W |Xi Cette méthode a été proposée par Bondu et Boullé 2011 pour la détection de changement dans le cadre de l’observation d’une variable numérique Xi Elle traite le problème de la détection de changement comme un problème d’apprentissage à deux classes Cette méthode utilise deux fenêtres pour détecter un changement une fenêtre de ré férence Wref qui contient les données du concept de départ et une fenêtre courante Wcur glissante sautante sur le flux Les exemples de la fenêtre de référence ont comme étiquette la classe ref et ceux de la fenêtre courante la classe cur Ces deux étiquettes consti tuent la variable cible W ∈ {Wref Wcur} du problème d’apprentissage Les exemples de ces deux fenêtres sont fusionnées et la discrétisation supervisée MODL Boullé 2006 appliquée à ces exemples Si la variable Xi est discrétisée en au moins 2 intervalles cela signifie qu’il y a au moins 2 zones où la distribution des exemples conditionnellement à la fenêtre W est significativement différente Dans ce cas la méthode conclut qu’un changement s’est produit 2 2 Méthodes avec classifieur Les méthodes avec classifieur observent les performances du classifieur et détectent un changement quand les performances varient de manière significative Ces méthodes ont comme hypothèses de départ que le classifieur est un processus stationnaire et que les données sont in dépendantes et identiquement distribuées iid Bien que ces hypothèses ne soient pas toujours validées ces méthodes ont prouvé leur intérêt sur diverses expérimentations Gama et al 2004 Baena García et al 2006 Bifet et al 2009 Les deux principales méthodes avec classifieur référencées dans l’état de l’art sont décrites ci dessous DDM La méthode DDM proposée par Gama et al Gama et al 2004 détecte les change ments en observant l’évolution du taux d’erreur du classifieur L’algorithme prend en entrée une distribution binomiale provenant de la variable binaire qui indique si l’exemple est bien classé 0 ou mal classé 1 par le classifieur Cette loi binomiale est approximée par une loi normale après avoir vu 30 exemples La méthode estime pour chaque exemple la probabilité qu’il soit mal classé pi pi correspond aussi au taux d’erreur et son écart type si = √ pi 1− pi i Cette méthode considère qu’une augmentation significative du taux d’erreur correspond à un changement de concept et donc qu’il faut réapprendre Les valeurs pi et si et les minima at teints pmin et smin sont conservés La méthode fonctionne en deux temps tout d’abord une alerte est levée warning puis une détection Ces deux niveaux sont définis de la manière suivante 1 alerte pi + si > pmin + 2 · smin 2 détection pi + si > pmin + 3 · smin Entre la phase d’alerte et de détection un nouveau classifieur est construit De cette manière Grille bivariée pour la détection de changement après la détection il est possible de ne pas repartir d’un classifieur sans apprentissage mais d’un classifieur ayant appris sur les données du flux comprises entre l’alerte et la détection EDDM La méthode EDDM Baena García et al 2006 reprend le mode de fonctionne ment de DDM mais propose un autre critère pour évaluer les seuils d’alerte et de détection Cette méthode utilise la distance entre les erreurs de classification plutôt que le taux d’erreur Cette distance correspond aux nombres de bonnes prédictions entres deux mauvaises prédic tions EDDM calcule la distance moyenne entre les erreurs p′i et l’écart type s ′ i et conserve les maxima de la moyenne p′max et l’écart s ′ max De la même manière que pour DDM un seuil d’alerte et de détection sont définis 1 alerte p′i + 2 · s′i p′max + 2 · s′max < α 2 détection p′i+2 · s′i p′max+2 · s′max < β Pour les expérimentations les paramètres sont fixés à α = 90% et β = 95% Sur des jeux de données synthétiques et réels EDDM détecte plus rapidement que DDM les changements graduels 3 Une nouvelle méthode de détection supervisée 3 1 Présentation La méthode proposée dans cet article pour détecter les changements de concept s’inspire de la méthode MODL P W |Xi Bondu et Boullé 2011 présentée dans la section 2 1 Le flux de données est constitué de d variables explicatives Xi i ∈ {1 d} Notre méthode fait l’hypothèse d’indépendance des variables conditionnellement aux classes Le test de change ment est donc réalisé par variable Xi sur les données provenant de deux fenêtres La première fenêtreWref contient les données du concept de départ La deuxièmeWcur est une fenêtre glis sante sautante sur le flux qui permet de capturer les données d’un éventuel nouveau concept Le choix de la taille des fenêtres est un compromis entre la réactivité aux changements et le nombre de mauvaises détections Une grande taille de fenêtre permet de détecter avec plus de confiance des motifs potentiellement plus complexes Une plus petite taille permet d’être plus réactif Fixer cette taille dépend du flux observé et du type de changements que l’on veut dé tecter De manière générale on peut traiter ce problème en utilisant plusieurs tailles de fenêtre en parallèle Les données sont étiquetées par fenêtre W ∈ {Wref Wcur} Notre intérêt porte sur la détection de la dérive du concept dans le cadre de la classification supervisée Par conséquent on s’intéresse à la probabilité de la fenêtre connaissant à la fois la classe C et la variable Xi P W |C Xi Il sera donc nécessaire d’utiliser une méthode permettant de mesurer la différence entre P Wref |C Xi et P Wcur|C Xi Parmi les méthode de l’état l’art de discrétisation groupage bivarié capables de prendre en compte la variable Xi et la classe C nous avons choisi d’utiliser l’approche MODL Boullé 2009 pour ses caractéristiques pas d’a priori sur la distribution des données faible sensi bilité aux valeurs atypiques pas de paramètres utilisateur régularisation pour éviter le sur apprentissage Un changement est détecté quand la variable à expliquer dans notre cas W peut être dis criminée à partir de l’observation de Xi et C Ceci se traduit dans l’approche MODL bivariée par l’observation d’une grille de discrétisation groupage de plus d’une cellule Si la grille n’a qu’une seule cellule alors la distribution des données n’a pas changé entre les deux fenêtres C Salperwyck et al La complexité algorithmique de cette méthode est en O T √ T log T où T est la somme de la taille des deux fenêtres référence et courante 3 2 Validation expérimentale détection sans classifieur Dans la suite de cette section on s’intéresse au comportement de la méthode proposée sur des données artificielles provenant de la simulation de différents types de changement Le comportement dans le cas stationnaire est étudié dans la section 3 2 1 la capacité à détecter un changement dans la section 3 2 2 et la capacité à détecter différents types de changement dans la section 3 2 3 Les expérimentations comparent les méthodes de l’état de l’art présentées précédemment ainsi que notre approche – test t de Welch avec signification statistique de 1% 5% et 10% – test de Kolmogorov Smirnov KS avec signification statistique de 1% 5% et 10% – méthode supervisée MODL P W |Xi – méthode supervisée bivariée MODL P W |Xi C 3 2 1 Comportement dans le cas stationnaire Le but de cette première expérimentation est d’étudier le comportement des méthodes dans le cadre d’un flux stationnaire où l’on ne doit détecter aucun changement Les fenêtres de ré férence et courante ont la même taille Etant donné que la méthode fait l’hypothèse d’indépen dance des variables une seule variable numériqueXa est utilisée pour la validation expérimen tale La distribution des classes se fait selon une gaussienne de paramètres µ1 = −1 σ1 = 1 pour la classe 1 et une gaussienne de paramètres µ2 = 1 σ2 = 1 pour la classe 2 Diffé rentes tailles de fenêtre ont été choisies entre 10 et 5 000 exemples Les expérimentations sont réalisées 1000 fois Les résultats sont présentés dans le tableau 1 Ceux ci confirment la robustesse de la méthode bivariée MODL car aucune détection n’est observée sur P W |Xa C Par contre quelques fausses alarmes ont lieu sur P W |Xa Bondu et Boullé 2011 dans moins de 1% des cas et pour de petites tailles de fenêtre Les autres tests se comportent bien pour des petites valeurs de signification statistique 1% Pour de plus grandes valeurs 10% de 1% à 3% de fausses détections sont réalisées par le test t de Welch et le test de Kolmogorov Smirnov méthode→ ↓ taille Welch 1% Welch 5% Welch 10% KS 1% KS 5% KS 10% MODL P W |Xa MODL P W |Xa C 10 0 9 20 0 0 8 3 0 20 0 7 13 0 5 22 4 0 30 1 6 19 0 3 12 3 0 50 0 5 21 0 2 17 6 0 100 0 3 19 0 4 20 1 0 200 0 5 28 0 5 13 0 0 300 0 6 16 1 5 21 0 0 500 1 6 22 2 7 18 1 0 1000 1 8 25 0 5 24 0 0 2000 0 4 13 0 7 20 0 0 5000 0 6 26 0 7 19 0 0 TAB 1 – Nombre de mauvaises détections selon la méthode détection et la taille de la fenêtre pour 1000 expérimentations Grille bivariée pour la détection de changement 3 2 2 Capacité à détecter un changement Le but de cette expérimentation est d’observer le temps nécessaire en nombre d’exemples pour détecter un changement en fonction de la taille de la fenêtre et des méthodes La plupart des méthodes sont capable de détecter ce type de changement Le point important est ici d’ana lyser la vitesse de détection Les fenêtres de référence et courante ont la même taille Une seule variable Xa est utilisée Le concept 1 est défini ainsi – la classe 0 suit une distribution N0 µ = −1 σ = 1 – la classe 1 suit une distribution N1 µ = 1 σ = 1 On simule ce changement en changeant la moyenne de la classe 0 qui passe de 1 à 2 et sa variance qui passe de 1 à 0 5 Pour la classe 1 seule la moyenne change en passant de 1 à 0 On obtient donc le concept 2 suivant – la classe 0 suit une distribution N0 µ = 2 σ = 0 5 – la classe 1 suit une distribution N1 µ = 0 σ = 1 Différentes tailles de fenêtres ont été testées entre 10 et 5 000 exemples et les expérimentations sont réalisées 1000 fois La position du changement dans la fenêtre est tirée de manière aléa toire car dans un cas réel la position du changement n’est pas connue Les résultats obtenus correspondent aux délais moyens de détection du changement en fonction de la taille de la fenêtre et des méthodes étudiées Les résultats sont présentés dans le tableau 2 On observe que jusqu’à une taille de fenêtre de 100 exemples la détection est difficile dans la fenêtre où a lieu le changement A partir d’une taille de 200 exemples le délai moyen est inférieur à la taille de la fenêtre et ce pour toutes les méthodes L’augmentation du seuil de signification à 5% et 10% entraine pour les tests de Welch et de Kolmogorov Smirnov une baisse du délai de détection La méthode basée sur MODL P W |Xa est légèrement plus longue à détecter que les méthodes paramétriques à 1% Cependant si on prend notre méthode MODL P W |Xa C alors celle ci est meilleure que les deux autres méthodes paramétrées à 1% méthode→ ↓ taille Welch 1% Welch 5% Welch 10% KS 1% KS 5% KS 10% MODL P W |Xa MODL P W |Xa C 10 15 14 14 15 15 15 15 15 20 29 26 24 29 28 26 28 29 30 41 36 33 43 40 36 41 40 50 62 53 49 67 57 54 65 58 100 103 90 86 110 96 90 109 96 200 178 160 150 185 166 160 195 163 300 241 218 211 252 227 214 269 218 500 367 337 321 375 344 330 404 325 1000 665 620 598 678 636 613 719 600 2000 1224 1188 1154 1260 1188 1174 1334 1120 5000 2886 2766 2741 2911 2781 2756 3081 2671 TAB 2 – Délai moyen de détection d’un changement selon la méthode de détection et la taille de la fenêtre pour 1000 expérimentations 3 2 3 Différents types de changements détectés Les expériences de cette section ont pour but d’observer quels types de changement moyenne variance inversion des classes les différentes méthodes sont capables de détecter Pour tous C Salperwyck et al les types de changement testés le concept de départ est le concept 1 défini ainsi la classe 0 suit une distributionN0 µ = 0 σ = 0 5 et la classe 1 suit une distributionN1 µ = 2 σ = 1 Différents changements sont appliqués au concept 1 pour expérimenter le comportement des différentes méthodes – Changement de moyenne On simule ce changement en changeant la moyenne de la classe 0 qui passe de 0 à 1 On obtient le concept 2 la classe 0 suit une distribution N0 µ = 1 σ = 0 5 et la classe 1 suit une distribution N1 µ = 2 σ = 1 – Changement de variance On simule ce changement en changeant la variance de la classe 0 qui passe de 1 à 0 5 On obtient le concept 2 la classe 0 suit une distribution N0 µ = 0 σ = 1 et la classe 1 suit une distribution N1 µ = 2 σ = 1 – Inversion des classes On simule ce changement en inversant les étiquettes des classes du concept 1 Pour ces expérimentations et pour les différents types de changement les tailles des fe nêtres ont été fixées à 1000 La fenêtre de référence contient le concept 1 et la fenêtre courante le concept 2 Le tableau 3 présente les résultats en termes de nombre de détections pour 1000 expérimentations Les meilleures méthodes sont celles qui sont capables de réaliser le plus de détections Méthode Moyenne Variance Inversion des classes Welch 1% 1000 0 0 Welch 2% 1000 0 0 Welch 10% 1000 19 10 KS 1% 1000 998 0 KS 2% 1000 1000 0 KS 10% 1000 1000 15 MODL P W |Xa 1000 1000 1 MODL P W |Xa C 1000 1000 1000 TAB 3 – Nombre de détections par changement pour les différentes méthodes de détection Toutes les méthodes sont capables de détecter de manière fiable un changement dans la moyenne Le test de Welch n’est pas capable de détecter les changements de variance et ces expériences le confirment Quelques détections 19 pour le test à 10% se produisent mais celles ci correspondent à des fausses détections et non pas à une détection de changement de variance Le test de Kolmogorov Smirnov et la détection MODL P W |Xa se comportent très bien pour les détections dans les changements de moyenne et variance Tous les tests précé dents détectent seulement des changements dans la répartition des données mais sans s’inté resser à la classe Par conséquent aucun d’entre eux n’est capable de détecter un changement qui n’intervient que par rapport aux classes Contrairement à ces tests statistiques la méthode de détection bivariée MODL P W |Xa C est capable de détecter ce genre de changements Les expérimentations confirment cette capacité 4 Application à la gestion de la dérive de concept Détecter les changements requiert ensuite de réagir à ces derniers Si l’on sait détecter les changements de concepts au cours du temps on pourra alors Žliobaite 2010 i soit réapprendre le modèle de classification à partir de zéro ii soit adapter le modèle courant iii soit adapter un résumé des données sur lequel se fonde le modèle courant iv soit travailler Grille bivariée pour la détection de changement avec la séquence des modèles de classification appris au cours du temps Cette section propose d’intégrer la méthode de détection précédente dans un algorithme de gestion de la dérive de concept afin de remplacer le classifieur après une détection de changement 4 1 Algorithme MDD Nous proposons d’intégrer notre méthode de détection à un nouvel algorithme que nous ap pelons MDD MODL Drift Detection Method Algorithme 1 Notre algorithme n’utilise pas les performances du classifieur pour détecter les changements contrairement aux algorithmes DDM et EDDM décrits dans la section 2 2 Il ne dépend donc pas du type de classifieur Le remplacement de l’ancien classifieur par un nouveau se fait suite à une détection sur au moins l’une des variables par la méthode bivariée MODL P W |Xi C Le remplacement n’est effectif que lorsque le taux d’erreur du nouveau classifieur est plus faible que l’ancien Ce taux d’erreur est calculé pour nos expérimentations à l’aide de la méthode tauxErreur qui correspond à une moyenne mobile exponentielle de paramètre α = 1 tailleWcur Le paramètre nmin est le nombre minimum d’exemples utilisé pour comparer les performances des deux classifieurs sa valeur est fixée à 30 nmin = 30 pour toutes les expérimentations Cette même valeur est utilisée par les méthodes DDM et EDDM avant qu’elles ne commencent à chercher un changement 4 2 Protocole expérimental Notre algorithme est configuré avec une même taille de fenêtre de 1000 pour la fenêtre de référence et la fenêtre sautante La problématique du réglage de la taille de la fenêtre n’est pas abordée en détail dans cet article Une grande taille de fenêtre permet de détecter avec plus de confiance ainsi que des motifs plus complexes Une plus petite taille permet d’être plus réactif Fixer cette taille dépend du flux observé et des changements que l’on veut détecter De manière générale on peut traiter ce problème en utilisant plusieurs tailles de fenêtre en parallèle comme le propose Lazarescu et al 2004 On peut Deux types de classifieur sont utilisés – un classifieur bayésien naïf utilisant une estimation de densité conditionnelle des classes basée sur des résumés à deux niveaux Salperwyck et Lemaire 2012 Le premier niveau est un résumé de quantiles à 100 tuples et le second niveau la discrétisation MODL – un arbre de Hoeffding Domingos et Hulten 2000 avec un résumé de quantiles à 10 tuples et un classifieur bayésien naïf utilisant la discrétisation MODL On présente les résultats pour le générateur basé sur un hyperplan en mouvement propo sée dans Hulten et al 2001 Ce générateur est configuré avec 10 attributs une vitesse de changement de 10−3 et 10% de bruit de classe Une méthode de l’état de l’art pour l’évaluation en ligne des classifieurs Gama et al 2009 est utilisée La méthode choisie mesure la performance en utilisant les exemples du flux comme données de test avant qu’ils ne soient appris La mesure utilisée est la précision moyenne du classifieur entre le début du flux et l’instant t C Salperwyck et al Notations x un exemple du flux Wref fenêtre de référence tailleWref sa taille Wcur fenêtre sautante tailleWcur sa taille classif classifieur en cours d’utilisation tauxErreurClassif son taux d’erreur nouvClassif classifieur qui apprend depuis la détection tauxErreurNouvClassif son taux d’erreur n nombre d’exemples utilisés pour l’apprentissage du nouveau classifieur nmin nombre minimum d’exemples avant de comparer la performance des deux classifieurs n← 0 tant que x← flux faire s’il y a un nouveau classifieur est il meilleur que l’ancien si estDémarré nouvClassif alors n← n+ 1 tauxErrClassif ← tauxErreur tauxErreurClassif classif x tauxErrNouvClassif ← tauxErreur tauxErreurNouvClassif nouvClassif x apprendre nouvClassif x si n > nmin et tauxErreurNouvClassif < tauxErreurClassif alors Wref ← ∅ Wcur ← ∅ classif ← nouvClassif tauxErrClassif ← 0 tauxErrNouvClassif ← 0 n← 0 remplissage des fenêtres si |Wref | < tailleWref alors Wref ←Wref ∪ x sinon si |Wcur| < tailleWcur alors Wcur ←Wcur ∪ x sinon pour i← 1 à d faire calcul du critère bivarié formule 4 de Boullé 2009 pour toutes les variables l← l + CalculerMODLBivarié Wref Wcur i détection si l > 0 alors changement détecté apprentissage d’un nouveau classifieur créer nouvClassif sinon flux stationnaire plus besoin d’avoir un nouveau classifieur détruire nouvClassif apprendre classif x Algorithme 1 Notre algorithme MDD MODL Drift Detection de remplacement du nouveau classifieur après changement de concept 4 3 Résultats La figure 1 présente les résultats pour le jeu de données basé sur un hyperplan en mou vement Sur cette figure toutes les méthodes permettent au classifieur d’avoir les mêmes performances respectivement pour le naïf Bayes et l’arbre de décision jusqu’à 100 000 et 200 000 exemples appris Pour le classifieur bayésien naïf entre 100 000 et 200 000 exemples DDM devient meilleur notre méthode MDD reste relativement stable et EDDM bien moins Grille bivariée pour la détection de changement bon Après 300 000 exemples alors que MDD reste stable DDM devient bien moins bon et EDDM meilleur mais moins bon que notre méthode On observe que notre méthode de dé tection est meilleure et beaucoup plus stable que les deux autres méthodes Pour l’arbre de décision entre 200 000 et 600 000 exemples DDM devient meilleur la méthode de détection MDD reste relativement stable et EDDM bien moins bon Après 600 000 exemples alors que MDD continue à s’améliorer DDM devient bien moins bon et EDDM un peu meilleur Comme pour le classifieur bayésien naïf on observe que notre méthode de détection est bien meilleure et beaucoup plus stable que les deux autres méthodes sur ce jeu de données 74 75 76 77 78 79 80 81 0 100000 200000 300000 400000 500000 600000 700000 800000 900000 1e+06 P ré c is io n m o y e n n e Hyperplan en mouvement vitesse de 0 001 − classifieur bayésien naïf MDD NB DDM NB EDDM NB 66 68 70 72 74 76 78 0 100000 200000 300000 400000 500000 600000 700000 800000 900000 1e+06 P ré c is io n m o y e n n e Nombre d’exemples appris Hyperplan en mouvement vitesse de 0 001 − arbre de Hoeffding MDD HT DDM HT EDDM HT FIG 1 – Précision moyenne des différentes méthodes de détection sur le jeu de données basé sur un hyperplan en mouvement pour le classifieur bayésien naïf et l’arbre de Hoeffding La figure 2 présente le nombre de détections et d’alertes des différents méthodes On ob serve que le comportement de DDM et EDDM n’est pas stable bien que la vitesse de chan gement la vitesse de rotation de l’hyperplan soit constante Ces méthodes ont tendance à détecter beaucoup de changements sur certaines périodes et aucun sur d’autres Leurs hypo thèses de départ processus stationnaire et données iid ne sont sans doute pas valides ce qui aboutit à un manque de robustesse Notre méthode de détection n’utilise pas le classifieur pour la détection mais seulement les données du flux On observe que son nombre de détections est relativement régulier pour un changement ayant une vitesse constante C Salperwyck et al 0 1 2 3 4 5 0 100000 200000 300000 400000 500000 600000 700000 800000 900000 1e+06 Hyperplan en mouvement vitesse de 0 001 − Bayésien naïf Détection MDD 0 1 2 3 4 5 0 100000 200000 300000 400000 500000 600000 700000 800000 900000 1e+06 0 5000 10000 15000 20000 N o m b re d e d é te c ti o n s N o m b re d ’a le rt e s Détection DDM Alerte DDM 0 1 2 3 4 5 0 100000 200000 300000 400000 500000 600000 700000 800000 900000 1e+06 0 5000 10000 15000 20000 N o m b re d ’a le rt e s Nombre d’exemples appris Détection EDDM Alerte EDDM FIG 2 – Nombre de détections et alertes en fonctions du nombre d’exemples du flux pour différentes méthodes de détection pour le jeu de données basé sur un hyperplan en mouvement 5 Conclusion Cet article présente une nouvelle méthode de détection de changement dans les flux de données Celle ci est basée sur l’observation du changement des distributions des exemples dans deux fenêtres Notre méthode n’a pas d’a priori sur la distribution des données ni sur le type de changement à détecter Elle est capable de détecter des changements rapides ou lents que cela soit sur la moyenne la variance ou tout autre changement dans la distribution Notre méthode fait l’hypothèse d’indépendance des variables conditionnellement aux classes et est capable de détecter des changements sur les probabilités P W |Xi C en utilisant l’approche MODL Chaque fenêtre est étiquetée et un changement est détecté s’il existe un modèle de discrétisation groupage permettant de distinguer les deux fenêtres La nouvelle méthode que nous proposons utilise le critère bivarié MODL P W |Xi C qui dans le cadre de notre méthode est à la fois i robuste dans le cas d’un flux stationnaire ii rapide à détecter tous types de changements dans la distribution des données iii capable d’utiliser l’information de classe Notre méthode a été comparée à deux méthodes de l’état de l’art détectant les variations de performance d’un classifieur Nous avons proposé un nouvel algorithme appelé MDD basé sur notre méthode de détection permettant au classifieur de se mettre à jour Celle ci n’utilise pas le classifieur pour la détection mais seulement les données du flux Ses performances en termes de précision sont meilleures et plus constantes que les deux méthodes de l’état de l’art testées Grille bivariée pour la détection de changement Références Baena García M J Del Campo Ávila R Fidalgo A Bifet R Gavaldà et R Morales Bueno 2006 Early Drift Detection Method Fourth International Workshop on Knowledge Dis covery from Data Streams 6 77–86 Bifet A G Holmes B Pfahringer R Kirkby et R Gavaldà 2009 New ensemble methods for evolving data streams Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining KDD ’09 139 Bondu A et M Boullé 2011 A supervised approach for change detection in data streams International Joint Conference on Neural Networks IJCNN Boullé M 2006 MODL A Bayes optimal discretization method for continuous attributes Machine Learning 65 1 131–165 Boullé M 2009 Optimum simultaneous discretization with data grid models in supervi sed classification a Bayesian model selection approach Advances in Data Analysis and Classification Domingos P et G Hulten 2000 Mining high speed data streams In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining pp 71–80 ACM New York NY USA Gama J P Medas G Castillo et P Rodrigues 2004 Learning with drift detection Advances in Artificial Intelligence SBIA 2004 286–295 Gama J P P Rodrigues R Sebastiao et P Rodrigues 2009 Issues in evaluation of stream learning algorithms In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining pp 329–338 ACM New York NY USA Hulten G L Spencer et P Domingos 2001 Mining time changing data streams In Procee dings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining pp 97–106 ACM New York NY USA Lazarescu M M S Venkatesh et H H Bui 2004 Using multiple windows to track concept drift Intelligent Data Analysis 8 1 29–59 Salperwyck C et V Lemaire 2012 A two layers incremental discretization based on order statistics Advances in Data Analysis and Classification Žliobaite I 2010 Learning under Concept Drift an Overview Technical report s sites google com site zliobaite Zliobaite_CDoverview pdf Summary We present an on line method for concept change detection on labeled data streams Our detection method uses a bivariate supervised criterion to determine if the data in two windows come from the same distribution Our method has no hypothesis neither on data distribution nor on change type It has the ability to detect changes of different kinds mean variance Experiments show that our method has better results than well known methods from the liter ature Moreover except from the window sizes no user parameter is required in our method 