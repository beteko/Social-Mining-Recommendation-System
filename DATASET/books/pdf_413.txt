Non-disjoints regroupant des documents de texte basé sur Word séquence noyau Chiheb-Eddine Ben N'Cir *, Afef Zenned **, Nadia Essoussi *** * LARODEC, ISGT, Université de Tunis chiheb.benncir@isg.rnu.tn ** LARODEC , ISGT, Université de Tunis afef.zenned@gmail.com *** LARODEC, ISGT, Université de Tunis nadia.essoussi@isg.rnu.tn Résumé. Ce document traite de deux questions dans le regroupement de texte qui sont la dé- tection des groupes non-disjoints et la représentation des données textuelles. En fait, un document de texte peut discuter de plusieurs thèmes puis, il doit appartenir à plusieurs groupes. L'algorithme d'apprentissage doit être en mesure de produire des grappes non disjoints et ayants documents à plusieurs clusters. La deuxième question concerne la représentation des données. les données textuelles sont souvent représentés comme un sac de fonctionnalités telles que les termes, expressions ou concepts. Cette représentation du texte évite la corrélation BE- termes d'interpolation et ne donne pas d'importance à l'ordre des mots dans le texte. Nous vous proposons une méthode d'apprentissage non supervisé capable de détecter des groupes qui se chevauchent dans le document texte en considérant le texte comme une séquence de mots et en utilisant la séquence de mots noyau comme mesure de similarité. Les expériences montrent que les surclasse de la méthode proposée par les méthodes existantes qui se chevauchent en utilisant le sac de mot en repré- sentation termes de précision et de détecter le regroupement des groupes les plus pertinents dans les documents textuels. 1 Introduction regroupement de texte est une application importante dans le domaine des informations de recherche (IR). Il consiste à regrouper les documents similaires dans le même groupe, alors que des documents différents doivent appartenir à différents groupes sans utiliser des catégories prédéfinies. Cette définition peut être une question cruciale dans de nombreuses applications de la vie réelle de regroupement de texte où un document doit être attribué à plus d'un groupe. Cette question se pose naturellement parce qu'un document peut discuter de plusieurs sujets et peut appartenir à plusieurs thèmes. Par exemple, un article de journal concernant la par- ticipation d'un football à la sortie d'un film d'action peut être groupé avec les deux catégories Sports et Cinéma. De nombreuses méthodes de classification ont été proposées pour résoudre le problème de la détection des groupes non disjoints dans les données. Ce type d'application est arbitré comme le regroupement de chevauchement (Diday, 1984), (boursiers et al., 2011). Nos travaux concerne la détection des groupes à base de k-means de gorithme. Les méthodes existantes qui se chevauchent, lorsqu'il est appliqué au texte le regroupement de documents (Cleuziou, non-disjoints regroupant des documents texte 2008), utilisez la représentation modèle vectoriel (VSM) pour l'ensemble des documents. Cette représenta- tion est basée sur l'hypothèse que la position relative des jetons sont en tête sans rapport avec la perte de corrélation avec des mots adjacents et à la perte des informations concernant les positions de mots. La perte de l'information et de la perte de corrélation entre les mots adjacents influent sur la qualité des grappes obtenues. Nous vous proposons dans cet article, d'utiliser un modèle structuré pour la représentation de texte lors de groupes qui se chevauchent detect- ING en fonction des séquences de mots. Cette représentation, prend en compte les renseignements sur les positions des mots et a l'avantage d'être plus indépen- dent linguistique. Nous vous proposons une méthode qui se chevauchent en mesure de détecter les groupes concernés dans les données textuelles sur la base de mots de séquence du noyau comme une mesure de similarité. Le présent document est organisé comme suit: présente Sect.2 la séquence de mots du noyau et les méthodes de classification qui se chevauchent existantes, présente alors Sect.3 la méthode WSK à base de KOKM que nous vous proposons. Les expériences sur les différents ensembles de données sont décrites et discutées dans Sect.4. Enfin, sect.5 présente conclusion et les travaux futurs. 2 Contexte Dans le modèle vectoriel (VSM), chaque document de texte est représenté par un vecteur de jetons (mots) où la taille du vecteur est déterminé par le nombre de jetons différents dans tous les documents D. Chaque documents dj se transformeront dans un vecteur: dj = (W1J, W2J, ..., w | T | j), où T est l'ensemble des termes T = (t1, ..., t | T |) (ou jetons) qui apparaît au moins une fois dans le corpus (| T | est la taille du vocabulaire), et WKJ représente le poids (fréquence ou de l'importance) du terme tk dans le document dj. Les documents dont les vecteurs sont proches les uns des autres en fonction de jetons fréquences sont considérées comme un contenu similaire. Cette représentation est basée sur l'hypothèse que la position relative des jetons a peu d'importance qui conduit à la perte de corrélation avec les mots adjacents et conduisant à la perte des informations concernant les positions de mots. Le « n-grammes » représentation de texte permet de résoudre le problème de la perte d'information positions de mots en considérant indépendam- ment document texte sous forme de séquences de n caractères consécutifs (syllabes ou mots). L'ensemble des n-grammes est obtenu par l'extraction de toutes les sous-séquences possibles ordonnées de n caractères consécutifs (syllabes ou mots) le long du texte. Cette repré- sentation des fils de texte à une grande dimension caractéristiques de séquences représentant le document texte. Ce problème est résolu dans les tâches de récupération d'informations en utilisant des machines du noyau sur des séquences de texte. De nombreux noyaux connus sous le nom chaîne du noyau tels que le n-grammes du noyau (Leslie et al., 2002), String Subsequence noyau (Lodhi et al., 2001) et Word séquence noyau (Cancedda et al., 2003) sont proposés dans la littérature. Ces noyaux de retour du produit intérieur entre docu- ments mis en correspondance dans un espace de représentation dimensionnelle. Ce produit intérieur est calculé sans calculer explicitement des vecteurs de caractéristiques. 2,1 WSK: Word séquence noyau WSK est défini comme une extension de la chaîne de séquence noyau (SSK) proposé par Lodhi et al. (2001) qui mesurent la similarité entre deux phrases ou deux documents en fonction du nombre de séquences de caractères partagés entre eux. Cancedda et al. (2003) étend la Benn'cir C. et al. noyau SSK et propose le noyau WSK qui mesurent la similarité entre deux séquences à base de mot plutôt que le caractère. Que Σ l'alphabet qui consiste dans l'ensemble des mots qui existent dans tous les documents, soit S = s1s2s3 ... s | s | la séquence de mots avec | S | est la longueur de S, soit u = s [i] une sous-séquence de S avec s [i] = si1 ..sij ..sin où si1 et sij dans cette sous-séquence ne sont pas nécessairement contigus dans S, le mappage de fonction φ pour la phrase s dans l'espace caractéristique est donnée par la définition de φu pour chaque u ∈ Σn que: φu (s) = Σ i: u = s [i] λl (i), (1) où l (i) est la longueur de sous-séquence s [i] en s avec l (i) = en - i1 + 1 et λ est le facteur de décroissance servant à pénaliser des sous-séquences non contiguës. Ces caractéristiques mesurent le nombre d'occurrences de sous-séquence dans la phrase u s les pondérant en fonction de leur longueur. Donc, étant donné deux chaînes s1 et s2, le produit intérieur des vecteurs de caractéristiques est obtenue en calculant la somme de toutes les communes séquences: Kn (s1, s2) = Σ u∈Σn φu (s1) φu (s2) = Σ u∈ Σn Σ i: u = s1 [i] Σ j: u = s2 [j] λl (i) + l (j). (2) L'objectif de cette représentation est de conserver les informations concernant les positions des mots et de garder le sens linguistique des termes en utilisant des mots ordonnés comme des unités atomiques. Par exemple, les termes « fils-frère » désignent une signification particulière qui peut être perdu si elle est cassée. De plus, le nombre de fonctions par document est réduit, car il utilise des séquences de mots plutôt que des séquences de caractères. 2.2 Méthodes existantes qui se chevauchent sur la base des k-means algorithme existant k-moyens méthodes basées étendent les méthodes de classification floue et possibilistes à pro- duire des grappes se chevauchent. Exemple de ces procédés sont les c-moyen de logique floue (Bezděk, 1981) et les méthodes c-possibilistes moyens (Krishnapuram et Keller, 1993). Ces méthodes ont besoin d'un traitement post-traitement pour générer des clusters durs et se chevauchent par seuillage adhésions clusters. Des méthodes plus récentes sont basées sur l'adaptation des algorithmes k-moyens à la recherche de couvertures optimales (Cleuziou, 2008), (Cleuziou, 2009), (BenN'Cir et al., 2010). Contrairement à k-means floue et possibilistes, ces méthodes produisent des grappes qui se chevauchent dur et n'a pas besoin d'aucun traitement post-traitement. le critères optimisés par ces méthodes recherchent des groupes qui se chevauchent optimales. Une méthode récente proposée désigné comme le noyau se chevauchent k-moyens (KOKMφ) (BenN'Cir et Essoussi, 2012), se prolonge le noyau k-moyens pour détecter non disjoints et non linéairement séparables grappes. Par une application implicite des données à partir d'un espace d'entrée à un niveau supérieur, éventuellement infi- nie, l'espace de fonction, KOKMφ regards pour la séparation dans l'espace des fonctions et résout le problème de chevauchement avec les clusters non-linéaire et les séparations non sphériques. Compte tenu de l'ensemble des observations X = {xi} Ni = 0 avec xi ∈ Rd, et N est le nombre d'observations. Soit C le nombre de couvertures et φ (xi) la représentation du xi d'observation dans un espace de dimension hauteur d'une transformation non linéaire φ: xi 7 → φ (xi) ∈ F. Le KOKMφ non-disjoints regroupant des documents de texte méthode introduit la contrainte de chevauchement (une observation peut appartenir à plus d'un cluster) dans la fonction objectif qui minimise une erreur locale sur chaque observation définie par la distance entre l'observation et son image dans la fonction l'espace: J ({πc} Cc = 1) = Σ xi∈X ∥φ (xi) - im (φ (xi)) ∥2, (3) où im (φ (xi)) est l'image de l'observation xi et est définie par le centre de gravité de grappes prototypes à laquelle appartient xi. Si l'observation xi est attribué à un seul groupe, l'image est équivalent au représentant du groupe suivant. La fonction objectif est calculée sans effectuer de manière explicite le mappage non linéaire φ en utilisant la fonction du noyau Kij = φ (xi) .φ (xj) évaluer le produit scalaire dans l'espace de caractéristique entre xi et xj: J ({πc} Cc = 1 ) = Σ xi∈X [Kii - 2 Li CΣ c = 1 Pic · KIMC + (1 Li) 2 CΣ c = 1 l = 1 CΣ PicPil · Kmcml]. (4) 3 Solution proposée: KOKM basée WSK Pour détecter des groupes non disjoints de documents texte séquentiel, nous proposons une méthode de chevauchement arbitré comme « WSK à base KOKM » en utilisant WSK comme une mesure de similarité entre documents structurée. Compte tenu d'un ensemble de documents D = {DQ} | D | q = 1 où chaque document DQ est défini dans l'espace de fonction par le u φu coordonnées (DQ), qui mesure le nombre d'occurrences de séquence u dans le document DQ pondéré selon il est longueurs. La méthode proposée consiste à la minimisation d'une erreur locale sur chaque document, où l'erreur locale est définie par la distance du noyau entre le document et l'image de lui. La fonction objective de la WSK à base KOKM est décrit par: J ({} πc Cc = 1) = Σ dq∈D ∥φ (DQ) - im (φ (DQ)) ∥2. (5) où C est le nombre de groupes qui se chevauchent et im (φ (dq)) est l'image du document dq défini par le centre de gravité de prototypes de clusters à laquelle le document dq appartient: im (φ (dq)) = CΣ c = 1 PQC · φ (mc) CΣ c = 1 PQC, (6) avec PQC est une variable binaire indiquant l'appartenance du document dq dans la grappe et c mc est le prototype du c du cluster dans l'espace de caractéristiques. Utilisation du noyau WSK défini dans l'équation 2 et en utilisant le noyau Trick, la fonction objective est effectué comme suit: C. Benn'cir et al. J ({πc} Cc = 1) = Σ dq∈D [Σ u∈Σn φu (dq) φu (dq) - 2 Lq CΣ c = 1 PQC · Σ u∈Σn φu (dq) φu (DMC) + (1LQ) 2 CΣ c = 1 l = 1 CΣ PqcPql · Σ u∈Σn φu (DMC) φu (DML)] = Σ dq∈D [Kn (dq, dq) - 2 Lq CΣ c = 1 PQC · Kn (dq, DMC) + 1 Lq 2 CΣ c = 1 l = 1 CΣ PqcPql · Kn (DMC, DML)], (7) où Lq = CΣ c = 1 PQC, Σn est l'ensemble de toutes possibles commandés mot-séquences de longueur n et de DMC est le prototype du groupe c. La minimisation de la fonction objective est effectuée localement par deux étapes principales itérer: la première étape concerne le calcul des prototypes clusters où chaque prototype est défini par le document qui minimise les distances avec les documents d'autres appartenant au même groupe. Ce calcul de prototypes est réalisée dans l'espace de représentation où le document dmc représentant prototype de c cluster est calculé comme suit: dmc = min q∈πc Σ j∈πc, j = q ̸ wj. Σ u∈Σn || φu (dq) - φu (dj) || 2 Σ j∈πc, j = q ̸ wj = min q∈πc Σ j∈πc, j = q ̸ wj [Kn (dq, dq) - 2.Kn (dq, dj) + Kn (dj, dj)] Σ j∈πc, j = q ̸ wj, (8) où wj est un poids de la Kern el la distance entre le document et le document DQ dj en fonction du nombre de groupes auxquels le document dj appartient. Ce poids est plus important si le document dj appartient à plus d'un cluster pour prendre en compte le fait que les documents qui se chevauchent dj ont une faible influence dans la détermination de prototype de cluster ainsi que le nombre d'augmentations d'affectation. La deuxième étape concerne l'attribution de plusieurs des documents à un ou plusieurs groupes. Cette étape est effectuée en utilisant une heuristique qui explore les ensembles combinatoires de signments as- possibles. L'heuristique consiste, pour chaque document, en grappes de tri du plus proche au plus éloigné du, assignant alors le document dans l'ordre défini en affectation minimise l'erreur cal lo- définie dans la fonction objective et il minimise la fonction objectif de trou. La règle d'arrêt de l'algorithme de base WSK KOKM se caractérise par deux critères: le grand nombre possible d'itérations ou l'amélioration minimale de la fonction objective entre deux itérations. L'algorithme principal de WSK à base KOKM est décrite comme suit: non-disjoints regroupant des documents de texte algorithme 1 WSK basé KOKM (D, C, Tmax, ε) → {πc} Cc = 1 Exigent: D: ensemble de documents, Tmax: nombre maximum d'itérations, ε: l'amélioration minimale de la fonction objective, C: nombre de groupes. Assurer: 1: Initialisation des prototypes de clusters avec un des documents au hasard, des documents attribuer et valeur dérive de la fonction objectif J0 ({πc} Cc = 1) dans l'itération en utilisant l'équation 7. 0 2: Calcul des prototypes de grappes en utilisant l'équation 8. 3: documents Affectez un ou plusieurs groupes. 4: Calculer Jt ({πc} Cc = 1) en utilisant l'équation 7. 5: if (t <tmax et Jt-1 ({πc} Cc = 1) - Jt ({πc} Cc = 1)> ε) puis 6 : passer à l'étape 2. 7: 8 autres: Retour les adhésions clusters {} πc Cc = 1 dans l'itération t. 9: end if 4 expériences et discussions expériences ont été effectuées sur l'ordinateur avec 4 Go de RAM et 2,1 GHz Intel Core 2 Duo. Les données sont prétraitées en supprimant quelques mots d'arrêt. La représentation modèle vectoriel de chaque ensemble de données est construit en utilisant le « module prétraiter texte WEKA » où est calculé en utilisant la technique TF * IDF les fréquences d'apparition des mots. Pour la mise en œuvre de la Parole séquence du noyau, nous utilisons la définition récursive de la WSK définie par Cancedda et al. (2003) basée sur la technique de programmation dynamique. L'avantage de cette mise en œuvre est de réduire la complexité de temps et d'effectuer WSK sans extraire implicitement des séquences de mots. La complexité du temps de calcul noyau WSK entre deux uments doc- d1 et d2 est réduite à O (n | d1 d2 || |) où n est la longueur de la séquence utilisée et | di | est le nombre de mots dans le document di. La complexité de calcul du procédé de WSK à base de KOKM est évaluée à O (N.C2.Nc) où N est le nombre de documents, C est le nombre de grappes et Nc est le nombre maximal de documents dans chacune des grappes. Des expériences ont été réalisées sur deux séries de données textuelles se chevauchant qui sont respectivement Reuters 1 et 2 Ohsumed ensembles de données. Nous avons utilisé un sous-ensemble de Reuters composé de 76 documents et un sous-ensemble de Ohsumed composé de 83 documents. Chaque document dans chaque jeu de données est marquée par une ou plusieurs étiquettes à partir d'un ensemble de 5 catégories où chaque catégorie contient 20 documents. Les résultats sont comparés en fonction de trois mesures de validation externe: précision, de rappel et de mesure F-. Ces mesures de validation tentent d'estimer si la prédiction des catégories est correcte par rapport aux vraies catégories sous-jacentes dans les données. Pour chaque ensemble de données, le nombre de groupes est défini sur le nombre de catégories sous-jacentes dans l'ensemble de données. Tableau 1 et le tableau 2 rapport des notes moyennes et la variation de l'écart-type de précision, rappel et F-mesure sur les pistes dix en utilisant des méthodes OKM et KOKMφ basé sur sentation de VSM par rapport à la WSK à base KOKM méthode proposée (nous fixons n = 2 la longueur de 1. voir http://kdd.ics.uci.edu/databases/reuters-transcribed/reuters-transcribed.html 2. cf. http://disi.unitn.it/moschitti/corpora/ohsumed-first -20000-docs.tar.gz C. Benn'cir et al. Avec issue Sans issue Méthodes de précision Rappel F-mesure de précision Rappel F-mesure OKM 0275 ± 0,01 ± 0968 ± 0,01 0,429 0,03 0,275 ± 0,01 ± 0968 ± 0,03 0,429 0,01 KOKMφ (linéaire) 0275 ± 0,01 ± 0955 ± 0,04 0427 0,02 0,275 ± 0,01 ± 0,958 ± 0,04 0,428 0,01 KOKMφ (polynomiale) 0275 ± 0,01 ± 0955 ± 0,04 0427 0,01 0275 ± 0,01 0,958 ± 0,04 0,428 ± 0,01 KOKMφ (RBF σ = 10) 0274 ± 0965 0,01 ± 0,03 0,02 ± 0426 0274 ± 0968 0,01 ± 0,03 0427 ± 0, 02 KOKMφ (RBF σ = 108) 0275 ± 0955 0,01 ± 0,05 0,02 ± 0427 0275 ± 0958 0,01 ± 0,04 ± 0,01 0428 WSK à base de KOKM 0.499 ± 0,04 0670 ± 0, 12 0569 ± 0,04 ± 0,05 0,458 ± 0698 ± 0,02 0553 0,04 TAB. 1 - Comparaison entre OKM et KOKMφ représentation basée VSM avec WSK basé KOKM sur Reuters Dataset. Avec issue Sans issue Méthodes de précision Rappel F-mesure de précision Rappel F-mesure OKM 0274 ± 0799 ± 0,03 ± 0,36 0,396 ± 0,04 0,262 ± 0,04 0761 0,378 ± 0,32 0,02 KOKMφ (linéaire) 0297 ± 0798 ± 0,10 ± 0,36 0,417 ± 0,11 0,297 ± 0,795 0,10 ± 0,36 0,416 0,11 KOKMφ (polynomiale) 0297 ± 0798 ± 0,10 ± 0,35 0,417 0,297 0,10 ± 0,10 ± 0795 0,36 ± 0,11 0417 KOKMφ (RBF σ = 10) 0248 ± 0980 0,01 ± 0,02 0,01 ± 0396 0248 ± 0983 0,01 ± 0,02 0396 ± 0, 01 KOKMφ (RBF σ = 108) 0262 ± 0835 ± 0,04 0,40 ± 0,03 0385 0260 0840 ± ± 0,04 0,40 ± 0,03 0383 WSK à base de KOKM 0308 0696 ± 0,03 ± 0, 08 0421 ± 0,02 ± 0,312 ± 0,02 0641 0,06 0,420 ± 0,03 TAB. 2 - Comparaison entre OKM et KOKMφ représentation basée VSM avec WSK basée KOKM sur Ohsumed Dataset. des séquences de mots et de λ = 0,9 la valeur du facteur de décroissance). Les résultats sont comparés avec et sans sans issue. Pour chaque course, toutes les méthodes sont calculées avec la même initialisation des semences pour garantir que toutes les méthodes ont les mêmes conditions expérimentales. Les valeurs en gras correspondent aux scores obtenus. Mieux Le F-mesure obtenue avec WSK à base KOKM est caractérisé par une haute valeur com- épurée des procédés qui se chevauchent sur la base de la représentation VSM. L'amélioration de la F-mesure est induite par l'amélioration de la précision. Par exemple, dans les données Reuters définir la précision obtenue à l'aide WSK à base de KOKM est 0,458 tout en utilisant des méthodes et KOKMφ OKM la précision obtenue max est 0,275. L'amélioration de la précision est réalisée avec et sans ming tige-. Les rappels obtenus avec KOKMφ et méthodes OKM sont caractérisées par une valeur élevée (le rappel obtenu avec OKM dans la série de données Reuters est équivalent à 0,968). Ces valeurs élevées de rappel est expliquée par la façon dont les observations et Assigner OKM KOKMφ à tous les groupes en raison du problème de dominance diagonale. Par exemple, dans le jeu de données Reuters, où la mensionality di- de la matrice de VSM est très clairsemée (1482 mots), OKM et KOKMφ ont la question de la domination diagonale et attribue donc chaque observation à tous les groupes. Les résultats obtenus prouvent la conclusion théorique que l'examen du texte comme une séquence de mots améliore la précision de classification par rapport à la représentation VSM. Le sens de lan- gues naturelles dépend des séquences de mots, et les séquences de mots fréquents peuvent fournir des informations précieuses sur compact et structures de documents. En fait, les méthodes fonction du noyau à base (Sac de Word noyau ou Word séquence noyau) surclassent méthode non du noyau. Ces résultats non-disjoints regroupant des documents texte prouvent que la recherche de la séparation entre les clusters dans un espace caractéristique est mieux que la recherche de la séparation dans l'espace d'entrée. Séparabilité entre documents peut être améliorée lorsque les documents sont mis en correspondance avec un espace de représentation. 5 Conclusion Nous proposons dans cet article la méthode WSK à base KOKM qui est capable de détecter des groupes non disjoints de documents textuels séquentiels basés sur le noyau mot séquence en tant que mesure de simi- larité. La détection groupes qui se chevauchent en considérant le texte comme une séquence de mots im- prouve la qualité des groupes obtenus par rapport à la représentation VSM du texte. Préliminaires résultats obtenus sur des ensembles de données Reuters et Ohsumed prouvent l'efficacité de la méthode proposée par rapport aux méthodes qui se chevauchent en utilisant la représentation de VSM. Cette méthode proposée peut être appliquée pour beaucoup d'autres domaines d'application où les besoins de données textuelles à être affecté à plus d'un cluster. Nous prévoyons de réaliser des expériences dans d'autres ensembles de données réelles qui se chevauchent où les séquences de texte sont plus pertinentes que les séquences de Reuters et Ohsumed datasetd comme dans la détection des groupes de données biologiques textuelles. Références BenN'Cir, C. et N. Essoussi (2012). Chevauchement reconnaissance des modèles avec des séparations linéaires et non linéaires à l'aide de noyaux définis positifs. International Journal of Computer cations Appli- (IJCA). BenN'Cir, C., N. Essoussi et P. Bertrand (2010). Kernel se chevauchent k-moyens de regroupement dans l'espace des fonctions. À la Conférence internationale sur la découverte des connaissances et la recherche d'information KDIR, Valencia, SPA, pp. 250-256. SciTePress Bibliothèque numérique. Bezdek, J. C. (1981). Reconnaissance des formes avec algoritms fonction objectif floue. Plenum Press 4 (2), 67-76. Cancedda, N., E. Gaussier, C. Goutte et J. Renders (2003). les noyaux de séquences de mots. Journal of Machine Learning Research 3, 1059-1082. Cleuziou, G. (2008). Une version étendue de la méthode k-moyens de regroupement se chevauchent. Dans la Conférence internationale sur la reconnaissance des formes ICPR, Floride, États-Unis, pp. 1-4. IEEE. Cleuziou, G. (2009). Okmed et wokm: deux de OKM verser variantes la classification recou- vrante. Revue des Nouvelles Technologies de l'Information, CÃl'paduÃĺs Édition 1, 31-42. Diday, E. (1984). Les commandes et les grappes qui se chevauchent par des pyramides. Rapport technique 730, INRIA, France. Fellows, M. R., J. Guo, C. Komusiewicz, R. Niedermeier, et J. Uhlmann (2011). données basées sur le graphique en cluster avec des chevauchements. Optimization Discrète 8 (1), 2-17. Krishnapuram, R. et J. M. Keller (1993). Une approche possibiliste de regroupement. actions IEEE Trans- sur les systèmes Fuzzy 1, 98-110. Leslie, C. S., E. Eskin et W. S. Noble (2002). Le noyau du spectre: Un noyau de chaîne pour la classification des protéines svm. Dans Symposium du Pacifique sur Bioinformatique, p. 566-575. C. Benn'cir et al. Lodhi, H., N. Cristianini, J. Shawe-Taylor et C. Watkins (2001). Texte classication en utilisant le noyau de la chaîne. Le Journal of Machine Learning Research 2, 419-444. Ce travail résumé Problématiques deux parents traite à la classification des Données textuelles. La Première problèmatique des Se APPLIQUER La détection non-disjoints Groupes. En effet, un docu- ment Textuel may Aborder several et par thématiques Différentes la suite il Appartenir à Doït several Groupes. L'algorithme d'apprentissage Doït of this Tenir compte et Doït contrainte each Document à attributeur un OU à several Groupes differents. La concerns la Deuxième problématique des Données textuelles modélisation. Les Données Mode- textuelles lisées Sont sous Souvent formes vectorielles. This forme de la représentation Négligé Entre les Annoter corrélation et ne donne à l'importance Aucune d'apparitions des Ordre Dans le texte mots. Nous proposons de classification Une méthode non capable de supervisee des Détecter en Recouvrements Groupes Avec modélisant le texte sous forme de de Séquences Annoter. Le WSK de (Word séquence noyau) is used Comme de mesure Entre les séquences similarité de Annoter. Les Expérimentations la performances réalisées montrent de la proposed par rapport méthode aux methods recouvrantes to vary Qui la modélisation utilisent vectorielle. Page blanche