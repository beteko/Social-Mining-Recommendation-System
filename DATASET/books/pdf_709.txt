articles assemblage pdfUne nouvelle stratégie d’Apprentissage Bayésienne Alexis Bondu Vincent Lemaire Marc Boullé EDF R D ICAME SOAD 1 avenue du Général de Gaulle 92140 Clamart alexis bondu edf fr OrangeLabs 2 avenue Pierre Marzin 22300 Lannion prenom nom orange ftgroup com Résumé Dans cet article une nouvelle stratégie d’apprentissage actif est pro posée Cette stratégie est fondée sur une méthode de discrétisation Bayésienne semi supervisée Des expériences comparatives sont menées sur des données unidimensionnelles l’objectif étant d’estimer la position d’un échelon à partir de données bruitées 1 Notations Les données D sont composées de deux sous ensembles T et U qui correspondent respecti vement aux données étiquetées et non étiquetées avec D = T ∪U L’ensemble T contient des couples x y où x ∈ R et y ∈ Y est une valeur discrète représentant la classe de l’exemple x L’ensemble U contient des réels Les notations suivantes sont adoptées N le nombre d’exemples observables N = |D| N l le nombre d’exemples étiquetés N l = |T | J le nombre de classes observées dans les données J = |Y| 2 Discrétisation semi supervisée Bayésienne L’approche MODL discrétise les variables explicatives dans le but d’estimer les distri butions conditionnelles aux classes Le problème de la discrétisation d’une variable numé rique est transposé en un problème de sélection de modèles Un modèle de discrétisation M I {Ni} {Nij} est défini par les paramètres suivants i I est le nombre d’intervalles ii {Ni} est le nombre d’exemples dans chaque intervalle qui définit les bornes du modèle iii {Nij} est le nombre d’exemples de chaque classe dans chaque intervalle qui définit les distri butions conditionnelles localement à chaque intervalle Une démarche Bayésienne maximisant P M |D est appliquée pour sélectionner le meilleur modèle de discrétisation noté Mmap Maximum a posteriori Cette démarche revient à maximiser P M P D|M La distribution a priori des modèles P M et la vraisemblance des données P D|M sont calculées analyti quement en exploitant le caractère discret de la famille de modèles et en adoptant des hypo thèses faiblement informatives sur les données Finalement le Mmap minimise l’Equation 1 dont les deux termes correspondent à la distribution a priori des modèles et à la vraisemblance des données RNTI E 19 707 Apprentissage Actif Bayésien C M = −logP M z }| { log N + log CI−1N+I−1 IX i=1 log CJ−1Ni+J−1+ IX i=1 log Ni PJ j=1 Nij − IX i=1 log Nui PJ j=1 N u ij | {z } −logP D|M 1 3 Une nouvelle méthode d’apprentissage actif Cette section présente une stratégie originale d’apprentissage actif fondée sur la méthode de discrétisation semi supervisée décrite à la Section 2 La qualité d’un modèle de discrétisa tion est donnée par la probabilité du modèle connaissant les données Le critère Csemi super est une expression analytique de P M |D au sens des hypothèses de modélisation de l’approche MODL Boullé 2006 Notre stratégie d’apprentissage actif cherche à étiqueter l’exemple qui maximisera la qualité du futur modèle sans connaître la classe du nouvel exemple et sans connaître le meilleur modèle à l’itération suivante Notre démarche prend en compte ces incer titudes en menant un calcul d’espérance sur tous les cas possibles Un critère dont l’optimisa tion désigne l’exemple xt+1 ∈ U qui maximise l’espérance de P M |D xt+1 est établi Cactif xt+1 = X M∈M 2 4P M P D|M ×X y∈Y " P y|M D xt+1 × P M × P D xt+1 y|M P M′∈M P M ′ × P D|M ′ × P y|D M ′ xt+1 35 2 4 Conclusion t Notre stratégie active est évaluée dans le cadre de l’estimation d’une fonction échelon à partir de données bruitées Castro et Nowak 2008 et est comparée à la dichotomie probabiliste Horstein 1963 Contrairement à notre approche la dichotomie probabiliste doit être rensei gnée du niveau de bruit présent dans les données Les deux approches donnent des résultats comparables lorsque le niveau de bruit est connu Dans le cas général cette information n’est pas disponible c’est pourquoi la dichotomie probabiliste est renseignée d’un niveau de bruit erroné lors de son évaluation Dans ces conditions notre stratégie est plus performante que la dichotomie probabiliste Finalement notre stratégie est plus générique que la dichotomie probabiliste Références Boullé M 2006 MODL A bayes optimal discretization method for continuous attributes Machine Learning 65 1 131–165 Castro R et R Nowak 2008 Foundations and Application of Sensor Management Chapter Active Learning and Sampling Springer Verlag Horstein M 1963 Sequential decoding using noiseless feedback In IEEE Transmition Information Theory Volume 9 pp 136–143 Summary In this article a new active learning strategy is proposed Comparative experiments are conducted on unidimensional data the aim is to estimate the location of a step function from a noisy sample RNTI E 19 708 