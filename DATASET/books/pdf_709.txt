articles assemblage pdfune nouvelle stratégie apprentissage bayésienne alexis bondu vincent lemaire boullé icame avenue général gaulle 92140 clamart alexis bondu orangelabs avenue pierre marzin 22300 lannion prenom orange ftgroup résumé article nouvelle stratégie apprentissage actif posée cette stratégie fondée méthode discrétisation bayésienne supervisée expériences comparatives menées données unidimensionnelles objectif étant estimer position échelon partir données bruitées notations données composées ensembles correspondent respecti vement données étiquetées étiquetées ensemble contient couples valeur discrète représentant classe exemple ensemble contient réels notations suivantes adoptées nombre exemples observables nombre exemples étiquetés nombre classes observées données discrétisation supervisée bayésienne approche discrétise variables explicatives estimer distri butions conditionnelles classes problème discrétisation variable rique transposé problème sélection modèles modèle discrétisation défini paramètres suivants nombre intervalles nombre exemples chaque intervalle définit bornes modèle nombre exemples chaque classe chaque intervalle définit distri butions conditionnelles localement chaque intervalle démarche bayésienne maximisant appliquée sélectionner meilleur modèle discrétisation maximum posteriori cette démarche revient maximiser distribution priori modèles vraisemblance données calculées analyti quement exploitant caractère discret famille modèles adoptant thèses faiblement informatives données finalement minimise equation termes correspondent distribution priori modèles vraisemblance données apprentissage actif bayésien nouvelle méthode apprentissage actif cette section présente stratégie originale apprentissage actif fondée méthode discrétisation supervisée décrite section qualité modèle discrétisa donnée probabilité modèle connaissant données critère csemi super expression analytique hypothèses modélisation approche boullé notre stratégie apprentissage actif cherche étiqueter exemple maximisera qualité futur modèle connaître classe nouvel exemple connaître meilleur modèle itération suivante notre démarche prend compte incer titudes menant calcul espérance possibles critère optimisa désigne exemple maximise espérance établi cactif conclusion notre stratégie active évaluée cadre estimation fonction échelon partir données bruitées castro nowak comparée dichotomie probabiliste horstein contrairement notre approche dichotomie probabiliste rensei niveau bruit présent données approches donnent résultats comparables lorsque niveau bruit connu général cette information disponible pourquoi dichotomie probabiliste renseignée niveau bruit erroné évaluation conditions notre stratégie performante dichotomie probabiliste finalement notre stratégie générique dichotomie probabiliste références boullé bayes optimal discretization method continuous attributes machine learning castro nowak foundations application sensor management chapter active learning sampling springer verlag horstein sequential decoding using noiseless feedback transmition information theory volume summary article active learning strategy proposed comparative experiments conducted unidimensional estimate location function noisy sample