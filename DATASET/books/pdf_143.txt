Un passage pertinent et récupération Re rang approche pour la question ouverte de domaine Répondre Nouha Othman *, Rim Faiz ** * Université de Tunis, l'Institut Supérieur de Gestion de Tunis, LARODEC, Tunisie othmannouha@gmail.com ** Université de Carthage Carthage IHEC , LARODEC, Tunisie rim.faiz@ihec.rnu.tn~~V~~singular~~3rd Résumé. Question systèmes répondant (QAS) s visent à revenir directement des réponses précises aux questions en langage naturel. Récupération et passages de re-classement sont considérés comme les plus difficiles tâches dans un QAS typique et requièrent un effort non négligeable. Dans cet article, nous proposons une nouvelle approche pour la récupération et RE- passages classement à l'aide de n-grammes et SVM. Notre moteur n-gramme à base de récupération passage repose sur une nouvelle mesure de similarité entre un passage et une ques- tion. Les passages récupérés sont encore re-classé en utilisant un modèle de classement SVM combinant différentes mesures de similarité de texte afin de retourner le passage le plus pertinent à une question donnée. Nos expériences et les résultats ont montré des résultats prometteurs et démontré que notre approche est compétitive. 1 Introduction Au cours des dernières années, avec le développement continu de la technologie de l'information, la quantité de données a augmenté massivement tous les jours. De ce fait, ces dernières années ont vu un intérêt croissant pour la réponse aux questions (QA) qui est l'un des principaux domaines de recherche en information de recherche (IR) avec des applications principalement à partir des informations d'extraction (IE) et le traitement du langage naturel (NLP) (Faiz, 2006) , dont l'objectif principal est de fournir directement une réponse précise et concise à une question posée par l'utilisateur en langage naturel à partir d'une importante collection de documents ou de base de données (Voorhees, 2001). En effet, le domaine QA se divise en deux catégories: QA fermé domaine qui traite des questions sur un domaine spécifique comme la biologie et la médecine, et QA domaine ouvert qui traite des questions d'ordre général dans divers domaines sans aucune limitation. Dans notre travail, nous nous concentrons sur la deuxième catégorie que les techniques utilisées ne sont pas adaptées vers un domaine spécifique. Fondamentalement, un QAS typique peut être largement considéré comme un pipeline qui se compose de quatre modules principaux (Tellex et al., 2003): analyse de la question, la recherche documentaire, la récupération de passage et l'extraction de réponse, où chaque module doit faire face à des défis spécifiques. En particulier, la récupération de passage (PR) est toujours considéré comme la tâche principale d'un QAS typique car elle permet de réduire l'espace de recherche d'une grande collection de documents à un nombre fixe de passages. De toute évidence, SQR ne peut pas trouver la bonne réponse à une question donnée, à moins que la réponse existe dans l'un des passages récupérés. Par conséquent, il a été largement étudié au cours des dernières années. passages Re rang est aussi une tâche cruciale à la fin du gazoduc QAS qui aspire à commander les passages récupérés tels que les plus pertinents - 111 - Un passage pertinent et récupération approche resitue classement pour la question les Answering apparaissent en premier. Dans le but d'améliorer la performance des existants SQR, nous nous concentrons sur ces deux tâches pour tenter d'augmenter le nombre de réponses correctes et retournées assurer leur pertinence. Dans cet article, nous proposons une nouvelle approche pour récupérer et re-classement des passages pour un domaine ouvert QAS. Notre passage module de recherche est basé sur un modèle n-gramme où nous proposons une nouvelle mesure de similarité entre un passage et une question en fonction du degré de proximité ou d'une dispersion des mots n-grammes de la question dans le passage. Les passages récupérés sont encore re-classé en utilisant un modèle SVM Classement (Joachims, 2002) combinant différentes mesures de similarité de texte qui constituent les caractéristiques. Ceux-ci comprennent notre nouvelle mesure à base de n-gramme, ainsi que d'autres caractéristiques lexicales et sémantiques qui ont déjà été éprouvées avec succès dans la tâche sémantique Justifications similarité (STS) à * SEM 2013 (Buscaldi et al., 2013). Nous l'intention de retourner le passage le plus pertinent, le premier rang un, comme une réponse pertinente à une question donnée. Le reste de cet article est organisé comme suit: Dans la section (2), nous donnons un aperçu des travaux connexes sur les tâches PR et le classement. Ensuite, nous présentons dans la section (3) notre approche proposée pour la récupération et re-classement des passages pour l'AQ. Section (4) est consacré à l'évaluation de notre méthode afin de prouver sa capacité. Dans la section (5) nous concluons notre article et présentons quelques perspectives. 2 Travaux connexes sur Passage récupération et tâches de classement Dans cette section, nous passons en revue les approches les plus importantes de la littérature liée à PR classées par type de correspondance appliquée entre les passages candidats et la question, et les principaux travaux proposés sur le classement pour la sélection des réponses classées selon le modèle appliqué. 2.1 Types de contrepartie pour récupération Passage En effet, PR est généralement considéré comme le noyau d'un QAS typique. Ainsi, de nombreuses approches ont été développées dans le but de relations publiques pour améliorer les performances de SQR. Tellex et al. (2003) ont réalisé une évaluation quantitative des différents algorithmes de relations publiques pour AQ basées sur la correspondance lexicale où il a déduit que les algorithmes les plus proposés traitent chaque terme de la question comme un symbole indépendant et ne considèrent pas l'ordre des termes et leurs relations de dépendance. Afin de remédier à cette lacune, il y a eu plusieurs tentatives pour prendre en compte les dépendances à long terme. En outre, plusieurs ouvrages reposent sur la comparaison syntaxique comme (Cui et al., 2005) découlant des relations syntaxiques pour correspondre à des questions avec des passages. Néanmoins, la principale limite de filtrage syntaxique est la nécessité d'un analyseur syntaxique qui n'est pas disponible pour tou- jours toutes les langues. Ajouté à cela, il faut l'adaptation et la performance du SQR dépend en grande partie sur la performance de l'analyseur. D'autres travaux ont été basées sur la correspondance sémantique tels que (Ofoghi et Yearwood, 2009). Bien qu'ils permettent de dé- tect de vraies réponses, ils ont besoin de ressources sémantiques qui ne sont généralement pas disponibles dans toutes les langues et ne couvrent pas tous les domaines, ni ni tous les termes. En outre, il y a eu d'autres plusieurs travaux combinant à la fois des techniques sémantiques et syntaxiques dans le contexte de relations publiques. Sinon, certains travaux ont eu recours à un modèle différent pour récupérer des passages allant au-delà de ce qui précède simple, correspondant lexical. Ces derniers comptaient sur n-grammes qui se réfère à des séquences de mots extraits consécutifs d'un texte donné, comme un outil puissant et rapide qui ne traite pas avec des termes comme symboles indépendants, mais il prend en compte la dépendance entre les simples. Dans ce - 112 - Contexte N. Othman et R. Faiz, Radev et al. (2005) ont proposé une méthode probabiliste pour le langage naturel basé sur le Web QA, où les documents web sont segmentés dans des passages qui seront classés en utilisant un score de n-gramme basé sur la pondération tf-idf. En outre, Correa et al. (2010) ont développé un système PR pour l'AQ basé sur une mesure de similarité n-grammes favorisant les passages contenant plus requête n-grammes et les plus de comparer les passages candidats extraits par la technique des mots-clés. En outre, Buscaldi et al. (2010) ont suivi la même approche précédente, mais la seule différence est sur le modèle n-gramme appliqué qui considère le passage n-grammes existant dans la question et leur proximité. Notre méthode pour récupérer des passages est différent de ceux à base de n-gramme ci-dessus, nous avons mis davantage l'accent sur n-grammes communs entre la question et le passage et nous procédons différemment pour extraire les n-grammes. En effet, nous introduisons une nouvelle similitude me- sûr calculée à partir des poids des n-grammes question. Nous construisons un poids de passage au total en naviguant sur la question n-grammes, en gardant le poids d'un n-gramme si elle est complètement trouvée dans le passage et réduire ce poids si elle est divisée en petits n-grammes dans le passage. 2.2 Approches de classement pour réponse de sélection L'une des étapes clés à la fin de la canalisation QAS est la sélection de réponse qui commence par le classement des passages candidats fournis par le module PR. Étant donné une requête qui exprime la question d'un utilisateur, la fonction de classement des ordres les passages récupérés tels que le mo st ceux qui sont pertinents à la requête donnée apparaissent en premier. Ainsi, plusieurs modèles de classement ont été proposées pour résoudre ce problème dans l'assurance qualité. En fait, certains travaux invoqués modèles basés sur la connaissance de rang tels que les sages passions (Bilotti et al, 2010;. Araki et Callan, 2014) où les connaissances en question et des réponses telles que l'entité nommée (NE) présente, est représentée comme un graphe d'annotation et les inférences sont tirées de la base de connaissances. Néanmoins, la principale limitation de la plupart des approches fondées sur le savoir est qu'ils comptent sur un grand nombre de déductions et manuel concep- tion de fonctions. En outre, la cartographie et prédicats correspondants et arguments aux relations du modèle reste une tâche très complexe. D'autres travaux mis en place des approches basées sur des modèles aussi appelé modèles qui ne sont plus d'un ensemble de règles d'évaluation de contexte prédéfinis conçus et extraits de la question et les passages candidats et ils sont souvent appliqués en fonction du type de question. Par exemple, Severyn et al. (2013) appliquée à des modèles d'apprentissage de rang pour apprendre automatiquement les modèles complexes, par exemple, l'apprentissage des structures sémantiques relationnelles qui apparaissent dans les questions ainsi que leurs passages. Cependant, la plupart des approches à base de motifs sont très complexes et nécessitent beaucoup de données de formation. Dans le cas contraire, certains travaux ont utilisé le contexte des mots comme simple intuition pour les passages de classement tels que (Toba et al, 2010;.. Yen et al, 2013). Dans ce dernier ouvrage, les auteurs ont proposé un modèle nommé (CRM) qui re-classe les passages récupérés à l'aide contextuelle classement de l'information contextuelle des noms propres, des motifs syntaxiques, traits sémantiques pour chaque mot dans la fenêtre contextuelle ainsi que la position de mot pour prédire si un passage candidat donné est pertinent pour le type de question. Cependant, la performance du CRM dépend fortement de la classification des questions. Il est intéressant de noter que notre modèle re-classement passage est largement inspiré de cette dernière approche basée sur SVM qui est un modèle d'apprentissage VISED super qui était dans la plupart des cas appliquées avec succès pour le classement passage comme dans (Moschitti et Quarteroni, 2011). Néanmoins, nous avons recours à modèle Classement SVM au lieu de SVM, qui intègre un ensemble de caractéristiques différentes de celles utilisées dans (Yen et al., 2013). Contrairement à ce dernier, nous sommes contraints ni par mots NE ni par une fenêtre de taille fixe. Nous sommes allés au-delà d'une simple détection de la classe NE, la forme et la partie étiquette partie du discours du mot à calculer lexical, des mesures de similarité sémantique et n-gramme. - 113 - Un passage pertinent de récupération et approche Re-classement pour la question Réponse 3 Approche proposée L'idée de base de notre approche est d'abord réduire l'espace de recherche en utilisant n-grammes pour récupérer les 10 premiers passages qui sont les plus susceptibles de répondre à la question de l'utilisateur . Le nombre de passages retournés est fixé à 10 comme la plupart de l'état des systèmes de relations publiques d'art prennent des valeurs proches de 10. Toutefois, étant donné que la structure n-grammes repose uniquement sur une simple dépendance entre les termes, il ne suffit pas de garantir une grande pertinence. Par conséquent, nous avons tendance à re-rang les passages récupérés à l'aide d'un modèle SVM classement qui combine des mesures supplémentaires de similarité lexicale et sémantique pour revenir le passage le plus pertinent, le premier rang un, pour répondre à la question d'entrée. Dans cette section, nous présentons notre approche pour récupérer et passages de re rang nommé PRR qui est essentiellement composé de trois modules principaux: analyse de la question, relations publiques et re rang passage. La figure 1 représente l'architecture globale de l'approche proposée PRR. Dans ce qui suit, nous détaillons ses différents constituants. FIGUE. 1 - Architecture globale de notre approche 3.1 PRR Question Module d'analyse L'objectif de l'analyse de la question est de générer une requête formelle par prétraiter la question saisie par l'utilisateur et l'extraction des termes utiles. Cette requête est générée en appliquant le nettoyage texte, suppression des mots interrogatifs, tokens, arrêt des mots retrait et à endiguer. La requête sera formellement définie comme suit: Q = {t1, t2, ..., tq} où t désigne un qu séparé terme ERY et q représente le nombre de termes dans la requête. 3.2 Passage Retrieval Module Fondamentalement, notre module PR est composé de deux éléments principaux: extraction de passage des candidats et d'extraction de passage pertinent. Ce paragraphe est consacré à les détailler. - 114 - N. Othman et R. Faiz 3.2.1 Passage du candidat Extraction d'abord, nous indexer la collection en coupant les documents dans les paragraphes nommés pas- sages. Pour chacun, nous enregistrons les informations associées, comme son identifiant, le nom du document, le numéro et le texte. Ensuite, on extrait les termes et éliminons les mots vides. Découlant est également appliquée pour faciliter la recherche et l'indexation des mots. Un passage est formellement défini comme suit: P = {t1, t2, ..., tp} où t représente une durée distincte du passage P et p désigne le nombre de termes de passage. Par la suite, nous donnons une fréquence à chaque terme de passage dans le passage afin de calculer la fréquence maximale et les poids à long terme. Une fois que les passages sont indexés, leurs termes seront stockés dans l'index inversé. Afin de calculer le poids des termes de la requête, nous avons re triés à la formule employée dans (Correa et al., 2010) qui ne tient pas compte de la fréquence des mots, mais il ne prend en compte leur pouvoir discriminant entre les passages. Que pour identifier les passages qui contiennent au moins un des termes de la requête, nous avons juste besoin de chercher les termes de la requête dans l'index inversé, où pour chaque terme, la liste des passages connexes est enregistrée et prendre l'intersection de ces passages. Les passages candidats nommés Pc sont définis comme bas vantes: Pc = {P1, P2, ..., Pn} où Pi est un passage candidat et n est le nombre de passages candidats. Notez que le poids d'un passage de termes candidats est calculé par la même manière que les termes de la requête. Pour filtrer les passages candidats, on calcule la similitude entre chaque passage des candidats et la question en utilisant la mesure de similarité suivante que les mots de Siders ne con- en commun entre la requête et le passage: s (p, q) = Σ ti∈P ∩Q w (ti, q) Σ ti∈Q w (ti, q). Les passages candidats sont ensuite classés en fonction de leurs valeurs de similarité. Ainsi, le nombre de passages candidats (n) est réduit à (nb). L'ensemble des passages candidats renvoyés sera réglé sur: Pc = {P1, P2, ..., Pnb} Nous devons réduire la complexité globale du système en termes de temps et de l'espace et permettre une analyse plus approfondie qui n'a pas été possible à l'avance en raison de la taille énorme de collec- tion. Par conséquent, le nb de nombre devrait être en essayant de trouver un juste milieu entre un grand et un petit nombre afin de réduire la complexité du système, mais sans exclure des passages qui peuvent contenir la réponse et sont mal classés. Par exemple, nous pouvons définir le nb de nombres à 100 Ensuite, nous allons appliquer un filtre aux passages candidats nb en utilisant des structures n-gramme afin d'en extraire ceux qui sont pertinents. 3.2.2 Passage pertinent Extraction Jusqu'à présent, les passages candidats renvoyés par l'étape précédente ont seulement un petit nombre de mots en commun avec la question. Néanmoins, ce critère n'est pas assez bon pour juger de la pertinence d'un passage. Il est donc nécessaire d'aller au-delà d'une simple vérification des occurrences de mots. Dans ce contexte, nos objectifs de méthodologie proposée pour exploiter d'autres critères de sélection tels que la présence de séquences de mots, leur longueur, leur dépendance, etc. A cet effet, nous utilisons la technique n-gramme qui assure la dépendance simple entre les termes, la réduction de l'ambiguïté, la langue l'indépendance et il peut non seulement faire face à une énorme quantité de données, mais aussi avec son hétérogénéité. Notre méthodologie pour extraire les passages pertinents se compose des éléments suivants: N-gramme Génération Nous avons d'abord identifier les termes communs entre une question et un passage donné et ensuite nous construisons le vecteur - → Tc des termes communs entre la question et le passage. Nous avons juste besoin de parcourir les termes de la question et de contrôle pour chacun d'eux - 115 - Un passage pertinent et récupération approche resitue classement pour la question Répondre si elle est un terme du passage pour l'ajouter dans le vecteur. Cette dernière est définie par: - → Tc   t1 P1Q [p11, .., P1M] t2 P2Q [p21, .., P2M] .. .. tn PNQ [PN1, .., PNM]    où ti est le terme ième en commun entre la question et le passage et i = {1..n}. n désigne le nombre des termes de question, PIQ représente la position du terme i dans la question, JIP est la position j du terme ième dans le passage et j = {} 1..m. m est le nombre de termes dans le passage.Thereafter, nous construisons les vecteurs n-gramme du vecteur question --- → QNG et le passage --- → NGP en naviguant sur le vecteur - → Tc et le regroupement des termes ayant des positions successives dans la question et dans le passage. N-gramme Pondération Le poids de chaque n-gramme de la question est calculée sur la base de sa longueur et la somme de ses pondérations à long terme conformément à: w (QNG) = l × Σti∈terms (QNG) w (ti, q) où l est le nombre de termes contenus dans la question n-gramme (QNG). En effet, la multiplication de la somme des poids de la longueur n-gram peut favoriser des mots adjacents plutôt que des indépen- dants. De toute évidence, les mots sont regroupés plus significatifs et moins ambigu que les mots séparés. Donc, il est raisonnable de donner un mot indépendant un poids plus grand quand il appartient à un n-gramme. En ce qui concerne le passage, les n-grammes sont pondérés en fonction de leur degré de similitude avec les n-grammes de la question. Nous attribuons un poids cumulé au passage en parcourant les n-grammes de la question et à chaque n-gramme, soit est son poids tout ou une plus faible est ajouté à la masse du passage. Plus précisément, si un n-gramme de la question se trouve dans le passage, son poids sera ajouté au poids cumulatif, mais si le n-gramme est divisé en petits n-grammes dans le passage d'un poids inférieur sera ajouté au poids cumulé. Ce poids inférieure est fixée en fonction du nombre des petits n-grammes. Il est à noter qu'il y a trois cas possibles: - Cas 1: la requête n-gramme est l'une des n-grammes passage: ngqì = ngPj, ngPj ∈NGP - Cas 2: La requête n-gramme est faite en combinant un certain nombre n du passage n-grammes: ngqì = ∪ PNG, PNG ∈ NGP - Cas 3: la requête n-gramme est inclus dans l'un des passages n-grammes: ngqì ∈ ngPj, ngPj ∈ NGP soit w le poids d'add au passage lorsque nous parcourons à travers la question n-grammes QNG. Dans les cas 1 et 3, NGQ existe dans le passage, de sorte que le poids supplémentaire w est calculé selon la formule suivante: w (PNG) = w (QNG) = l × Σti∈terms (QNG) w (ti, q) où l est la longueur du n-gramme QNG et w (ti, q) est le poids de sa durée ti. Dans le cas 2, QNG est divisé en sous-n-grammes dans le passage, que SNG être le nombre de ceux-ci. Dans ce cas, le poids supplémentaire w a la valeur: w (PNG) = w (QNG) GNS = l SNG × Σ ti∈terms (QNG) w (ti, q) Psim de similarité mesurer notre mesure de similarité de passage appelée Psim entre un passage et une question ne dépasse pas le rapport entre le poids du passage et celui de la question. Nous commandons les passages en fonction des valeurs de cette mesure afin de ramener ceux qui ont les valeurs les plus élevées. Le poids d'un passage est cumulatif comme mentionné ci-dessus. Elle est la somme des poids partiels calculés à chaque étape à ajouter à la masse totale de passage. A - 116 - N. et R. Othman Faiz correspond pas à pas de calcul à la vérification de l'apparition d'un n-gramme de la question dans le passage sous-jacent et le poids est donnée par la formule 1 suivante: w (P) = qΣ i = 1 × Σ li SNGI t∈terms (ngqì) w (t, q) (1) dans laquelle q désigne le numéro de la question n-grammes. En ce qui concerne le poids de la question, il est calculé selon la formule 2: w (Q) = l (Q) × Σ ti∈ (Q) w (ti, q) (2) où L (Q) est le nombre de les termes d'interrogation et w (ti, q) est le poids d'un terme d'interrogation. w (Q) est le même que le poids d'un n-gramme calculé en utilisant la formule 3.2.2 lorsque la QNG n-gramme est la question. l = l (Q) est le nombre de termes d'interrogation et SNG = 1 étant donné que toutes les conditions sont regroupées et forment un uni-gramme. Une fois eu la poids de la question et le poids de chaque passage, on calcule la mesure de similarité qui est fixée à la formule 3: Psim (p, q) = w (P) w (Q) = Σqi = 1 × li SNGI Σt∈terms (ngqì) w (t, q) l (Q) × Σti∈ (Q) w (ti, q). (3) De toute évidence, cette similitude est maximale quand elles sont toutes regroupées la question des termes dans le passage. Par exemple, nous considérons les termes suivants d'une question Q et ceux d'un passage P: Q (termes) = commerce, ammonium, nitrate, engrais, entravées, européen, économique, communautaire. P (termes) = ammonium, nitrate, essentiels, ingrédient, variété, produits, certains, destinés, utilisation, izers fertilisés, d'autres, explosifs, raison, DIVERGENCES, les dispositions nationales, classification, contenu, européen, économique, communautaire, règlements , le contrôle, la commercialisation. Le vecteur correspondant - → Tc entre la question donnée et le passage est réglé sur: ------ → Tc (Q, P) = ammonium, nitrate, engrais, européen, économique, communautaire. De ce dernier on peut en déduire: ------ → QNG (Q) = [engrais de nitrate d'ammonium] [Communauté économique européenne] et ------ → NGP (P) = [nitrate d'ammonium] [engrais] [ Communauté Économique Européenne]. Dans cet exemple, --- → NGQ est composé de deux n-grammes nous avons donc deux poids de passage partiel pour le calcul. La première question n-gramme est divisé en deux SUBn-grammes dans le passage de sorte, SNG est égal à 2 tandis que le second est exactement égale à un passage du n-gramme ainsi, SNG est égal à 1. Ainsi, compte tenu de 1.766 et 1.524 les pondérations à long terme de ngQ1 et ngQ2 respectivement, w1 (P) = L (ngQ1) sng1 × Σ t∈terms (ngQ1) w (t, q) = (3/2) × 1,766 whilew2 (P) = L (ngQ2) sng2 × Σt ∈terms (ngQ2) w (t, q) = (3/1) × 1,524. Donc, le poids total de passage est égale à la somme de w1 (P) et w2 (P). D'autre part, le poids de la question sera réglée à: w (Q) = l (Q) × Σti∈ (Q) w (ti, q) = 8 × 4,924 4,924 où est le résultat de la somme de termes de la requête poids. Pour résumer, notre méthode est différente de celles à base de n-grammes précédemment cité. Tout d'abord, nous procédons différemment pour extraire le n-grammes dans la mesure où au lieu d'extraire tous les n-grammes pour tous les n valeurs possibles de la question et le passage, comme dans (Correa et al., 2010) et (Buscaldi et al., 2010 ), ou tous les n-grammes de taille n, comme dans (Radev et al., 2005), on extrait seulement n-grammes communs entre la question et les passages de tailles différentes. Donc, on n'a pas besoin d'inclure - 117 - Un passage pertinent et récupération Re rang approche pour la question Répondre à une étape supplémentaire pour sélectionner n-grammes communs de tous les n-grammes extraits. En second lieu, le poids de n-grammes, nous prenons en compte à la fois la somme des termes de poids et de leur longueur comme dans (Radev et al., 2005), tandis que Correa et al. (2010) et Buscaldi et al. (2010) considèrent que la somme du poids des termes. Troisièmement, notre mesure Psim est calculée à partir du poids de la question n-grammes et dépend de la n-gramme est entièrement existe ou il est divisé dans le passage. 3.3 Passage Re rang module donné un ensemble de passages récupérés retournés par notre moteur n-gramme à base de PR, nous avons recours à la Ranking SVM appelé modèle RankSVM qui combine différents textes similitude me- sures qui constituent les caractéristiques de re-rang les en fonction de leurs degrés de similitude avec la question. RankSVM est une version classement du modèle SVM introduit pour résoudre le problème du classement de manière supervisée. L'idée derrière la méthode soulignage de cette machine ing populaire est de transformer le problème du classement dans la classification par paires et apprendre une fonction de classement de prédiction en utilisant l'intuition de SVM. Nous rappelons que RankSVM a été appliquée avec succès dans le cadre de l'IR, notamment pour la recherche de documents (Cao et al., 2006). Il est à noter que notre modèle de re-classement passage se compose de deux phases: la formation et les tests. Dans les deux phases, les différentes mesures de similarité sont calculées pour chaque passage et ces derniers sont entrés dans le classificateur RankSVM qui re rang les passages compte tenu de leurs valeurs caractéris- tique. Seul le passage au premier rang par notre modèle sera retourné par le sy la tige comme la plus pertinente réponse à la question d'un utilisateur donné. Au cours de la première phase, un ensemble de passages annotés entrés dans le modèle re rang passage à chaque passage classé où est marqué soit +1 (à droite) ou -1 (mauvais), alors que dans la phase de test, les passages ne sont pas étiquetés comme ils sont celles extraites par notre module de PR. Bien que la technique n-gramme assure seulement une dépendance simple entre les termes, il ne semble pas assez satisfaisante pour assurer la pertinence des sages extraits passions. Ainsi, nous avons recours à d'autres caractéristiques importantes, en particulier les sémantiques. En fait, les caractéristiques utilisées dans notre modèle de classement ont déjà fait leurs preuves avec succès dans la tâche Justifications sémantique similarité (Buscaldi et al., 2013) (STS) à * SEM 2013 qui nécessite des systèmes ING partici- pour déterminer le degré de similitude entre les paires des phrases de texte. Parmi les fonctionnalités proposées, nous ne considérerons WordNet basé conceptuelle similarité, entité nommée Overlap, Edit distance et au lieu de la N-gramme basé similarité appliquée dans cette tâche, nous re sorte à celle proposée par nous-mêmes dans ce travail. En effet, nous avons adapté ces caractéristiques au contexte de l'AQ. C'est-à-dire les paires de phrases deviennent paires de passage-question. Notez que plus nous ajoutons des fonctionnalités, plus la complexité du programme est. De plus, à ce stade, les mesures de similarité de texte basé sur les fréquences terme ne sont pas suffisantes pour récupérer les sages pertinents passions (Keikha et al., 2014). D'où, dans notre cas, nous avons principalement eu recours à des caractéristiques sémantiques pour assurer la pertinence des réponses. 4 L'évaluation expérimentale 4.1 datasets et outils Fondamentalement, deux principales ressources sont nécessaires pour le développement et l'évaluation d'un QAS: une collection de documents et un groupe de questions. Pour l'évaluation de notre module de relations publiques, nous - 118 - N. Othman et R. Faiz avons utilisé l'ensemble de données fournies dans l'exercice ResPubliQA 2009 de CLEF qui cherche à récupérer les paragraphes de la collection de test à réponse (Peñas et al., 2010) une question donnée choisi à partir d'une série de questions différentes. Dans nos expériences, nous utiliserons la collection française que seuls quelques systèmes ont été testés dans cette langue en raison de son ambiguïté. Les expériences sont réalisées sur 338 questions, 1388818 passages tirés de la collection donnée, 100 passages utilisés de ceux qui sont renvoyés par le modèle de recherche et 10 passages renvoyés par le modèle n-gramme. D'autre part, d'évaluer l'applicabilité de l'approche globale, nous avons utilisé les ressources fournies dans l'exercice de ResPubliQA2010 (Peñas et al., 2010) qui vise à renvoyer soit des paragraphes ou des réponses exactes que la sortie du système à un ensemble de 200 plus questions complexes sur deux collections d'essais. Notez que cette fois-ci, nous allons utiliser toute la collection anglaise pour la formation et les tests. En fait, nous travaillons sur les passages, les ensembles de données donnés devraient être les plus appropriés pour évaluer notre approche. Nous insistons sur le fait que nous avons testé l'approche globale à l'aide du corpus anglais que nous avons eu recours aux versions anglaises des principaux outils utilisés pour atteindre des performances jugées plus telles que la version anglaise de WordNet Lexical Database et le NE pour l'anglais reconnaisseur. , Nous pouvons évidemment aussi évaluer notre approche dans d'autres langues simplement en intégrant des outils multilingues. Afin de valider notre approche, nous avons mis au point un système nommé PexRank (extraction de passage et système de classement) et nous avons utilisé le système open source JIRS 1 (information JAVA Système de récupération) décrits dans Gómez et al. (2007) pour les processus d'indexation et de recherche et adapté à nos besoins. Pour le passage classement, nous avons utilisé la SVM open source lumineuse 2. Notez que les passages des flux de formation étiquetés dérivés des fichiers de jugement de paires question / réponse ResPubliQA2009 anglais. 4.2 Mesures d'évaluation Pour évaluer la performance de notre moteur PR, nous sommes basés sur les mesures suivantes: - La précision: qui est défini comme le pourcentage de réponses correctes par rapport à tous posé des questions (dans notre cas pour les 10 premières positions). - Le nombre de les questions ayant passage correct au premier rang. - Le Rang réciproque moyen (de MRR) qui indique l'inverse multiplicatif de la position de rang de la première réponse correcte et a été largement été utilisée dans QA pour répondre le classement. Pour évaluer l'approche globale, nous sommes basés sur les mesures CLEF suivantes: - Le c @ 1 mesure qui a été introduite par CLEF comme la principale mesure d'évaluation pour les tâches de passage et de sélection de réponse. La formule de c @ 1 est réglé sur: c @ 1 = 1n (+ nR nU NRN) où nR désigne le nombre de questions correctement répondu, est nU le nombre de questions sans réponse et n est le nombre total de questions. - Précision globale: la précision calculée sur toutes les réponses évaluées. - Nous avons également utilisé le nombre de questions sans réponse (#NoA), le nombre de réponses correctes (#R), le nombre de questions a répondu à tort (#W), le nombre de questions sans réponse où une réponse candidat est mis au rebut (# NoA R): Dans ce cas, le système choisit de laisser la question sans réponse (comportement pessimiste) et le nombre de questions sans réponse avec une mauvaise réponse du candidat (#NoA W). Notez que nous avons fixé une valeur de seuil pour le score final à 0,15 comme il a été choisi par de nombreux auteurs pour le résultat du classement final. Donc, nous répondons à la question que si le score le plus élevé 1. http://sourceforge.net/projects/jirs/ 2. http://svmlight.joachims.org/ - 119 - Un passage pertinent et récupération Re rang approche pour question valeur est supérieure à 0,15 Answering. Dans le cas contraire, nous ne revenons pas de réponse à la question donnée. Nous croyons que le retour sans réponse à une question posée est mieux qu'offrir une mauvaise réponse. 4.3 Résultats et discussion Nous avons comparé les résultats obtenus par notre moteur PR à ceux du système NLEL (Correa et al., 2010) qui a utilisé un modèle n-gramme à base de PR et il a été classé au premier rang dans la CLEF 2009 piste QA pour les Français la langue. LANGUETTE. 1 - Les résultats de la comparaison entre PexRank et NLEL PexRank NLEL Nombre de questions ayant correctes 272 260 passages dans les 10 premières positions Précision 0,804 0,670 Nombre de questions dont correct 159 142 passage est en première position MRR 0,409 0,365 Le tableau 1 montre que notre système a donné de meilleurs résultats que NLEL dans tous les critères. En effet, PexRank a répondu à un grand nombre de questions, avec une différence égale à 12 questions plus que NLEL. Nous avons obtenu plus de réponses dans la première position avec une différence égale à 17 questions. De plus, nous avons déduit que la valeur de MRR de PexRank est supérieure à celle de NLEL parce que le nombre de réponses obtenues par notre système est plus grande dans les premières positions et tions plus faibles dans les derniers. Maintenant, nous passons à évaluer l'approche globale. Les résultats obtenus dans notre système de fonctionner sont présentés dans le tableau 2, où l'on compare nos résultats à ceux rapportés par d'autres systèmes participant à l'exercice de ResPubliQA2010 effectuer la même tâche de sélectionner le passage le plus pertinent pour répondre à une question donnée, décrite dans (Peñas et al ., 2010). LANGUETTE. 2 - Comparaison entre PexRank et systèmes similaires Précision du système c @ 1 #R #W #NoA #NoA R #NoA W PexRank 0,74 0,83 149 26 25 0 0 uiir101PSenen 0,72 0,73 143 54 3 0 3 bpac102PSenen 0,68 0,68 136 64 0 0 0 dict102PSenen 0,67 0,68 117 52 31 17 14 bpac101PSenen 0,65 0,65 129 71 0 0 0 elix101PSenen 0,65 0,65 130 70 0 0 0 nlel101PSenen 0,64 0,65 128 68 4 2 2 uned102PSenen 0,65 0,65 129 71 0 0 0 Les résultats rapportés dans le tableau 2 montrent que PexRank surpasse toute les autres systèmes EFFECTUEREZ dES la même tâche en termes de précision et c @ 1 mesure avec une précision score égal à 0,74 et ac @ 1 score égal à 0,83, qui sont nettement bons résultats. En outre, le fait que notre c @ 1 valeur est supérieure à la cote de précision prouve que l'utilisation de notre aucun critère de réponse est justifiée et a permis d'obtenir un haut c @ 1 mesure. Nous avons remarqué que, sur 99 questions complexes, notre système a répondu avec succès 48 questions. La plupart des questions sans réponse où les questions d'opinion. De même, l'en correctement répondu aux questions étaient pour la plupart ceux d'opinion et les causes. Néanmoins, il est possible d'autres expériences sur - 120 - N. Othman et R. Faiz grands ensembles de données pour décider de la valeur de seuil pour le classement score final. Notez que, nous avons choisi de ne pas fournir une réponse candidate pour les questions sans réponse, ni correctes, ni in- correct. Bien que la tâche de sélection de paragraphe est juste une PR, la principale différence de IRs pur est d'ajouter la possibilité de laisser la question sans réponse à l'étape de validation. Il est à noter que cette tâche permet de poster des questions complexes et de les évaluer de manière simple. 5 Conclusion Poser une question en langage naturel et d'avoir une réponse précise devient aujourd'hui un atout majeur pour l'utilisateur et constitue un défi considérable dans de nombreux domaines d'application tels que le commerce électronique, l'enseignement à distance et la recherche mobile. Dans cet article, nous avons abordé deux tâches cruciales dans l'assurance qualité et propose une nouvelle approche pour la récupération et des passages re rang prenant ad- vue de n-grammes et modèles RankSVM. Bien que nos résultats expérimentaux ont montré des résultats prometteurs, nous croyons que notre approche pourrait être améliorée en incorporant d'autres fonctionnalités telles que celle syntaxique dans le modèle de re-classement sans augmenter de manière significative la complexité du programme. À l'avenir, nous attendons avec impatience d'évaluer notre approche sur corpus écrits dans d'autres langues et de permettre à notre système de retourner une réponse précise au lieu d'un passage. Références Araki, J. et J. Callan (2014). Un modèle de similitude d'annotation dans le passage de classement pour histor- validation ical d'information. Dans Proc. de l'ACM SIGIR internationale 37e sur la recherche et conf de développement dans IR, p. 1111-1114. ACM. Bilotti, M. W., J. Elsas, J. Carbonell et E. Nyberg (2010). l'apprentissage de Rang pour répondre à la question factoid des contraintes linguistiques et sémantiques. Dans Proc. du 19 international ACM conf de l'information et KM, p. 459-468. ACM. Buscaldi, D., J. Le Roux, J. J. G. Flores, et A. Popescu (2013). LIPN-core: similarité de texte sémantique en utilisant n-grammes, wordnets, analyse syntaxique, esa et recherche d'information fonctionnalités basées. Dans Proc. du 2ème joint Sémantique conf lexicales et computationnelle, p. 63. Buscaldi, D., P. Rosso, J. M. Gómez-Soriano, et E. Sanchis (2010). Répondre aux questions avec un moteur de recherche de passages à base de n-gramme. JIIS 34 (2), 113-134. Cao, Y., J. Xu, T.-Y. Liu, H. Li, Y. Huang et H.-W. L'honorable (2006). Adaptation du classement svm à la recherche de documents. Dans Proc. du SIGIR international annuel ACM 29 sur la recherche et conf de développement dans IR, p. 186-193. ACM. Correa, S., D. Buscaldi et P. Rosso (2010). Nlel-Maat à respubliqa. Dans multilingue Informa- tion accès I. évaluation texte expériences de récupération, pp. 223-228. Springer. Cui, H., R. Sun, K. Li, M.-Y. Kan, et T.-S. Chua (2005). Question réponse la recherche de passages en utilisant les relations de dépendance. Dans Proc. du SIGIR international annuel 28 ACM pour la recherche et conf de développement dans IR, p. 400-407. ACM. Faiz, R. (2006). Identification des phrases pertinentes dans les articles de presse pour l'extraction d'informations sur les événements. IJCPOL 19 (01), 1-19. - 121 - Un passage pertinent la recherche et l'approche Re rang pour la question Réponse Gómez, J. M., D. Buscaldi, P. Rosso et E. Sanchis (2007). JIRS ​​système de récupération de passage indépendant de la langue: Une étude comparative. Dans Proc. du 5ème international sur la PNL conf (icône- 2007), pp. 4-6. Keikha, M., J. H. Park, W. B. Croft, et M. Sanderson (2014). Récupération des passages et trouver des réponses. Dans Proc. du Symposium Computing document Australasie 2014, p. 81. ACM. Moschitti, A. et S. Quarteroni (2011). noyaux linguistiques pour réponse re rang dans les systèmes répondant à des questions. IPM 47 (6), 825-842. Ofoghi, B. et J. Yearwood (2009). Peut-information de classe sémantique peu profonde aide réponse la recherche de passages? En 2009 AI: Les progrès de l'intelligence artificielle, pp 587-596.. Springer. Peñas, A., P. Forner, Á. Rodrigo, R. F. E. Sutcliffe, C. Forascu et C. Mota (2010). Vue d'ensemble de respubliqa 2 010: Question de répondre à l'évaluation sur la législation européenne. En 2010 CLEF et ateliers, LABs documents portables, 22-23 Septembre 2010, Padoue, Italie. Peñas, A., P. Forner, R. Sutcliffe, a. Rodrigo, C. Forăscu, I. Alegria, D. Giampiccolo, N. Moreau et P. Osenova (2010). Vue d'ensemble respubliqa 2009: Question d'évaluation de réponse sur la législation européenne. Dans l'information multilingue Accès I. évaluation texte expériences de récupération, pp. 174-196. Springer. Radev, D., W. Fan, H. Qi, H. Wu, et A. Grewal (2005). question probabilistes répondre sur le web. JASIST 56 (6), 571-583. Severyn, A., M. Nicosie, et A. Moschitti (2013). structures de construction classificateurs pour le passage de reclassement. Dans Proc. du 22 international ACM conf CIKM, pp. 969-978. ACM. Tellex, S., B. Katz, J. Lin, A. Fernandes, G. et Marton (2003). L'évaluation quantitative des algorithmes de récupération Pas- sage pour répondre à la question. Dans Proc. de l'international annuel 26 conf ACM SIGIR sur la recherche et le développement en IR, p. 41-47. ACM. Toba, H., S. Sari, M. Adriani, et R. Manurung (2010). Approche contextuelle pour la sélection du paragraphe dans la tâche de réponse aux questions. Dans CLEF (Documents portables / Labos / ateliers). Voorhees, E. M. (2001). La piste TREC répondeur question. JNLE 7 (04), 361-378. Yen, S.-J., Y.-C. Wu, J.-C. Yang, Y.-S. Lee, C.-J. Lee, et J.-J. Liu (2013). Un modèle de contexte classement basé machine vecteur de support pour répondre à la question. JIS 224, 77-87. Les CV de questions-Systèmes Réponses (SQR) s Visent à RETOURNER des reponses precises Directement Ë des questions posees en langage naturel. L'extraction et le des passages Sont reclassement considérés les Comme les plus de Difficiles Tâches de un SQR et typique encore l'effort exigeant de un non trivial. Dans this article, nous proposons Une nouvelle approche Pour L'extraction et le reclassement des passages en Utilisant les n-grammes et SVM. Notre Système d'extraction de passages basons sur la technique des n-grammes repos Sur une nouvelle de mesure Entre passage un similarité et Une question. Les passages ensuite réordonnés extraits en Sont un modèle basons Utilisant sur RankSVM Combinant de Measures Différentes de RETOURNER similarité le AFIN passage Le plus pertinent verser question juin Donnée. Nos expériences et nos ÉTAIENT Résultats et prometteurs Que notre have démontré approach is concurrentielle. - 122 -