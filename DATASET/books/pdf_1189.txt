Microsoft Word - EGC2004_Khiops.doc une méthode robuste pour partitionner les valeurs des attributs catégorielles Marc Boullé * * France Télécom R & D, 2, avenue Pierre Marzin, 22300 Lannion, France marc.boulle@francetelecom.com CV. Dans le domaine de l'apprentissage supervisez, les methods de groupages des d'un attribut Modalités symbolique de construct un permettent nouvel au attribut synthetic au maximum la conservant Valeur informationnelle de l'initiale et attribut le diminuant Nombre de Modalités. Nous proposons ici juin de l'algorithme généralisation de discrétisation Khiops1 for the du groupages des Problème Modalités. L'algorithme de CONTROLER Përmet Proposé a priori le osée de sur-et d'Improving apprentissage la robustesse des significativement groupages Produits. This characteristic was de robustesse available in la statistique des étudiant les variations du Khi2 du critère de LORs de regroupements d'un tableau lignes de Contingence et en modélisant le comportement de l'algorithme statistique Khiops. Des Expérimentations de Intensifs Ontario permis et approach this valider Montré Que la Ontario méthode de groupages Khiops aboutIt à des groupages Performants, à la Fois en term et de qualité prédictive Nombre de Faible Groupes. 1. Introduction Alors que le problème de discrétisation a été largement étudié dans le passé, le problème de regroupement n'a pas été exploré si profondément dans la littérature. Cependant, dans la réalité des ensembles de données d'exploration de données, il existe de nombreux cas où le regroupement des valeurs des attributs catégoriques est une étape de pré-traitement obligatoire. Le problème de regroupement consiste à diviser l'ensemble des valeurs d'un attribut catégorique en un nombre fini de groupes. Par exemple, la plupart des arbres de décision exploitent une méthode de regroupement pour gérer les attributs catégoriques, afin d'augmenter le nombre de cas dans chaque nœud de l'arbre [Zighed et Rakotomalala, 2000]. les réseaux de neurones sont basées sur des attributs numériques et souvent utiliser un codage binaire 1-à-N pour prétraiter catégorique attributs. Lorsque les catégories sont trop nombreuses, ce schéma de codage peut être remplacé par une méthode de regroupement. Ce problème se pose dans de nombreux autres algorithmes de classification, tels que les réseaux bayésiens, la régression linéaire ou régression logistique. En outre, le regroupement est un procédé d'usage général qui est intrinsèquement utiles dans l'étape de préparation des données du procédé d'extraction de données [Pyle, 1999]. Les méthodes de regroupement peuvent être regroupés en fonction de la stratégie de recherche de la meilleure partition et au critère de regroupement utilisé pour évaluer les partitions. L'algorithme simple essaie de trouver les meilleurs bipartition avec une catégorie contre tous les autres. Une approche plus intéressante consiste à rechercher une bipartition de toutes les catégories. Le procédé de l'avant séquentiel de sélection dérivé de la [. Cestnik et al, 1987] et évalués par [Berckman, 1995] est un 1 les brevets français N ° 01 07006 et N ° 02 16733 une méthode robuste pour diviser les valeurs de Categorical Attributs RNTI - 1 algorithme glouton qui initialise un groupe avec la meilleure catégorie (contre les autres), et ajoute de nouvelles catégories itérativement à ce premier groupe. Lorsque l'attribut de classe a deux valeurs, [Breiman et al., 1984] ont proposé une méthode d'CART optimale pour regrouper les catégories en deux groupes pour le critère de Gini. Cet algorithme trie d'abord les catégories en fonction de la probabilité de la première valeur de classe, et puis recherche les meilleurs éclatés dans cette liste triée. Cet algorithme a une complexité temporelle de I.log (I), où I est le nombre de catégories. Sur la base des idées présentées dans [Lechevallier, 1990; Fulton et al., 1995], ce résultat peut probablement être étendue à trouver la partition optimale des catégories en groupes K dans le cas de deux valeurs de classe, avec l'utilisation d'un algorithme de programmation dynamique de la complexité du temps I2. Dans le cas général de plus de deux valeurs de classe, la re pas d'algorithme pour trouver le regroupement optimal avec des groupes K, en dehors de la recherche exhaustive. Cependant, [Chou, 1991] a proposé une approche basée sur K-means qui permet de trouver une partition localement optimale des catégories en K- groupes. algorithmes d'arbres de décision gèrent souvent le problème de regroupement avec une heuristique gloutonne basée sur une classification ascendante des catégories. L'algorithme commence par un seul groupe de catégorie, puis recherche la meilleure fusion entre les groupes. Le processus est répété jusqu'à ce qu'aucune autre fusion peut améliorer le critère de regroupement. L'algorithme CHAID [Kass, 1980] utilise cette approche gourmande avec un proche critère de ChiMerge [Kerber, 1991]. Les meilleures fusions sont recherchées en réduisant au minimum le niveau de confiance du critère du chi carré appliqué localement à deux catégories: elles sont fusionnées si elles sont statistiquement similaires. L'algorithme ID3 [Quinlan, 1986] utilise le critère de gain d'information pour évaluer les attributs catégoriques, sans regroupement. Ce critère tend à favoriser les attributs avec de nombreuses catégories et [Quinlan, 1993] a proposé en C4.5 pour exploiter le critère de rapport de gain, en divisant le gain d'information par l'entropie des catégories. Le critère du chi carré a également été appliquée globalement sur l'ensemble des catégories, avec une version normalisée de la valeur du chi carré tels que V ou T du Tschuprow de Cramer [Ritschard et al., 2001] afin de comparer deux différents partitions -SIZE. La méthode de regroupement Khiops est une généralisation directe de la méthode de discrétisation Khiops [Boullé, 2003a]. Au lieu de fusionner des valeurs numériques adjacentes afin d'intervalles de construction, le procédé de groupement fusionne les valeurs nominales en groupes de valeurs. Dans les deux cas, l'algorithme de recherche est une heuristique gloutonne ascendante qui optimise le critère du chi carré appliqué à l'ensemble des intervalles ou des groupes. La règle d'arrêt est basé sur le niveau de confiance calculé avec les statistiques du chi carré. La méthode arrête automatiquement le processus de fusion dès que le niveau de confiance, liée à l'épreuve de l'indépendance entre l'attribut partitionné et l'attribut de classe, ne diminue pas plus. L'ensemble des groupes résultant d'une méthode de regroupement fournit un classificateur univariée élémentaire, qui prévoit la distribution des valeurs de classe dans chaque groupe a appris. Une méthode de regroupement peut être considéré comme un algorithme inductif, donc soumis à overfitting. Nous appliquons une méthode similaire à celle développée pour la méthode de discrétisation Khiops afin d'apporter un véritable contrôle de surajustement. Le principe est d'analyser le comportement de l'algorithme lors du regroupement d'un organisme indépendant d'attribut explicatif de l'attribut de classe. Nous étudions les statistiques des variations des valeurs du chi carré lors de la fusion des catégories et proposons de modéliser le maximum de ces variations dans un processus de regroupement complet. L'algorithme est ensuite modifié afin de forcer toute fusion dont la variation de la valeur du chi carré est inférieure à la variation maximale prédite par notre modélisation statistique. Ce changement dans l'algorithme donne la garantie probabiliste intéressant que tout attribut indépendant seront regroupés au sein d'un seul groupe terminal et que tout attribut dont Boullé RNTI - 1 groupe se compose d'au moins deux groupes contient vraiment des informations prédictives sur l'attribut de classe. Ceci est confirmé expérimentalement. Le reste du document est organisé comme suit. La section 2 présente brièvement les initiales de Khiops de regroupement algorithme. La section 3 présente la modélisation statistique de l'algorithme et son réglage fin pour éviter surajustement. L'article 4 procède à une vaste évaluation expérimentale. 2. Le regroupement Khiops Méthode Dans cette section, nous rappelons les principes du test du chi carré et présente l'algorithme de regroupement Khiops, dont la description détaillée et l'analyse peut être trouvée dans [Boullé, 2003b]. 2.1 Le test du chi carré: Principes et Notat ions Considérons un attribut explicatif et un attribut de classe et déterminer si elles sont indépendantes. Tout d'abord, tous les cas sont résumés dans un tableau de contingence, où les cas sont comptés pour chaque paire de valeurs d'attributs explicatifs et de classe. La valeur de chi carré est calculée à partir du tableau de contingence, d'après le tableau 1 notations. nij: fréquence observée pour les i-ième valeur explicative A B C Total et une valeur de classe d'un jième n11 n12 n13 n1. ni .: Fréquence totale observée pour i e valeur explicative b n21 n22 n23 n2. n.j: Total fréquence observée pour les j-ième valeur de la classe c n31 n32 n33 n3. N: Nombre total observé fréquence d n41 n42 n43 n4. I: Nombre de valeurs d'attributs explicatifs e N51 N52 N53 n5. J: Nombre de valeurs classe totale n.1 n.2 n.3 N TAB 1 - Table de contingence utilisée pour calculer la valeur du chi carré. Laissez eij = ni..n.j / N, représentent la fréquence attendue pour la cellule (i, j) si les attributs explicatifs et de classe sont indépendants. La valeur de chi carré est une mesure sur l'ensemble de tableau de contingence de la différence entre les fréquences observées et les fréquences attendues. Il peut être interprété comme une distance par rapport à l'hypothèse de l'indépendance entre les attributs. () ΣΣ - = i j ij ijij e en Chi 2 2. (1) Dans l'hypothèse nulle d'indépendance, la valeur du chi carré est soumis à des statistiques du chi carré avec (I-1). (J-1) degrés de liberté. Ceci est la base d'un test statistique qui permet de rejeter l'hypothèse de l'indépendance; plus la valeur du chi carré est, plus le niveau de confiance est. 2.2 La valeur initiale algorithme de chi carré dépend des fréquences observées locales dans chaque ligne individuelle et sur les fréquences mondiales observées dans l'ensemble de tableau de contingence. Ceci est une bonne une méthode robuste pour partitionner les valeurs des attributs catégorielles RNTI - critère candidat 1 pour une méthode de regroupement. Les statistiques du chi carré est paramétrées par le nombre de valeurs explicatives (en rapport avec les degrés de liberté). Afin de comparer deux groupes avec différents numéros de groupe, nous utilisons le niveau de confiance au lieu de la valeur carrée khi. Le principe de l'algorithme Khiops est de minimiser le niveau de confiance entre l'attribut explicatif groupés et l'attribut de classe par le biais de statistiques du chi carré. La valeur du chi carré n'est pas fiable pour tester l'hypothèse de l'indépendance si la fréquence attendue dans une cellule du tableau de contingence tombe en dessous une valeur minimale. Les Copes algorithme avec cette contrainte dans un pré-traitement: une catégorie initiale qui ne remplit pas la contrainte de fréquence minimale est inconditionnellement fusionnées en un groupe spécial. Le procédé Khiops est basé sur un algorithme de bas en haut gourmand. Il commence par catégories initiales et cherche ensuite la meilleure fusion entre les catégories. L'algorithme est répété jusqu'à ce qu'aucune autre fusion peut diminuer le niveau de confiance. La complexité de calcul de l'algorithme peut être réduite à O (n.log (N) + I2.log (I)) avec certaines optimisations [Boullé, 2003b]. Il existe deux différences principales entre l'algorithme Khiops initial et l'algorithme CHAID similaire [Kass, 1980]. Tout d'abord, le critère de chi-carré est appliquée globalement à la partition entière, dans le cas de l'algorithme Khiops, alors qu'il est appliqué localement à deux groupes adjacents dans le cas de l'algorithme CHAID. En second lieu, l'algorithme Khiops arrête le processus de fusion lorsque le niveau de confiance augmente après la meilleure fusion candidat, alors que l'algorithme CHAID arrête lorsque le niveau de confiance est au-delà d'un seuil fixé par l'utilisateur. 3. Analyse statistique de l'algorithme L'algorithme Khiops choisit la meilleure fusion entre toutes les fusions possibles des catégories et itère ce processus jusqu'à ce que la règle d'arrêt est remplie. Lorsque l'attribut explicatif et l'attribut de classe sont indépendants, l'ensemble résultant des groupes devrait être composé d'un seul groupe, ce qui signifie qu'il n'y a pas d'information prédictive l'attribut explicatif. Dans ce qui suit, nous étudions le comportement statistique de l'algorithme Khiops initial. Dans le cas de deux attributs indépendants, la valeur du chi carré est soumis à des statistiques du chi carré, avec espérance et de la variance connue. Nous étudions la loi DeltaChi2 (variation de la valeur du chi carré après la fusion des deux catégories) dans le cas de deux attributs indépendants. Au cours d'un processus de regroupement, un grand nombre de fusions sont évaluées, et, à chaque étape, l'algorithme Khiops choisit la fusion qui maximise la valeur du chi carré; à savoir la fusion qui minimise la valeur DeltaChi2 puisque la valeur de chi carré, avant l'opération de fusion est fixe. La règle d'arrêt est remplie lorsque la meilleure valeur DeltaChi2 est trop grande. Toutefois, dans le cas de deux attributs indépendants, le processus de fusion devrait se poursuivre jusqu'à ce que l'algorithme de regroupement atteint un seul groupe terminal. La plus grande valeur de DeltaChi2 rencontrées au cours de l'algorithme de fusion des étapes de décision doit alors être acceptée. Nous allons essayer d'estimer cette valeur MaxDeltaChi2 dans le cas de deux attributs indépendants et de modifier l'algorithme afin de forcer les fusions tant que cette limite n'est pas atteint. 3.1 Statistiques des valeurs MaxDeltaChi2 de l'algorithme Khiops Concentrons-nous sur deux lignes r et r « de la table de contingence, avec des fréquences n et n », et les probabilités de ligne des valeurs de classe p1, p2, ... pj et P'1, P'2, ... P'j. Laissez P1, P2, ... Pj la Boullé RNTI - 1 probabilités des valeurs de la classe sur toute la table de contingence. La valeur du chi carré ne peut que diminuer lorsque les deux lignes sont fusionnées. Définissons la valeur DeltaChi2 comme la variation de la valeur du chi carré lors d'une fusion. () Σ = - + = J j j jj P pp nn nn DeltaChi 1 2' '' 2. (2) Nous avons prouvé que, dans le cas d'un indépendant de l'attribut explicatif d'un attribut de classe avec des valeurs de J, la valeur DeltaChi2 résultant de la fusion de deux lignes avec les mêmes fréquences est asymptotiquement distribuée comme les statistiques du chi carré avec J-1 degrés de liberté [Boullé, 2003b]. La valeur MaxDeltaChi2 est égale au maximum des valeurs de DeltaChi2 rencontrées au cours du processus de regroupement complet vers le bas d'un seul groupe terminal, lorsque l'attribut groupé est indépendant de l'attribut de classe. Dans le cas d'un processus de discrétisation, où les fusions sont contraintes à être adjacentes dans la table de contingence, nous avons proposé dans [Boullé, 2003a] une formule analytique de rapprocher les statistiques des MaxDeltaChi2. Dans le cas d'un processus de regroupement, nous n'avons pas pu rapprocher les statistiques de la MaxDeltaChi2 analytiquement. Cependant, nous avons montré dans [Boullé, 2003b] que les statistiques de la MaxDeltaChi2 ne dépend que de deux paramètres: le nombre de catégories initiales I et le nombre de valeurs de classe J. Plus précisément, les propositions suivantes sont des conjectures qui ont été vérifiés par une vaste expériences sur des données synthétiques: - les statistiques du MaxDeltaChi2 est indépendante de la taille de l'échantillon, - les statistiques du MaxDeltaChi2 est indépendante de la répartition des catégories, - les statistiques du MaxDeltaChi2 est indépendant de la distribution de la classe. Par exemple, on a évalué la première conjecture dans le cas des ensembles de données aléatoires avec 50 catégories initiales et 2 classes équiréparties équiréparties. Nous avons recueilli les valeurs MaxDeltaChi2 résultant d'un processus de regroupement complet, pour 1000 jeux de données générés au hasard. Cette expérience a été répétée pour un grand nombre de tailles d'échantillons allant de 1000 à 200000 cas et a montré que les fonctions de répartition des valeurs MaxDeltaChi2 sont indépendantes de la taille de l'échantillon. Le même genre d'expériences a été effectuée pour vérifier les autres conjectures. Nous avons également prouvé les propositions suivantes dans les cas où il n'y a que deux catégories ou deux classes. Proposition 1. Dans le cas de deux catégories et classes J, les statistiques de la valeur MaxDeltaChi2 est le chi-s statistiques Quare avec (J-1) degrés de liberté. Proposition 2. Dans le cas de I équidistribuée catégories et deux classes équiréparties, la moyenne de la valeur MaxDeltaChi2 est asymptotiquement égale à 2I / π. Dans le cas général, les statistiques de la valeur MaxDeltaChi2 n'a pas pu modéliser avec une expression mathématique, comme celle de la méthode de discrétisation Khiops. Nous avons choisi de calculer expérimentalement la moyenne et l'écart-type de la MaxDeltaChi2, pour un grand nombre de paires de paramètres (I, J). L'analyse des résultats montre un comportement linéaire avec une méthode robuste pour diviser les valeurs de Categorical Attributs RNTI - 1 rapport à deux paramètres I et J, qui est conforme aux propositions 1 et 2. Cette observation permet d'utiliser une table de valeurs à environ la moyenne et l'écart type des valeurs MaxDeltaChi2 et de compter sur une interpolation linéaire entre les valeurs pré-calculées. Enfin, nous faisons une dernière hypothèse, confirmée par l'évaluation expérimentale: la fonction de répartition des valeurs MaxDeltaChi2 peut être approchée par une loi normale avec le même écart moyen et standard. Tous les détails de la simulation sont donnés dans [Boullé, 2003b]. Pour conclure, la valeur MaxDeltaChi2 utilisée par l'algorithme de regroupement Khiops est calculé en raison d'une interpolation linéaire de la moyenne et l'écart-type trouvé dans un tableau de valeur calculée avant pour un nombre donné de catégories et de valeurs de classe. En utilisant la loi normale inverse, la valeur MaxDeltaChi2 est déterminée de sorte qu'elle sera plus grande que les valeurs de DeltaChi2 observées avec une probabilité p (p = 0,95 par exemple). 3.2 Le robuste Khiops algorithme de groupement algorithme robuste Khiops 1. Initialisation 1.1 Trier les valeurs d'attributs explicatifs 1.2 Créer un groupe élémentaire pour chaque valeur 1.3 Création d'un groupe spécial pour traiter toutes les catégories initiales qui ne remplissent pas la contrainte de fréquence minimale; si nécessaire, fusionner ce groupe spécial avec la catégorie reste moins fréquente 1.4 Calculer la valeur MaxDeltaChi2 liée au nombre initial de groupes et de valeurs de classe 2. Optimisation du groupement: répéter les étapes suivantes 2.1 Évaluer toutes les fusions possibles entre des paires de groupes 2.2 Rechercher la meilleure fusion 2.3 fusion et continuer aussi longtemps que l'une des conditions suivantes est pertinente - le niveau de confiance du groupement diminue après la fusion - la valeur DeltaChi2 de la meilleure fusion est inférieure à la valeur MaxDeltaChi2 Dans le cas de deux attributs indépendants , le regroupement devrait se traduire par un seul groupe terminal. Pour une p probabilité donnée, la modélisation statistique des algorithmes Khiops fournit une valeur théorique MaxDeltaChi2 (p) qui sera supérieure à toutes les valeurs DeltaChi2 des fusions réalisées au cours du processus de regroupement, avec une probabilité p. Le premier algorithme de regroupement Khiops est ensuite modifié afin de forcer toutes les fusions dont la valeur est inférieure à DeltaChi2 MaxDeltaChi2 (p). Cela garantit le comportement attendu de l'algorithme avec une probabilité p. Dans le cas de deux attributs à la relation de dépendance inconnue, cette amélioration des garanties de l'algorithme que lorsque l'attribut groupé est constitué d'au moins deux groupes, l'attribut explicatif détient réellement des informations concernant l'attribut de classe avec une probabilité supérieure à p. Nous vous conseillons de laisser p = 0,95, afin d'assurer des résultats fiables de regroupement. L'impact sur l'algorithme Khiops initial est limité à l'évaluation de la règle d'arrêt et conserve la complexité de calcul supra-linéaire de l'algorithme. Boullé RNTI - 1 4. Expériences Dataset continue Taille nominale Classe majorité Attributs Attributs Valeurs Précision adulte 7 8 48842 2 76,07 Australian 6 8 690 2 55,51 sein 10 0 699 2 65,52 Crx 6 9 690 2 55,51 Coeur 10 3 270 2 55,56 HorseColic 7 20 368 2 63,04 ionosphère 34 0 351 2 0 22 64,10 Champignon 8416 2 53,33 TicTacToe 0 9 958 2 65,34 véhicule 18 0 846 4 25,77 4 Waveform 0 0 5000 3 33,84 Vin 13 0 178 3 39,89 TAB 2 - datasets. Dans notre étude expérimentale, nous comparons la méthode Khiops regroupement avec d'autres algorithmes de regroupement supervisé sur deux critères: la performance prédictive et le nombre de groupes. Afin d'évaluer la performance intrinsèque des méthodes de regroupement et d'éliminer le biais du choix d'un algorithme d'induction spécifique, nous utilisons un protocole similaire méthode [Zighed et Rakotomalala, 2000], où chaque groupe est considéré comme une méthode inductive élémentaire prédit la distribution des valeurs de classe dans chaque groupe appris. Nous avons choisi de ne pas utiliser le critère de précision, car il se concentre uniquement sur la valeur de la classe majoritaire et ne peut différencier les prédictions correctes faites avec une probabilité 1 de prédictions correctes fait avec une probabilité légèrement supérieure à 0,5. En outre, de nombreuses applications, notamment dans le domaine de la commercialisation, se fondent sur la notation des instances et doivent évaluer la probabilité de chaque valeur de classe. Pour évaluer la qualité prédictive des groupes, nous utilisons la divergence Kullback-Leibler [Kullback, 1968] appliqué à comparer la distribution des valeurs de la classe estimée de l'ensemble d'apprentissage (basé sur les groupes ont appris) avec la distribution des valeurs de la classe observée sur l'ensemble de test (sur la base des valeurs initiales: le même pour toutes les méthodes testées). Pour une catégorie donnée, laissez pj la probabilité de la j-ième valeur de classe estimée sur l'ensemble d'apprentissage (avec l'utilisation du groupe contenant la catégorie), et QJ la probabilité de la valeur de la classe jeme observée sur l'ensemble de test (à l'aide seule la catégorie). La divergence de Kullback-Leibler entre la distribution estimée et la distribution observée est: () Σ = = J j j j j q p pqpD 1 log || . (3) L'évaluation globale de la qualité prédictive est calculée comme la moyenne de la divergence Kullback- Leibler sur l'ensemble de test. Afin de lisser les distributions empiriques et de traiter des probabilités zéro, nous utilisons l'estimateur de Laplace. Pour d'autres approches pour la définition des mesures de qualité d'ajustement, voir par exemple [Ritschard et Zighed, 2003]. Une méthode robuste pour partitionner les valeurs des attributs catégorielles RNTI - 1 Le problème de regroupement est un problème bi-critères qui tente de compromis entre la qualité prédictive et le nombre de groupes. Le classificateur optimal est le classificateur Bayes: dans le cas d'un classificateur univariée basé sur un seul attribut catégorique, le regroupement optimal est de ne rien faire. Dans les expériences, nous recueillons à la fois les résultats de la qualité prédictive en utilisant la divergence Kullback-Leibler et le nombre de groupes. Nous avons recueilli 12 ensembles de données de U.C. dépôt Irvine [Blake et Merz, 1998], chaque ensemble de données a au moins quelques dixièmes de cas pour chaque valeur de classe et des attributs catégoriques avec plus de deux valeurs. Afin d'augmenter le nombre de candidats attributs catégoriques pour le regroupement, les attributs continus ont été discrétisés dans un pré-traitement avec un 10 discrétisation sans supervision égale largeur. Le tableau 2 décrit les ensembles de données; la dernière colonne correspond à la précision de la classe majoritaire. Les méthodes de regroupement étudiés dans la comparaison sont les suivants: - Khiops: la méthode décrite dans le présent document, - Initial Khiops: la version initiale de la méthode, décrite à l'article 2, - CHAID: la méthode de regroupement utilisé dans la méthode CHAID [Kass, 1980 ], - Tschuprow: la méthode de regroupement décrit par exemple dans [Ritschard et al, 2001], - Ratio Gain:. la méthode de regroupement utilisé dans la méthode C4.5 [Quinlan, 1993]. Toutes ces méthodes sont basées sur un algorithme de bas en haut avide qui se raccorde de manière itérative les catégories en groupes, et détermine automatiquement le nombre de groupes dans la partition finale des catégories. La méthode du rapport de gain est la seule méthode basée sur l'entropie; les autres méthodes utilisent la base chi critères carrés. La première méthode Khiops applique le critère chi-carré sur toute la table de contingence et évalue la partition avec le niveau de confiance lié. La méthode Khiops robuste améliore l'algorithme Khiops initial en fournissant des garanties contre surapprentissage. La méthode Tschuprow est également basée sur une évaluation globale de la table de contingence, mais il utilise T la normalisation de la valeur du carré chi- Tschuprow au lieu du niveau de confiance pour évaluer les partitions. La méthode de CHAID applique le critère de chi-carré localement à deux rangées de la table de contingence. Pour la méthode CHAID, le niveau de signification est fixé à 0,95 pour le seuil de chi-carré, et la correction Bonferroni est pas appliquée. Nous avons réimplémenté ces groupement approches alternatives afin d'éliminer tout écart résultant de différentes divisions de validation croisée. Les groupements sont effectuées sur les 230 attributs des ensembles de données, en utilisant un stratifié dix fois la validation croisée. Afin de déterminer si les performances sont significativement différentes entre la méthode Khiops et les méthodes alternatives, les statistiques t de la différence des résultats est calculée. Sous l'hypothèse nulle, cette valeur a une loi de Student avec 9 degrés de liberté. Le niveau de confiance est fixé à 5% et un test bilatéral est réalisé pour rejeter l'hypothèse nulle. 4.1 Qualité des Groupements Les tables ensemble de résultats sont trop grandes pour être imprimées dans le présent document. Les résultats de la qualité prédictive sont résumés dans le tableau 3, des rapports pour chaque ensemble de données de la moyenne des divergences Kullback- Leibler et le nombre de victoires Khiops significatives (+) et les pertes (-) pour chaque comparaison de la méthode. Les résultats ont été normalisés en utilisant la divergence Kullback-Leibler évalué lorsque aucun regroupement est fait. Les moyens sont des moyens géométriques afin de se concentrer sur les rapports des performances entre les méthodes testées. Boullé RNTI - 1 Les résultats montrent des différences significatives entre les méthodes qui permettent de classer les méthodes testées. Dans un premier groupe de la méthode, la méthode de regroupement Khiops obtient les meilleurs résultats, suivi par la méthode initiale Khiops groupement et puis par la méthode CHAID. La méthode Khiops obtient significativement meilleurs résultats que la méthode CHAID pour 24% des attributs groupés, et nettement moins bons résultats pour 7% des attributs. Dans un deuxième groupe de méthodes, les méthodes Ratio Tchuprow et le gain sont clairement surperformé par les trois principales méthodes. Par exemple, la méthode Khiops dépasse la méthode du ratio de gain pour 35% des attributs, et est battu pour seulement 3,5% des attributs. Dataset Khiops Ini. Khiops CHAID Tschuprow Gain Ratio + - + - + - + - Adult 1,05 1,13 3 2 1,07 4 4 3,76 10 0 4,16 10 0 australien 1,04 1,06 0 0 1,10 2 0 1,10 1 0 1,24 3 0 sein 1,24 1,24 1 0 1,36 4 0 1,45 2 0 1,66 5 0 Crx 1,06 1,07 0 1 1,08 0 1 1,10 1 0 1,23 3 0 Coeur 0,98 1,02 1 0 1,02 0 0 1,03 2 0 1,07 3 0 HorseColic 1,02 1,01 1 4 1,07 3 2 1,08 3 0 1,04 3 2 ionosphère 1,07 1,03 1 3 1,13 7 1 1,06 2 2 1,08 3 4 champignons 1,10 1,24 4 2 1,21 6 2 2,29 11 1 2,60 11 1 TicTacToe 0,97 0,97 0 0 0,91 0 1 0,95 0 0 0,95 0 0 véhicule 1,10 1,10 5 1 1,11 4 4 1,12 2 2 1,30 9 0 Waveform 0,92 0,99 13 0 1,01 19 0 1,48 30 0 1,47 30 0 vin 1,23 1,20 0 1 1,37 6 1 1,24 1 1 1,23 0 1 Synthèse 1,04 1,07 29 14 1,10 55 16 1,35 65 6 1,42 80 8 TAB 3 - Moyens de la qualité prédictive des groupes, le nombre de victoires significatives (+) et des pertes (-) par jeu de données pour la méthode Khiops par rapport aux méthodes alternatives. En résumé, le critère de la qualité prédictive suggère le classement suivant des méthodes éprouvées: Khiops, initiale Khiops, CHAID, Tschuprow, Ratio Gain. 4.2 Taille du groupement Les résultats du numéro de groupe sont résumées dans le tableau 4. Les différences sont très importantes entre les méthodes testées. Les méthodes Ratio Tschuprow et le gain produisent les plus petits groupes de taille moyenne, au détriment d'une faible qualité prédictive. Parmi les méthodes de regroupement de haute qualité, la méthode Khiops est un gagnant pour le numéro du groupe criteri sur, suivie de la méthode Khiops initiale et la méthode CHAID. Les groupes produits par la méthode Khiops sont toujours plus petit que ceux produits par la méthode CHAID, et les différences sont importantes pour 60% des attributs. Bien que les méthodes de Ratio Tschuprow et le gain obtiennent des groupes plus petits en moyenne, les résultats sont contrastés entre les ensembles de données. Pour près d'un quart des attributs, la méthode Khiops obtient des groupements nettement plus petite que la méthode du ratio de gain. Il est intéressant d'analyser plus en profondeur les résultats de l'ensemble de données de forme d'onde, où environ la moitié des attributs sont des attributs du bruit. Une inspection des groupements révèle que l'une méthode robuste pour diviser les valeurs de Categorical Attributs RNTI - Méthode 1 Khiops robustes de regroupement est la seule méthode qui identifie correctement les attributs de bruit avec des groupements réduits à un seul groupe. Dataset Khiops Ini. Khiops CHAID Tschuprow Gain Ratio + - + - + - + - Adult 3,67 3,99 5 0 4,83 11 0 2,05 2 10 2,33 2 10 australien 1,91 2,19 6 1 2,19 4 0 2,19 3 1 2,36 7 1 Sein 2,60 2,83 3 0 4,16 9 0 1,98 1 7 1,98 1 7 Crx 1,93 2,16 5 1 2,18 3 0 2,15 3 1 2,42 8 2 Coeur 1,91 2,27 5 0 2,14 4 0 2,11 3 1 2,08 3 1 HorseColic 1,87 2,20 11 0 2,24 10 0 2,03 7 4 2,03 8 4 ionosphère 2,47 2,94 17 1 3,18 25 0 2,09 0 15 2,05 0 17 Champignon 3,06 3,11 3 3 3,57 10 0 2,00 0 13 2,19 1 13 TicTacToe 2,03 2,03 0 0 2,11 1 0 2,00 0 0 2,00 0 0 véhicule 3,50 3,90 7 0 4,84 17 0 2,58 0 11 2,85 3 11 Waveform 2,67 3,56 30 0 3,76 35 0 2,73 21 19 3,18 21 18 vin 2,60 2,95 5 0 3,56 11 0 2,10 0 6 2,05 1 7 Synthèse 2,54 2,95 97 6 3,28 140 0 2,22 40 88 2,38 55 91 TAB 4 - Moyens de la taille des groupes, le nombre de victoires significatives (+) et des pertes (-) par jeu de données pour la méthode Khiops par rapport aux méthodes alternatives. En résumé, le critère numéro du groupe suggère le classement suivant des méthodes éprouvées: Tschuprow, Ratio Gain, Khiops, initiale Khiops, CHAID. 4.3 Bi-critères d'analyse des résultats afin de mieux comprendre les relations entre la qualité prédictive et la taille des groupes, nous tirons à la figure 1, les moyens globaux des résultats sur un plan de deux critères avec le numéro de groupe sur la coordonnée x et la qualité prédictive sur la coordonnée y. A titre de comparaison, nous présentons également les résultats obtenus par trois méthodes de groupage alternative simple: - Mode: bipartition sans supervision des catégories avec un groupe contenant le mode, soit la catégorie la plus fréquente, - Chi Valeur unique: bipartition des catégories avec une catégorie contre tous les autres, sélectionnés à l'aide du critère de chi-carré (une fusion finale est toujours possible), - exhaustive CHAID: bipartition des catégories obtenues avec l'algorithme CHAID en forçant les fusions jusqu'à ce que la partition contient au plus deux groupes. Les trois méthodes de regroupement de bipartition sont classés comme prévu pour le critère de la qualité prédictive. Les Tschuprow et le gain de méthodes Ratio qui sont autorisés à construire une partition avec plus de deux groupes n'obtiennent pas de meilleurs résultats sur la qualité prédictive que la méthode Exhaustive CHAID. Le groupe des méthodes efficaces (Khiops, initiale Khiops et CHAID) prend clairement avantage des partitions à plusieurs groupes. Parmi ces méthodes principales, la méthode Khiops domine les autres méthodes sur les deux critères. Enfin, compte tenu de la complexité de calcul des algorithmes, celle de l'algorithme optimisé Khiops est O (n.log (N) + Boullé RNTI - 1 I2.log (I)), tandis que d'autres méthodes est O (n.log (N) + I3). Cependant, la différence de temps d'exécution est mineur dans de nombreux cas, lorsque le nombre de valeurs catégoriques I est très faible. 1,10 1,20 1,30 1,00 1,40 1,50 1,60 1,70 1,80 1,90 2,00 1,0 1,5 2,0 2,5 3,0 3,5 4,0 Groupe Nombre K u llb ac k- L ei b le r D iv er g en CE Khiops initiale Khiops CHAID Chi Valeur unique mode Exhaustive CHAID Tschuprow Ratio Gain FIGUE. 1 - évaluation Bi-critères du groupement m éthodes pour le numéro de groupe et les critères de qualité prédictive 5. Conclusion Le principe de la méthode Khiops de regroupement est de minimiser le niveau de confiance lié à l'épreuve de l'indépendance entre l'attribut groupé et l'attribut de classe. Au cours du processus bottom-up de l'algorithme, de nombreuses fusions entre les catégories sont effectuées que les variations produisent de la valeur chi-carré de la table de contingence. En raison d'une modélisation statistique de ces variations lorsque l'attribut explicatif est indépendant de l'attribut de classe, nous avons amélioré l'algorithme de regroupement initial Khiops afin de garantir que les groupes d'attributs indépendants sont réduits à un seul groupe. Cette résistance attestés à surapprentissage est une alternative intéressante à l'approche de validation croisée classique. De nombreuses expériences comparatives montrent que la méthode Khiops surclasse les autres méthodes de regroupement testées. Il permet de réduire considérablement le nombre de valeurs d'attributs catégoriques dans l'étape de pré-traitement exploration de données, tout en gardant la plupart de leur performance prédictive monothétique. [Berckman Références, 1995]. Berckman N. C Valeur de regroupement pour les arbres de décision binaires. Rapport technique. Département Informatique - Université du Massachusetts, 1995. [Blake et Merz, 1998] C.L. Blake et Merz C.J.. UCI référentiel de bases de données d'apprentissage machine URL Web http://www.ics.uci.edu/~mlearn/MLRepository.html, Irvine, CA: Université de Californie, Département de l'information et de l'informatique, 1998. [Boullé, 2003a] M . Boullé. Khiops: une discrétisation Méthode des attributs continus avec une résistance garantie au bruit. Actes de la troisième Conférence internationale sur l'apprentissage et fouille de données dans la reconnaissance des formes, 50-64, 2003. Une méthode robuste pour les valeurs de Partitionnement catégorielles Attributs RNTI - 1 [Boullé, 2003b] M. Boullé. Groupage des facts d'Robuste un par la symbolique attribut Khiops méthode. Note technique NT / FTR & D / 8028, France Télécom R & D, 2003. [Breiman et al., 1984] L. Breiman, J. H. Friedman R.A. Olshen et Pierre C.J.. Et régression des arbres. Californie: [. Cestnik et al, 1987] Wadsworth International, 1984. B. Cestnik, I. Kononenko et I. Bratko. ASSISTANT 86: Un outil pour la connaissance explicitation utilisateurs sophistiqués. Dans Bratko & Lavrac, Les progrès dans l'apprentissage machine, Wilmslow, Royaume-Uni (Eds.): Sigma Press, 1987. [Chou, 1991] P.A. Chou. Optimal Partitionnement pour la classification et la régression des arbres. IEEE Transactions sur le modèle d'analyse et de l'intelligence artificielle, 13 (4): 340-354, 1991. [. Fulton et al, 1995] T. Fulton, S. Kasif et S. Salzberg. Des algorithmes efficaces pour trouver des fractionnements façon multi pour les arbres de décision. Actes de la Conférence mixte internationale Treizième sur l'intelligence artificielle, San Francisco, CA: Morgan Kaufmann, 244-255, 1995. [Kass, 1980] G.V. Kass. Une technique d'exploration pour étudier de grandes quantités de données catégoriques. Statistique appliquée, 29 (2): 119-127, 1980. [Kerber, 1991] R. Kerber. ChiMerge discrétisation des attributs numériques. Actes de la 10e Conférence internationale sur l'intelligence artificielle, 123-128, 1991. [Kullback, 1968] S. Kullback. Théorie de l'information et de la statistique. New York: Wiley, (1959); réédité par Dover, 1968. [Lechevallier, 1990] Y. Lechevallier. Recherche d'une partition sous Une contrainte d'optimale totale ordre. Rapport technique N ° 1247, INRIA, 1990. [Pyle, 1999] D. Pyle. Préparation des données pour l'exploration de données, Morgan Kaufmann, 1999. [Quinlan, 1986] J.R Quinlan. Induction d'arbres de décision. Machine Learning, 1: 81-106, 1986. [Quinlan, 1993] J.R Quinlan. C4.5: Programmes d'apprentissage machine. Morgan Kaufmann, 1993. [Ritschard et al., 2001] G. Ritschard D.A. Zighed et N. Nicoloyannis. Maximisation de l'association par Regroupement de lignes Ou de tableau d'un Colonnes Croisé. Math. & Sci. Hum, n ° 154-155:. 81-98, 2001. [Ritschard et Zighed, 2003] G. Ritschard et D.A. Zighed. Modelisa tion de tables de Contingence par induction d'arbre. Extraction et Gestion des Connaissances, 381-392, 2003. [Zighed et Rakotomalala, 2000] D.A. Zighed et R. Rakotomalala. Graphes d'induction. Hermes Science Publications, 327-359, 2000. Résumé Dans l'apprentissage machine supervisé, le partage des valeurs (également appelées regroupement) d'un objectif d'attributs catégoriques à la construction d'un nouvel attribut synthétique qui conserve les informations de l'attribut initial et réduit le nombre de ses valeurs. Dans cet article, nous proposons une nouvelle méthode de regroupement Khiops, basé sur une généralisation de l'algorithme de discrétisation Khiops. Cette méthode de regroupement fournit des garanties contre surapprentissage et conduit ainsi à des groupes robustes. Cette propriété découle d'une modélisation statistique de la méthode Khiops qui permet d'affiner l'algorithme. De nombreuses expériences démontrent la validité de cette approche et montrent que la méthode de regroupement Khiops construit des groupes de grande qualité, tant en termes de qualité prédictive et petit nombre de groupes.