transformation espace description apprentissage transfert nistor grozavu younès bennani lazhar labiod université paris clément 93430 villetaneuse france email firstname secondname paris13 lipade paris descartes university saints pères 75006 paris france email lazhar labiod parisdescartes résumé papier proposons étude utilisation appren tissage topologique pondéré méthodes factorisation matricielle transformer espace représentation données sparse menter qualité apprentissage adapter apprentissage transfert factorisation matricielle permet trouver variables latentes apprentissage topologique pondéré utilisé détecter pertinentes parmi celles représentation nouvelles données basée leurs projections modèle topologique pondéré apprentissage transfert proposons nouvelle méthode représentation données faite manière première phase utilisant modèle topologique élagué expérimentations présentées cadre challenge international avons obtenu résultats prometteurs 5ieme compétition internationale introduction exploration données domaine pleine évolution interdisciplinaire beaucoup intérêt nombreux domaines scientifiques objectif exploration données extraire connaissances partir ensembles données volumineux binant méthodes statistique intelligence artificielle méthodes gestion bases données taille données mesurée selon dimensions nombre variables nombre observations dimensions peuvent prendre valeurs élevées poser problème exploration analyse données fondamental mettre place outils traitement données permettant meilleure compréhension données cette étude intéressons réduction dimension espace descrip cadre apprentissage supervisé travers factorisation matricielle transformation espace description transformation espace faciliter processus apprentissage transfert factorisation approximative factorisation tensorielle décomposition matrice jouent fondamental amélioration données extraction composantes latentes point commun suppression bruit réduction modèle recons truction faisabilité séparation aveugle sources blind source separation remplacer données origines représentation approximative reduite dimensions obtenues matrice factorisation éventuellement décomposition matri cielle décomposition valeurs singulières traite lignes colonnes manière symétrique fournit informations matrice données cette thode permet aussi trier information contenue matrice telle sorte façon générale partie pértinente devienne visible propriété utile mining nombreux autres domaines méthode bidiagonalisation golub kahan initialement formulée golub kahan calcul cette méthode aussi utilisée calculer bidiagonalisation partielle notre méthode utilisons cette technique données sparse analyse composants principales autres données reste article organisé comme section présente brièvement principe factorisation matricielle utilisation cette technique clustering ainsi principes apprentissage transfert methodes proposées apprentissage supervisé apprentisage topologique transfert presentées section respectivement section présentons résultats validation interprétation conclusion perspectives données section transformation espace description transformation supervisée apprentissage supervisé souvent utilisé clustering données comme procedé prétraitement données toutefois existe certain nombre méthodes produisent nouvelles représentations données partir données étiquetés méthodes supervisées parfois utilisées comme outil prétraite modèles apprentissage supervisé étant donné matrice données présentée comme vecteurs variables observations lignes caractéristiques colonnes transformation supervisée espace description produire autre matrice données dimension représentation transformée velles variables latentes matrice similarité entre données dimension application méthode supervisée matrice transformée fournir meilleurs résultats rapport données initiale transformation espace description suivant étapes successives premier temps décomposons matrice sparse données selon méthode ensuite matrice variables latentes obtenue après cette décomposition utilisée apprentissage modèle topologique grozavu permet détecter pondérer caractéristiques pertinentes codage finale chaque donnée distances chaque donnée chaque prototype modèle cette dernière matrice distances représente nouvelle description données évaluer qualité nouveau codage données grozavu nouvelle représentation présentée suite classificateur analyse discri minante linéaire données apprentissage évaluation finale voici méthode proposée transformation espace description normalisation réduction dimension factorisation matricielle chaque colonne quantification matricielle nombre vecteurs propres retenus appliquer étape matrices calcul matrices distances transformation supervisée modèles prédictifs capables classer nouvelles instances prédire correctement étiquettes nécessitent généralement apprentissage utilisant grandes quantités données labellisées malheureusement données étiquetées apprentissage peuvent disponibles annotation manuelle données certains pratiques souhai table produire représentations données peuvent réutilisables domaine autre cette étude voulons examiner comment représentation dévelop ensemble étiquettes utilisée apprendre manière facile nouvelle tâche similaire proche exemple domaine reconnaissance écriture chiffres manuscrits étiquités seront disponibles apprentissage tâche évaluation serait alors reconnaissance lettres manuscrites alphabétiques apprentissage apprentissage transfert apprentissage transfert proposons nouvelle méthode transformation espace description représentation données faite manière première méthode supervisée utilisant carte élaguée élagage effectué après étiquetage matrice prototypes utilisant étiquettes disponibles élagage consiste éliminer prototypes étiquetés presentent données étiquetés obtient décomposition matrice initiale ayant comme resultat matrice prototypes étiquetés effet cette nouvelle matrice represente données autres classes disponibles transfert prototypes seront utilisés comme dictionnaire codage données validation évaluation finale effet ensembles données validation évaluation finale projetés prototypes étiquetés calculant distance euclidienne entre observations prototypes carte cette dernière matrice distances représentera nouvel espace description figure transformation espace description transformation epace description apprentissage transfert validation approches proposées protocole expérimental méthodes transformation espace données proposons travail testées cadre challenge international apprentissage supervisé transfert unsupervised transfer learning challenge guyon challenge constitué phases apprentissage supervisé transformation espace données apprentissage transfert détails concer challenge peuvent trouvés officiel challenge causality unsupervised learning première phase challenge aucune étiquette fournie participants ticipants invités produire représentations données seront évaluées organisateurs tâches apprentissage supervisé étiquettes tâches apprentissage supervisé utilisé évaluation resteront inconnues participants phase autres labels seront disponibles apprentissage transfert phase deuxième phase challenge apprentissage transfert certaines étiquettes fournies participants mêmes ensembles données utilisés première phase normalement permetre améliorer représentations données obtenues prémière phase bases données mises disposition participants challenge tableau résume description ensembles données utilisées valider approches performances prédiction évaluées fonction courbe apprentissage ensemble versus nombre exemples utilisés reéaliser apprentissage under curve fawcett calculeée toutes observations donneées salperwyck lemaire données avicenna obtenons petit score normal problème assez difficile apprentissage super données harry avons construit matrice prototypes taille 30x30 cellules avant transformer données initial utilisant factorisation matricielle vecteurs propres avons utilisé grozavu bases données dataset domain spars transf avicenna handwriting 150205 50000 harry video 69652 20000 images 111808 24000 sylvester ecology 572820 100000 terry 47236 217034 40000 avons construit matrice prototypes taille 30x30 cellules résultats obtenus permis positionner deuxième données challenge après réduction dimension données sylvester utilisant avons construit matrice prototypes taille 40x40 cellules avons obtenu score évaluation finale finallement données terry 47236 variables avons utilisé méthode matrice prototypes taille carte 33x33 après transformation matricielle initiale utilisant résultats experimentaux apprentissage supervisé données supervisé transfert avicenna 701728 182106 623894 105119 harry 961722 709893 961722 709893 786303 489439 759892 363303 sylvester 825077 44926 624744 126217 terry 994574 808953 888154 566029 résultats challenge peuvent consultés oficiel challenge notre équipe causality unsupervised learning results analysant résultats challenge pouvons conclure approche avons proposée offre performances dépassent largement autres méthodes comme celles basées forêts aléatoires factorisation negative analyse factorielle réduction dimensionalité contre première phase challenge gagnant équipe guyon utilisé algorithme apprentissage noyaux utilisant validation progressivement amélioré noyau transformation espace description conclusion travail avons proposé méthodes transformation espace cription données méthode basée combinaison technique décompo sition matricielle classification topologique pondérée extension utilise processus supervisé élagage modèle topologique avons adapté thodes challenge unsupervised transfer learning transformer espace caractéristiques différents données approches démontré grande efficacité problèmes grandes dimensions différent types données deuxième phase challenge méthodologie apprentissage transfert nouvelles connaissances proposée utilisant technique élagage matrice prototypes obtenue résultats obtenus prometteurs ouvrent nouvelles perspectives références fawcett graphs notes practical considerations researchers machine learning golub kahan calculating singular values pseudo inverse matrix numer grozavu bennani lebbah variable weighting cluster characte rization topographic unsupervised learning ijcnn09 international joint conference neural network guyon lemaire taylor unsupervised transfer learning challenge international joint conference neural networks salperwyck lemaire impact taille ensemble apprentissage étude empirique conférence internationale francophone extraction gestion connaissance summary paper propose study toplogical weighting learning transform representation space dataset order increase quality learning adapting transfer learning transformation feature space weighted topological models space representation representation based their projections topological weighted model example dataset described representation consisting distances example components topological model prototype transfer learning propose method where representation first phase using pruned topological model experiments presented international challenge where obtained results place