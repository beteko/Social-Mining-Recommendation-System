multi catégorisation textes juridiques retour pertinence vincent pisetta hakim hacid djamel zighed laboratoire pierre mendès france 69767 france vpisetta lyon2 hhacid lyon2 zighed lyon2 résumé fouille données textuelles constitue champ majeur traitement automatique données large variété conférences comme consacrées cette étude intéressons fouille textes juridiques objectif classement automatique textes utilisons outils analyses linguistiques extraction terminologie repérer concepts présents corpus concepts permettent construire espace représentation faible dimensionnalité permet utiliser algorithmes apprentissage basés mesures similarité entre individus comme graphes voisinage comparons résultats issus graphe utilisés réduction dimensionnalité introduction cadre général apprentissage automatique fichier apprentissage comportant lignes colonnes lignes représentent individus colonnes attributs quantitatifs qualitatifs observés chaque individu ligne contexte suppose également échantillon apprentissage relativement conséquent rapport nombre attributs généralement taille échantillon ordre nombre variables espérer obtenir certaine stabilité erreur généralisation erreur apprentissage attribut prédire supposé valeur unique variable valeurs réelles régression variable modalités discrètes appelées classes appartenance classement questions relatives rapports entre taille échantillon taille espace variables étudiées façon approfondies publications relatives apprentissage statistique vapnik papier décrivons situation apprentissage écarte significativement cadre classique décrit effet contexte expérimental permet disposer immédiatement ensemble apprentissage conséquent chaque individu appartenir plusieurs classes simultanément chaque individu décrit ensemble attributs valeurs texte langage naturel anglais multi catégorisation textes juridiques retour pertinence avant décrire approche préconisons apprendre contexte allons abord rappeler problématique application visée section section trois décrivons approche méthodologique retenue section quatre décrivons étapes mises œuvre mettre forme données notamment stratégie analyse linguistique œuvre extraire principaux concepts jouer variables décrivons ensuite section modèles topologiques graphes proximité permettent gérer multi classes comparatif utilisons méthode arbre décision également mieux identifier concepts discriminants section présentons résultats issus analyse linguistique apprentissage décrivons également principe apprentissage boucle pertinence relevance feedback concept central usager boucle visant améliorer modèle prédiction détaillons performances obtenues section concluons détaillons perspectives travail notamment utilisation méthodes règles association cadre expérimental problématique travail inscrit projet collaboration bureau international travail plusieurs signé conventions lient droit travail international concrètement accord porte conventions élaborées convention convention celles contiennent série articles signataire engage respecter derniers soumis inspection ayant vérifier bonne application conventions chaque inspection experts délivrent rapport concerné rapport règles appliquées violations constatées partir faits concrets souligne efforts mettre place adéquation conventions texte libre codification rigide violations rapports experts stockés banque données accessible membres experts effectuent régulièrement analyses définissent nouvelles recommandations étudient évolutions droit travail différents objectif notre travail définir mettre place méthodes outils mining permettant traiter efficacement rapidement corpus deviennent inexploitables manuellement experts souhaiteraient avoir outils permettant repérage automatique textes signalant violation plusieurs règles finalité étant catégorisation automatique textes étiquetés experts pourront alors synthétiser difficultés rencontrent différents application conventions échéant identifier moyens aider contenu conventions ainsi liste signataires accessible ilolex convde ilolex convde pisetta description corpus données comprend textes chaque texte correspond commentaire annuel adressé experts concerné chaque texte décrit règles relatives chaque convention violées modalités cette violation textes rédigés anglais juristes mandatés banque données constituée comporte textes signalant violations relatives convention convention textes classés convention ainsi étudier évolution temps textes relatifs chaque convention trajectoires constituent points important travail experts notons clore corpus texte relater violation plusieurs règles précisons également identification règles violées effectue posteriori interprétation observations commentaires enquêteurs travail étiquetage effectue heure actuelle experts juriste raisons délais interprétation associé facilitent exploitation enquêtes menées existe violations convention convention méthodologie principes généraux mettre point outil identification violations corpus avons procédé techniques apprentissage automatique choix porté méthodes apprentissage supervisé produisent modèles prédiction évalués jugés acceptables utilisateur peuvent alors utilisés comme moyen automatique catégorisation nouveaux textes aboutir modèle prédiction principe consiste fournir algorithme apprentissage exemples textes classés appellerons ensemble apprentissage notre problème classes multiples autrement chaque texte échantillon apprentissage appartenir plusieurs classes chacune identifiée règle convention serait violée formellement texte corpus global règles convention susceptibles violées alors exprime texte comporte violations relatives règles convention notons contexte difficile extrêmement coûteux effectuer cette catégorisation manuellement seule traite avons suggéré experts annoter soixantaine textes convention convention convention serviront apprentissage initiale appelons premier corpus amorçage algorithme apprentissage supervisé graphe induction zighed rakotomalala vapnik résultat apprentissage modèle erreur généralisation estimé échantillon cross validation multi catégorisation textes juridiques retour pertinence application modèle échantillon textes anonyme taille relativement modeste disons vingtaine permet prédire chaque individu anonyme règles seraient violées exemple contrôle pertinence permet utilisateur évaluer chaque étiquetage individus anonymes usager alors valider totalement partiellement étiquetage proposé modèle texte prédiction jugée erronée alors texte concerné extrait remis échantillon apprentissage cette opération étant renouvelée chaque individu étiqueté réitérons processus apprentissage nouvel échantillon ainsi construit obtenons nouveau modèle espère erreur faible nouvel échantillon anonyme taille modeste faciliter vérification manuelle constitué réitération processus recyclage individus étiquetés classifieur nouvel apprentissage après rectification manuelle étiquettes devrait conduire amélioration itérative modèle question choix algorithme capable gérer étiquetage multiple graphes proximité toussaint partie méthodes apprentissage instance permettent toutes techniques supposent ailleurs individus plongés espace représentation lequel définir métrique textes doivent conséquent transformés ensemble vecteur chaque texte pourra alors considéré comme point coordonnées texte espace seront représente alors variables comment elles extraites objet partie analyse linguistique objectif étant trouver concepts adaptés application données effectuons extraction terminologie intégralité corpus finalité cette extraction construction concepts relatifs conventions concepts ainsi extraits constituent espace représentation documents textes étiquetés experts violations connues servent ensuite apprentissage utilisons classifieurs quinlan graphes voisins relatifs toussaint prédire violations contenues textes étiquetés méthodologie décrite figure pisetta méthodologie analyse espace représentation textes extraction terminologie choisissons construire notre espace représentation extraction concepts avantages cette technique rapport méthodes telles grammes matrices occurrences réduction importante dimensionnalité permettant notamment usage classifieurs utilisant mesures similarité diverses applications basées principe données résultats intéressants kumps méthodes différentes existent construction concepts apprentissage extraction première statistique recherche discriminants selon attribut prédire ensuite regroupés concepts occurrences partir règles association kumps seconde méthode linguistique consiste extraire terminologie corpus regrouper termes extraits selon proximité sémantique notre préférence porte techniques analyse linguistique choix justifie analyse linguistique permet lutter contre polysémie lever certaines ambiguïtés liées contexte flurh fonctionne également petites unités textuelles pouliquen notre apprentissage comportant exemples semble difficile utiliser techniques apprentissage décrites notre travail effectué collaboration experts domaine juridique raison supplémentaire utiliser techniques linguistiques utilisons chaîne traitement décrite figure multi catégorisation textes juridiques retour pertinence chaîne traitement linguistique après phase normalisation traitement propres conservation majuscules effectuons étiquetage grammatical corpus grâce logiciel brill brill cette opération attribuer chaque étiquette grammaticale passons ensuite extraction terminologie roche méthodologie place avant basée approche statistique contrairement autres approches bourigault jacquemin extraction terminologique passe recherche candidats termes derniers ensembles unités adjacentes lexicales syntaxiques étiquetés grammaticalement notre sémantiques étiquetés conceptuellement groupons ensuite candidats termes extraits selon proximité sémantique manière repérer concepts présents textes choix candidats termes création concepts reprenons méthodologie utilisée baneyx distinguons étapes sélection candidats termes premier temps parcourons ensemble résultats donnés étudions abord termes fréquence apparition supérieur seuil premier temps fixons seuil élevé cette étape préliminaire permet repérer grands conceptuels regroupons ensuite candidats termes sémantiquement proches outils wordnet miller recours expert primordial certaines plates formes proposent outils sophistiqués comme syntex upery bourigault jacquemin permettent analyser proximité distributionnelle entre candidats termes phases construction étant itératives augmentons rapidement représentation examinant candidats termes fréquence apparition corpus inférieure seuil augmentation progressive nombre candidats termes possède issues pisetta certains nouveaux candidats termes viennent renforcer concepts existants autres nouveaux candidats termes créent nouveaux concepts peuvent concepts existants représentation vectorielle documents niveau problème choix modèle représentation avons choisi modèle vectoriel salton paraît adapté modèle booléen raison semble simpliste appliquer logique binaire recherche information modèle vectoriel permet calculer scores similarités entre différents documents pouliquen modèle vectoriel propose représenter document dimensions représentées avons adapté représenter document vecteur concepts plutôt représenter fonction fréquence concept document utilisons pondération salton buckley score permet donner importance concept fonction fréquence document frequency pondérée fréquence apparition concept corpus inverse document frequency ainsi concept spécifique document score correspondant fréquence apparition contre concept apparaissant documents corpus pondération maximale calculons chaque concept document score concept document fréquence absolue apparition concept document nombre documents apprentissage contenant concept nombre documents apprentissage cette opération disposons apprentissage disposons forme tabulaire modélisation outils généralisation avons présent défini espace représentation documents objectif maintenant utiliser techniques apprentissage classer automatiquement documents notre étude sommes amenés classer textes multi étiquettes autrement susceptibles comporter plusieurs violations possibilités alors envisageables approche globale approche binaire division problèmes multi catégorisation textes juridiques retour pertinence effectuons approches classifieurs différents utilisés utilisons arbres décision approche binaire graphes voisinage approche globale prédiction graphe voisins relatifs représentation vectorielle documents dimensionnalité raisonnable permet conséquent avoir recourt classifieurs basés notion voisinage avons choisi graphes proximité provenant géométrie computationnelle preparata shamos plutôt graphes présentent plusieurs avantages rapport permettent mieux définir proximité entre individus clech nécessitent mesure dissimilarité toussaint choisissons distance euclidienne plusieurs modèles graphes existent notre choix porte graphe voisins relatifs compromis entre nombre voisins complexité algorithmique graphe voisins relatifs points voisins vérifient propriété suivante hypersphère rayon centrée hypersphère rayon centrée mesures dissimilarité entre points voisins seulement lunule formée intersection hypersphères toussaint façon formelle appliquons fonction décision simple texte étiqueté hérite propriétés voisins contenus apprentissage nombre voisins texte étiqueter règle probabilité nouveau texte étiqueter contienne violation écrit nombre voisins contenant violation application texte anonyme permet prédire règles seraient violées exemple pisetta prédiction arbre décision plaçons optique prédire présence absence chaque violation construisons conséquent autant arbres existe règles formellement considérons chaque règle comme étant attribut booléen existe règles violation construisons arbres chaque arbre alors modèle prévoyant présence absence chaque règle obtenons ainsi modèles renvoient règle estimée violée sinon notons cette approche valable mesure violations priori indépendantes suffit ensuite agréger modèles obtenir modèle donnant liste violations détectées texte discrimination effectuée algorithme résultats méthodes comparatif issue analyse linguistique obtenons concepts convention concepts convention présentons résultats observés convention notre textes étiquetés taille modeste textes étape processus relevance feedback réalisée concerne textes étiquetés experts étaient présents initialement apprentissage présentons résultats prédiction textes issue comparatif avons utilisé selon principe méthodes robustes résistant forte dimensionnalité données joachim différence essentielle réside utilisées traitement textes excepté normalisation résultats présentés résultats obtenus présentons résultats obtenus terme reclassement résultats décrits tableau observe reclassement notons existe seule violation laquelle mieux prise compte séquences prédictions parfois instables traduit mauvaise sensibilité spécificité observons sensibilité spécificité parfois violations fréquemment rencontrées corpus apprentissage ainsi chances quelques textes contenant violations soient nombre suffisant compte voisinage individu étiqueter problème éventuellement résoudre technique retour pertinent décrite précédemment multi catégorisation textes juridiques retour pertinence classés sensibilité spécificité classés sensibilité spécificité classés sensibilité spécificité violation violation violation violation violation violation violation violation violation violation résultats trois méthodes classification conclusion perspectives finalité travail proposer modèle prédiction capable déterminer violations plusieurs concernant convention droit travail approche apprentissage automatique adoptée premier temps préparation données avons extrait grâce techniques analyses linguistiques ensemble candidats termes permettent ensuite construire concepts relatifs corpus étudié cette opération réduire dimensionnalité espace représentation textes corpus avons ainsi mesure utiliser graphes voisinage méthode classique catégorisation automatique résultats semblent intéressants mesure méthodes prédiction utilisons aboutissent reclassement acceptables dépit apprentissage comportant exemples envisageons présent augmenter taille celle améliorer prédiction aboutir résultats robustes phase experts cours liste concepts extraits corpus validée derniers perspectives travail observer impact relevance feedback qualité prédiction effet cette dernière devrait augmenter mesure nombre interventions experts serait intéressant comparer nouveau qualité prédiction notre approche lorsque apprentissage conséquente utilisation autres techniques catégorisation textuelles comme winnow dagan éventuellement autres classifieurs aussi avérer intéressantes pisetta références baneyx charlet jaulent construction ontologies médicales fondée extraction terminologique partir textes application domaine pneumo logie journées francophones informatique médicale brill transformation based error driven learning natural language essing study speech tagging computational linguistics bourigault jacquemin extraction clustering integrated platform computer aided terminology proceedings european chapter association computational linguistics bergen pages clech contribution méthodologique fouille données complexes thèse laboratoire université lumière dagan karov mistake driven learning categorization proceedings second conference empirical methods fluhr indexation recherche information textuelle ingénierie langues paris hermès gaines comparing conceptual structures consensus conflict correspondence contrast knowledge science institute university calgary hajek havranek chytil method prague academia joachim categorization support vector machines relevant features proceedings international conference machine learning slovenia kumps francq delchambre création espace conceptuel données contextuelles international conference statistical analysis textual miller fellbaum tengi wolff wakefield langone haskell wordnet cognitive science laboratory princeton university pouliquen delamarre indexation textes médicaux traction concepts utilisations preparata shamos computational geometry introduction springer quinlan programs machine learning mateo morgan kaufman roche heitz matte tailliez kodratoff système itératif extraction terminologie domaine partir corpus spécialisés proceed international conference statistical analysis textual volume multi catégorisation textes juridiques retour pertinence salton smart retrieval system experiment automatic document process jersey prentice englewood cliffs salton buckley weighting approaches automatic retrieval information processing management toussaint relative neighborhood graphs finite planar pattern ognition vapnik nature statistical learning theory springer zighed rakotomalala graphe induction mining paris hermès summary retrieval important field automatic information natural language essing large variety conferences dedicated paper interested retrieval especially automatic juridical texts classification facilitate their retrieval linguistic tools terminology extraction order deter concepts presents corpus those concepts create dimensionality space which enabling automatic learning algorithms based similarity measures proximity graphs compare results extracted graph which without reducing dimensionnality