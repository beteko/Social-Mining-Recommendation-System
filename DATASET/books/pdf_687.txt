articles assemblage pdfregrouper données textuelles nommer groupes classes recouvrantes marian andrei rizoiu julien velcin hugues chauchat laboratoire université lumière lyon2 mendès france 69676 cedex france marian andrei rizoiu lyon2 julien velcin lyon2 hugues chauchat lyon2 résumé organiser données textuelles tirer aujourd ainsi lorsque souhaite analyser débat ligne forum discussion voudrait pouvoir rapidement quels princi thèmes abordés manière discussion structure autour parce texte associé plusieurs thèmes proposons méthode originale regrouper données textuelles torisant chevauchements nommer chaque groupe manière lisible contribution principale article méthode globale permet réaliser toute chaîne partant données textuelles brutes jusqu caracté risation groupes niveau sémantique dépasse simple ensemble introduction extraction information partir données structurées particulier textuelles domaine recherche actif internet constitue véritable trouve actuellement information articles blogs chats forums débats cette profusion explique nombreux travaux cherchent extraire information utile ayant partir données présent travail étroite collaboration jeune entreprise organise analyse débats ligne supposons ayons ensemble textes traitent conséquences écono miques décision politique aimerions disposer outil capable extraire principaux thèmes associés réactions cette décision manière automatique minimum connaissance préalable textes outil regrouper textes proposer plusieurs chacune catégories thématiques pourraient alors politique gouvernement propositions opposition réactions syndicales efficacité économique justice sociale textes langage naturel étant naturellement associés plusieurs thématiques cleuziou avons choisi développer système capable besoin classer texte plusieurs catégories nommer catégories recouvrantes données textuelles proposons outil automatisé puisse traiter données textuelles adaptable plusieurs langues notre travail organisé étapes première évidence thématiques abordées corpus regroupe textes autour celles manière recouvrante deuxième étape caractérise chaque thématique proposant suites extraits directement textes groupes documents obtenus nommés information contenue chaque texte particulier synthétisée différentes catégories auxquelles appartient cette manière objectifs atteints dégager automatiquement liste thématiques abordés corpus affecter chaque document plusieurs thématiques permet appréhender rapidement corpus complexe regroupe nombreux textes contributions peuvent ainsi résumées méthode globale inclut algorithme clustering recouvrant couple méthode extraction motifs fréquents cette méthode fonctionne connaissances liste outils employée différentes langues nouvelles expérimentations complètent celles réalisées précédemment térature ainsi comparons plusieurs mesures pondération décrire textes évaluation basée experts toujours difficile évaluer jectivement qualité celle comporte subjectivité proposons évaluation basée système notes données experts section présente approches existantes littérature problème tering recouvrant extraction expressions fréquentes section expose notre solution suivie section série expérimentations menées langue française langue anglaise section conclut propose perspectives recherche geraci observent problème extraction thématiques divisé problèmes regroupement documents similaires traction expressions partir corpus autre lumière cette remarque notre recherche bibliographique divise naturellement parties regrouper documents domaine regroupement données textuelles clustering beaucoup traité littérature résultats significatifs obtenus particulièrement tâche extraction thématiques topic extraction beaucoup outils existants agape ganascia armil geraci offrent possibilité construire partition textes crisp clustering signifie chaque document appartenir seule catégorie considérant textes langage naturel évoquent ralement plusieurs thématiques avons centré notre travail techniques clustering recouvrant recouvrant entendons cette section techniques construisent recouvrement mathématique document appartient exactement plusieurs thématiques également celles construisent pondération appartenance catégories document appartient moins différentes thématiques rizoiu singular value decomposition décomposition valeurs singulières utili lingo osinski obtenir catégories chevauchent principale algorithme consiste décomposer matrice termes documents chaque étant représenté vecteur produit trois matrices peuvent considérés comme centres clusters latent dirichlet allocation proposé modèle probabi liste génératif considère documents comme collections chaque considéré comme échantillon modèle mélange composants mélange représentations sujets traités thématiques obtient distributions probabi lités peuvent interprétées comme probabilités appartenance documents différentes catégories présente sortie floue approche overlapping means extension algorithme classique means proposée cleuziou partage mêmes grands principes celui objectif minimiser fonction critère principe distorsion principale férence algorithme rapport means document attribué plusieurs clusters section décrit méthode manière détaillée extraction motifs fréquents regroupement documents présenté section précédente constitue bonne méthode organiser collection textes porrata nécessaire synthétiser davantage information lorsque celle devient volumineuse solution consiste fournir utilisateurs description intelligible catégories bonne description catégorie motif contient consécutifs sédant signification dépasse celle isolés fouille données appelons motifs expressions phrase notons cette description comporter prépositions articles lecteur humain notre exemple important expression alors séquence plusieurs jugés pertinents quand ensemble tandis isolé pertinent hammouda roche divise algorithmes extraction catégories fonction approche linguistique numérique hybride approches linguistiques roche trois systèmes linguistiques présen termino lexter intex fastr systèmes utilisent informations morphologiques syntaxiques textes textes ainsi marqués chaque système approche différente découvrir expressions termino utilise analyseur lexico syntaxique décrire phrases certains motifs patterns utilisés découvrir motifs groupe prépositionnel groupe adjectivale lexter utilise informations morphologiques extraire texte groupes nominaux maximaux approches numériques algorithmes utilisent informations numériques statistiques découvrir thématiques certains mesurent dépendance entre collocation binaire aussi appelée bigramme chaque couple texte information mutuelle calculé permet calculer dépendance entre nommer catégories recouvrantes données textuelles fonctionnement général système lorsqu trouvent autre fenêtre dimension précise anaya sánchez exemple fenêtre dimension considérée autour avant centre après partir algorithme extraction bigrammes certains auteurs roche esatec biskri proposent construire grammes combinant façon itérative bigrammes alors ajoutant nouveau grammes existants beaucoup mesures statistiques proposées calculer force lation entre similitude anaya sánchez mesure localmaxs combinée probabilité symétrique conditionnelle mutual expectation silva nikos effectuent expériences certains mesures connues score pearson square likelihood ratio comparer capacité identifier bigrammes autres approches reposent détection grammes lingo osinski osinski weiss expressions découverts approche basée arbre suffixes algorithme décrit détail section approches hybrides système hybride ajoute informations linguistiques essentiellement numérique processus améliore généralement résultats biskri approche proposée travail proposons solution modulaire globale réaliser toute chaîne traitement partant données textuelles brutes fournissant caractérisation catégo extraites niveau sémantique dépasse simple ensemble avons cherché solution serait possible indépendante langue utilisée texte figure permet faire fonctionnement général notre système système collection documents rédigés langage naturel première étape rizoiu consiste prétraiter cette collection rendre utilisable algorithme apprentissage partir cette collection prétraitée documents regroupés utilisant algorithme section algorithme choisi préférence autres approches discu précédemment principalement produit recouvrement classes nécessaire fixer seuil transformer degrés appartenance relation appartenance stricte algorithme simple implémenter efficace terme temps calculs adapté données volumineuses souhaitons traiter module extraction motifs reprend corpus textes format initial raison motivé choix module prétraitement élimine outils words révèle problématique extraction clusters utilisation ensemble lemmatisés séparés leurs articles considérés comme superflus quasi vides lecteur humain trouver candidats manière automatisée possible avons choisi utiliser approche basée arbre suffixes section dernière étape notre système associe découverts étape précédente catégories recouvrantes trouvées choisis soient représentatifs documents catégorie réalisation notre système avons choisi travailler cadre classique fouille textes utilisant représentation vectorielle documents salton avons choix réduire dépendance notre système langue pouvoir traiter efficacement grandes quantités données textuelles savons cependant structures données complexes développées langage naturel elles conservent mieux information elles semblent difficiles appliquer grands corpus détaillons présent chaque étape notre système prétraitement prétraitement partie importante algorithme fouille textes seule dépende langue composée éléments stemmatisation stemming élimination outils stopwords anglais utilise algorithme porter français algorithme proposée projet dépar tement informatique université neuchâtel listes outils extraites adresse comme phase découverte candidats requiert textes forme initiale version traitée documents également conservée regroupement textes prétraités processus regroupement textes clustering commencer initialement documents traduits ensemble vecteurs utilisant choix quatre pondérations différentes presence absence fréquence inverse document frequency tfxidf frequency inverse document frequency réalisation notre système sommes inspirés myung campaign members unine jacques savoy index nommer catégories recouvrantes données textuelles pouvoir choisir facilement mesure pouvoir combiner différentes sures documents transformés vecteurs regroupement réalisé rithme autorise recouvrements texte appartenir plusieurs tégories means chaque document affecté centroïde proche associe chaque document image correspond ensemble centroïdes image centre gravité centroïdes associés document document alors ajouté unique catégorie catégories permettent minimiser distance entre document cette image abord choisit hasard centroïdes ensemble données réitère étapes suivantes affectation documents clusters centroïdes clusters basée nouvelle configuration calculée étape algorithme arrête lorsqu converge minimum local notre implémentation algorithme respecte indications données auteurs cleuziou seule condition arrêt modifiée forme originelle algorithme arrête quand partition varie acceptant classes recouvrantes centroïdes peuvent encore changer itération suivante centroïdes dépend documents présents propre groupe aussi autres centroïdes résultants dernière itération processus ultérieur attribution classes étant fortement tributaire centroïdes semblé important continuer optimiser vecteurs recou vrement change pourquoi avons seuil minimum variation fonction critère entre itérations extraction candidats objectifs notre système donner utilisateur description lisible catégories faire extrait ensemble candidats partir corpus documents traités osinski présente quatre conditions doivent remplies collocation terme puisse considérée comme candidat apparaître texte fréquence déterminée hypothèse expressions apparaissent souvent texte grande puissance descriptive manière duale apparitions isolées forte probabilité expressions incorrectes roche traverser frontières phrase parce phrases queurs déplacements thématiques expressions complète expressions complètes expressions incomplètes président nicolas sarkozy plutôt président nicolas commencer finir outil contre outils peuvent situés intérieur expression avons choisi utiliser approche basée arbre suffixes extraire candidats algorithme fonctionne phases trouve expressions complètes gauche droite premier temps intersection ensembles filtre obtenir ensemble expressions complètes détaillons fonctionne algorithme dessous rizoiu construction arbre suffixes algorithme découverte expressions complètes droite repose utilisation arbre suffixes arbre suffixes tableau alphabétiquement suffixes chaîne caractères notre unité damentale caractère problèmes importants construction arbre efficacité suffixes termes temps exécution espace mémoire larsson présente solutions manber myers algorithme sadakane compare performances avons choisi utiliser deuxième proche rapide comme expression dépasser limite phrase avons modifié algorithme proposé osinski construisant arbre fixes chaque phrase avons concaténé arbres extraction expressions avons trouvé expressions complètes droite cherchons expressions complètes gauche réalisé appli quant algorithme précédemment inversant document premier devient dernier ainsi suite séries peuvent ensuite croisées temps linéaire précisons candidats extraits ainsi peuvent expressions complexes plusieurs également isolés parfois possible expliquer contenu cluster celui suffisam signifiant dernière phase algorithme consiste filtrer candidats abord candidats fréquence dépasse seuil donné éliminés souvent expressions assimiler bruit deuxième phase filtrage élimine outils quand trouvent début candidats quatrième condition dessus associer clusters dernière étape notre système consiste associer candidat chacun utilisant recouvrement calculé étape candidats étape propo choisir candidats présentent similarité maximum distance cosinus centroïde chaque catégorie rappelons centroïde existant synthétise mieux contenu cluster autrement vecteur termes pertinents poids élevé postulons candidat autant représentatif catégorie proche centre prenons candidats réintroduisons collection documents comme pseudo documents après avoir appliqué prétraitement celui prévu documents originaux introduisons espace vectoriel utilisant système pondération termes autres documents ensuite suffit calculer similarité entre chacun pseudo documents centre clusters candidat présente score élevé choisi étiqueter cluster expérimentations système proposons évalué parties première série expérimen tations concentre phase regroupement seconde phase caractérisation clusters nommer catégories recouvrantes données textuelles données souhaitions proposer système aussi indépendant possible langue pourquoi avons effectué expérimentations corpus écrits anglais textes styles écriture différents concerne anglais avons naturellement choisi corpus reuters contient milliers articles journaux comportant chacun entre raison principalement élevé évaluation chacun clusters experts avons choisi travailler ensemble données avons suivi thodologie présenté cleuziou choisissant documents étiquetés experts comme présentant moins sujet cependant tester capacité notre système traiter corpus grands avons utilisé jusqu documents concerne français avons utilisé textes recommandés notre parte naire industriel textes forums ligne comme exemple commémora tions france forums contiennent entre documents forum libération comportant chacun entre contrairement articles journaux reuters style écriture informel evaluation regroupement expériences cleuziou évaluent performances comparati vement algorithme recouvrant means avons repris expérimen tations avons enrichies étudiant influence système pondération termes comportement algorithme regroupement avons utilisé méthode évaluation experts produit algorithme comparé regroupement proposé experts suite expérimentation réalisée cleuziou avons utilisé ensemble données documents correspondant partie corpus reuters considérons documents comme étant associées appartiennent classe processus regroupement considérons cette association correcte documents étiquette reuters commune partition ensuite évaluée fonction nombre total associations nombre associations correctes nombre total associations attendus indicateurs calculer précision rappel fscore precision recall fscore precision recall precision recall avons effectué expérimentations fixant faisant varier nombre classes répétant algorithme regroupement prendre meilleur score obtenu résultats expérimentations données figures figure confirme hypothèse initiale selon laquelle approche chevauchement adapté fouille textes langage naturel alors qualité partitions algorithme recouvrement baisse quand nombre groupes augmente approche chevauchement maintient score stable résultats naturels confirment obtenus cleuziou umass datasets reuters 21578 categorization collection rizoiu comparaison fscore entre kmeans fscore obtenu chaque pondération notre contribution premières expérimentations consiste faire varier pondéra termes résultats cette comparaison trouvent figure intéressant observer mesure obtient meilleurs résultats frequency effet plupart outils fouille textes utilise aujourd mesure tfxidf evaluation catégories évaluer catégories formées algorithme clustering avons choisi approche basée experts signifie plusieurs personnes évaluent manuellement chaque résultat donnent expérimentations avons simplement utilisé moyenne notes données experts avons choisi cette approche cherchons obtenir intelligibles humain experts puissent juger différemment pertinence postulons consensus possible permet discriminer intéressants autres ailleurs littérature actuelle propose standard matière avons effectué notre évaluation corpus différents anglais partie corpus reuters français discussion ligne forum commémorations france chaque ensemble données avons exécuté algorithme faisant varier paramètres système pondération termes nombre clusters résultats distribués experts chaque cluster échelle suivante cluster totalement dénué apporte aucune information contenu documents assez intéressant résume teneur groupe apporte informations utiles clusters notés calcule pourcentage bonne qualité qualité moyenne mauvaise qualité chaque système pondération termes figures présentent résultats obtenus corpus chaque barre présente fréquence niveaux appréciation moyen mauvais niveau décroissant selon codage utilisé nommer catégories recouvrantes données textuelles qualité différents tèmes pondération anglais qualité différents tèmes pondération français observe codages présence absence frequency aboutissent jugés meilleurs experts confirmation expérimentale théorique mesure également présente tfxidf pénalise apparaissent nombreux documents cette pénalisation utile construire classes perturbe sélection nommer clusters expressions choisies doivent représentatives grand nombre documents cluster apparaître souvent textes conclusions perspectives conclusions confronté quantités toujours importantes information textuelle cherche moyens efficaces rapides regrouper synthétiser cette information système proposons permet regrouper documents extraire thématiques préhensibles différentes approches proposées jusqu laissent souvent carac téristique essentielle textes langage naturel peuvent traiter multiples sujets pourquoi algorithmes regroupement réduisent qualité globale résul espérés prennent cette caractéristique compte avons recherché solutions recouvrantes partir algorithme point cleuziou avons essayé améliorer compléter riences antérieures différents systèmes pondération termes avons choisi approche statistique extraction expressions texte pouvant fonctionner différentes langues résultats obtenus anglais français ensembles nature différente encourageants ouvrent perspectives intéressantes rizoiu perspectives avons application souple laisse place nombreuses perspectives parmi lesquelles comparaison nouveaux algorithmes pensons performances algorithme doivent comparées algorithmes section résultat clustering étant nature faudra utiliser seuil documents appartiennent exactement plusieurs clusters meilleure association cluster actuel travaux associés catégories basant uniquement similitude entre centre chaque cluster candidat aboutir donner similaires catégories différentes pensons possible résoudre problème prenant compte similitude centres autres clusters cleuziou version pondérée proposée cemment devrait permettre améliorer qualité globale processus clustering evaluation automatisée cluster pourrions davantage matiser processus évaluation experts envisageons solution extraira candidats partir documents corpus indépendamment algorithme regroupement alors possible évaluer automatiquement extraits notre système expériences envisageons entendu étendre expérimentations réalisées corpus grands styles différents autres langues références anaya sánchez porrata berlanga llavori document cluste algorithm topic discovering labeling ciarp proceedings iberoamerican congress pattern recognition berlin heidelberg springer verlag biskri meunier joyal extraction termes complexes approche modulaire semiautomatique données textuelles louvain neuve belgique gérard purnelle cédrick fairon dister presses universitaires louvain volume 192201 930344 jordan lafferty latent dirichlet allocation journal machine learning research cleuziou extension moyennes recherche classes couvrantes noirhomme fraiture venturini volume revue nouvelles technologies information cépaduès éditions cleuziou okmed variantes classification recou vrante ganascia gancarski volume revue nouvelles technologies information cépaduès éditions silva guilloré pereira using localmaxs algorithm traction contiguous contiguous multiword lexical units progress artificial intelligence nommer catégories recouvrantes données textuelles guilloré lopes extraction automatique associations textuelles partir corpora traités rajman chapelier 5èmes journées internationales analyse statistique données textuelles volume lausanne ecole polytechnique fédérale lausanne geraci pellegrini maggini sebastiani cluster generation cluster labelling snippets accurate hierarchical solution hammouda matute kamel corephrase keyphrase extraction document clustering larsson notes suffix sorting lundfd6 myung picachoo customizable feature extraction utilizing characteristics textual icuimc proceedings interna tional conference ubiquitous information management communication nikos fakotakis kokkinakis comparative evaluation collocation extraction metrics proceedings language resources evaluation conference osinski algorithm clustering search results master thesis poznan university technology poland osinski weiss conceptual clustering using lingo algorithm evaluation directory project porrata berlanga llavori shulcloper topic discovery based mining techniques process manage porter algorithm suffix stripping program roche intégration construction terminologie domaines spécialisés processus global fouille textes thesis université paris salton vector space model automatic indexing commun velcin ganascia topic extraction agape summary organizing textual derive meaning major challenge today wishes analyze online discussion forum desirable quickly which themes discussion structured around there observation generally associated several themes propose method combine textual allowing overlaps assign group appoint readable possible contribution paper method which allows entire chain starting textual characteri zation groups semantic level which exceeds collection words