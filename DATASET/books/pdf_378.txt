classification supervisée adaptée obtenir arbres décision simplifiés olivier parisot yoanne didry pierrick bruneau thomas tamisier département informatique systèmes collaboration centre recherche public gabriel lippmann belvaux luxembourg parisot lippmann résumé induction arbre décision technique puissante laire extraire connaissance néanmoins arbres décision obtenus depuis données issues monde peuvent complexes ficiles exploiter cadre article présente solution originale adapter résultat classification supervisée quelconque obtenir arbres décision simplifiés chaque cluster introduction utilisée origine comme outil décision arbres décision populaires fouille analyse visuelle données succès explique notamment utilisent formalisme transparent simple comprendre murthy pratique génération automatique arbres décision depuis données possible grâce induction arbre décision technique connue quinlan malheu reusement arbres décision générés depuis données issues monde peuvent grands difficiles exploiter nombreuses approches simplification proposées connue élagage pruning breslow consiste primer parties arbre faible pouvoir explicatif autre existe approches travaillent directement données utilisant méthodes preproces parisot 2013a enfin classification supervisée clustering outil particulièrement utile fouille données priori cette technique également exploitée obtenir arbres décision simples conséquence étude récente proposé nouvelle approche classification supervisée obtenir arbres décisions simples parisot 2013b article présentons méthode permettant adpater classification supervisée existante simplifier arbre décision obtenu partir chaque cluster contribution méthode proposée figure adapter classification supervisée pouvant obtenue moyen toute technique existante hiérarchique means classification supervisée adaptée obtenir arbres décision simplifiés précisément adaptation classification supervisée posée clusters revient effectuer succession déplacements éléments entre clusters création suppression clusters manière assurer durant adaptation classification obtenue éloignée sification initiale indice jaccard jaccard utilisé comparer similarité classifications similaires indice proche différentes indice proche méthode adaptation classification supervisée phase adaptation matérialise forme algorithme algorithme paramètres entrée suivants données comprenant attribut classe classification supervisée initiale ainsi indice jaccard minimum lequel descendre résultat obtenu classification supervisée adaptée laquelle chaque cluster produire arbre décision simplifié algorithm algorithme adaptation clusters require jaccardindexlimit nbpasseslimit ensure nbpasses while jaccardindexlimit nbpasses nbpasseslimit deplacer cherche cluster cible existe déplace calcul indice jaccard nbpasses nbpasses while principe algorithme suivant déplacements entre clusters effectués indice jaccard minimum spécifié atteint certain nombre itérations algorithme trouve déplacement possible effectuer conséquent indice jaccard minimum spécifié jamais atteint nombre passes maximum également prévu priori éléments susceptibles déplacés cluster autre chercher parmi rendent arbres décisions complexes éléments sifiés expliqués arbre décision éléments classifiés branches ayant parisot faible pouvoir classification posteriori ensuite assurer retirer éléments cluster origine effet réellement positif taille arbre décision généré depuis cluster origine calculons arbre décision avant retrait arbre décision après retrait comparons tailles taille inférieure celle alors élément retiré élément sélectionné déplacé autre cluster proposons choisir cluster lequel arbre décision mieux impacté ajout élément autres termes calculons chaque cluster arbre décision avant ajout arbre décision après ajout comparons taille cluster taille toujours supérieure taille alors cluster cible déplacement sinon cluster cible cluster lequel ratio entre taille taille meilleur déplacement effectué expériences prototype réalisé utilisant fonctionnalités offertes tests réalisés sélection données bache lichman avons comparé arbres obtenus situations suivantes génération arbre décision données complet classification supervisée données algorithme means différentes valeurs génération arbre décision chaque cluster application notre méthode adaptation clusters obtenus précédem génération arbre décision chacun clusters génération arbres décision effectuée utilisant algorithme implémentation algorithme configuré désactivant fonction élagage manière obtenir arbres décision initiaux complexes clusters taille arbre erreur données moyennes tailles arbres erreur chaque cluster dataset kmeans vehicle autos credit spectrometer landsat credit mushroom anneal adult classification supervisée adaptée obtenir arbres décision simplifiés résultats obtenus notamment classifications composées clusters table montrent notre méthode permet simplifier arbres décision chaque cluster ensemble données testés gains spectaculaires concernent données vehicle credit adult effet taille moyenne arbres décision réduite jusqu bémol toutefois certains comme mushroom means produit clusters ayant arbres décision simplifiés notre méthode permet simplifier davantage conclusion perspectives article avons présenté méthode permettant utiliser résultat classification supervisée simplifier efficacement arbres décision chacun clusters méthode procède déplacements éléments entre clusters réduisant mesure taille arbres décision chacun clusters futurs travaux concerneront recherche solution similaire données références bache lichman machine learning repository breslow simplifying decision trees survey knowl clustering theory algorithms applications frank holmes pfahringer reutemann witten mining software update sigkdd explor newsl jaccard nouvelles recherches distribution florale bulletin société vaudoise sciences naturelles réunies murthy automatic construction decision trees multi disciplinary survey knowl discov parisot bruneau didry tamisier 2013a driven preprocessing decision support cooperative design visualization engineering volume lecture notes computer science springer berlin heidelberg parisot didry tamisier otjacques 2013b using clustering improve trees visualization proceedings international conference information visualisation london united kingdom quinlan induction decision trees machine learning summary decision trees simple powerful knowledge extraction visual analysis however decision trees complex built world solve issue clustering efficiently paper proposes original solution adapt clustering results order simplify decision obtained cluster