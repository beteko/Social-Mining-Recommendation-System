 Régression floue et crédibiliste par SVM pour la classification des images sonar Hicham Laanaya Arnaud Martin Driss Aboutajdine Ali Khenchaf GSCM LRIT Université Mohammed V Agdal Faculté des sciences de Rabat Maroc aboutaj fsr ac ma fsr ac ma GSCM ENSIETA E3I2 EA3876 2 rue François Verny 29806 Brest cedex 9 laanayhi Arnaud Martin Ali Khenchaf ensieta fr ensieta fr e3i2 Résumé La classification des images sonar est d’une grande importance par exemple pour la navigation sous marine ou pour la cartographie des fonds ma rins En effet le sonar offre des capacités d’imagerie plus performantes que les capteurs optiques en milieu sous marin La classification de ce type de données rencontre plusieurs difficultés en raison des imprécisions et incertitudes liées au capteur et au milieu De nombreuses approches ont été proposées sans donner de bons résultats celles ci ne tenant pas compte des imperfections des données Pour modéliser ce type de données il est judicieux d’utiliser les théories de l’in certain comme la théorie des sous ensembles flous ou la théorie des fonctions de croyance Les machines à vecteurs de supports sont de plus en plus utilisées pour la classification automatique aux vues leur simplicité et leurs capacités de généralisation Il est ainsi possible de proposer une approche qui tient compte de ces imprécisions et de ces incertitudes au cœur même de l’algorithme de classification L’approche de la régression par SVM que nous avons introduite permet cette modélisation des imperfections Nous proposons ici une application de cette nouvelle approche sur des données réelles particulièrement complexes dans le cadre de la classification des images sonar 1 Introduction Les images sonar sont utilisées pour leur rapidité à imager de grandes zones là où l’optique ne peut le faire On les retrouve ainsi dans de nombreuses applications telles que l’aide à la navigation sous marine ou la cartographie sous marine Les images sonar sont entachées de plusieurs imprécisions et incertitudes dues à l’instru mentation utilisée le capteur sonar et au milieu marin Les paramètres qui entrent en jeu pour la reconstruction de ces images géométrie du dispositif coordonnées du bateau mouvements du sonar sont aussi entachés des bruits de mesure Il s’ajoute à ceci des interférences dues à des trajets multiples des signaux utilisés à des bruits de chatoiement ou encore à la faune et Régression floue et crédibiliste par SVM pour la classification des images sonar la flore Ces imperfections rendent la tache difficile pour la caractérisation des fonds marins à partir de ce type de données Il est donc nécessaire de proposer des algorithmes robustes aux imperfections pour la classification automatiques des images sonar Plusieurs choix sont envisageable pour remédier aux problèmes d’imperfections soit nous tentons de supprimer ces imperfections ce qui nécessite une compréhension souvent diffi cile de la physique qui a conduit à ces imperfections soit nous cherchons à développer des processus de traitement robustes à ces imperfections soit nous cherchons à les modéliser Le cadre théorique des théories de l’incertain offre la possibilité de modéliser finement ces imperfections Parmi elles la théorie des ensembles flous et la théorie des fonctions de croyance permettent de tenir compte des incertitudes et imprécisions De nombreuses approches ont été proposées pour la classification des images sonar par exemple dans Laanaya et al 2005b et Leblond et al 2005 Ces approches ne tiennent pas compte de l’incertitude de l’expert lors de la segmentation de ces images Nous adopterons dans ce papier l’approche que nous avons proposée dans Laanaya et al 2006 avec une ré solution du problème d’optimisation adaptée à la classification automatique des images sonar Cette approche a donné des résultats intéressants sur des données générées nous montrerons ici son intérêt sur les données complexes que sont les images sonar Ainsi nous présenterons une description rapide des fonctions d’appartenance et des fonc tions de croyance utilisées par l’approche de la régression par SVM Nous rappelons ensuite l’approche de la régression par SVM après une brève introduction du principe des SVM Cette approche est comparée au SVM classique et discutée dans une dernière partie à partir d’images sonar 2 Théories de l’incertain Nous avons vu dans Martin 2005 que les théories de l’incertain telles que la théorie des sous ensembles flous introduite par Zadeh 1965 la théorie des possibilités de Dubois et Prade 1987 ou encore la théorie des fonctions de croyance de Dempster 1967 et Shafer 1976 permettent la modélisation de données incertaines et imprécises dans le cadre de la classification d’images sonar Ces théories sont fondées sur les fonctions d’appartenance pour les premières et sur les fonctions de croyance pour la dernière Afin d’intégrer directement les contraintes liées à ces fonctions dans un algorithme de classification nous rappelons ici les caractéristiques des fonc tions d’appartenance de la théorie des sous ensembles flous et des fonctions de croyance de Dempster et Shafer 2 1 Les fonctions d’appartenance Les fonctions d’appartenance permettent de décrire une appartenance floue à une classe Ainsi l’appartenance d’une observation x à une classe Ci parmi Nc classes est donnée par une fonction µi x telle que  µi x ∈ [0 1] Nc∑ i=1 µi x = 1 1 H Laanaya et al Dans ce cas nous considérons les classes floues Dans le cas de classes nettes il est possible de considérer les distributions de possibilité Typiquement x peut représenter une partie du fond marin et Ci le type de sédiment présent sur l’image x Nous verrons au paragraphe 4 1 2 comment ces fonctions µi peuvent être choisie dans notre application 2 2 Les fonctions de croyance La théorie des fonctions de croyance est fondée sur la manipulation des fonctions de masse Les fonctions de masse sont définies sur l’ensemble de toutes les disjonctions du cadre de dis cernement Θ = {C1 CNc} et à valeurs dans [0 1] où Ci représente l’hypothèse “l’ob servation appartient à la classe i” La contrainte de normalité couramment employée est ici donnée par ∑ A∈2Θ mj A = 1 2 où m représente la fonction de masse La première difficulté est donc de définir ces fonc tions de masse selon le problème Nous verrons comment il est possible de le faire pour notre application dans la section 4 1 2 A partir de ces fonctions de masse d’autres fonctions de croyance peuvent être définies telles que les fonctions de crédibilité représentant l’intensité que toutes les sources croient en un élément et telles que les fonctions de plausibilité repré sentant l’intensité avec laquelle on ne doute pas en un élément Afin de conserver un maximum d’informations il est préférable de rester à un niveau cré dal i e de manipuler des fonctions de croyance pendant l’étape de manipulation des infor mations pour prendre la décision sur les fonctions de croyance à l’issue de la manipulation de ces fonctions Si la décision prise par le maximum de crédibilité peut être trop pessimiste la décision issue du maximum de plausibilité est bien souvent trop optimiste Le maximum de la probabilité pignistique introduite par Smets 1990 reste le compromis le plus employé La probabilité pignistique est donnée pour tout X ∈ 2Θ avec X 6= ∅ par betP X = ∑ Y ∈2Θ Y 6=∅ |X ∩ Y | |Y | m Y 1−m ∅ 3 2 3 Similitudes Ainsi les fonctions d’appartenance et les fonctions de masse permettent une modélisation de l’incertitude et de l’imprécision à partir de points de vue différents Ces fonctions ont toutes deux la particularité d’être à valeurs dans [0 1] et d’avoir une contrainte de normalité équivalente Nous allons voir dans la section suivante comment intégrer ces contraintes dans une régression linéaire multiple 3 Régression floue et crédibiliste par SVM Nous avons proposée dans Laanaya et al 2006 une nouvelle approche pour la classifi cation automatique fondée sur une régression effectuée à partir des SVM Cette approche a Régression floue et crédibiliste par SVM pour la classification des images sonar montré des performances remarquables sur des données générées Afin d’assoir les notations utiles pour la suite nous rappelons le principe des SVM sur laquelle s’appuie la régression floue et crédibiliste présentée ensuite 3 1 Principe du classifieur SVM Les machines à vecteurs de support initiées par Vapnik 1998 sont avant tout une ap proche de classification linéaire à deux classes Elles tentent de séparer des individus issus de deux classes +1 et 1 en cherchant l’hyperplan optimal qui sépare les deux ensembles en garantissant une grande marge entre les deux classes Un nombre réduit d’exemples pour la recherche de l’hyperplan est suffisant pour la description de cet hyperplan Dans le cas où les exemples sont linéairement séparables on cherche l’hyperplan y = w x + b qui maximise la marge entre les deux ensembles où w x est le produit scalaire de w et x Ainsi w est la solution du problème d’optimisation convexe Min ‖w‖2 2 4 sous les contraintes yt w xt + b − 1 ≥ 0 ∀t = 1 l 5 où les xt ∈ IRd représentent les l données d’apprentissage et yt ∈ {−1 +1} la classe Ce problème d’optimisation se résout par la méthode du lagrangien Dans le cas où les données ne sont pas linéairement séparables les contraintes 5 sont relachées par l’introduction de termes positifs ξt Nous cherchons alors à minimiser 1 2 ‖ w ‖2 +C l∑ t=1 ξt 6 sous les contraintes données pour tout t { yt w xt + b ≥ 1− ξt ξt ≥ 0 7 où C est une constante choisie par l’utilisateur Le problème se résout alors de manière simi laire au cas linéairement séparable Afin de classer un nouvel élément x il suffit d’étudier la fonction de décision donnée par f x = sign ∑ t∈SV ytα 0 t xt x− b0 8 où SV = {t α0t > 0} pour le cas séparable et SV = {t 0 < α0t < C} pour le cas non séparable est l’ensemble des vecteurs de support et αt ≥ 0 sont les multiplicateurs de Lagrange Dans les cas non linéaire le principe des SVM est de projeter par une fonction noyau les données de départ dans un espace de grande dimension éventuellement infinie Ainsi la classification d’un nouvel élément x est donnée par la fonction de décision f x = sign ∑ t∈SV ytα 0 t K x xt − b0 9 H Laanaya et al où K est la fonction noyau dont les plus utilisées sont le noyau polynomial K x xt = x xt + 1 d d ∈ IN et le noyau gaussien K x xt = e−γ‖x−xt‖ 2 γ ∈ IR+ Le choix du noyau et l’optimisation des paramètres de celui ci reste délicat selon l’application 3 2 Régression floue et crédibiliste par SVM Nous avons situé cette approche dans la littérature Laanaya et al 2006 Ainsi elle est novatrice par la prise en compte des contraintes similaires de normalisation des fonctions de croyance et d’appartenance dans le problème de régression multiple De plus nous proposons ici d’employer une résolution du problème d’optimisation pouvant gérer de grande quantité de données Soient les vecteurs d’apprentissage xt ∈ IRd et les fonctions associées yt ∈ IRN où N = Nc le nombre de classes dans le cas des fonctions d’appartenance et N = 2Nc dans le cas des fonctions de masse Ainsi par la régression multiple linéaire nous cherchons une fonctionnelle f = f1 fN où les fn sont linéaires de forme fn x = wn x + bn Nous cherchons à déterminer cette fonctionnelle telle que pour les xt yt de la base d’apprentissage |ytn − wn xt + bn| ne dépasse pas un certain � fixé pour tout n Nous supposons ainsi que tous les points sont à l’intérieur du cylindre défini par � Afin de généraliser nous associons un facteur C pour les points qui sont à l’extérieur du cylindre défini par � Le problème d’optimisation convexe revient donc à celui exposé dans la section 3 1 et le critère à minimiser est 1 2 N∑ n=1 ‖wn‖2 + C N∑ n=1 l∑ t=1 ξtn + ξ tn 10 sous les contraintes données pour tout t et tout n  ytn − wn xt − bn ≤ � + ξtn wn xt + bn − ytn ≤ � + ξ tn N∑ n=1 wn xt + bn = 1 wn xt + bn ≥ 0 wn xt + bn ≤ 1 ξtn ξ tn ≥ 0 11 Le lagrangien est donc donné par L = 1 2 N∑ n=1 ‖wn‖2 + C N∑ n=1 l∑ t=1 ξtn + ξ tn − N∑ n=1 l∑ t=1 ηtnξtn + η tnξ tn 12 − N∑ n=1 l∑ t=1 αtn � + ξtn − ytn + wn xt + bn − N∑ n=1 l∑ t=1 α tn � + ξ tn + ytn − wn xt − bn − N∑ n=1 l∑ t=1 βtn wn xt + bn − N∑ n=1 l∑ t=1 β tn 1− wn xt − bn Régression floue et crédibiliste par SVM pour la classification des images sonar − l∑ t=1 γt 1− N∑ n=1 wn xt + bn où les η α β et γ sont les multiplicateurs de Lagrange et sont positifs Au point selle du lagrangien L on a pour tout t et tout n ∂L ∂bn = 0 ∂L ∂wn = 0 ∂L ∂ξtn = 0 et ∂L ∂ξ tn = 0 Ainsi  l∑ t=1 σtn = 0 wn = l∑ t=1 σtnxt ηtn = C − αtn η tn = C − α tn 13 avec σtn = αtn − α tn + βtn − β tn − γt En intégrant ces équations 13 dans le lagrangien équation 12 le problème revient à maximiser −1 2 N∑ n=1 l∑ t t′=1 σtnσt′nxt xt′ − N∑ n=1 l∑ t=1 β tn + γt N − N∑ n=1 l∑ t=1 α tn � + ytn − N∑ n=1 l∑ t=1 αtn �− ytn sous les contraintes  l∑ t=1 σtn = 0 αtn ∈ [0 C] α tn ∈ [0 C] βtn ≥ 0 β tn ≥ 0 γt ≥ 0 Enfin pour prédire la nème sortie ỹn d’un nouvel élément x on calcule ỹn = l∑ t=1 σtnxt x + bn où bn est déduite des conditions de Kuhn Karush et Tucker  αtn � + ξtn − ytn + wn xt + bn = 0 α tn � + ξ tn + ytn − wn xt − bn = 0 C − αtn ξtn = 0 C − α tn ξ tn = 0 βtn wn xt + bn = 0 β tn 1− wn xt − bn = 0 H Laanaya et al Si pour un t0 αt0n ∈]0 C[ alors ξt0n = 0 ainsi bn = yt0n − wn xt0 − � un raisonnement identique sur α donne bn = yt0n − wn xt0 + � La résolution du système d’optimisation de la régression par SVM pour des problèmes de grande dimension nécessite des mémoires de stockage de grande taille Ainsi l’application des algorithmes d’optimisation classiques est difficile Ces limites ont été constatées dans Laanaya et al 2006 Une solution est d’utiliser des méthodes d’optimisation itératives où on essaye de résoudre des sous problèmes du problème principale Nous avons adapté la résolution par SMO Sequential Minimal Optimization développée par Platt 1998 pour les machines à vecteurs de support pour notre problème d’optimisation Il résout des sous problèmes de dimension deux d’une manière analytique Nous pouvons ainsi résoudre des problèmes de grande taille avec une vitesse remarquable Si on suppose que la relation entre les xt et les sorties ỹt est non linéaire nous pouvons re présenter les données de départ en utilisant un noyau Ainsi le produit scalaire entre les données de la base d’apprentissage peut être donc substitué par un noyau le produit scalaire x x′ de vient K x x′ Une régression linéaire peut alors s’appliquer dans l’espace de représentation Pour une observation x la sortie ỹ se prédit en considérant les N valeurs ỹn = l∑ t=1 σtnK x xt + bn A partir de cette approche de régression sur les fonctions d’appartenance ou les fonctions de croyance nous obtenons un classifieur en prenant la décision via le maximum des fonctions d’appartenance ou le maximum de la probabilité pignistique 4 Expérimentations Nous présentons ici l’application de notre approche pour la classification des images sonar En effet l’environnement sous marin lui même est très incertain et les systèmes de mesure sont complexes et imprécis Il est particulièrement important de classifier les fond marins pour de nombreuses applications telles que la navigation et la cartographie sous marine Nous trou verons plusieurs études sur la classification de images sonar citons par exemple Martin et al 2004 Laanaya et al 2005a Laanaya et al 2005b et Leblond et al 2005 Les données à classifier sont ainsi entachées de nombreuses imperfections dues aux bruits de mesure aux interférences des signaux utilisés pour l’acquisition aux bruits de chatoiement et à la faune et la flore 4 1 Base de données La base de données est constituée de 42 images sonar fournies par GESMA Groupe d’Etudes Sous Marines de l’Atlantique et ont été obtenues à partir d’un sonar Klein 5400 au large des côtes finistériennes Ces images ont été labellisées à partir d’un logiciel déve loppé spécialement en spécifiant le type du sédiment présent sable ride vase roche caillou tis ou ombre voir figure 1 et le degré de certitude de l’expert sûr moyennement sûr ou non sûr Parmi ces sédiments nous avons considéré trois classes distinctes particulièrement Régression floue et crédibiliste par SVM pour la classification des images sonar Sable Ride Roche Cailloutis Roche et sable Ride et vase FIG 1 – Exemple d’image sonar fournit par le GESMA et d’imagettes étiquetées importantes pour la navigation sous marine et les sédimentologues Ainsi la première classe regroupe roche et cailloutis la deuxième classe les rides et la troisième le sable et les vases L’unité de classification retenue est l’imagette de taille 32×32 pixels soit environ 640×640 cm 4 1 1 Extraction de paramètres Afin de réduire les problèmes de représentativité des imagettes qui comportent plus d’un sédiment et les problèmes liés à l’évaluation cf Martin et al 2006 nous ne considérons ici que les imagettes homogènes imagettes avec un seul type de sédiment Nous avons ainsi 31957 imagettes Nous avons calculé sur ces imagettes six paramètres extraits à partir des matrices de co occurrence calculés sur les imagettes Martin et al 2004 Les matrices de cooccurrence Cd sont calculées en comptant les occurrences identiques de niveaux de gris entre deux pixels contigus dans une direction d donnée Quatre directions sont considérées 0 45 90 et 135 degrés Dans ces quatre directions six paramètres d’Haralick sont calculés l’homogénéité le contraste l’entropie la corrélation et l’uniformité L’homogénéité qui a une valeur élevée pour des images uniformes ou possédant une texture périodique dans la direction d est donnée par NG∑ i=1 NG∑ j=1 C2d i j 14 où NG est le niveau de gris des imagettes L’estimation du contrast est donnée par 1 NG − 1 NG−1∑ k=0 k2 NG∑ i j=1 |i−j|=k Cd i j 15 H Laanaya et al L’entropie qui a de faibles valeurs s’il y a peu de probabilités de transition élevées dans Cd est définie par 1− NG∑ i=1 NG∑ j=1 p i j log Cd i j 16 La corrélation entre les lignes et les colonnes de la matrice est donnée par NG∑ i=1 NG∑ j=1 i− µx j − µy Cd i j σxσy 17 où µx σx µy σy représentent respectivement les moyennes et écart types des distributions marginales des éléments de la matrice de cooccurrence La directivité qui définie l’existence d’une direction privilégiée de la texture est calculée par NG∑ i=1 Cd i i 18 L’uniformité qui caractérise la proportion d’un même niveau de gris est donnée par NG∑ i=1 Cd i i 2 19 Nous avons moyenné ces paramètres selon les quatre directions d ainsi chaque imagette est représentée uniquement par six parammètres 4 1 2 Modélisation des fonctions floues et crédibilistes Nous avons utilisé l’approche de Keller et al 1985 pour calculer la fonction d’apparte nance des vecteurs d’apprentissage que nous utiliserons pour l’apprentissage du SVM flou et l’approche de Denœux 1995 pour estimer les fonctions de masses que nous utiliserons pour l’apprentissage du SVM crédibiliste L’approche de Keller et al 1985 est celle d’un k plus proches voisins flou Les fonctions d’appartenance d’un vecteur d’apprentissage xt sont estimées dans un premier temps par µi xt = ki xt kf 20 où kf est le nombre de plus proches voisins choisi pour le voisinage flou VKf et ki xt = |Ci ∩ VKf xt | Dans un second temps nous calculons la fonction d’appartenance pour un vecteur x à classifier µi x = l∑ t=1 µi xt ‖x− xt‖2 l∑ t=1 1 ‖x− xt‖2 21 Régression floue et crédibiliste par SVM pour la classification des images sonar La norme employée est ici la norme euclidienne La classe d’appartenance de x est ensuite décidée de manière classique comme la classe donnant le maximum des fonctions d’appartenance prédites par notre régression L’approche de Denœux 1995 calcule une estimation des fonctions de masses à partir d’un modèle de distance { mk Ci|x t k x = αieγid 2 x x t k mk Θ|x t k x = 1− αieγid 2 x x t k 22 où Ci est la classe associée à x t k qui sont les k vecteurs d’apprentissage les plus proches de la valeur x et la distance employée est la distance euclidienne αi et γi sont des coefficients d’affaiblissement et de normalisation Les k fonctions de masse ainsi calculées pour chaque x sont combinées par la règle orthogonale normalisée de Dempster Shafer Cette règle est donnée pour deux experts et pour tout A ∈ 2Θ A 6= ∅ par m A = ∑ B∩C=A m1 B m2 C 1− ∑ B∩C=∅ m1 B m2 C 23 et m ∅ = 0 La décision est ensuite prise par le maximum sur les fonctions de masse prédites par notre régression Dans ce cas il est équivalent au maximum de probabilité pignistique car les seuls éléments focaux sont les singletons et l’ignorance 4 2 Résultats Nous avons effectué un tirage aléatoire de 3000 imagettes homogènes sur toute la base de données 31957 imagettes ainsi la base d’apprentissage contient des effectifs différents pour les trois classes 15 53% des imagettes contiennent du roche et cailloutis 11 85% sont des imagettes rides et les 72 62% restants sont du sable et de la vase La base de test est constituée de 1000 imagettes choisies de façon aléatoire Nous avons répété cette opération 10 fois afin d’obtenir des estimations plus fiables des taux de classification Nous avons comparé la classification fondée sur les machines à vecteurs de support donnée par le logiciel libSVM de Chang et Lin 2001 et une version modifiée de ce dernier qu’on a développée pour intégrer notre approche Les matrices de confusion normalisées obtenues par le SVM classique avec les paramètres par défaut de libSVM noyau gaussien avec γ = 1 et C=1 SVM crédibiliste et SVM flou avec un noyau gaussien avec γ = 1 C = 1 et � = 0 1 sont données ci dessous SVM classique SVM crédibiliste SVM flou 61 62 25 26 13 1223 08 62 59 14 32 4 99 10 97 84 04   70 59 15 73 13 6816 81 70 28 12 91 6 42 13 91 79 66   68 99 16 60 14 4116 18 66 09 17 74 5 85 7 59 86 56  Nous avons ainsi obtenu un taux de 78 02±5 14% pour un SVM classique et des taux de 77 14±5 22% pour le SVM crédibiliste et 81 40±4 83% pour le SVM flou Dans le cas du H Laanaya et al SVM classique nous avons obtenu un vecteur de bonne classification de [61 62±4 85 62 59±5 52 84 04±1 69] [70 59±4 54 70 28± 5 22 79 66±1 83] par la régression crédibiliste par SVM et [68 99±4 61 66 09±5 6 86 56±1 55] par la régression floue par SVM Les vecteurs d’er reurs sont donnés par [26 21 27 76 14 84] pour le SVM classique [20 51 22 27 16 82] pour le SVM crédibiliste et [21 01 23 00 14 76] pour le SVM flou En comparaison avec l’approche classique des SVM nous avons ainsi une amélioration significative de la classification des trois classes pour la régression floue issue des SVM et une amélioration significative avec la régression crédibiliste issue des SVM pour les deux premières classes la classe des roches et des cailloutis et la classe des rides ces deux dernières classes sont particulièrement difficiles à classifier du fait de leur faible représentativité Notons que c’est l’approche crédibiliste qui donne les meilleurs résultats pour ces deux classes Ainsi la nouvelle approche a apporté une amélioration pour la classification des différentes classes des images sonar qui sont particuliè rement difficile à caractérisées 5 Conclusion Nous avons proposé dans ce papier une nouvelle résolution de l’approche de régression floue et crédibiliste à partir de machines à vecteurs de support pour la classification précé dement introduite Les résultats obtenus sur les images sonar ont montré l’intérêt de cette approche En particulier l’approche crédibiliste donne de très bons résultats sur des données faiblement apprises alors que l’approche floue permet d’avoir une meilleure classification pour chaque classe considérée Nous n’avons donné ici que des résultats en utilisant des valeurs empiriques pour les pa ramètres C � et γ Le réglage de ces paramètres peut se faire en utilisant les algorithmes génétiques par exemple il est possible aussi d’intégrer l’optimisation de ces constantes dans le problème d’optimisation générale des SVM pour la régression Références Chang C C et C J Lin 2001 Libsvm a library for support vector machines Software available at csie ntu edu tw ∼cjlin libsvm Dempster A P 1967 Upper and lower probabilities induced by a multivalued mapping Annals of Mathematical Statistics 83 325–339 Denœux T 1995 A k nearest neighbor classification rule based on dempster shafer theory IEEE Transactions on Systems Man and Cybernetics Part A Systems and Humans 25 5 804–813 Dubois D et H Prade 1987 Théorie des possibilités Masson Keller J M M Gray et J Givens 1985 A fuzzy k nn neighbor algorithm IEEE Transac tions on Systems Man and Cybernetics 15 580–585 Laanaya H A Martin D Aboutajdine et A Khenchaf 20 23 June 2005a A new dimen sionality reduction method for seabed characterization Supervised curvilinear component analysis IEEE OCEANS’05 EUROPE Brest France Régression floue et crédibiliste par SVM pour la classification des images sonar Laanaya H A Martin A Khenchaf et D Aboutajdine 15 18 March 2005b Feature selec tion using genetic algorithm for sonar images classification with support vector machines European Conference on Propagation and Systems Brest France Laanaya H A Martin A Khenchaf et D Aboutajdine 19 20 Octobre 2006 Classification par règression floue et crèdibiliste à base de machines à vecteurs de support LFA 2006 Toulouse France Leblond I M Legris et B Solaiman 20 23 June 2005 Use of classification and segmen tation of sidescan sonar images for long term registration IEEE Oceans’05 Europe Brest France Martin A Novembre 2005 Fusion de classifieurs pour la classification d’images sonar RNTI Extraction des connaissances Etat et perspectives 259–268 Martin A H Laanaya et A Arnold Bos 2006 Evaluation for uncertain image classification and segmentation Pattern Recognition 39 Martin A G Sevellec et I Leblond 21 22 October 2004 Characteristics vs decision fusion for sea bottom characterization Colloque Caractérisation in situ des fonds marins Brest France Platt J 1998 Sequential minimal optimization A fast algorithm for training support vector machines Microsoft Research Technical Report MSR TR 98 14 Shafer G 1976 A mathematical theory of evidence Princeton University Press Smets P 1990 Constructing the pignistic probability function in a context of uncertainty Uncertainty in Artificial Intelligence 5 29–39 Vapnik V N 1998 Statistical Learning Theory John Wesley and Sons Zadeh L A 1965 Fuzzy sets Information Control 8 338–353 Summary The sonar image classification is of great importance for underwater navigation or for seabed cartography Indeed the sonar is more suitable than optical captors for seabed imagery The classification of such kind of data encounters several difficulties due to the imprecisions and uncertainties present on these data Many approaches were proposed without giving good results they do not take into account the data imperfections To model this kind of data it is judicious to use the uncertain theories like the fuzzy subsets theory or the belief function theory The support vector machines are more and more used for automatic classification due to their simplicity and their generalization capacities Thus it is possible to propose an approach that take into account these imprecisions and uncertainties The regression by SVM approach that we have proposed model these imperfections We propose here an application of this new approach for particularly complex real data in the framework of sonar image classification Introduction Théories de l'incertain Les fonctions d'appartenance Les fonctions de croyance Similitudes Régression floue et crédibiliste par SVM Principe du classifieur SVM Régression floue et crédibiliste par SVM Expérimentations Base de données Extraction de paramètres Modélisation des fonctions floues et crédibilistes Résultats Conclusion 