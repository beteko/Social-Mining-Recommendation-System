articles assemblage pdfInférence Bayesienne du Maximum d’Entropie pour le Diagnostic du Cancer F Dornaika et F Chakik IKERBASQUE Basque Foundation for Science University of the Basque Country San Sebastian Spain fadi_dornaika ehu es LaMA Laboratory Lebanese University Tripoli Lebanon fchakik ul edu lb 1 Introduction et formulation L’objectif de ce papier est de montrer que le principe du Maximum d’Entropie Buck et Macaulay 1991 emanant de la physique peut être utilisé en inférence statistique dans les tâches de classification binaires basées sur les exemples Le Principe du Maximum d’Entropie est une approche systématique pour déterminer empiriquement la fonction de distribution de probabilités à partir de laquelle un ensemble de données a été tiré Nous avons un ensemble d’apprentissage de M couples { −→x m cm } m = 1 M où −→x m est un vecteur que l’on appelle exemple de dimension N dont les composantes peuvent prendre des valeurs binaires ou réelles Les cm indiquent la classe de chaque exemple Nous supposons qu’il y a C classes Dans le cas d’une classification binaire C = 2 La densité de probabilité qui maximise l’en tropie a la forme générale suivante Z est une constante de normalisation P −→x c = 1 Z exp [ − ∑ n λn An −→x c ] 1 où les An −→x c sont des mesures "observables" qui sont fonction du vecteur −→x et de sa classe les λn scalaires ou vecteurs sont à déterminer Si l’on adopte les deux observables suivants i −→A 1 −→x c = c−→x et ii A2 −→x c = −→x 2 on obtiendra une solution analytique pour la densité P −→x c = 1Z exp [ −c−→x · −→λ 1 − λ2 −→x 2 ] Pour la classification binaire on aura c = ±1 −→λ 1 et λ2 sont analytiquement estimés à partir des exemples Chakik et al 2004 Une fois la densité est connue la classification adoptera la règle du Maximum a posteriori MAP 2 Diagnostic du cancer Les exemples de cette application Wolberg et Mangasarian 1990 sont constitués par des vecteurs à 9 dimensions et qui sont classés comme bénins ou malins Nous disposons au RNTI E 19 677 Inférence Bayesienne du Maximum d’entropie total de 683 exemples dont 65 5% sont bénins A partir de cet ensemble nous générons deux ensembles d’apprentissage et de généralisation test Nous avons fixé la taille de l’ensemble d’apprentissage à 525 exemples comme de nombreux auteurs ce qui nous permettra de faire des comparaisons Donc l’ensemble de test est formé par les 158 exemples restants Ainsi nous avons estimé le taux de classification correcte en effectuant 10 partitions l’ensemble de données 10 fold cross validation Les résultats sont tels que l’erreur d’apprentissage moyenne est de 3 37% alors que l’erreur de test moyenne est de l’ordre de 3 04% et dont les variances sont de l’ordre de 0 07 et 2 1 respectivement Ce résultat est légèrement moins bon que les résultats obtenus par NetLines Torres et Gordon 1998 dont l’erreur de test moyen est de l’ordre de 1 6% mais meilleur que Cascade Correlation Depenau 1995 dont l’erreur de test est de 4 4% La figure 1 illustre la sensibilité qui dépend du taux de faux négatifs et la spécificité qui dépend du taux de faux positifs correspondant aux 10 ensembles de test 0 0 2 0 4 0 6 0 8 1 0 0 2 0 4 0 6 0 8 1 Specificity S en si bi lit y Data sets FIG 1 – Graphe représentant la sensibilité et la spécificité correspondant aux 10 ensembles de test Références Buck B et V Macaulay 1991 Maximum Entropy in Action Clarendon Press Oxford Chakik F A Shahin J Jaam et A Hasnah 2004 An approach for constructing complex discriminating surfaces based on bayesian interference of the maximum entropy Interna tional Journal of Information Sciences 163 4 Depenau J 1995 A global local learning architecture for classification In International Neural Network Sociaety Meeting Torres J et M Gordon 1998 Efficient adaptive learning for classification tasks with binary units Neural Computation 10 4 1007–1030 Wolberg W et O Mangasarian 1990 Multisurface method of pattern separation for medical diagnosis applied to breast cytology In National Academy of Sciences Summary In this paper we show that the Maximum Entropy Principle can be used by a Bayesian statistical inference for classification tasks We present an application using benchmark data related to cancer diagnostic Classification comparison is also provided RNTI E 19 678 