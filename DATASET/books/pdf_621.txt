articles assemblage pdfBien cube les données textuelles peuvent s’agréger Sandra Bringay Anne Laurent Pascal Poncelet Mathieu Roche Maguelonne Teisseire LIRMM – CNRS 161 rue Ada Montpellier France {bringay laurent poncelet mroche teisseire} lirmm fr Univ Montpellier 3 CEMAGREF – UMR TETIS maguelonne teisseire cemagref fr Résumé La masse des données aujourd’hui disponibles engendre des besoins croissants de méthodes décisionnelles adaptées aux données traitées Ainsi ré cemment de nouvelles approches fondées sur des cubes de textes sont apparues pour pouvoir analyser et extraire de la connaissance à partir de documents L’ori ginalité de ces cubes est d’étendre les approches traditionnelles des entrepôts et des technologies OLAP à des contenus textuels Dans cet article nous nous inté ressons à deux nouvelles fonctions d’agrégation La première propose une nou velle mesure de TF IDF adaptative permettant de tenir compte des hiérarchies associées aux dimensions La seconde est une agrégation dynamique permet tant de faire émerger des groupements correspondant à une situation réelle Les expériences menées sur des données issues du serveur HAL d’une université confirment l’intérêt de nos propositions 1 Introduction Avec le développement de l’Internet de plus en plus de documents textuels sont dispo nibles Extraire de la connaissance ou analyser et interroger de tels volumes de données est un enjeu important et de nombreux travaux de recherche se sont intéressés à ces problématiques Ainsi par exemple les travaux menés autour de la fouille de textes ont proposé de nouvelles approches pour classer automatiquement des documents Sebastiani 2002 rechercher les nouvelles tendances Saga et al 2009 ou extraire de l’information dans des données tex tuelles Chang et al 2006 Plus récemment de nouvelles approches fondées sur des cubes de textes proposent d’utiliser les technologies OLAP pour analyser et extraire de la connais sance L’un des avantages de ces approches est notamment de pouvoir utiliser des opérateurs comme Roll Up ou Drill Down pour naviguer au travers des hiérarchies et ainsi agréger les données en fonction des requêtes utilisateurs De manière à illustrer les problématiques que nous étudions dans cet article considérons par exemple les documents extraits de dépêches concernant le virus de la grippe A H1N1 En étudiant les différents articles il est aisé de constater que plusieurs catégories de documents peuvent apparaître articles sur le vaccin articles sur de nouveaux cas déclarés articles sur les recommandations ou même articles généraux Dans un processus d’aide à la décision si nous désirons retrouver les mots caractéristiques de chaque catégorie nous pouvons utiliser RNTI E 19 585 Bien cube les données textuelles peuvent s’agréger des entrepôts de données Dans un tel contexte il est indispensable d’extraire pour chacune des catégories les termes les plus représentatifs en tenant compte du fait qu’il peut exister une hiérarchie entre les différentes catégories c à d la catégorie "vaccin" peut être divisée en "vaccin en Europe" "vaccin en Asie" "vaccin aux Etats Unis" etc Dans cet exemple nous considérons qu’il existe une hiérarchie disponible Toutefois une telle connaissance n’est pas forcément aisée à obtenir et sa définition n’est pas toujours caractéristique d’une réalité Par exemple pourquoi établir une distinction entre "vaccin en Europe" et "vaccin aux Etats Unis" Cette distinction est d’autant plus complexe à effectuer lorsque l’utilisateur ne sait pas au préalable qu’il peut exister dans les documents des spécificités propres aux régions Dans cet article notre contribution est double D’une part nous proposons un nouveau modèle de données qui permet de construire un entrepôt de données textuelles afin de répondre aisément aux demandes des décideurs via des requêtes OLAP en tenant compte des hiérarchies existantes D’autre part nous étendons ce modèle à la définition automatique de dimensions générées à partir des documents étudiés sur lesquels le décideur pourra également naviguer Le reste de l’article est organisé de la manière suivante Dans la section 2 nous présentons notre problématique à partir d’une base exemple qui illustrera les différents concepts introduits Dans la section 3 nous décrivons les travaux antérieurs liés à ce contexte La section 4 détaille notre proposition Les expérimentations menées sont décrites dans la section 5 Enfin nous concluons cet article en présentant quelques perspectives 2 Problématique FIG 1 – La hiérarchie associée à l’Enseignement Supposons que nous ayons une hiérarchie liée aux enseignements définie de la manière suivante des enseignants appartiennent à une composante et une université est composée de plusieurs composantes UFR IUT etc La figure 1 décrit une telle représentation dans la quelle Comp1 est composée de quatre enseignants Comp2 est composée de deux enseignants et les deux composantes appartiennent à une même Université Univ1 Sur cette figure les dif férentes descriptions de cours documents textuels associées aux enseignants sont également représentées Nous pouvons ainsi constater sur la figure que l’enseignant e1 est attaché seul à la description d1 d’un cours alors que l’enseignant e2 enseigne avec un autre intervenant d’une autre composante enseignant e5 pour effectuer le cours d3 Nous considérons par la suite qu’un document propre à un enseignement est décrit par un ensemble de mots clés Par exemple le document d5 est décrit par les mots clés m15 m16 m17 m18 et m19 Le tableau 1 décrit les différentes caractéristiques des enseignements RNTI E 19 586 S Bringay et al Doc enseignant composante Univ Liste de mots clés d1 e1 Comp1 Univ1 {m1 m2 m3 m4 m5} d2 e2 Comp1 Univ1 {m6 m7 m8 m9 m10} e3 Comp1 Univ1 d3 e2 Comp1 Univ1 {m6 m7 m8 m11 m12} e5 Comp2 Univ1 d4 e2 Comp1 Univ1 {m6 m13 m14 m11 m10} e4 Comp1 Univ1 d5 e5 Comp2 Univ1 {m15 m16 m17 m18 m19} e6 Comp2 Univ1 TAB 1 – Liste de mots clés d’enseignants et des composantes par document Rappelons que le but de nos travaux est de proposer des mots clés représentatifs en fonction des différents niveaux de hiérarchies existants enseignant composante etc dans un contexte d’entrepôt de données Ces mots clés seront présents dans les cellules de l’entrepôt De manière classique nous pouvons regrouper les enseignants suivant les composantes en appliquant la hiérarchie existante Ceci permet de sélectionner les mots les plus discriminants à mettre en relief pour le décideur Ainsi si nous prenons le niveau "enseignant" nous pou vons constater par exemple que pour le décideur les mots représentatifs pour l’enseignant e2 sont m6 m7 m8 m9 m10 m11 m12 m13 et m14 Par contre si nous nous intéressons au niveau "composantes" nous constatons que les mots représentatifs diffèrent Ainsi notre pre mière contribution dans cet article est d’utiliser et d’adapter des mesures issues du domaine de la Recherche d’Information dans un contexte d’entrepôt de données Ces mesures proposent d’utiliser les connaissances liées à une organisation hiérarchique existante afin de sélectionner les mots clés les plus discriminants en fonction du niveau de la hiérarchie interrogée Considérons à nouveau les différents mots utilisés dans les documents Si nous examinons l’enseignant e1 qui appartient à Comp1 nous pouvons constater qu’il ne partage aucun de ses enseignements avec les membres de sa composante alors que e2 et e5 de composantes diffé rentes partagent par contre des enseignements Notre objectif dans la seconde contribution de cet article est de faire émerger ce type de comportement et donc de permettre au décideur de connaître les regroupements réels des enseignants indépendamment de toute hiérarchie exis tante 3 Travaux Antérieurs Les entrepôts de données ont été introduits au début des années 1990 Codd et al 1993 pour répondre aux besoins grandissants des décideurs Ceux ci souhaitaient alors être munis de bases de données non pas dédiées au stockage robuste de leurs données pour répondre à des requêtes simples et répétitives bases de données transactionnelles mais plutôt à une représentation de leurs données en vue de prendre les meilleures décisions et répondre à des requêtes non répétitives et plus complexes Le modèle multidimensionnel a alors été proposé pour répondre à ce besoin et permet d’étudier un ensemble d’indicateurs ou mesures en fonction de plusieurs dimensions chaque dimension pouvant être munie d’une ou plusieurs RNTI E 19 587 Bien cube les données textuelles peuvent s’agréger hiérarchies Les opérateurs OLAP permettent de naviguer de manière intuitive dans de telles données multidimensionnelles par exemple pour visualiser les données à différents niveaux de hiérarchies Quelques travaux récents se sont intéressés à intégrer les données textuelles dans un contexte d’entrepôt de données Dans ce cadre des méthodes d’agrégation adaptées aux données tex tuelles ont été proposées Par exemple les travaux de Keith et al 2005 proposent d’utiliser des approches de TALN Traitement Automatique du Langage Naturel pour agréger les mots ayant la même racine ou les mêmes lemmes connaissances morpho syntaxiques Les auteurs proposent également de rassembler les mots sur la base de classifications sémantiques généra listes existantes WordNet et Roget Outre l’utilisation de connaissances morpho syntaxiques et sémantiques pour agréger les données textuelles d’autres travaux utilisent des approches numériques issues du domaine de la Recherche d’Information RI pour agréger les données textuelles Pujolle et al 2008 Lin et al 2008 Pérez Martínez et al 2008 Ainsi Lin et al 2008 agrège les documents sur la base des mots clés présents dans ces derniers en uti lisant une hiérarchie sémantique des mots présents dans l’entrepôt et des mesures issues de la RI De telles méthodes issues de la RI sont aussi utilisées dans les travaux de Pérez Martínez et al 2008 qui consistent à prendre en compte une dimension "contexte" et "pertinence" pour construire un entrepôt de données textuelles appelé R Cube Certaines approches proposent d’ajouter une nouvelle dimension spécifique Par exemple dans Zhang et al 2009 les au teurs ajoutent une dimension ’topic’ et appliquent l’approche PLSA Hofmann 1999 pour extraire les thèmes représentatifs des documents dans cette nouvelle dimension Enfin Pu jolle et al 2008 proposent d’agréger des parties de documents afin d’offrir au décideur des mots clés caractéristiques propres à cette agrégation Dans ce cadre les auteurs utilisent une première fonction pour sélectionner les mots clés les plus significatifs en utilisant la mesure TF IDF classique issue du domaine de la RI L’objectif de nos travaux est assez similaire à cette dernière approche Toutefois nous souhaitons étendre la prise en compte de la hiérarchie dans les documents rendus aux décideurs En d’autres termes nous souhaitons ne retourner que les mots clés significatifs par rapport à un niveau donné Par exemple dans le cas des mots clés significatifs leur agrégation Avg Kw qui utilise un TF IDF ne permet de connaître que les mots significatifs pour des chercheurs mais ne permet pas de prendre en compte une hiérarchie existante Pujolle et al 2008 proposent également d’utiliser une ontologie légère Toutefois là aussi l’objectif est différent car ils s’intéressent à la représentation de mots génériques par rapport aux mots du domaine Dans notre cas nous souhaitons extraire les mots clés signifi catifs par rapport à une hiérarchie existante En outre nous souhaitons pouvoir effectuer des regroupements significatifs pour le décideur même s’il n’existe pas de hiérarchie fixe définie 4 Contribution Dans cette section nous présentons notre approche Dans un premier temps nous décrivons le modèle de données utilisé Nous présentons ensuite l’agrégation adaptative selon le niveau existant puis l’agrégation dynamique Pour chacune de ces approches nous présentons tout d’abord le principe général puis nous explicitons sa mise en œuvre RNTI E 19 588 S Bringay et al 4 1 Le modèle de données Dans cette section nous définissons un modèle de données pour représenter les cubes de textes Une table de faits F est définie sur le schéma D = {T Tn M} où Ti i = 1 n correspondent aux dimensions Pérez Martínez et al 2008 et M correspond à une mesure Les différentes mesures utilisées sont décrites dans les sections suivantes Chaque dimension Ti est définie sur un domaine D = dom Ti partitionné en un ensemble de catégories ou niveaux de granularité Cj On a donc D = ∪jCj D doit être muni d’un ordre partiel �D permettant de comparer les valeurs du domaine D Chaque catégorie représente les valeurs associées à un niveau de granularité Nous notons e ∈ D pour préciser que e est une valeur de dimension de D s’il existe une catégorie Cj ⊆ D telle que e ∈ ∪jCj Notons que deux catégories particulières sont distinguées et sont présentes sur toutes les dimensions ⊥D et�D ∈ CD correspondant respectivement au niveau de plus fine et de plus forte granularité Dans le cadre de notre approche l’ordre partiel défini sur les domaines des dimensions correspond à l’inclusion ensembliste des mots clés associés aux valeurs de dimension considérées Ainsi soient deux valeurs e1 e2 ∈ ∪jCj on a e1 �D e2 si e1 est logiquement contenu dans e2 Par exemple la dimension Enseignement de la figure 1 possède les catégories ⊥enseignement = Enseignant ≤ Composante ≤ Universite ≤ �enseignement Les valeurs de dimen sions sont dom Enseignement = {e1 e2 e3 Comp1 Comp2 Univ1 } réparties dans ces catégories niveaux de granularité de la manière suivante Enseignant = {e1 e2 e3} Composante = {Comp1 Comp2} Univ = {Univ1 } L’ordre partiel �D sur les va leurs des dimensions peut bien entendu être généralisé aux catégories pour C1 C2 ∈ CD on a alors C1 ≤D C2 si ∃e1 ∈ C1 e2 ∈ C2 tels que e1 �D e2 Par exemple nous avons e1 �D Comp1 �D Univ1 �D � La prise en compte de hiérarchie dynamique est telle que toutes les catégories de cette dimension doivent respecter l’ordre partiel défini Notre modèle permet de prendre en compte différentes dimensions e g le temps tel que ⊥temps = mois ≤ semestre ≤ année ≤ �temps et bien entendu une dimension corres pondant aux différentes informations extraites des documents Cette dimension est définie de la manière suivante il n’existe pas de hiérarchie sur cette dimension et chaque valeur cor respond aux mots clés associés aux documents Ainsi pour un enseignant donné le contenu d’une cellule correspond à la fréquence d’apparition d’un mot dans un document Par exemple pour l’enseignant e1 elle peut contenir la fréquence d’apparition du mot m1 4 2 Agrégation Adaptative selon le niveau hiérarchique 4 2 1 Présentation générale Dans nos travaux nous nous appuyons sur une hiérarchie originale adaptée aux données textuelles Dans cette hiérarchie les nœuds sont les éléments que nous souhaitons agréger et les feuilles sont les descripteurs mots clés de ces éléments Pour chaque agrégation le but que nous nous fixons est de sélectionner les descripteurs pertinents Cette sélection dépendra du niveau et des nœuds que nous désirons agréger Nous proposons dans ce cas une mesure fondée sur la mesure TF IDF bien connue en Recherche d’Information Nous montrerons dans la section 4 2 2 de quelle manière nous avons adapté cette mesure à la problématique des entrepôts de données Notre approche s’appuie sur l’utilisation d’une hiérarchie du domaine ce qui est relativement classique dans la littérature voir section 3 Cependant l’originalité de RNTI E 19 589 Bien cube les données textuelles peuvent s’agréger notre approche réside dans la méthode d’agrégation qui dépend du niveau traité d’où le nom d’agrégation adaptative Ainsi d’un niveau à l’autre les descripteurs pertinents extraits pour caractériser une cellule de notre entrepôt peuvent se révéler extrêmement différents En reprenant l’exemple que nous avons décrit en section 2 les mots clés pour décrire un IUT par exemple le mot clé "Réseaux" n’est pas toujours adapté pour discriminer les ensei gnements effectués par les intervenants dans une telle composante En d’autres termes un tel mot clé est caractéristique pour décrire un IUT spécialisé par rapport à différentes composantes mais ne permet pas de discriminer les cours d’un IUT "Réseaux et Télécommunication" De la même manière en utilisant une hiérarchie de laboratoires laboratoire équipe chercheur un terme très discriminant pour décrire une équipe par exemple le terme ’data mining’ n’est pas nécessairement pertinent pour distinguer les membres d’une équipe de fouille de données 4 2 2 Méthode mise en œuvre Dans notre processus la première étape consiste à fusionner chaque feuille correspondant aux attentes de l’utilisateur Ceci revient à fusionner les mots de manière booléenne et ou fré quentielle des différents documents Le but de cette étape est de lister tous les mots situés dans les documents correspondant à un niveau donné par exemple "enseignant" "compo sante" "Université" Si l’utilisateur souhaite axer sa recherche au niveau de l’enseignant e les mots clés des articles écrits par e forment le vecteur de cet enseignant Nous pouvons appliquer ce même principe au niveau des composantes Roll up À titre d’exemple en nous appuyant sur la figure 1 et le tableau 1 e2 est associé aux documents d2 et d3 Nous construisons alors un espace vectoriel dont la dimension correspond au nombre de mots rencontrés ou sélectionnés dans l’ensemble des documents Le processus appliqué est illustré dans le tableau 2 qui représente les vecteurs de documents de manière booléenne et fréquentielle Représentation booléenne Mots d2 d3 d4 ens e2 m1 0 0 0 0 m2 0 0 0 0 m6 1 1 1 1 m7 1 1 0 1 m8 1 1 0 1 m9 1 0 0 1 m10 1 0 1 1 m11 0 1 1 1 m12 0 1 0 1 m19 0 0 0 0 Représentation fréquentielle Mots d2 d3 d4 ens e2 m1 0 0 0 0 m2 0 0 0 0 m6 fr 2 6 fr 3 6 fr 4 6 fr 2 6 + fr 3 6 + fr 4 6 m7 fr 2 7 fr 3 7 0 fr 2 7 + fr 3 7 m8 fr 2 8 fr 3 8 0 fr 2 8 + fr 3 8 m9 fr 2 9 0 0 fr 2 9 m10 fr 2 10 0 fr 4 10 fr 2 10 + fr 4 10 m11 0 fr311 fr 4 11 fr 3 11 + fr 4 11 m12 0 fr312 0 fr 3 12 m19 0 0 0 0 TAB 2 – Vecteur de mots clés relatif à l’enseignant e2 À partir des vecteurs constitués nous sélectionnons les termes les plus discriminants par rapport au niveau d’éléments souhaités par exemple les enseignants Pour effectuer une telle RNTI E 19 590 S Bringay et al sélection nous nous appuyons sur la mesure TF IDF que nous adaptons à notre probléma tique Traditionnellement la mesure TF IDF donne un poids plus important aux mots carac téristiques d’un document Salton et al 1975 Ainsi pour attribuer un poids de TF IDF il est nécessaire dans un premier temps de calculer la fréquence d’un terme Term Frequency Celle ci correspond au nombre d’occurrences de ce terme dans le document considéré Ainsi pour le document dj et le terme ti la fréquence du terme dans le document est donnée par l’équation suivante TFi j = ni j∑ k nk j où ni j est le nombre d’occurrences du terme ti dans dj Le dénominateur correspond au nombre d’occurrences de tous les termes dans le document dj La fréquence inverse de docu ment Inverse Document Frequency mesure l’importance du terme dans l’ensemble du corpus Elle consiste à calculer le logarithme de l’inverse de la proportion de documents du corpus qui contiennent le terme et est définie de la manière suivante IDFi = log2 |D| |{dj ti ∈ dj}| où |D| représente le nombre total de documents dans le corpus et |{dj ti ∈ dj}| représente le nombre de documents où le terme ti apparaît c à d ni j �= 0 Enfin le poids s’obtient en multipliant les deux mesures TF − IDFi j = TFi j × IDFi Dans notre cas nous ne calculons pas les termes représentatifs par rapport au nombre de documents mais plutôt par rapport au niveau de granularité souhaité Ainsi dans notre cas la formule représentant un IDF adaptatif est donnée ci dessous IDF ki = log2 |Ek| |{ekj ti ∈ ej}| où |Ek| représente le nombre total d’éléments de type k dans notre exemple k = {Enseignant Composante Université} qui correspond au niveau de la hiérarchie que le décideur souhaite agréger |{ej ti ∈ ej}| est relatif au nombre d’éléments de type k dans lequel le terme ti apparaît Cette mesure permet d’attribuer un poids adapté au niveau d’agrégation décidé par l’utilisateur Ainsi nous calculons ce poids TF IDF ki pour chacun des mots ti Nous pouvons ainsi conserver les n mots ayant les poids les plus élevés Exemple 1 Nous donnons dans la table 3 l’IDF des mots au regard du niveau traité Com posante Enseignant illustré en section 2 Ceci permet de mettre en relief dans la table 4 les mots caractéristiques de chaque niveau Par exemple le mot m10 est assez caractéristique de la composante 1 il ne représente jamais un mot clé de la composante 2 Cependant un tel mot clé est utilisé par de nombreux enseignants e2 e3 e4 il n’est donc pas caractéristique pour décrire l’enseignement effectué par les enseignants de l’Université Enfin pour chaque niveau nous pouvons calculer le TF IDF de chacun des mots Le résultat d’un tel calcul est donné dans la table 5 Pour simplifier la présentation des résultats nous appliquons une fré quence TF de 1 aux mots clés présents ce qui revient à utiliser une représentation booléenne RNTI E 19 591 Bien cube les données textuelles peuvent s’agréger Mot Valeur IDF enseignant m1 log2 6 1 = 2 58 m2 log2 6 1 = 2 58 m6 log2 6 4 = 0 58 m7 log2 6 3 = 1 00 m11 log2 6 3 = 1 00 m12 log2 6 2 = 1 58 Mot Valeur IDF composante m1 log2 2 1 = 1 m2 log2 2 1 = 1 m6 log2 2 2 = 0 m7 log2 2 2 = 0 m11 log2 2 2 = 0 m12 log2 2 2 = 0 TAB 3 – Exemple de calcul de l’IDF à différents niveaux enseignant composante IDF enseignant Mots 2 58 m1 m2 1 58 m12 1 00 m7 m11 0 58 m6 IDF composante Mots 1 m1 m2 0 m6 m7 m11 m12 TAB 4 – Mots discriminants triés au niveau "Enseignant" gauche Mots discriminants triés au niveau "Composante" droite 4 3 Agrégation Dynamique 4 3 1 Présentation générale Dans cette section nous proposons de mettre en place une mesure dynamique afin d’agré ger les éléments Ce problème d’agrégation dynamique est par exemple étudié dans le contexte des taxonomies dynamiques e g Sacco 2000 Le fait de nous appuyer sur les seules connais sances de la hiérarchie ne permet pas toujours une agrégation de qualité représentant une si tuation réelle Par exemple dans le cadre d’une Université un enseignant peut enseigner des cours très différents de la thématique de sa propre composante A contrario les enseignants de deux composantes différentes peuvent se révéler extrêmement proches Dans ce cas nous proposons d’effectuer un regroupement sur la base des données textuelles qui permettent de mieux décrire les éléments à agréger Enseignant TF IDF Enseignant e1 P m1 = 1 × 2 58 = 2 58 P m2 = 1 × 2 58 = 2 58 e2 P m6 = 1 × 0 58 = 0 58 P m7 = 1 × 1 00 = 1 00 e3 P m6 = 1 × 0 58 = 0 58 P m7 = 1 × 1 00 = 1 00 e4 Composante TF IDF Composante composante1 P m1 = 1 × 1 = 1 P m2 = 1 P m6 = 0 P m7 = 0 composante2 P m6 = 1 × 0 = 0 P m7 = 0 P m12 = 0 TAB 5 – TF IDF au niveau "Enseignant" et "Composante" RNTI E 19 592 S Bringay et al 4 3 2 Méthode mise en œuvre De la même manière que l’agrégation adaptative section 4 2 la première étape consiste à fusionner les termes des feuilles c’est à dire les documents Ceci permet de constituer des vecteurs de mots clés pour chaque niveau Enseignant Composante Université en appliquant une représentation de type Salton Salton et al 1975 Notons que nous pouvons sélection ner un nombre donné de mots clés les plus fréquents pour limiter les informations contenues dans l’entrepôt Par la suite nous appliquons une méthode de clustering Jain et al 1999 pour rassembler les éléments qui partagent les mêmes mots Bien entendu le résultat d’agré gation obtenu peut différer du regroupement fondé sur une hiérarchie statique comme nous le montrerons dans nos expérimentations section 5 Les méthodes de clustering que nous utilisons k means dans nos expérimentations s’appuient sur des mesures classiques afin de calculer la proximité entre deux vecteurs Jaccard représentation booléenne cosinus dis tance euclidienne représentation fréquentielle etc Avec les approches de clustering utilisées pour chaque regroupement formé nous obtenons un vecteur moyen Nous sélectionnons alors les mots caractéristiques c’est à dire ayant le poids le plus élevé de ces vecteurs moyens Notons que pour cette représentation dynamique nous pouvons bien sûr accorder des poids booléens fréquentiels ou de type TF IDF pour construire nos vecteurs Notons que l’agrégation désagrégation des éléments pour effectuer une analyse de type OLAP peut s’effectuer par la variation du paramètre k de l’algorithme de clustering appli qué ici k means En effet le fait de choisir le nombre de groupes à obtenir permet d’agré ger désagréger Drill down et Roll up les éléments pour une meilleure analyse Exemple 2 En considérant l’exemple précédent nous effectuons un regroupement fondé sur un algorithme de type k means en appliquant différentes valeurs de k nombre de regrou pements différent Les résultats des regroupements avec les vecteurs moyens associés sont donnés dans les tableaux 6 et 7 Lorsque nous utilisons le même nombre de groupes que la hié rarchie statique deux composantes nous remarquons que le regroupement proposé par notre algorithme est différent cf tableau 6 Ce regroupement reflète davantage la réalité propre aux cours donnés par les enseignants Avec la hiérarchie statique nous avons Classe 1 = {e1 e2 e3 e4} Classe 2 = {e5 e6} alors que pour la hiérarchie dynamique Classe 1 = {e1} Classe 2 = {e2 e3 e4 e5 e6} En effet le regroupement formé met en exergue le fait que l’enseignant e1 est isolé par rapport à sa propre composante Les vecteurs moyens des groupes sont donnés dans le tableau 6 Pour chaque regroupement formé nous retenons n mots clés représentatifs c’est à dire ayant le score le plus élevé À titre d’exemple le mot le plus représentatif du groupe formé des enseignants {e2 e3 e4 e5 e6} est le mot clé m6 Ce dernier a un poids de 0 8 le mot m6 est utilisé pour décrire les cours de 4 enseignants sur les 5 du groupe formé dynamiquement 5 Expérimentations De manière à évaluer notre proposition différentes expérimentations ont été réalisées Les données utilisées correspondent à des articles publiés dans un laboratoire LIRMM sur l’an née 2009 305 articles et référencés dans la base de données HAL archive ouverte pluridis ciplinaire Dans ce contexte nous utilisons une hiérarchie dont l’élément le plus élevé est le RNTI E 19 593 Bien cube les données textuelles peuvent s’agréger Mots 0 1 m1 0 1 m2 0 1 m3 0 1 m4 0 1 m5 0 1 m6 0 8 0 m7 0 6 0 m8 0 6 0 m9 0 4 0 m10 0 6 0 m11 0 6 0 m12 0 4 0 m13 0 4 0 m14 0 4 0 m15 0 4 0 m16 0 4 0 m17 0 4 0 m18 0 4 0 m19 0 4 0 Mots 0 1 2 3 m1 0 1 0 0 m2 0 1 0 0 m3 0 1 0 0 m4 0 1 0 0 m5 0 1 0 0 m6 1 0 1 0 5 m7 0 0 1 0 5 m8 0 0 1 0 5 m9 0 0 1 0 m10 1 0 1 0 m11 1 0 0 5 0 5 m12 0 0 0 5 0 5 m13 1 0 0 5 0 m14 1 0 0 5 0 m15 0 0 0 1 m16 0 0 0 1 m17 0 0 0 1 m18 0 0 0 1 m19 0 0 0 1 Mots 0 1 2 3 4 m1 0 1 0 0 0 m2 0 1 0 0 0 m3 0 1 0 0 0 m4 0 1 0 0 0 m5 0 1 0 0 0 m6 1 0 1 0 5 1 m7 0 0 1 0 5 1 m8 0 0 1 0 5 1 m9 0 0 1 0 1 m10 1 0 1 0 1 m11 1 0 1 0 5 0 m12 0 0 1 0 5 0 m13 1 0 1 0 0 m14 1 0 1 0 0 m15 0 0 0 1 0 m16 0 0 0 1 0 m17 0 0 0 1 0 m18 0 0 0 1 0 m19 0 0 0 1 0 TAB 6 – Utilisation de l’algorithme k means de Weka pour différentes valeurs de k 2 groupes gauche 4 groupes centre 5 groupes droite N Instances 0 5 83% 1 1 17% N Instances 0 1 17% 1 1 17% 2 2 33% 3 2 33% N Instances 0 1 17% 1 1 17% 2 1 17% 3 2 33% 4 1 17% TAB 7 – Les différents regroupements obtenus pour 2 groupes gauche 4 groupes centre 5 groupes droite Les instances correspondent au nombre d’éléments enseignants présents dans chaque groupe laboratoire qui possède plusieurs équipes Ces dernières sont composées de chercheurs Les documents traités correspondent aux résumés d’articles Le but de nos expérimentations est de comparer les agrégations effectuées en utilisant une hiérarchie statique section 4 2 ou dy namique section 4 3 Par manque de place nous ne nous focalisons ici que sur l’agrégation dynamique Dans un premier temps nous appliquons l’étiqueteur grammatical TreeTagger1 sur notre corpus afin de ne retenir que les noms extraits à partir des résumés d’articles Pour chaque document nous retenons les m m = 10 20 30 mots clés ayant le plus grand nombre d’occurrences et constituons des vecteurs associés à chaque document Les résultats reportés ici concernent un sous ensemble du laboratoire 3 équipes repré sentant 84 chercheurs Ce sous ensemble nous permet d’analyser manuellement les résultats obtenus qui sont synthétisés dans le tableau 8 Nous pouvons alors comparer le regroupement dynamique par rapport à un rassemblement fixé par une hiérarchie existante Nous avons mené nos expérimentations en faisant varier le nombre m de mots sélectionnés pour caractériser un chercheur Par ailleurs nous faisons varier le nombre de clusters formés Les résultats du 1 ims uni stuttgart de projekte corplex TreeTagger RNTI E 19 594 S Bringay et al m 10 20 30 k=2 1 NSG 11 instances 1 NSG 11 instances 1 NSG 11 instances 1 RG 73 instances 1 RG 73 instances 1 RG 73 instances k=3 2 NSG 11 et 7 instances 2 NSG 11 et 3 instances 2 NSG 11 et 3 instances 1 RG 66 instances 1 RG 70 instances 1 RG 70 instances k=4 3 NSG 11 7 1 instances 4 NSG 3 NSG 11 8 2 instances 1 RG 65 instances 42 28 11 3 instances 1 RG 63 instances k=5 4 NSG 11 7 3 1 instances 5 NSG 4 NSG 11 8 7 2 instances 1 RG 62 instances 34 28 11 8 3 instances 1 RG 56 instances TAB 8 – Modification des groupes proposés par l’agrégation dynamique algorithme k means selon différentes valeurs de k NSG formé = Nouveau Sous Groupe formé RG = Ras semblement de groupes tableau 8 montrent que les groupes formés automatiquement sont assez différents de la ré partition réelle des chercheurs dans différentes équipes L’analyse manuelle montre que de nombreux sous groupes spécifiques sont formés ces derniers représentent des ensembles de chercheurs travaillant sur un sous thème des trois équipes de recherche À titre d’exemple avec k = 3 et un nombre m = 20 de mots sélectionnés un cluster de 3 individus est créé Celui ci correspond à trois chercheurs qui travaillent sur une thématique de "fouille de textes" dans une équipe ayant un axe de recherche plus général Les autres expérimentions menées avec l’en semble des 511 chercheurs répertoriés dans les archives HAL 2009 du laboratoire confirment ces observations Ainsi l’application d’une agrégation dynamique en fixant par exemple la di mension propre à l’année permet de mettre en relief des informations nouvelles et intéressantes pour les décideurs Comparativement à une représentation classique notre entrepôt de données textuelles né cessite de stocker m mots par document Ce choix du paramètre m expérimenté dans cette section aura une influence importante quant à la taille finale de notre entrepôt de textes No tons qu’après avoir effectué les agrégations un sous ensemble de ces mots sera retourné à l’utilisateur 6 Conclusion Dans cet article nous avons proposé deux nouvelles fonctions afin d’agréger des données textuelles d’un entrepôt Nos fonctions permettent de proposer au décideur les mots les plus significatifs issus de ces agrégations La première fonction s’appuie sur une mesure issue de la Recherche d’Information que nous avons étendue afin de prendre en compte les informations d’une hiérarchie existante La seconde fonction proposée effectue une agrégation dynamique sur la base d’algorithmes de clustering Nos expérimentations ont montré que les agrégations effectuées en utilisant ces deux types de fonctions se révèlent différentes ce qui permet d’ap porter des informations originales à partir des données textuelles de notre entrepôt Dans nos futurs travaux nous souhaitons appliquer et expérimenter ces méthodes d’agrégation pour des données particulières telles que les données d’opinions Ceci demandera une recherche de des cripteurs linguistiques plus précis syntagmes adjectivaux par exemple pour caractériser les données textuelles RNTI E 19 595 Bien cube les données textuelles peuvent s’agréger Références Chang C H M Kayed M R Girgis et K F Shaalan 2006 A survey of web information extraction systems IEEE Trans Knowl Data Eng 18 10 1411–1428 Codd E S Codd et C Salley 1993 Providing olap on line analytical processing to user analysts An it mandate In White Paper Hofmann T 1999 Probabilistic latent semantic analysis In In Proc of Uncertainty in Artificial Intelligence UAI’99 pp 289–296 Jain A K M N Murty et P J Flynn 1999 Data clustering A review ACM Comput Surv 31 3 264–323 Keith S O Kaser et D Lemire 2005 Analyzing large collections of electronic text using olap Technical Report TR 05 001 UNBSJ CSAS Lin C X B Ding J Han F Zhu et B Zhao 2008 Text Cube Computing IR Measures for Multidimensional Text Database Analysis In In Proc of Int Conf on Data Mining ICDM’08 pp 905–910 Pérez Martínez J M R B Llavori M J A Cabo et T B Pedersen 2008 Contextualizing data warehouses with documents Decision Support Systems 45 1 77–94 Pujolle G F Ravat O Teste et R Tournier 2008 Fonctions d’agrégation pour l’analyse en ligne olap de données textuelles fonctions top_kwk et avg_kw opérant sur des termes Ingénierie des Systèmes d’Information 13 6 61–84 Sacco G 2000 Dynamic taxonomies A model for large information bases IEEE Transac tions on Knowledge and Data Engineering 12 3 468–479 Saga R H Tsuji et K Tabata 2009 Loopo Integrated text miner for fact graph based trend analysis In HCI 9 pp 192–200 Salton G A Wong et C S Yang 1975 A vector space model for automatic indexing Commun ACM 18 11 613–620 Sebastiani F 2002 Machine learning in automated text categorization ACM Comput Surv 34 1 1–47 Zhang D C Zhai et J Han 2009 Topic cube Topic modeling for olap on multidimensional text databases In In Proc of the SIAM Int Conference on Data Mining pp 1123–1134 Summary With the development of the Internet the amount of textual information grows explosively and it is more and more desirable to provide the end user with new tools for analysing and extracting knowledge from such amount of data Recently new approaches have been defined in order to enhance tradionnal Datawarehouse and OLAP technologies by handling text doc uments In this paper we focus on two new aggregative functions The former is based on an extension of the classical TF IDF measure to take into account existing hierarchies The latter proposes to dynamically define a hierarchy in order to emphasize real situation extracted from texts Experiments conducted on articles stored in the HAL repository show the efficiency of our proposals RNTI E 19 596 