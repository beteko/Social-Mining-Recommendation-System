détection données aberrantes partir motifs fréquents énumération exhaustive arnaud giacometti arnaud soulet université françois rabelais tours campus blois 41000 blois prenom tours résumé détection données aberrantes outliers consiste détecter observations anormales données durant dernière décennie méthodes détection outliers utilisant motifs fréquents proposées elles extraient première phase motifs fréquents assignent chaque transaction score mesurant degré aberration fonction nombre motifs fréquents couvre article proposons nouvelles méthodes calculer score aberration fondé motifs quents première méthode retourne exact chaque transac extraire moindre motif cette méthode avère temps polynomial rapport taille données seconde méthode méthode approchée utilisateur final contrôler erreur maximale estimation étude expérimentale montre intérêt méthodes données volumineux approche exhaustive échoue calculer solution exacte nombre motifs précision notre méthode approchée meilleure celle méthode classique introduction détection données aberrantes consiste détecter observations anormales données hawkins problème détection données aberrantes importantes applications telles détection fraudes bancaires intrusions réseau récemment méthodes détection données aberrantes proposées catégorielles utilisant concept motifs fréquents koufakou approches considérer nombre motifs quents couvrant chaque observation probable observation couverte grand nombre motifs fréquents donnée aberrante puisque motifs fréquents respondent caractéristiques communes données méthodes détection extraient abord motifs fréquents données ensuite attribuent chaque observation score mesurant degré aberration comptabilisant motifs fréquents contient méthodes détection données aberrantes suivent schéma étapes motifs locaux modèle global méthodes étapes knobbe visent extraire exhaustivement motifs locaux données première étape construire modèles globaux détection données aberrantes partir motifs fréquents deuxième étape comme classifieurs mesures calculées partir motifs exemple exhaustivité première phase souvent considérée comme avantage crucial construire modèles calculer mesures qualité cependant complétude extraction première étape oblige ajuster seuils extractions constitue difficulté reconnue seuils extraction devient irréalisable seuils élevés certains motifs pourtant essentiels manqués enfin exhaustivité conduit énormes volumes motifs budget équivalent temps nombre motifs méthodes exhaustives peuvent produire collections mieux adaptées construction modèle seconde étape manière intéressante méthode exhaustive garantir certaine qualité deuxième étape article revisite calcul frequent pattern outlier factor utilisant thodes exhaustives échantillon utilisé voire aucun motif proposons abord méthode calculer exact chaque transaction etonnamment notre méthode énumérative aucun motif généré fortiori également méthode exhaustive reformulons opérant directement paires transactions cette méthode calcule temps polyno nombre transactions nombre items données expériences montrent cette méthode parvient calculer exact données approche habituelle échoue ensuite proposons également méthode approchée exploite échantillon motifs collection complète motifs fréquents lisant inégalité bennett cette méthode sélectionne taille échantillon manière garantir erreur maximale confiance donnée expériences montrent efficacité cette méthode erreur maximale réduite travaux relatifs article concentrons méthodes détection données rantes motifs fréquents koufakou large détection données aberrantes exemple disponible méthodes fondées motifs bénéficient progrès extraction réalisés cours dernières décennies méthodes double intérêt elles adaptées gérer données catégorielles contrairement plupart autres méthodes dédiées données numériques elles restent également opéra tionnelles espaces grande dimension première approche introduit score aberration fondé motifs fréquents frequent pattern outlier factor exploite collection complète motifs fréquents utilise approche opposée considérant itemsets fréquents récemment koufakou remplacé collection motifs fréquents représentation condensée motifs dérivables compacte moins coûteuse extraire aimerions montrant proposée calculé extraire moindre motif extrayant échantillon réduit récemment résurgence domaine extraction motifs méthodes exhaustives travers échantillonnage motifs boley échan tillonnage motifs accéder espace motif procédure échantillonnage giacometti soulet trans items trans items trans items trois données légères variations efficace simuler distribution définie rapport certaine mesure intérêt constante normalisation cadre algorithmes exemple détaillés boley cette façon utilisateur dispose accès rapide direct ensemble langage motifs paramètre éventuellement taille échantillon échantillonnage motifs introduit faciliter exploration données interactive leeuwen article étudions utilisation échantillonnage motifs assigner chaque transaction budget inférieur celui méthode exhaustive obtient qualité finale élevée erreur contrôlable détecter données aberrantes motifs fréquents définitions ensemble littéraux distincts appelés items itemset motif ensemble langage itemsets correspond données sactionnel multi ensemble itemsets chaque observation données appelée transaction exemple tableau donne trois exemples données transactionnels comportant transactions décrites items couverte motifs avantage mesures intérêt évaluer pertinence motifs exemple support motif données proportion sactions couvertes agrawal motif fréquent quand support excède seuil minimal défini utilisa ensemble motifs fréquents seuil suite manipulons multi ensembles motifs collections admettant plusieurs occurrences motif représentativité multi ensemble motifs dénotée somme supports chacun motifs domaine variation représentativité élevée multi ensemble motifs cardinalité fixée signifie contient motifs communs données comparer contenu multi ensembles motifs utilisons jointure dénotée retourne motifs apparaissant exemple détection données aberrantes partir motifs fréquents frequent pattern outlier factor intuitivement transaction représentative données lorsqu contient nombreux motifs fréquents données inverse donnée aberrante contient seulement quelques motifs fréquence plutôt basse frequent pattern outlier factor formalise cette intuition forme mesure définition frequent pattern outlier factor transaction défini manière suivante domaine variation signifie transaction repré sentative données tandis signifie transaction donnée aberrante autres normalisations possibles modifiant dénominateur comme normalisation choisie transactions restent ordon manière similaire affecte kendall utilisons suite évaluer notre méthode noter modélisation markovienne lyste score correspond proportion temps analyste dédiera transaction suite étude motifs giacometti premier données tableau couverte tandis seulement couverte support ainsi exemple semble donnée aberrante facile augmentation fréquence motifs couvrant premières transactions décroît encore manière similaire augmentation nombre motifs couvrant premières transactions décroît aussi formulation problème notre contexte détection données aberrantes consiste calculer chaque transaction problème problème exact etant donné donnéesd calculer chaque transaction pratique calcul exact réalisé extrayant motifs apparaissant moins données cette tâche coûteuse faisable données volumineux place approché collection motifs fréquents correspondant seuil minimal support supérieur définition exhaustif etant donné seuil minimal support exhaustif transaction défini manière suivante fpofσ giacometti soulet minimal support threshold chess connect mushroom pumsb 10000 100000 minimal support threshold chess connect mushroom pumsb kendall nombre motifs seuil minimal support approximation devient précise lorsque seuil minimal support devient trace partie gauche kendall fpofσ comparé plusieurs données malheureusement quand seuil minimal support devient faible nombre motifs partie droite figure temps extraction explose ailleurs telle approche donne aucune estimation erreur commise moindre nombre motifs temps affirmons possible obtenir meilleure approximation ayant borne maximale erreur kendall varie irrégulièrement selon données seuil support minimal fixer seuil obtenir bonne efficacité bonne qualité cette raison paraît intéressant utilisateur erreur maximale tolère résultat plutôt seuil méthode calcul problème problème approché etant donné données réels trouver fonction approximant chaque transaction confiance problème particulier problème fixant méthode énumérative exacte cette section traite problème calculer transaction défini formule représentativité terme support motifs apparaissant reformuler cette mesure considérant chaque transaction apporte transac exemple données première transaction repose chaque ensemble résulte intersection motifs couvrant couvrant autre transaction cette manière proportion paires transactions ordonnées manière appro exact section définition formelle détection données aberrantes partir motifs fréquents algorithm méthode énumérative exacte input données output calculé chaque transaction initialiser normaliser return cette observation coeur propriété dessous propriété reformulation etant donné données reformulé manière suivante chaque transaction preuve soitd données etant donné définissons sinon chaque transaction obtenons injectant cette équation définition prouve propriété correcte point conceptuel intéressant noter finalement transaction juste somme similarité chacune transactions similarité entre cette mesure assez proche méthodes traditionnelles utilisant distance entre paires données manière intéressante formule propriété calculée simple double boucle algorithme conséquent premier résultat important article montrer problème résolu temps polynomial contraire avait envisagé littérature propriété complexité toutes transactions calculé temps manque place cette preuve plusieurs autres omises notre connaissance notre proposition première méthode calculer temps polynomial moins données volumineux notamment beaucoup transactions cette complexité reste élevée alors recourir méthodes approchées résultat obtenu rapidement giacometti soulet méthode exhaustive approchée cette section traite problème exploitant échantillonnage motifs commen proposons méthode approximer partir échantillon motifs selon support montrons alors comment choisir taille échantillon manière contrôler erreur maximale echantillonnage motifs section avons utilisation motifs fréquents insuffi sante approximer précision mesurent singularité chaque transaction repose aussi motifs spécifiques support varie faible moyen inversement considérer motifs fréquents serait aussi erreur contribuent significativement approche raisonnable sélectionner motifs aléatoirement probabilité proportionnelle poids calcul typiquement données tableau itemset important itemset calcul cause fréquence respective dernières années techniques échantillonnage proposées tirer toirement motifs proportionnellement fréquence boley telles proches idéales apporter collection adaptée motifs reste tâche triviale approximer partant cette collection définition échantillonné etant donné entier échantillon transaction défini manière suivante fpofk échantillon motifs tirés selon support important noter utilisé place comme définition comme technique échantillonnage tient compte fréquence quand motifs nécessaire impliquer support nouveau effet tirage considéré remise approximation correcte cette remise motifs fréquents seraient désavantagés tirage remise induit motif avoir plusieurs occurrences échantillon taille échantillon transaction possible calculer différentes valeurs échantillonné cause échantillon varie seuil élevé moins écart entre différentes valeurs issues échan tillons différents élevé ailleurs taille échantillon grande meilleure approximation propriété convergence etant donné données échantillonné converge toutes transactions preuve signifie existe constante αsupp ensuite chaque transaction obtenons détection données aberrantes partir motifs fréquents algorithm méthode exhaustive approchée input données confiance borne output échantillonné toutes transactions erreur bornée confiance while ajouter motif échantillon argmaxu sélectionner transaction forte représentativité estimer erreur maximale estimer erreur maximale return αsupp injectant résultat définition concluons propriété correcte convergence intérêt cette approche rapidité convergence supérieure celle exhaustif comme montre étude expérimentale section cette rapidité accompagne bonne efficacité pratique grâce complexité raisonnable échantillonnage motifs propriété complexité échantillonné calculable tempso etant donné nombre motifs échantillonné ainsi efficace calculer cependant choix seuil difficile essentiel obtenir approximation désirée comme suggéré problème section suivante présente méthode itérative éviter choix seuil utilisateur majoration erreur cette section montre comment déterminer taille échantillon calculer échantillonné satisfaisant paramètres spécifiés utilisateur erreur maximale confiance donnée tirer échantillon motifs estimer erreur maximale utilisant résultat statistique appelé inégalité bennett calculée inférieure celle souhaitée utilisateur algorithme retourne échantillonné grâce échantillon courant sinon algorithme augmente taille échan tillon tirant nouveau motif ainsi suite utilisons inégalité bennett estimer erreur courante échantillon résultat statistique indépendamment toute distribution après observations pendantes variable aléatoire comprise inégalité bennett garantit confiance vraie moyenne moins respecti vement moyenne variance observée échantillon giacometti soulet notre variable aléatoire nombre moyen motifs contenus échan tillon couvre transaction notée covsk définie mellement ainsi covsk facile réécrire échantillonné partir covsk fpofk covsk covsk inégalité bennett cette définition permet borner exact propriété bornes échantillonné etant donné confiance échantillonné transaction borné manière suivante covsk covsk covsk covsk argmaxv covsk algorithme retourne approché chaque transaction garantissant erreur maximale inférieure confiance boucle principale itère jusqu erreur maximale estimée inférieure seuil souhaité lignes calculent cette erreur maximale utilisant propriété erreur maximale dessous ligne retourne échantillonné échantillon courant sinon motif supplémentaire ligne comme désiré problème algorithme contrôle approximation ensemble transactions propriété justesse etant donné données confiance borne algorithme retourne échantillonné chaque transaction approximant erreur majorée confiance etude expérimentale cette étude expérimentale objectif comparer vitesse notre méthode énumérative exacte méthode exhaustive exacte aussi estimer qualité notre méthode approchée exhaustive méthode exhaustive manque place considérons nouvelles expériences montrant intérêt détecter données aberrantes comme aspect largement détaillé littérature koufakou expérimentations conduites données provenant machine learning repository repository tableau donne caractéristiques données premières colonnes expérimentations réalisées linux processeur mémoire chaque mesure reportée moyenne arithmétique mesures répétées méthode énumérative exacte tableau reporte temps exécution requis calculer exact utilisant méthode exhaustive exhaustive méthodes enumérative exacte approchée colonnes important noter méthode exhaustive bénéficie implémentation originale particulièrement reconnue repository méthode enumérative exacte efficace rivalise approche exhaustive détection données aberrantes partir motifs fréquents approchée chess connect mushroom pumsb retail temps exécution méthodes exactes méthode approchée minimal support threshold chess connect mushroom pumsb minimal support threshold chess connect mushroom pumsb erreur exhaustif échantillonné rapport atout principal garantir calcul exact données méthode exhaustive échoue pumsb exécution arrêtée après particulier méthode exacte énumérative efficace données denses complexité indépendante nombre motifs méthode exhaustive approchée cette section compare notre méthode échantillonnage approximer approche exhaustive comme référence utilisons kendall comparer ordre chaque méthode approchée ordre calculé grâce méthode exacte manière avons aussi calculé erreur moyenne transaction partie gauche figure trace différence entre kendall échantillonné celui exhaustif quand courbe dessus gnifie ordre échantillonné meilleur celui exhaustif partie droite reporte erreur moyenne échantillonné divisée celle exhaustif quand courbe dessus signifie erreur moyenne giacometti soulet 10000 100000 maximal error chess connect mushroom pumsb retail maximal error chess connect mushroom pumsb retail nombre motifs erreur réelle selon erreur maximale échantillonné petite celle exhaustif chaque point seuil nimal support utilisé comme paramètre méthode exhaustive temps taille échantillon fixée nombre motifs extraits correspondant seuil support échantillonné clairement précis exhaustif budget motifs quand celui augmente diminution seuil minimal support certains données chess différence toujours positive ratio erreurs moyennes montre notre approche échan tillonnage meilleure approximation notamment quand nombre motifs devient grand figure trace nombre motifs erreur réelle méthode approchée variant borne comme attendu erreur autorisée petite nombre motifs requis échantillon élevé conséquent temps exécution intéressant noter notre méthode approchée souvent rapide méthodes exactes tableau enfin erreur moyenne réelle transaction méthode approchée toujours inférieure celle souhaitée exemple donne erreur réelle inférieure écart résulte inégalité bennett aucune hypothèse distribution conclusion avons revisité calcul extrayant moins possible motifs voire aucun malgré cette contrainte notre proposition méthode exacte complexité mieux adaptée certains grands données notre méthode approchée utilisant technique échantillonnage apporte garanties supplémentaires résultat bornant erreur expérimentations montré intérêt approches terme rapidité précision rapport méthode traditionnelle maximum motifs extraits grâce échantillonnage notre proposition combine puissance éprouvée thodes fondées motifs ajoutant garantie supplémentaire qualité résultat sacrifier vitesse pensons étendue autres mesures impliquant motifs modèles composés motifs voudrions aussi adapter notre approche détection données aberrantes partir motifs fréquents construire algorithmes anytime consiste étendre échan tillon motifs indéfiniment jusqu utilisateur final souhaite interrompre processus algorithme retourne alors obtenu échantillon courant erreur estimée remerciements travail partiellement soutenu projet préfute références agrawal srikant algorithms mining association rules large bases volume boley lucchese paurat gärtner direct local pattern sampling efficient random procedures sigkdd international conference knowledge discovery mining giacometti soulet balancing analysis frequent patterns advances knowledge discovery mining springer hawkins identification outliers volume springer huang outlier frequent pattern based outlier detection computer science information systems knobbe crémilleux fürnkranz scholz local patterns global models approach mining local patterns global models proceedings workshop koufakou secretan georgiopoulos derivable itemsets detection large dimensional categorical knowledge information integrating classification association mining international conference knowledge discovery mining contrast pattern based clustering quality index catego rical pattern recognition ghoting parthasarathy distributed outlier detection mixed attribute mining knowledge discovery leeuwen interactive exploration using pattern mining interactive knowledge discovery mining biomedical informatics springer summary outlier detection consists detecting anomalous observations recently outlier detection methods proposed frequent patterns order compute outlier factor transaction paper provides exact approximate methods calculating frequent pattern outlier factor without exhaustive enumeration propose algorithm returns exact without mining pattern present approximate method where controls maximum error estimated study shows interest methods large datasets where exhaustive mining fails provide exact solution accuracy approximate method outperforms baseline approach