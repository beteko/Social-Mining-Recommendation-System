final_paper_france.PDF Extraction du texte Résumé Utilisation de l'indexation sémantique et Latent Information Retrieval Technique: Comparaison des quatre stratégies Bellaachia * Abdelghani, Anand Mahajan * * Département Informatique Université George Washington Washington DC, 20052 bell@gwu.edu http: //seas.gwu .edu / ~ cloche Résumé. Dans cet article, nous présentons quatre techniques de résumé de texte générique. Chaque technique extrait un résumé de texte par le classement et l'extraction des phrases à partir d'un document original. La première méthode, SUMMARIZER 1, utilise recherche d'information des méthodes standard (IR) à des peines de rang. La deuxième méthode, SUMMARIZER 2, utilise la technique d'analyse sémantique latente (LSA) pour identifier les phrases sémantiquement importantes, pour les créations sommaires. La troisième méthode, SUMMARIZER 3, utilise une combinaison de la technique d'analyse sémantique latente, la réduction et la mesure de pertinence. La quatrième méthode utilise simplement la TF * IDF (fréquence de durée * de fréquence de document inverse) schéma de pondération. Les évaluations des quatre méthodes est utilisé dans des conférences Comprendre le document (CIC) des ensembles de données du NIST. Nous avons comparé le résumé de chaque méthode avec les résumés manuels. Summarizer 4, avec ses frais généraux plus bas, a des performances comparables à summarizer 1. L'analyse montre qu'une combinaison de technique LSA et la mesure de pertinence (summarizer 3) a la meilleure performance moyenne. 1. Introduction La vitesse et l'ampleur de la diffusion de l'information ont considérablement augmenté avec la croissance explosive du web dans le monde entier. En utilisant des techniques de récupération d'informations classiques (IR) pour trouver des informations pertinentes efficacement dans une vaste mer de documents texte accessible sur Internet, est devenu de plus en plus insuffisante. Les moteurs de recherche de texte servent de filtres d'information qui passer au crible une première série de documents pertinents. Leur approche par mots-clés récupère des millions de visites par lequel l'utilisateur est submergé. Par conséquent, il est nécessaire de techniques d'identifier rapidement les documents les plus pertinents. Summarizers texte peuvent être utilisés pour aider les utilisateurs à identifier ensemble final des documents pertinents. Recherche de texte et deux technologies sont summarization essentielles qui se complètent mutuellement. Présenter à l'utilisateur un résumé de chaque document facilite grandement la tâche de trouver les documents souhaités. Les objectifs de Summarizers texte peuvent être classés selon leur intention, et de la couverture mise au point [MCDONALD ET AL.]. Intention fait référence à l'utilisation potentielle du résumé. Firmin et texte Résumé Utilisation de l'indexation sémantique et Latent recherche d'information technique RNTI - E - 2 Chrzanowski diviser l'intention un résumé en trois catégories principales [ET FIRMIN CHRZANOWSKI, 1999]: - indicatif -, informatif et - évaluative. résumés indicatifs donnent une indication sur le thème central du texte original ou suffisamment d'informations pour juger la pertinence du texte. des résumés d'information peuvent servir de substituts pour les documents complets. résumés évaluatives expriment le point de vue de l'auteur sur un sujet donné. Mise au point fait référence à la portée du résumé, si générique ou requête pertinente. Enfin, la couverture fait référence au nombre de documents qui contribuent au résumé, si le résumé est fondé sur un seul document ou plusieurs documents. des résumés de texte peuvent être des résumés aux requêtes ou des résumés génériques [Gong et Liu, 2001]. Création d'un résumé de requête pertinente est un processus de récupération des phrases pertinentes de requête à partir du document et peut être facilement atteint par l'extension des technologies classiques IR. Comme ils sont « requête biaisées », ils ne fournissent pas un sens global du contenu du document. Cependant, un résumé générique donne un sens global du contenu du document et détermine dans quelle catégorie il appartient. Un bon résumé générique doit contenir les principaux thèmes du document tout en gardant la redondance au minimum. Puisque ni requête, ni le sujet est fourni au summarizatio n processus, il est tout un défi de développer une méthode de générique de haute summarization qualité. Dans cet article, nous présentons quatre méthodes de résumé de texte générique. Chaque méthode crée un résumé de texte par le classement et l'extraction des phrases à partir d'un document original. La première méthode, SUMMARIZER 1, utilise recherche d'information des méthodes standard (IR) à des peines de rang. La deuxième méthode, SUMMARIZER 2, utilise la technique d'analyse sémantique latente (LSA) pour identifier les phrases sémantiquement importantes, pour les créations sommaires. La troisième méthode, SUMMARIZER 3, utilise une combinaison de la technique d'analyse sémantique latente, la réduction et la mesure de pertinence. La quatrième méthode utilise simplement le TF * schéma de pondération IDF. Nous avons également comparé les performances de toutes ces méthodes à l'aide des conférences Comprendre le document (CIC) des ensembles de données du NIST. L'article est organisé de la manière suivante. La section suivante décrit les travaux connexes. La section 3 présente les quatre méthodes de compression. Les évaluations de rendement sont présentés à la section 4. Enfin, la section 5 conclut le document. 2. Travaux connexes Summarization est une tâche difficile traitement du langage naturel. Il nécessite une analyse sémantique, le traitement et l'interprétation du discours déductif (regroupement du contenu en utilisant les connaissances du monde). Les tentatives d'exécution véritable abstraction - création de résumés comme des résumés - n'ont pas été très réussie. programmes d'abstraction texte produisent des phrases grammaticales qui résument les concepts d'un document. Les concepts dans un résumé sont souvent considérés comme ayant été comprimé. Alors que la formation d'un résumé peut mieux répondre à l'idée d'un résumé, sa création implique une plus grande complexité et la difficulté [Hovy et Lin, 1998]. Heureusement, cependant, une approximation appelée extraction est plus réalisable aujourd'hui. Pour créer un extrait, un système a besoin simplement d'identifier les plus importants / actualité / thème central (s) du texte Résumé Utilisation de l'indexation sémantique et Latent recherche d'information technique RNTI - E - 2, le texte et les retourner au lecteur. Un reste sommaire extrait plus proche du document original, en utilisant des phrases du texte, limitant ainsi le biais qui pourrait autrement apparaître dans un résumé [LUHN, 1958]. Bien que le résumé est pas nécessairement cohérente, le lecteur peut se faire une opinion du contenu de l'original. La plupart des systèmes automatisés de récapitulation extraits produisent aujourd'hui seulement. La majorité des études de recherche ont été mis l'accent sur la création de résumés de texte requête pertinente. SUMMARIST est une tentative de développer une technologie d'extraction robuste [Hovy et Lin, 1998]. Elle produit des résumés d'extrait en cinq langues (et a été liée aux moteurs de traduction pour ces langues dans le système MUST). SUMMARIST est basée sur la « équation » suivante: Summarization = Identification + Sujet + interprétation génération. Le summarizer texte de CGI / CMU utilise une technique appelée Maximal Marginal Pertinence (ROR) qui mesure la pertinence de chaque phrase dans le document à l'utilisateur fourni requête, ainsi que les phrases qui ont été sélectionnés et ajoutés dans le résumé [Goldstain et al.]. La sélection des phrases qui sont très pertinents à la requête de l'utilisateur, mais sont différents les uns des autres crée le résumé du texte. Le système de gestion des connaissances (KM) de -.Résumé SRA International Inc. propose l'utilisation analyse morphologique, le marquage du nom et de la résolution co-référence [SRA]. Ils ont utilisé une technique d'apprentissage de la machine afin de déterminer la combinaison optimale de ces caractéristiques en combinaison avec des informations statistiques du corpus d'identifier les meilleures phrases pour inclure dans un résumé. R. Barzilay et M. Elhadad mis au point une méthode qui crée des résumés de texte en trouvant des chaînes lexicales du document [Barzilay ET Elhadad, 1997]. Le système Cornell / Sabir utilise les capacités de récupération de classement de documents et le passage des moteurs de recherche de texte SMART pour identifier efficacement les passages pertinents dans un document [ET BUCKLEY ET AL., 1999]. B. Chauve victoire et T.S. Morton a développé un summarizer qui sélectionne des phrases du document jusqu'à ce que toutes les phrases dans la requête sont couverts [ET BALDWIN T.S. MORTON, 1998]. Une phrase dans le document est considéré comme couvrir une phrase dans la requête si elles co-réfèrent à la même personne, organisation, événement, etc. Le papier par Yihong Gong et Xin Liu [Gong et Liu, 2001], compare les résumés manuels avec les résumés automatisés à l'aide du retrait (R), de précision (P) le long de F. Ils montrent que les exécute sur la base de la méthode IR mieux sur la moyenne. Dans cet article, nous examinons les performances des quatre méthodes de résumé qui sont discutés en détail dans la section suivante. 3. Summarizers Quatre méthodes de résumé de texte générique sont présentés. Ils créent des résumés de texte par le classement et l'extraction des phrases à partir des documents originaux. Les méthodes sont les suivantes: - SUMMARIZER 1: utilise des méthodes standard IR à la pertinence de la peine de rang; - SUMMARIZER 2: utilise la technique de LSA pour identifier les phrases sémantiquement importantes pour les créations sommaires; - SUMMARIZER 3: utilise une combinaison de la technique d'analyse sémantique latente, la réduction et la pertinence mesure; - SUMMARIZER 4: utilise système de pondération TF * IDF à des peines de rang et de phrases choisit haut pour former un résumé. Texte Résumé Utilisation de l'indexation sémantique et Latent recherche d'information technique RNTI - E - 2 Chaque méthode tente de sélectionner des phrases qui couvrent les principaux thèmes du document, autant que possible et en même temps, maintient la redondance au minimum. Les premières mesures prises pour chacun sont les suivants: 1. Décomposer le document en phrases individuelles; 2. Créez un vecteur de fréquence à long terme pondérée pour chaque phrase. Le vecteur de fréquence de terme pondérée Si = [S1i S2i ... SNI] T de phrase i est définie par: sji = L (SJI). G (SJI) (1), L (SJI) est la pondération locale pour terme j dans la phrase i, G (SJI) est la pondération globale pour terme j dans tout le document. Un document est décrit par une matrice de similarité, où chaque colonne représente le vecteur de fréquence terme- de chaque phrase. La matrice peut être soit normalisée ou non normalisée et peut utiliser l'une des méthodes de pondération suivantes: - Les poids locaux sont: n poids: L (SJI) = tf (SJI), le poids binaire: L (SJI) = 1, si tf (SJI)? 1, L (SJI) = 0, sinon, le poids augmentée: L (SJI) = 0,5 + 0,5 * (tf (SJI) / tf (max)) où, tf (max) = max {tf (1i), tf ( 2i), ..., tf (mi)}, poids Logarithme: L (SJI) = log (1 + tf (ji)) - Les poids globaux sont les suivants: Aucune pondération: G (SJI) = 1, la fréquence du document inverse ( IDF): G (j) = log (N / n (j)) où N est le nombre total de phrases dans le document, et n (j) est le nombre de phrases qui contiennent terme j. - Si par Normalise Normalization sa longueur | Si |. Utilise sa forme originale Si. 3.1. Summarizer 1 Cette summarizer prend en entrée, le document pour résumer, la taille de synthèse souhaitée, le choix des systèmes de pondération locaux et mondiaux, et le choix du calcul de mesure de pertinence (intérieure Produit / Cosinus similarité / coefficient Jaccard, tel que défini plus tard). Il produit, un résumé qui est un extrait sur la base la plupart des phrases pertinentes dans le document. Les principales étapes de SUMMARIZER 1 sont les suivants: 1. Décomposer le document en phrases individuelles et d'utiliser ces phrases pour former la phrase ensemble candidat S. 2. Créer le vecteur terme de fréquence pondérée Ai pour chaque phrase i? S et le vecteur de fréquence à long terme pondérée D pour l'ensemble du document. Texte Résumé En utilisant Latent Semantic Indexing et de recherche d'information technique RNTI - E - 2 3. Pour chaque phrase i? S, calculer la mesure de pertinence entre Ai et D, qui est le produit intérieur ou Cosinus similarité, ou coefficient de Jaccard entre Ai et D. 4. Sélectionnez k phrase qui a le score de pertinence plus élevé et l'ajouter au résumé. 5. Supprimer k de S, et d'éliminer tous les termes contenus dans k du document. Recalcule le vecteur fréquence terme pondérée D pour l'ensemble du document. 6. Si l'engourdissement er des phrases dans le résumé atteint la valeur prédéfinie, mettre fin à l'opération: sinon, passez à l'étape 3. Pour déterminer la pertinence mesure, les fonctions suivantes sont envisagées: - Produit intérieur (IP): IP (Ai, D) =? tk = 1 (AIK * dk) où, AIK est le poids de k terme dans la phrase i et dk est le poids de terme k dans le document. - Cosinus similarité (Cos): Cos (Ai, D) =? tk = 1 (aik * dk) / (? tk = 1? a2ik * tk = 1? d2k). - Coefficient Jaccard (JC): JC (Ai, D) =? tk = 1 (AIK * dk) / (tk = 1 a2ik + tk = 1 d2k -?? tk = 1 (AIK * dk)) Dans l'étape 4, k phrase qui a la mesure de pertinence plus élevé avec le document celui qui représente le mieux le contenu important du document. Sélection de phrases en fonction de leurs mesures de pertinence garantit que le résumé couvre les sujets principaux du document. D'autre part, ce qui élimine tous les termes contenus dans k du document à l'étape 5, assure que la sélection de la phrase suivante choisira les phrases avec un chevauchement minimal avec peine k. 3.2. 2 Cette Summarizer Summarizer sélectionne les phrases les plus élevées de chaque classement sujet / concept de saillant à l'aide de l'analyse sémantique latente (LSA de). LSA implique l'application de la décomposition en valeurs singulières (SVD). Étant donné un m? n, termes par phrase matrice A = [A1 A2 ... An] où, chaque vecteur de colonne Ai représente le vecteur terme de fréquence pondérée de phrase i dans le document, m est le nombre total de termes et n est le nombre total de Phrases. Le SVD de A est défini comme [PRESSE ET ET AL, 1992.]: A = U? VT (2) où U = [uij] est une matrice colonne de orthonormé mxn dont les colonnes sont appelés à gauche vecteurs singuliers; ? = Diag (1?, ...,? N) est une matrice diagonale nxn dont les éléments diagonaux sont des valeurs singulières non négatifs triés par ordre décroissant, et V = [vij] est un nxn orthonormé matrice dont les colonnes sont appelés vecteurs singuliers droit. Si le rang (A) = r, alors? satisfait? 1 ? ? 2? ...? ? r>? r + 1 = ... =? n = 0 (3) L'interprétation de l'application de la SVD aux termes de phrase matrice A peut être faite à partir de deux points de vue différents. Du point de transformation de vue, le SVD tire un résumé de texte à l'aide Latent Semantic Indexing et de recherche d'information technique RNTI - E - 2 correspondance entre l'espace de dimension m engendré par les vecteurs de fréquence à long terme pondéré et l'espace vectoriel singulier r dimensions avec tous les ses axes linéairement indépendants. Cette cartographie projets chaque vecteur de colonne i de la matrice A, qui représente le vecteur de fréquence terme- pondérée de phrase i, à vecteur colonne? i = [VI1 VI2 ... vir] T de la matrice VT, et des cartes de chaque vecteur rang j dans la matrice A, qui indique le nombre d'occurrences du terme j dans chacune des pièces, à vecteur ligne? j = [uj1 uj2 ... UJR] T de la matrice U. Ici, chaque élément de vix de? i, ujy de? j est appelé l'indice de la x? e, y? e vecteurs singuliers, respectivement. Du point de vue sémantique, la SVD dérive la structure sémantique latente du document représenté par la matrice A [Deerwester ET AL., 1990]. Cette opération reflète la répartition du document original en r vecteurs de base linéairement indépendants ou des concepts. Chaque terme et phrase du document est conjointement indexé par ces vecteurs / concepts de base. L'ampleur de la valeur singulière correspondant indique le degré d'importance de ce modèle dans le document. Toutes les phrases contenant ce modèle de combinaison de mots seront projetés le long de ce vecteur singulier, et la phrase qui représente le mieux ce modèle aura la plus grande valeur d'index avec ce vecteur. Les principales étapes de SUMMARIZER 2 sont les suivants: 1. Décomposer le document D en phrases individuelles, et d'utiliser ces phrases pour former l'ensemble phrase candidat S, et ensemble k = 1. 2. Construct les termes de phrases matrice A pour le document D. 3. Effectuer la SVD sur A pour obtenir U, la matrice de valeurs singulières? Et la matrice de vecteur singulier droit VT. Dans l'espace vectoriel singulier, chaque phrase i est représenté par la vecteur colonne ? i = [VI1 VI2 ... vir] T de VT. 4. Sélectionnez le kème droit vecteur singulier de la matrice VT. 5. Sélectionnez la phrase qui a la plus grande valeur d'index avec le k-ième vecteur singulier droit, et l'inclure dans le résumé. 6. Si k atteint le nombre prédéfini, mettre fin à l'opération: sinon, k incrément par un, et passez à l'étape 4. À l'étape 5, trouver la phrase qui a la plus grande valeur d'index avec le k-ième vecteur singulier droit est équivalent à trouver le vecteur de colonne? i dont l'élément k-ième vik est le plus grand. Cette opération équivaut à trouver la meilleure phrase décrivant le concept / sujet représenté par le vecteur singulier kème. Depuis sont classés les vecteurs singuliers dans l'ordre décroissant de leurs valeurs singulières correspondantes, le vecteur singulier kème représente le concept important kème / sujet. Parce que tous les vecteurs singuliers sont indépendants les uns des autres, les phrases sélectionnées par cette méthode contiennent un minimum de chevauchement. 3.3. Summarizer 3 Cette summarizer prend en entrée, le document pour résumer, la taille de synthèse souhaitée, le choix des systèmes de pondération locaux et mondiaux, le choix du calcul de mesure de pertinence (intérieure Produit / Cosinus Similitude / Jaccard Co-efficace tel que défini précédemment). Il produit, un résumé qui est un extrait de la taille désirée. Summarizer 3 Réalise décomposition de valeur singulière, suivie d'une réduction puis par le calcul de la mesure de pertinence pour déterminer les phrases à ajouter au résumé. Après avoir effectué SVD sur A (comme décrit dans résumeur 2), les valeurs singulières obtenues signifient les concepts pondérés maximales possibles dans la collection de phrases. L'équation (3) Résumé du texte à l'aide et indexation sémantique latente recherche d'information technique RNTI - E - 2 ci-dessus montre que le nombre de r »valeurs singulières non nulles signifient le nombre de concepts pondérés. La réduction de la dimension des composants de SVD-à-dire U,? et VT est défini comme suit: la Fig. 1 SVD Dimension Reduction Après la décomposition, la dimension de chaque composant est réduite en fonction de la valeur de « r » à savoir les non nuls des valeurs singulières, comme indiqué ci-dessus. Dans notre cas, nous utilisons r = n. A nouveau, on obtient, après re-multiplier les composantes réduites (matrices). A contient maintenant les informations les plus pondérée dans un espace de dimension caractéristique très élevée. Chaque vecteur de colonne A représente une phrase. Effectuez la pertinence Mesure de calcul entre chaque phrase et le Document D. Rang toutes les phrases et choisir la phrase avec le score le plus élevé et l'ajouter au résumé. Retirez tous les termes dans la phrase du document et recalcule D. Répéter le calcul de mesure de la pertinence et de construire le résumé de la taille désirée. Le flux de fonctionnement est suit comme: 1. Décomposer le document en phrases individuelles, et d'utiliser ces phrases pour former l'ensemble de la phrase candidate S. 2. Construct la matrice des termes par des phrases A pour le document. 3. Effectuer la SVD sur A pour obtenir U, la matrice de valeurs singulières? Et la matrice de vecteur singulier droit VT. Dans l'espace vectoriel singulier, chaque phrase i est représenté par le vecteur de colonne? i = [VI1 VI2 ... vir] T de VT. 4. Effectuez la réduction r = n. 5. Obtenir une nouvelle fois par re-multiplier U,? et VT. Ured? rouge VTred A m x r r r r x x n x m x n x = réduction de la dimension A U? VT = x Résumé du texte à l'aide et indexation sémantique latente recherche d'information technique RNTI - E - 2 6. Maintenant, utilisez la mesure souhaitée Pertinence et ajouter la phrase la plus élevée classé k au résumé. 7. Retirer tous les termes de k à partir de D et A et re-calcul D. 8. Répéter à travers l'étape 6 jusqu'à ce que la synthèse de la taille souhaitée est formée. L'opération SVD équivaut à trouver les concepts saillants / thèmes représentés par les vecteurs singuliers. Étant donné que les vecteurs singuliers sont classés par ordre décroissant de leur correspondant valeurs singulières, r vecteurs singuliers représentent les concepts importants r / thèmes. Après réduction, l'application (r = n) pour chaque matrice, A contient les informations les plus pondéré dans un espace de caractéristique dimensionnelle très élevée. En outre, la sélection des phrases en fonction de leurs scores de pertinence garantit que le résumé couvre les sujets principaux du document. D'autre part, ce qui élimine tous les termes contenus dans k du document à l'étape 7 assure que la sélection de la phrase suivante choisira les phrases avec un chevauchement minimal avec k. 3.4. Summarizer 4 Cette summarizer sélectionner des phrases du TF * du schéma de pondération IDF pour sélectionner des phrases. Il est le plus simple parmi toutes les techniques proposées. Il fonctionne comme suit: 1. Décomposer le document en phrases individuelles et d'utiliser ces phrases pour former la phrase ensemble candidat S. 2. Créer le vecteur terme de fréquence pondérée Ai pour chaque phrase i? S en utilisant TF * IDF. 3. Somme le TF * IDF score pour chaque phrase et le rang eux. 4. Sélectionnez le nombre prédéfini de phrases dans le résumé de A. 4. Évaluation du rendement Dans cette section, nous comparons les sorties automatiques (récapitulation extraits) de chaque Summarizer, avec les résumés manuels (résumés) générés par les évaluateurs humains indépendants. Nous avons utilisé des jeux de données conférences Comprendre le document (DUC) du NIST pour l'évaluation de la performance. L'ensemble de données comprend trois séries de documents de chaque évaluateur / sélecteur humain indépendant. Chaque jeu a entre 3 et 20 documents. Chaque sélecteur construit résumés (résumés) pour chaque document dans le jeu d'une longueur approximative de 100 mots. Un échantillon des données DUC a été choisi pour nos fins de test. Il se compose de 2 ensembles de documents (un ensemble de chacun des sélecteurs 2). L'ensemble de sélection 1 se compose de 5 documents, alors que l'ensemble de sélecteur 2 de 4 documents. Chaque sélecteur crée un résumé (abstract) intitulé « Résumé original », pour chaque document dans sa / son ensemble. En outre un sélecteur, autre que le sélecteur d'origine du document, crée un résumé (abstract) intitulé « Résumé double », pour chaque document. Ainsi, il y a deux résumés manuels (résumés) pour chaque document. Résumés (Original / double) pour le même document peuvent être de tailles différentes (pas de phrases.). Nous créons des résumés automatisés (taille similaire aux résumés manuels) pour tous les neuf documents des deux sélectionneurs. Nous comparons ensuite les résumés automatisés avec le résumé du texte à l'aide Latent Semantic Indexing et recherche documentaire Technique RNTI - E - 2 résumés manuel à l'aide mesure « Cosinus similarité » pour voir ce qui correspond au document résumé de plus près. En raison du manque d'espace dans cet article, nous présentons uniquement les résultats de la comparaison entre les résumés automatisés et des résumés originaux. D'autres résultats peuvent être trouvés dans [Bellaachia et Mahajan, 2003]. La figure 2 et la figure 3 montre le rendement des quatre summarizers à l'aide de produit interne et NTN: N = Non pondération local, T = FID pour la pondération globale et N = Aucune normalisation (voir schémas de pondération) Les chiffres montrent que SUMMARIZER 1 et 3 ont des performances comparables . Notez que SUMMARIZER 4 a la tête le plus bas parmi tous les autres résumeurs. Sélecteur 1, NTN, résumés d'origine 0,7 0,75 0,8 0,65 0,85 0,9 0,95 1 2 3 4 5 Document N ° C en os e Si m ila ri ty Summarizer1 Summarizer2 Summarizer3 Summarizer4 FIG. 2 - Sélecteur 1 Résultats Sélecteur 2, NTN, résumés d'origine 0,75 0,8 0,85 0,7 0,9 0,95 1 1 2 3 4 Document N ° C en os e Si m ila ri ty Summarizer1 Summarizer2 Summarizer3 Summarizer4 FIG. 3 - Sélecteur 2 Résultats Texte Résumé aide Latent Semantic Indexing et de recherche d'information technique RNTI - E - 2 La figure 4 montre la similitude cosinus d'une phrase (dans un résumé automatisé généré par chaque summarizer) avec le document d'entrée. SUMMARIZER 2 a la plus faible mesure et Summarizer 3 a la mesure la plus élevée, tandis que SUMMARIZ ER 1 et 4 ont des performances comparables. Cosinus de similarité de synthèse automatisé (par phrase) avec le document, généré en utilisant chaque résumeur, NTN et intérieure du produit 0,16 0,161 0,162 0,159 0,163 0,164 0,165 0,166 0,167 0,168 1 2 3 4 No. résumeur C os dans e Si m ila ri ty FIG. 4 - Performance Phrase 5. Concllusion Le présent document a présenté quatre méthodes de résumé de texte qui créent des résumés de texte génériques par le classement et l'extraction des phrases à partir des documents originaux. La première méthode utilise des méthodes de recherche d'information standard à la pertinence de la phrase de rang, tandis que la seconde méthode utilise la technique de LSA pour identifier les phrases sémantiquement importantes. La troisième méthode, SUMMARIZER 3, utilise une combinaison de la technique d'analyse sémantique latente, la réduction et la mesure de pertinence. La quatrième méthode utilise simplement le TF * schéma de pondération IDF. Nous avons utilisé des jeux de données conférences Comprendre le document (DUC) du NIST pour l'évaluation de la performance. Deux séries de documents ont été choisis pour notre évaluation de la performance. Summarizer 4, avec son plus bas frais généraux, a des performances comparables à summarizer 1. La technique LSI, tel qu'il est utilisé dans SUMMARIZER 2 et 3 summarizer, n'améliore le texte summarization. La combinaison de plusieurs techniques utilisées dans Summarizer 3 a la meilleure performance moyenne. Remerciement: Nous tenons à remercier M. Avinash K. Kanal pour sa mise en œuvre de la technique LSA. Texte Résumé Utilisation de l'indexation sémantique et Latent recherche d'information technique RNTI - E - 2 Références [Gong et Liu, 2001] Yihong Gong et Xin Liu. Summarization texte générique avec pertinence Mesure et analyse sémantique latente. Dans Actes de la conférence internationale annuelle 24 ACM SIGIR sur la recherche et le développement dans la recherche d'information, pp. 19 - 25, 2001. [Hovy et Lin, 1998] E.Hovy et C. Lin. texte automatisé dans summarist summarization. Dans Actes de l'atelier TIPSTER, Baltimore, MD, 1998. [Goldstain et al.] J. Goldstain, M. Kantrowitz, V. Mittal et J. Carbonell. Résumant documents texte: sélection des phrases et des mesures d'évaluation. Dans Proceedings of ACM SIGIR '99, Berkeley, CA, août 1999. [SRA] http://www.SRA.com. [Barzilay et Elhadad, 1997] R. Barzilay et M. Elhadad. En utilisant des chaînes lexicales pour le texte « , résumé dans les Actes de l'atelier sur le texte évolutif intelligent Summarization, Madrid, Espagne, août 1997. [Buckley et et al., 1999] C. Buckley et al .. et L'empire intelligent / pronostiqueur ir système. In Proceedings of TIPSTER Phase III d'atelier. 1999. [Baldwin et T. S. Morton, 1998] B. Baldwin et T. S. Morton. Dynamique à base coréférences summarization. Dans Actes de la troisième Conférence sur les méthodes empiriques dans le traitement du langage naturel (EMNLP3), Grenade, Espagne, Juin 1998. [Luhn, 1958] Luhn, H.P. La création automatique de résumés Littérature. dans Maybury, M. T. ed. Les progrès réalisés dans automatique. Summarization Texte Le MIT Press, Cambridge, 1958, 15-22. [ET FIRMIN CHRZANOWSKI, 1999] Firmin, T. et Chrzanowski, M.J. Une évaluation du automatique des systèmes texte récapitulation. dans Maybury, M. T. ed. Les progrès réalisés dans automatique Summarization texte, MIT Press, Cambridge, 1999. [McDonald et al.,] D. McDonald et al., « Utilisation de la peine-peine Heuristique pour classer les segments de texte dans TXTRACTOR, » MIS Département, Université de l'Arizona , Tucson, AZ. W. Appuyez sur et al, numérique Recettes en C [Presse et et al., 1992]. L'art de calcul scientifique. Cambridge, Angleterre. Cambridge University Press, 2 ed, 1992. S. Deerwester et al, « l'indexation par analyse sémantique latente, » JASIS, vol [Deerwester et al., 1990].. 41, pp 391-407, 1990. [Bellaachia et Mahajan, 2003] et Anand Abdelghani Bellaachia Mahajan. Comparaison des trois méthodes texte récapitulation. La 12e Conférence internationale sur les systèmes intelligents et adaptatifs et génie logiciel, San Francisco, Californie, Juillet 2003. Texte Résumé L'utilisation Latent Semantic Indexing et de recherche d'information Te chnique RNTI - E - 2 CV Ce papier d'methods Présente extraction quatre saisons de résumé de texte automatique. Elles Sont présentées à their visiter Chacune et Comparées à un CV de manuel Processus (extraction par de phrases pertinentes). Les methods 2 et 3 la décomposition aux utilisent facts Singulières (documents Divisés en phrases) pour selectionner les phrases better Les plus TYPIQUES. Les methods were Quatre personnes évaluées collection de juin Utilisant texte de NIST.