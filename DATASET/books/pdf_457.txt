Évaluer les réseaux bayésiens par échantillonnage avec des hypothèses simplifiées Saaid Baraty *, Dan A. Simovici * * Université du Massachusetts de Boston Computer Science Department, Boston, Massachusetts 02125 e-mail {sbaraty, DSim} @ cs.umb.edu, Résumé. La plupart des évaluations de remise en forme commune pour les réseaux bayésiens en présence de données est le critère Cooper Herskovitz. Cette technique implique d'énormes quantités de données et, par conséquent, les calculs expansives. Nous vous proposons une méthode d'évaluation alternative moins coûteuse en utilisant des hypothèses simplifiées des évaluations de duces pro- qui sont fortement corrélés avec la Cooper-Herskovitz cri- tère. 1 Introduction Nous étudions le problème de la construction d'un réseau bayésien pour un nomène composite nomène U ​​= {u1, u2,. . . , Un} où ui pour 1 ≤ i ≤ n sont discrètes variables aléatoires représentant l'affectation de l'état des attributs de U. Pour ce faire, nous partons d'une multiset de données D = {t1, t2,. . . , Tm} où un tuple n-aire ti est une instance de l'événement U. Nous appelons cette multiset comme ensemble de données de preuve (ensemble de données pour faire court). Un certain nombre d'hypothèses sont nécessaires pour obtenir une mesure pour l'évaluation de l'aptitude d'une structure de réseau bayésien (BNS) pour un ensemble de données d'apprentissage. hypothèses fortes font la evaluationmoremanageable. D'autre part, le modèle obtenu selon les hypothèses les plus faibles est mieux en mesure d'être conforme à la véritable distribution sous-jacente du problème. Soit G = (U, E) un graphe orienté acyclique ayant U comme ensemble de sommets et E que l'ensemble de ses bords, qui capture les dépendances probabilistes directes entre ces variables. Soit Θ soit l'ensemble de paramètres qui permet de quantifier la distribution de probabilité conjointe de U tel que spécifié par G. On note l'ensemble des affectations possibles d'une variable aléatoire ui par Dom (ui) = {U1i,. . . , Urii}. La notion de domaine peut être étendu à des ensembles de variables V à l'aide de produit cartésien. Si l'ensemble des nœuds parents de ui est PARG (ui), puis Dom (PARG (ui) = {U1i,..., U qii}. L'ensemble des non-descendants de ui, PNIA (ui) est l'ensemble des tous les noeuds U excluent ui et tous ses descendants Quand il est clair dans le contexte que nous laissons tomber l'indice G. la paire B = (G, Θ) les satisfait la condition de Markov local si PB (ui | e (ui)). = PB (ui | par (ui)) pour 1 ≤ i ≤ n, où PB est la distribution de probabilité de U défini par B. le modèle B est un réseau bayésien si elle satisfait à la condition de Markov locale par la règle de la chaîne, on a: PB. (u1, u2,, un...) = Πni = 1 PB (ui | Par (ui)) Par conséquent, si nous laissons θijk = P (ui = Uki | Par (ui) = U ji). et θij · = (θij1,, θijri...) pour 1 ≤ i ≤ n, 1 ≤ k ≤ ri et 1 ≤ j ≤ qi, puis la distribution de probabilité conjointe sur U est spécifiée par Θ = {θij · | 1 ≤ i ≤ n et 1 ≤ j ≤ qi} -. 11 - évaluation des réseaux bayésiens par échantillonnage 2 A base postéro-Score avec un ensemble réduit Hypothèses Cooper et Herskovitz a introduit le probabil ity P (G | D) en tant que mesure d'évaluer l'aptitude du G comme un modèle probabiliste de D. Puisque P (D) est constante à travers différents réseaux, nous pouvons travailler avec P (G, D). Soit ΩG l'espace des distributions toute probabilité thetav pour la structure G. Alors, P (G, D) = ∫ ΩG (Θ) P (D | Θ, G) f (Θ | G) P (G) dO. (1) Rappelons que Θ est un ensemble de distributions θij · = (θij1,, θij (ri-1), 1 -... Σri-1 k = 1 θijk) pour tout i et j. Les vecteurs θij · pour tout (i, j) ∈ [1..n] × [1..qi] doivent satisfaire Σri-1 k = 1 θijk ≤ 1 et θijk ≥ 0 pour tout k. En outre, Θ lui-même, la collecte de ces variables vecteurs aléatoires, peut être considéré comme une variable aléatoire. P (D | Θ, G) est la fonction de probabilité conditionnelle de données donné (G, Θ), f (Θ | G) est la fonction de densité conditionnelle de structure donnée Θ G, et P (G) est la fonction de probabilité a priori de Structure G. Pour évaluer ce nombre d'une intégrale d'hypothèses ont été introduites par Cooper et Herskovits (1993). L'indépendance des données suppose tuples de D sont indépendants compte tenu de la structure du réseau. L'hypothèse d'indépendance locale et mondiale (LGI) exige que θij · est conditionnellement indépendante de θi'j '· pour tous (i, j) = 6 (i', j ') compte tenu de la structure. Sur la base de l'hypothèse de LGI, Ω (Θ), l'espace des collections possibles Θ peut être écrit comme ΩG (Θ) = {i = 1 nn qiΠ j = 1 (θij1,..., Θij (ri-1) ) ∈ R ri-1 | ri-1Σ k = 1 θijk ≤ 1 et θij1,. . . , Θij (ri-1) ≥ 0} et on a f (Θ | G) = Πni = 1 Πqi j = 1 g (θij · | G) en raison de l'hypothèse de LGI. Cooper et Herskovits (1993) remplacer f par le produit ci-dessus dans l'égalité (1). En outre, ils prennent la g de distribution (θij · | G) pour chaque i et j est uniforme. Nous appelons cette hypothèse comme deuxième probabilité uniforme de commande (SOUPE). Heckerman et al. (1995) introduisent le BDE métrique qui est une mesure basée-postérieur similaire à CH métrique. Ils utilisent l'hypothèse de LGI et trois autres hypothèses: le second ordre de probabilité Dirichlet (de PDSO) (suggéré mais non utilisé dans Cooper et Herskovits (1993)), la modularité des paramètres et l'hypothèse échantillon multinomial (MS). PDSO est la généralisation de hypothèse SOUPE qui stipule que P (θij · | G) suit une distribution Dirichlet pour tous i et j. L'hypothèse de l'échantillon multinomial affirme que si nous définissons l'ensemble ordonné = {t1 Dl,. . . , Tl-1} puis, P (tl [ui] = uki | [... U1,, ui-1]... Tl = (UV11,, u vi-1 i-1), Dl, (G, Θ)) = θijk, t [V] désigne la restriction de V ⊆ U sur tuple t ∈ D et nous avons l'état Assign- ment PARG (ui) = U ji compatible avec tl [u1,. . . , Ui-1] = (u v1 1,..., U vi-1 i-1) et θijk ∈ Θ. Plus tard, l'hypothèse de PDSO a été remplacé par deux autres hypothèses, lence de la probabilité et la possibilité la structure, ce qui implique la prise en charge de PDSO. Notez que toutes les fonctions de ity proba- g (θij · | G) suit une distribution Dirichlet qui nécessite des paramètres ri. Ainsi, pour chaque G BNE nous devons spécifier Σn i = 1 paramètres ITRI, ce qui rend cette pratique d'approche. Pour surmonter cette difficulté Heckerman et al. (1995) codé la connais- sances avant en un seul réseau bayésien dénommé (un réseau antérieur) Bpr = (GPR, Θpr). Ensuite, ils ont mis le Dirichlet paramètre correspondant à la composante distribution de probabilité θijk à αijk = N '· PBPR (Ui = uki, ParGpr (ui) = U ji), oùN' est un paramètre donné d'utilisateur auquel ils - 12 - S. Baraty et DA Simovici considèrent comme étant une taille équivalente de l'échantillon. Le choix d'une des valeurs de N 'et la collection Θpr sans observer de données est arbitraire. Nous utilisons l'échantillonnage qui nous permettent de laisser des données façonner la répartition de la probabilité a posteriori sur des vecteurs θij ·. Dans l'évaluation de la P avant (G) Cooper et Herskovits (1993) suppose une distribution a priori uniforme. Ceci et d'autres hypothèses sont basées sur des paramètres qui doivent être spécifiés arbitrairement. L'échantillonnage permet d'utiliser les données en tant que substitut pour des hypothèses fortes ou de la connaissance de domaine dans la détermination des paramètres de la deuxième répartition de probabilité de l'ordre et de la probabilité a priori P (G). Laissez-S1 et S2 deux échantillons de D. disjoints Nous évaluons P (G | S1, S2) comme une mesure de remise en forme de la structure BN G. Puisque P (S1, S2) ne dépend pas de la spécifique bNs nous pouvons laisser tomber et à la place de calcul P (G, S1, S2). Notez que la règle de la chaîne P (G, S1, S2) = P (S1 | G, S2) · P (G | S2) · P (S2). Si nous prélevons régulièrement dans différentes structures, alors P (S2) est constante et peut être supprimée. Par conséquent, nous adoptons P (S1 | G, S2) · P (G | S2) en tant que mesure relative de l'aptitude des structures pour un ensemble de données D. Si on répète le processus d'échantillonnage, nous pouvons étendre notre mesure à (kΠ q = 1 P (S2q-1 | G, S2q) · P (G | S2q)) 1 k, où S1, S2,. . . , S2k sont des échantillons FROMD où S2q-1 ∩ S2q = ∅ pour chaque q. Nous nous référons à cette mesure que la validation de k-échantillon de la structure G pour les données SetD et désignons par SAMPk (G, D). Soit S = {t1,. . . , Ta} et S 'deux échantillons disjoints SIO. Le premier terme de SAMPk (G, D) peut être écrit sous la forme P (S | G, S ') = ∫ ΩG (Θ) P (S | Θ, G, S') f (Θ | G, S ') dO . (2) Soit D = (u1,..., Un) soit un ordre topologique des noeuds de G qui représente une connaissance préalable expert du domaine. Notons nS (t) le nombre d'occurrences de tuple t en S et laisser γijk (S) = || {t ∈ S | t [{ui}] = uki ∧ t [Par (ui)] = U ji} || et γij · (S) = k = 1 Σri γijk (S). Étant donné que les attributs de D sont discrètes, on a P (S | B) = aΠ l = 1 P (tl | Sl, Θ, G) = aΠ l = 1 nn i = 1 P (ui = tl [ui] | Ui = tl [Ui], Sl, θ, G) = aΠ l = 1 nn i = 1 j = 1 qiΠ riΠ r = 1 θ λlijr ijr, où la première égalité est par la règle de la chaîne et Sl = (t1,..., tl-1), la seconde égalité est en supposant hypothèse MS et Ui = (u1,..., ui-1) et λlijr = 1 si tl [ui] = uri ∈ Dom (ui ) et tl [Parg (ui)] = U ji ∈ Dom (Parg (ui)) et λlijr = 0 sinon. Depuis oa l = 1 λlijr = γijr (S), nous avons P (S | Θ, G) = i = 1 nn qiΠ j = 1 riΠ r = 1 θ γijr (S) ijr. (3) Ensuite, P (S | Θ, G, S ') = P (S ∪ S' | Θ, G) P (S '| Θ, G) = Πni = 1 Πqi j = 1 r Πri = 1 θ γijr (S∪S ') ijr Πni = 1 j = 1 Πqi Πri r = 1 θ γijr (S') ijr = nn i = 1 j = 1 qiΠ riΠ r = 1 θ γijr (S) ijr. (4) Pour le second terme de droite de l'égalité (2) on a f (Θ | S ', G) = P (S' | Θ, G) f (Θ | G) ∫ ΩG (Θ) P ( S '| Θ, g) f (Θ | g) dO (5) - 13 - Évaluation des réseaux bayésiens par échantillonnage On suppose theSOUP hypothèse et fixé chaque g (θij · | g) = (ri-1) !. La probabilité postérieure de Θ est conditionnée par G en présence de l'échantillon S ', comme le montre l'égalité (2). Cette approche est différente de celle utilisée dans Cooper et Herskovits (1993) où l'hypothèse de SOUPE a été appliquée directement sans intervention de données échantillon. Ensuite, nous avons ∫ ΩG (Θ) P (S '| Θ, G) f (Θ | G) dO = i = 1 nn qiΠ j = 1 ((ri - 1) · Πri r = 1 γijr! (S ') (de γij · (S!) + ri - 1)!), de l'égalité (3) et SOUPE, LGI, et d'un résultat de Jeffreys et Jeffreys (1988) (voir pages 468-470 de cette référence ). Ainsi, à partir des égalités précédentes et de (3) et (5) on a, f (Θ | S ', G) = nn i = 1 qiΠ j = 1 Γ (γij · (S') + ri) ri Π r = 1 θ γijr (S ') ijr Γ (γijr (S') + 1), (6) où Γ est la fonction d'Euler. La combinaison égalités (2), (4) et (6) on obtient P (S | G, S ') = nn i = 1 qiΠ j = 1 Γ (γij · (S') + ri) Γ (γij · (S ∪ S ') + ri) · riΠ r = 1 Γ (γijr (S ∪ S') + 1) Γ (γijr (S ') + 1), Pour rapprocher la quantité P (G | S) nous utilisons une légère variation d'une mesure appelée la distorsion de distribution introduite dans Baraty et Simovici (2009). nous voulons évaluer l'indépendance conditionnelle capturé par condition de Markov locale selon les données, ce qui est ici, nous voulons évaluer dans quelle mesure les conditions fs (Ui | e (ui)) = fs (ui | Par (ui)) détient pour 1 ≤ i ≤ n, où fS est la fonction de fréquence par rapport à l'échantillon S ⊆ D. pour y parvenir, on mesure la divergence de l'ensemble de distributions de probabilité fS (Ui | e (ui) = U) de l'ensemble de distributions de probabilité fs (ui | par (ui) = U [par (ui)]) pour tout i et U ∈ Dom (e (ui)). Définition 2.1 La divergence de Markov locale de la structure de fourche au niveau du noeud ui de G en fonction de l'échantillon S, notée LMDGS (ui), est le nombre Σ U fS (nd (ui) = U) · KL [fS (ui | e ( ui) = U), fs (ui | Par (ui) = U [Par (ui)])], où la somme s'étend sur tout U ∈ Dom (e (ui)). Ici KL [p, q] est la divergence Kullbach-Leibler entre les distributions de probabilité p = (p1,..., Pn) et q = (q1,..., Qn). Laissez-HS (π u) l'entropie de Shannon de l'ensemble S partitionné en fonction des valeurs de u, et que HS (π u | πW) l'entropie de Shannon conditionnelle de l'ensemble S partitionnées en fonction des valeurs de u, conditionnée par la partition de S conformément à l'affectation de l'ensemble des attributesW (voir Baraty et Simovici (2009)). Théorème 2.2 Pour 1 ≤ i ≤ n nous avons LMDGS (ui) = HS (πui | πPar (ui)) - HS (πui | πnd (ui)). Théorème 2.3 G S LMD (ui) = 0 si et seulement si fs (ui | e (ui)) = fs (ui | Par (ui)). Le théorème 2.2 implique que 0 ≤ LMDGS (ui) ≤ HS (πui). D'après le théorème 2.3 plus la valeur de GS DMT (ui) est, plus est la structure de la fourche au niveau du noeud ui pour satisfaire à la condition de Markov locale selon S. Par conséquent, la condition de Markov est plus proche d'être satisfaite selon l'échantillon S. On un autre côté, le plus près LMD GS (ui) est toHS (π ui) la plus divergente les deux - 14 - S. Baraty et DA Simovici distributions de probabilité fS (ui | e (ui) = U) un d fs (ui | Par (ui) = U [Par (ui)]) sont pour chaque U ∈ Dom (e (ui)). Lorsque LMDGS (ui) = HS (πui), nous haveHS (πui | πPar (ui)) = HS (πui) et HS (π ui | πnd (ui)) = 0. Cela signifie que l'ensemble Par (ui) a aucune capacité de prédiction du tout au niveau du noeud ui et l'ensemble e (ui) a une capacité de parfaite sur predication ui. Laissez BNE (U) l'ensemble de toutes les structures possibles sur bayésienne ensemble d'attributs U. P Define (G | S) P (G | S) = Σni = 1 (HS (π ui) - LMDGS (ui)) Σ G'∈BNS (U) Σni = 1 (HS (πui) - LMDG'S (ui)). En utilisant les évaluations précédentes, SAMPk (G, D) peut être écrit (kΠ q = 1 P (S2q-1 | G, S2q) · P (G | S2q)) 1 k =   kΠ q = 1 Σ ns = 1 (HS2q (π us) - LMDGS2q (us)) Σ G'∈BNS (U) Σns = 1 (HS2q (π us) - LMDG'S2q (us)) · qiΠ j = 1 Γ (γij · (S2q) + ri) Γ (γij · (S2q-1 ∪ S2q) + ri) riΠ r = 1 Γ (γijr (S2q-1 ∪ S2q) + 1) Γ (γijr (S2q) + 1)) 1 k. Si on échantillonne systématiquement les données à travers des structures différentes, nous pouvons laisser tomber les entités constantes par rapport à la BNE G et en supposant P S2q G = Σns = 1 (HS2q (π nous) - LMDGS2q (us)) nous avons mis, SAMPk (G, D) = (kΠ q = 1 P G S2q nn i = 1 qiΠ j = 1 Γ (γij · (S2q) + ri) Γ (γij · (S2q-1 ∪ S2q) + ri) riΠ r = 1 Γ (γijr (S2q-1 ∪ S2q) + 1) Γ (γijr (S2q) + 1)) 1 k. 3 Résultats expérimentaux et conclusions Nous avons mené des expériences sur trois structures bien connues GAM, GCAR et DRI pour les domaines d'alarme, Voiture Diagnosis2 et Cancer napolitain avec 37, 18 et 5 nœuds respec- tivement. Pour les deux premières structures, nous avons généré au hasard les tables de probabilités correspondantes, ΘAM et ΘCAR. Ensuite, en fonction des distributions de probabilité introduites par (GAM, ΘAM) et (GCAR, ΘCAR) nous avons produit des ensembles de données de tailles 80000 et 100000 respectivement. Pour la DRI, nous avons utilisé l'ensemble de données correspondant dans la littérature avec 7565 sans valeurs manquantes. Pour chaque ensemble de données, nous avons généré au hasard un certain nombre de structures de différentes complexités. Le nombre de bords de ces structures varie de 1 à 10, 12 - 108 et 12-330 pour NC, CAR et ensembles de données AM respectivement. Les figures 1 (a), 1 (b) et 1 (c) montrent des corrélations très fortes entre le score de CH et le score SAMP pour diverses valeurs de k. La mesure dérivée est moins cher à calculer, car il fonctionne avec des échantillons beaucoup plus petits que l'ensemble des données. Nous avons introduit une mesure basée sur la probabilité a posteriori pour mesurer l'aptitude d'une structure de réseau bayésien à partir des données. La conclusion de ce travail est que notre notation à base est une alternative-échantillonnage viable et beaucoup moins cher à la note CH. Le fait que nous utilisons l'échantillonnage pour réduire l'ensemble des hypothèses et nous obtenons une très forte corrélation entre les deux mesures confirme que la SOUPE et la distribution uniforme sur P (G) sont des hypothèses sûres et ne faussent pas la recherche. - 15 - Évaluation des réseaux bayésiens par échantillonnage (a) Les données d'alarme (b) Données de voitures Diagnosis2 (c) données sur le cancer napolitain (d) diagramme de comparaison de temps FIG. 1 - Corrélations entre log (SAMPk (G, D)) et log (CH) et le temps en ms nécessaires pour ouvrir une session de calcul (SAMP1) (G, CAR) et marque CH Références Baraty, S. et D. A. Simovici (2009). Use_edge dans les structures de réseau bayésien. Dans Actes de la 8e Conférence Data Mining d'Australie, Melbourne, pp. 193-201. Cooper, G. F. et E. Herskovits (1993). Procédé bayésien pour l'induction de réseaux de données probabilistes. Rapport technique KSL-91-02, l'Université de Stanford, laboratoire Knowledge System. Heckerman, D., D. Geiger, et D. M. Chickering (1995). Apprentissage des réseaux bayésiens: La combinaison des connaissances et des données statistiques. InMachine apprentissage, pp. 197-243. Jeffreys, H. et B. S. Jeffreys (1988). Dirichlet Intégrales. Cambridge, Royaume-Uni: Cambridge Uni- versité Press. L'évaluation qualitative résumé la, plus des Connue Bayesiens en réseaux de présence is the Données Cooper Herskovitz critère. Technique des This implique de Quantités massives Données Fait, par par conséquent, des Nombreux Calculs. Nous proposons d'Une méthode, plus évaluation des suppositions Efficace Simplifiées Utilisant et Qui produit des EVALUATIONS FORTEMENT corrélées Avec le Cooper-Herskovitz critère. - 16 -