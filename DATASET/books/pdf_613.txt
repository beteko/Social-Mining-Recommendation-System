articles assemblage.pdf Application de Markov logique au document Annotation et Citation Déduplication Jean Baptiste Faddoul *, Boris Chidlovskii * * Xerox Research Centre Europe 6, chemin de Maupertuis 38240 Meylan-FRANCE Résumé. approches d'apprentissage structurés sont capables de prendre en compte la structure relationnelle des données, promettant ainsi une amélioration par rapport aux approches non relationnelles. Dans cet article, nous examinons deux tâches liées aux documents dans les domaines paramètre relationnel, l'annotation de documents semi-structurés et la citation Déduplication. Pour les deux tâches, nous présentons les résultats de la comparaison approche d'apprentissage relationnel à savoir la logique de Markov, à une non-relationnelle à savoir Support Vector Machines (SVM). Nous découvrons que la complexité accrue en raison de la mise en relationnel est difficile à gérer dans les grands cas à grande échelle, où les modèles non-relationnels pourraient mieux performer. De plus, nos expériences montrent que, dans la logique de Markov, la contribution de sa composante probabiliste diminue dans les grands domaines d'échelle, et il tend à agir comme la logique du premier ordre (FOL). 1 Introduction Une grande majorité des modèles existants d'apprentissage de la machine peut être considérée comme non relationnelle. Ils représentent chaque objet comme un point isolé dans un espace, et ils apprennent des modèles de prédiction en utilisant les caractéristiques de chaque objet. Une nouvelle tendance dans l'apprentissage statistique est représentée par des modèles relationnels qui tiennent compte de la structure relationnelle des données. Les relations entre les objets sont fréquents dans les cas du monde réel, et de les prendre en compte peuvent offrir une amélioration de la performance potentielle par rapport aux modèles non relationnelles. D'autre part, les ensembles de données du monde réel sont grandes dans le nombre d'objets, les dimensions de caractéristiques et même les numéros de relation. Donc, du point de vue de l'évolutivité, plus simples modèles non relationnelles pourraient évoluer mieux et pourraient surpasser complexes. Dans cet article, nous étudions les modèles relationnels et non relationnels sur deux tâches différentes, l'annotation de documents semi-structurés et la citation Déduplication. Dans nos expériences, nous utilisons comme le meilleur SVM état de l'art modèle non-relationnel. A l'approche des modèles relationnels, nous avons appliqué une logique de Markov (introduite dans Domingos et Richardson (2007)), qui est un apprentissage statistique Relationnel (SRL) qui combine FOL et réseaux de Markov. la logique de Markov a été choisi pour sa capacité à représenter des relations plus complexes que les modèles précé- ously utilisés et un certain nombre de résultats importants présentés lors des tests sur des domaines différents (Culotta et McCallum (2006) et Kok et Yih (2009)). RNTI-E-19- 435 - Application de Markov logique au document Annotation et Citation Déduplication 1.1 Annotation des documents semi-structurés annotation de documents peut être considérée comme une classification1task collective (nous appelons les détails à Chakrabarti et al (1998) et Neville et Jensen. (2003)). Les objets à classer sont des fragments d'un document, tels que les jetons, les lignes et les paragraphes, alors que les classes sont des étiquettes sémantiques de ces fragments. Chaque objet est décrit par un ensemble de caractéristiques et une classe représente son label tic seman- (titre, auteur, référence, etc.). En outre, diverses relations entre deux objets quelconques peuvent être identifiés, comme next_token (), same_paragraph (), etc. 1.2 Citation Déduplication Citation Déduplication est le problème de la détermination des enregistrements dans une base de données faisant référence à la même entité monde réel (Monge et Elkan ( 1996)). Chaque enregistrement dans la base de données est composée de plusieurs champs. Et des informations obtenues à partir de la mise en correspondance d'enregistrement peut se propager à la correspondance des champs et vice versa. Nous avons introduit la différence entre les modèles relationnels et non relationnels et décrit deux tâches dans un cadre de domaines relationnel. Dans la section suivante, nous présentons une logique de Markov. Dans la section 3, nous présentons les résultats de la comparaison entre les modèles logiques de Markov et SVM sur les deux tâches. L'article 4 traite des problèmes d'évolutivité et de la section 5 conclut cet article. 2 logique Markov Markov est un modèle logique d'apprentissage relationnel structuré qui com bine FOL et probabilistes Bilistic modèles graphiques. Il a été introduit par Domingos et Richardson (2007). En FOL, un KB est un ensemble de formules qui peuvent être considérées comme un ensemble de contraintes sur l'ensemble des mondes possibles. Si un monde possible viole une formule, il a une probabilité nulle. L'idée de base dans la logique de Markov est d'adoucir ces contraintes: quand un monde possible viole une formule dans le KB, il est moins probable, mais pas impossible. Les moins formules un monde viole, plus il est probable. Chaque formule a un poids associé qui reflète la façon dont contrainte forte une est: plus le poids, plus la différence de probabilité de journal entre un monde qui répond à la formule et qui n'a pas, d'autres choses étant égales par ailleurs. Un ensemble de formules de la logique de Markov Markov est appelé un réseau logique (MLN). MLN définissent la distribution de probabilité sur mondes 2, où chaque état du réseau de Markov ML, C représente un monde possible. 3 Paramètres Expérience et résultats 3.1 Annotation Tâche Pour la tâche d'annotation, nous avons utilisé la collection BizCard, qui est une collection de cartes de visite numérisées avec différentes mises en page. Chaque carte est segmenté en blocs et des lignes, chaque ligne est segmenté en jetons (chacun a une annotation sémantique) et des séparateurs qui n'ont pas l'annotation (-., ,, etc.). Chaque jeton est annotées avec l'un des 17 classes, comme l'adresse, nom, email, affiliation, etc. La collection contient 106 cartes de visite avec une moyenne de classes d'objets 1Les sont pas indépendants, compte tenu des observations (les caractéristiques). 2A monde possible est une mission de vérité pour tous les échouages ​​de tous les prédicats dans la Base de connaissances (KB). RNTI-E-19 - 436 - J.-B. Faddoul et B. Chidlovskii 30 jetons à annoter dans chaque carte. Chaque jeton est décrit avec 135 caractéristiques qui ont été définies par un expert, les caractéristiques sont classées en trois groupes: caractéristiques de contenu Jeton (par exemple le nombre de chiffres dans un jeton), les caractéristiques d'attributs Jeton (egeg, le type de police) et les caractéristiques de contenu ligne (par exemple le confinement d'un nom de pays dans une certaine ligne) 3.1.1 Modèles nous avons comparé une approche non-relationnelle à savoir SVM avec un relationnel à savoir logique Markov: SVM: nous déployons le paquet libsvm par Chang et Lin (2001). Nous apprenons des modèles de SVM avec le noyau linéaire, parce que la formation avec différents types de rapports de noyaux que le linéaire montre les meilleures performances dans des domaines de grande dimension. Comme caractéristiques, nous avons utilisé toutes les 135 caractéristiques extraites de l'ensemble de données. A l'étape de pré-traitement, nous RESCALE caractéristiques de valeur float finis dans l'intervalle [0,1]. De plus, les caractéristiques qualitatives (comme la couleur) ont été cartographiés dans un ensemble de fonctions booléennes (isBlue, isGreen, etc.). logique de Markov: Pour la formation des modèles logiques de Markov nous déployons le logiciel Alchemy 3. Comme la logique de Markov adapte la syntaxe de FOL, ce qui représente la tâche d'annotation exige une définition de KB. Les prédicats d'un tel KB ont les motifs suivants: • Feat (x, v): x jeton a une valeur v pour la fonction Feat. Le domaine de x est l'ensemble des jetons dans le jeu de la formation au cours de la formation, et dans les tests ensemble au cours des essais. Le domaine de v est l'ensemble des valeurs possibles pour la fonction Feat. Le Feat caractéristique peut être une caractéristique locale dans les x jeton lui-même, ou une caractéristique dans un autre jeton x 'être dans une certaine relation avec x. Il y a 135 caractéristiques prédicats de ce type. • Classe (x, c): x jeton a la classe c. Le domaine de c est l'ensemble de toutes les annotations possibles. • Rel (x, x '): une relation Rel existe entre x et x'. Pour nos expériences, les pred- icat Rel pourrait être l'un des six prédicats, dont chacun est défini sur une paire de jetons: Gauche Frère LB (x1, x2), deuxième à gauche frère 2LB (x1, x2), Droite Frère RB (x1, x2), deuxième à droite Frère 2RB (x1, x2), la ligne suivante NL (x1, x2) et ligne précédente PL (x1, x2). Nous courons plusieurs tests de MLN pour cette tâche. Dans chaque essai, nous avons utilisé différents ensembles de caractéristiques et relations. Deux modèles de formules ont été utilisées: 1. formules non consanguine: Feat (x, v) ⇒ classe (x, c), e à modélise le problème de la classification en fonction ne dispose que sur (sans relations). 2. Formules relationnelles: Classe (x1, c1) ∧ Rel (x1, x2) ⇒ classe (x2, c2), qui modélise les classes basées sur les relations entre les jetons et leurs classes. 3.1.2 Résultats des rapports Tableau 1 résultats des expériences MLN sur la collection BizCard. Dans tous les essais, nous utilisons la validation croisée 5 fois. Dans chaque essai un ensemble différent de relations ont été utilisées avec 3http: //alchemy.cs.washington.edu/ RNTI-E-19- 437 - Application de Markov logique au document Annotation et Citation Déduplication toutes les 135 fonctions. Un grand nombre d'essais ont été fait, les personnes les plus accuracy4 sont présentés dans le tableau 1. Le cas de référence sans relations utilisées donne 66,42% de précision. formules relationnelles améliorer la précision lors de l'utilisation des petits de profondeur, avec une profondeur supérieure (2-RB, 2-LB), nous observons la perte de précision. Relations avec précision aucune 66,42 LB RB 72,85 70,78 LB + RB + LB 67,82 2-LB 66,87 NL + PL 66,56 TAB. 1 - Résultats de précision sur BizCard en utilisant différents paramètres de la logique de Markov. Le tableau 2 compare les valeurs de précision et le temps de fonctionnement en mode validation croisée 5 fois pour les deux SVM et le MLN qui présente les meilleurs résultats. Comme on peut le voir MLN de SVM dans la précision et la durée. 3.2 Citation Déduplication Tâche 3.2.1 CORA CORA Data Set est une collection de 1879 citations dans différents documents de recherche informatique Sciences 5. Il contient des citations à 168 document de recherche différent, donc il y a une moyenne de 11 citations au même article. Chaque citation est segmenté en champs (auteur, titre, éditeur, année, etc.). 3.2.2 Modèles Comme dans le cas de la carte d'affaires, nous avons comparé un SVM avec un classificateur MLN: MVB: nous avons utilisé libsvm par Chang et Lin (2001) pour mettre en œuvre un classificateur binaire basé sur la distance Levenshtein 6 comme suit. Pour chaque paire de citations on calcule la distance Levenshtein entre chaque type de champ (auteur, année, titre, etc.). On obtient alors un vecteur de distance pour le pourcentage 4Le d'exemples correctement classés 5Disponible à http://www.cs.umass.edu/~mccallum/data/cora-refs.tar.gz 6Minimum nombre d'opérations nécessaires pour transformer une chaîne dans la autre, où une opération est une insertion, la suppression ou la substitution d'un seul caractère Précision Temps de marche SVM 78.42 0,3 heures 135 Caractéristiques MLN 135 Feat. 72,85 + LB 5,1 heures par rapport TAB. 2 - SVM et MLN Précision et Durée BizCard. RNTI-E-19 - 438 - J.-B. Faddoul et B. Chidlovskii chaque paire de citations. Ce vecteur de distance est un vecteur dans l'espace de la classe 1 SVM si les deux citations sont les mêmes, et la classe 0 sinon. La tâche se transforme en une tâche de classification binaire. logique de Markov: Nous citerons les résultats par Singla et Domingos (2006). Le KB utilisé contient trois types de prédicats (on parle de la description détaillée de la base de connaissances de leur papier): 1. prédicats de classe sont les prédicats qui doivent être prédits: Auteur (b, a), Titre (b, t), V enue (b, c). 2. prédicats de preuve sont les prédicats observées: HasWordAuthor (a, w), HasWordT itre (t, w), HasWordV enue (v, w). 3. prédicats match sont des prédicats d'égalité entre les champs (ils doivent être associés à des axiomes d'égalité): SameAuthor (A1, A2), SameBib (b1, b2), SameTitle (T1, T2), SAMEV IEU (v1, v2). Les formules dans le KB modélisent les relations en connectant prédicats de preuve et de classe avec prédicats match. ASC Durée SVM 97.88 0,2 heures MLN 98.01 4,2 heures TAB. 3 - ASC et exécution de temps sur CORA. 3.2.3 Résultats Le tableau 3 compare MLN et SVM. Nous avons utilisé AUC (aire sous la courbe de précision rappel) pour pouvoir comparer nos résultats avec Domingos et les meilleurs résultats de Singla. Durée montré dans la table est obtenue en exécutant une validation croisée de 5 fois sur les données. Nous voyons que la CUA pour MLN et SVM est comparable, mais avec une différence significative dans le temps en cours d'exécution. 4 Discussion Comme nos évaluations montrent, MLN n'échelle pas aussi bien que des modèles plus simples comme SVM. Cela est susceptible de se produire lors de l'utilisation complic relations ATED ou ensembles de données très importants, ce qui donne dans un très grand Markov générés réseaux. En fait, FOL est un MLN avec des valeurs infinies de poids, parce que dans FOL chaque formule est une contrainte infiniment dur, donc un monde ne peut pas violer une formule (prouvée dans Domingos et Richardson (2007)). Dans nos expériences, la tendance MLN d'avoir de très grandes valeurs de poids et ainsi agir comme FOL était évident que nous avons utilisé des modèles complexes avec de grands ensembles de données à grande échelle. Le tableau 4 compare la différence entre les valeurs de poids moyen pour la collecte BizCard quand on change la taille du domaine des constantes. Le rôle de la logique dans MLN est juste au niveau de la représentation, afin d'obtenir un petit ularity Gran- dans la représentation des connaissances. Considérant que, au niveau d'inférence, l'inférence logique est attrayante, mais elle est remplacée par inférence probabiliste. Comme expériences montre, cette capacité de représenta- tion fournie par FOL, complique le graphique rendant l'évolutivité une tâche plus difficile. RNTI-E-19- 439 - Application de Markov logique de document d'annotation et Citation Deduplication Fraction de corpus utilisé poids moyen de 10% 1,03 50% 50,3% 100 807,01 TAB. 4 - Les poids moyens sur différents sous-ensembles de BizCard. 5 Conclusion logique de Markov est un modèle d'apprentissage de la structure capable de modéliser des relations complexes entre les objets pour mieux attraper la complexité des données du monde réel. Nos expériences confirment que la modélisation des relations d'objet et de les utiliser dans l'apprentissage peut améliorer les performances des tâches de documents pertinents. Néanmoins, sa performance reste modeste par rapport aux meilleurs modèles non relationnelles. Un autre inconvénient est son lac d'évolutivité. inconvénient d'un tel est dû à la très grande taille des réseaux de Markov générés. Une solution possible au problème est de combiner des modèles relationnels et non relationnelles, de manière à ce que les modèles non relationnelles formés avec des caractéristiques de l'objet alimenteront des modèles relationnels formés avec ces prédictions et que les relations. Références Chakrabarti, S., B. Dom et P. Indyk (1998). Amélioration de la catégorisation des liens hypertexte en utilisant hyper-. Chang, C.-C. et C.-J. Lin (2001). LIBSVM: une bibliothèque pour les machines à vecteurs de support. Logiciel disponible à http://www.csie.ntu.edu.tw/ cjlin / libsvm. Culotta, A. et A. McCallum (2006). logique pratique markoviens contenant quantificateurs du premier ordre avec une application à l'incertitude d'identité. En CHSLP '06: Actes de l'atelier sur les problèmes et de calcul ardus conjoint Inference dans le discours et le traitement du langage, Morristown, NJ, USA, pp 41-48.. Association de linguistique informatique. Domingos, P. et M. Richardson (2007). logique de Markov: Un Cadre Unifié pour l'apprentissage statistique Relationnel. Dans L. Getoor et B. Taskar (Eds.), Introduction à la statistique Relational d'apprentissage, pp. 339-371. MIT Press. Kok, S. et W.-T. Yih (2009). Extraction information produit des recettes de courrier électronique en utilisant la logique de markov. Dans Actes de la sixième Conférence sur Email et Anti-Spam. Monge, A. et C. Elkan (1996). Le problème de la correspondance des champs: algorithmes et applications. Dans aux instances de la deuxième Conférence internationale sur la découverte de connaissances et d'exploration de données, p. 267-270. Neville, J. et D. Jensen (2003). Classement collective avec les réseaux de dépendance relationnelle. Journal of Research Machine Learning 8, 2007. Singla, P. et P. Domingos (2006). résolution Entité avec la logique de markov. Dans En ICDM, pp. 572-582. IEEE Computer Society Press. RNTI-E-19 - 440 -