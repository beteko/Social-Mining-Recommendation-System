Le maintien d'une base de données en ligne Bibliographical: Le problème de la qualité des données Michael Ley *, Patrick Reuther * * Département des bases de données et des systèmes d'information, Université de Trèves, Allemagne {ley, Reuther} @ uni-trier.de http: //dbis.uni- trier.de http://dblp.uni-trier.de Résumé. CiteSeer et Google Scholar sont énormes bibliothèques numériques, qui permettent d'accéder aux publications scientifiques (ordinateur-). Les deux collections fonctionnent comme les moteurs de recherche spécialisés, ils explorent le web avec peu d'intervention humaine et d'analyser les documents de les classer et d'extraire des métadonnées des textes intégraux. D'autre part, il y a des bases de données bibliographiques traditionnelles comme INSPEC pour l'ingénierie et PubMed pour la médecine. Pour le domaine de l'informatique au service de DBLP a évolué d'une petite bibliographie spécialisée dans une bibliothèque numérique couvrant la plupart des sous-domaines de la science informatique. Les collections du second groupe sont maintenus avec un effort humain massif. À long terme cet investissement ne se justifie que si la qualité des données des collections maintenues manuellement reste beaucoup plus élevé que celui des collections de style du moteur de recherche. Dans cet article, nous discutons de gestion et de problèmes algorithmiques de la qualité des données. Nous nous concentrons sur le problème particulier des noms de personnes. 1 Introduction Dans les domaines les plus scientifiques la quantité de publications est en croissance exponentielle. L'objectif principal des publications scientifiques est de documenter et de communiquer de nouvelles idées et de nouvelles ré- sultats. Sur la publication de niveau personnel est une sorte de points de collecte de crédit pour le CV. Sur le plan institutionnel, il y a une demande croissante d'évaluer les scientifiques et les départements par des mesures bibliométriques, qui nous l'espérons considèrent la qualité du travail. Tous les aspects exigent une collecte fiable, l'organisation et l'accès aux publications. À l'ère de papier cette infrastruc- ture a été fournie par les éditeurs et les bibliothèques. Internet, cependant, a permis à de nouveaux joueurs d'offrir des services. Par conséquent, de nombreux portails Internet spécialisés sont devenus importants pour les communautés fiques fiques. Les moteurs de recherche comme Google (-Scholar) ou CiteSeer, des archives centralisées comme arXic.org/CoRR et un grand nombre de serveurs Web personnels et / ou service, il est très facile de communiquer du matériel scientifique. Les anciens joueurs - éditeurs, sociétés savantes, les bibliothèques, les producteurs de bases de données, etc. - face à ces nouveaux concurrents en construisant de grandes bibliothèques numériques comme ScienceDirect (Elsevier), SpringerLink, ACM Digital Library ou Xplore (IEEE) dans le domaine de la science informatique. DBLP (Digital Bibliographie et projet de bibliothèque) (Ley, 2002) est un Internet « nouveau venu » que le service a commencé en 1993. Le service DBLP a évolué à partir d'une petite bibliographie spécia- isé aux systèmes de bases de données et la programmation logique à une bibliothèque numérique couvrant la plupart des sous-champs - 5 - RNTI-E-6 Le maintien d'une base de données en ligne de Bibliographical informatique. Aujourd'hui (Octobre 2005) des indices de DBLP plus de 675.000 publications publiées par plus de 400,000 auteurs et est accessible plus de deux millions de fois par mois sur le site principal maintenu à notre service. Pour construire une base de données bibliographique nécessite toujours des décisions entre qualité et quantité. Vous pouvez décrire chaque publication par un très riche ensemble de métadonnées et comprennent des classifications, des liens de citations, résumés, etc. - ou de la limiter au minimum: les auteurs, le titre et le lieu de publication (journal, livre, adresse Web). Pour DBLP, nous avons décidé de l'approche minimaliste, nous empêchent nos ressources très limitées pour produire des métadonnées détaillées d'un grand nombre. Pour chaque attribut des métadonnées du degré de cohérence qui fait la différence: Il est facile de produire un grand nombre de notices bibliographiques sans normalisation des noms de revues, les noms de conférence, noms de personnes, etc. Dès que vous essayez de garantie qu'une entité ( Journal, conférence, personne, ...) est toujours représenté par la même chaîne de caractères et pas tities en- partager la même représentation, l'entretien des données soient vient très cher. Traditionnellement, ce processus est appelé le contrôle de l'autorité. En DBLP le nombre de différents journaux est quelques taines, le dreds nombre de différentes séries de conférences quelques milliers. Pour la cohérence de garantie à cette échelle nécessite des soins, mais il est est pas un vrai problème. Même pour une base de données graphique biblio- taille moyenne comme DBLP, le contrôle de l'autorité pour les noms de personnes est beaucoup plus difficile: l'ampleur est> 400K et les informations disponibles sont souvent incomplètes et contradictoires. 2 Processus de gestion de la qualité des données basée sur les données de la qualité comprend de nombreuses dimensions et aspects. présente Redman une ETY de Vari de dimension tels que l'exhaustivité, l'exactitude, l'exactitude, la monnaie et la cohérence des données, pour ne citer que quelques-uns (Redman, 1996). D'autres aspects sont les univocité, la crédibilité, l'actualité, signifiance. Une bonne vue d'ensemble sur les différentes dimensions de la qualité des données peuvent être obtenues à partir (Dasus et Johnson, 2003) (Scannapieco et al., 2005). l'acquisition de l'information est une phase critique pour la gestion de la qualité des données. Pour DBLP il existe un large éventail de sources d'information primaires. En général, nous obtenons des documents électroniques, mais parfois toutes les informations doivent être tapé. Certaines sources importantes comme SpringerLink pour les notes de conférence en série sciences informatiques fournissent des informations de base dans un format très structuré qui est facile à transformer en nos formats internes. Pour de nombreuses sources très diversement formatée, il est pas rentable de développer des programmes wrapper, nous devons utiliser un éditeur de texte standard et / ou des scripts adhoc pour transformer l'entrée à un format adapté à notre logiciel. Dans certains cas, nous avons seulement les premières pages (pages de titre, table des matières) d'un volume de journal ou d'une procédure. La table des matières contient souvent des informations inférieure à la tête de l'article lui-même: Parfois, les noms donnés des auteurs sont abrégés. Les informations d'affiliation pour les auteurs est souvent absent. De nombreuses tables des matières contiennent des erreurs, surtout si elles ont été produites sous la pression du temps comme de nombreuses procédures. Même dans la tête de l'article lui-même, vous trouverez peut-être des erreurs typographiques. Une politique très simple mais important est d'entrer tous les articles d'un numéro de volume ou de la revue des procédures en une seule étape. En DBLP nous ne faisons que très peu exception de ce tout ou rien politique. Pour la qualité des données ce qui a plusieurs avantages par rapport à l'entrée CV des scientifiques ou des listes de référence des documents: Il est plus facile de garantir une couverture complète d'une série de journal ou d'une conférence. Il y a moins de danger pour devenir biaisé en faveur d'une personne (s). La rapidité est seulement pour atteindre, si de nouveaux numéros de revues ou de procédures sont complètement entrés dès qu'ils sont publiés. - 6 -RNTI-E-6 M. Ley et P. Reuther Une décision de conception très tôt était de générer des pages de l'auteur: Pour chaque personne qui a (co) auteur (ou modifié) une publication indexées dans DBLP notre logiciel génère un HTML- la page qui lui énumère / ses publications et fournit des hyperliens vers les co-auteurs et aux tables des matières pages l'article est paru dans. du point de vue de la base de données de ces sont simples vues matérialisées, pour les utilisateurs, ils le rendent très pratique pour naviguer dans la personne -personne et graphiques personne-publication. Le graphique implicite par la relation de co-auteur est une instance d'un réseau social (Watts, 2004) (Staab, 2005), le filet de co-auteur DBLP a récemment été utilisé pour analyser la structure de plusieurs sous-communautés de l'informatique (Hassan et Holt, 2004 ) (Elmacioglu et Lee, 2005) (Liu et al., 2005). Nous interprétons une nouvelle publication comme un ensemble de nouvelles arêtes dans le graphe de co-auteur - ou comme une incrémentation des poids des bords existants. Pour chaque nouvelle publication, nous essayons de trouver tous les auteurs de la collection existante. Nous utilisons plusieurs outils de recherche simple avec une variété d'algorithmes correspondant, dans la plupart des cas des expressions régulières traditionnelles sont plus utiles que toutes les fonctions de distance délicate. La recherche est essentiellement un processus manuel entraîné par l'intuition et l'expérience comment trouver plus efficacement perso n noms qui pourraient être mal orthographiés ou incomplets. Habituellement, ce processus de recherche manuelle est organisée en deux niveaux: Nous recrutons des étudiants pour effectuer la mise en forme (si nécessaire) et une première passe de recherche. Ils annoter des articles ou des noms qui nécessitent une enquête plus approfondie ou plus de connaissances de fond. Souvent, les étudiants trouvent incomplètes ou sans erreur dans la base de données. Dans un second passage sur la table des matières les cas problématiques sont traités et erreurs dans la base de données sont corrigées (ce qui est fait par M. Ley). Enfin les nouvelles informations sont entrées dans la base de données. Au cours de cette étape beaucoup de simples conventions de mise en forme sont vérifiés par des scripts, par exemple, nous sommes avertis s'il y a des caractères majuscules consécutifs dans un nom de personne. Lors d'une journée de travail, nous ajoutons -500 notices bibliographiques à DBLP. Il est irréaliste de croire que cela est possible sans introduire de nouvelles erreurs et sans oublier les anciens. Il est inévitable que les soins au cours du processus d'entrée varie. Le rêve évident est d'avoir un outil qui fait le travail - ou plus réaliste - ce qui nous permet de le faire. Pour approcher cet objectif, nous avons essayé de comprendre comment nous trouvons des erreurs et des incohérences plus efficacement. Souvent, il est très utile de regarder le voisinage d'une personne dans le graphe de co-auteur. Parce que la plupart des publications scientifiques sont produites par des groupes, de nombreuses erreurs apparaissent localement. Une première étape importante pour faciliter l'inspection manuelle a été le développement du navigateur DBL- (Klink et al., 2004) dans le cadre du projet SemiPort (Fankhauser et al., 2005). Le DBL-Browser fournit une interface utilisateur visuelle dans l'esprit de Microsoft Explorer: Un mélange de visualisations d'arbre avec dossier et documents icônes et de l'hypertexte de style web, il est très facile de naviguer à l'intérieur et entre les pages de l'auteur. Pour les personnes ayant de longues listes de publications la liste chronologique fournie par notre interface web devient insuffisante, des sélections par le co-auteur, revue / conférence, année, etc. sont très utiles. La DB mémoire principale sous-jacente du DBL-Browser garantit des temps de latence courts. Ceci est un facteur très important pour la facilité d'utilisation du système: une réaction rapide rend pratique « fouiner » et trouver des entrées suspectes. Le processus de la stratégie axée sur ce qui tente d'erreurs Avert d'entrer dans la base de données en contrôlant et en améliorant le processus d'acquisition de l'information devrait être complétée par une plus de données stratégie axée sur ce qui tente de détecter et corriger les erreurs dans les données existantes (Redman, 1996). - 7 - RNTI-E-6 Le maintien d'une base de données en ligne 3 Bibliographical guidée par les données des stratégies basées sur les données de gestion de la qualité peut être divisé en bashing base de données et les modifications de données. L'idée clé derrière dénigrement de base de données est de comparer ou recouper les données stockées dans une base de données de différentes sources de données comme une autre base de données ou d'informations des personnes du monde réel afin de trouver des erreurs ou pour confirmer la qualité des données d'origine. dénigrement de base de données est utile pour la détection d'erreur, mais la correction des erreurs est gênant. S'il existe des différences entre les deux enregistrements - qui sont supposés sous forme d'enregistrements décrivant la même entité de différentes sources - la question se pose laquelle des deux dossiers est correct, ou si l'un de ces événements est à cent pour cent correct. les modifications de données ne se concentrent pas sur la comparaison des enregistrements provenant de différentes sources, mais utilisent des règles métier. Ces règles métier sont spécifiques au domaine de la base de données. Pour le domaine des notices bibliographiques une telle règle est par exemple: « Alertez-nous s'il y a des auteurs dans l'ensemble de données qui varient légèrement dans leur orthographe, mais ont exactement les mêmes co-auteurs ». Exactement cette règle a été mise en œuvre par un logiciel simple: Nous construisons une structure de données qui représente le graphe de co-auteur. Nos algorithme vérifie toutes les paires (A1, A2) des noeuds d'auteurs qui ont la distance 2 sur le graphique. Si les noms de ces noeuds sont très similaires, nous les soupçonnons de représenter la même personne: si StringDistance (nom (a1), nom (a2)) < t avertissement alors la fonction de StringDistance et la valeur de seuil t requis une certaine expérimentation. À l'heure actuelle une version modifiée de la distance Levenshtein classique est utilisé, il met en œuvre des règles spéciales pour les caractères diacritiques (accents, trémas de, etc.) et pour les pièces de nom abrégé. Le programme produit une liste de plusieurs milliers d'avertissements. Le principal problème ne sont pas les fausses gouttes, mais les paires suspectes qui ne peuvent être résolus en raison du manque d'information. Dans de nombreux cas, nous sommes en mesure de trouver la partie manquante du casse-tête - par exemple sur les « pages d'accueil personnelles » des scientifiques eux-mêmes, mais souvent les informations ne sont pas disponibles avec un effort raisonnable. Nous avons vite découvert qu'il est plus économique de ne regarder que les personnes dont la liste de publications a été modifié récemment. Pour ces personnes, il est plus susceptible de résoudre orthographes contradictoires ou pour remplir les parties de nom abrégé. Le logiciel simple esquissée ci-dessus est utilisé quotidiennement depuis 2 ans. Il nous a aidés à trouver un grand nombre d'erreurs, mais il devrait être remplacé par un système amélioré pour deux raisons: Nous trouvons encore des erreurs trop plus ou moins par hasard et non par un processus de recherche bien compris. La précision des avertissements est encore trop faible - nous passons trop de temps sur des paires suspectes de noms que nous ne pouvons pas résoudre. Parce que le temps nous pouvons investir pour des corrections d'erreur est très limitée, nous avons besoin d'un outil qui nous montre les cas les plus prometteurs. 4 Cadre pour personne Nom Matching / Outlook Nous expérimentent actuellement un cadre logiciel beaucoup plus flexible pour la correspondance nom de la personne. Les idées principales sont les suivantes: • Il n'a pas de sens d'appliquer des fonctions à distance à toutes les paires de noms de personnes dans notre col- lection parce que cet espace de produit est trop grand (O (n2) algorithmes pour n> 400000) et parce que la comparaison des noms totalement sans rapport avec produit trop de gouttes fausses. Notre distance - 8 -RNTI-E-6 M. Ley et P. Reuther 2 dans l'heuristique du graphe de co-auteur est un (très réussie) par exemple d'une fonction de blocage. Un bloc est un ensemble de noms de personnes qui sont quelque part « en rapport », le blocage est défini comme un ensemble de blocs. Un nom de personne peut être membre de plusieurs blocs à l'intérieur d'un blocage. fonctions de distance sont appliquées uniquement à tous les tuples tirés d'un bloc et non de l'ensemble beaucoup plus grand de tous les noms - la complexité est désormais dominé par la taille du plus grand bloc. Une fonction de blocage est un algorithme qui produit un blocage. • Un ensemble très riche de fonctions de distance est décrite dans la littérature. Un excellent point de départ pour les explorer est le projet SecondString (Bilenko et al., 2003). Notre logiciel permet de brancher facilement dans de nouvelles fonctions à distance et de les combiner. Pour les noms de domaine très personne fonctions spécifiques semblent être utiles, par exemple pour correspondre à des transcriptions de noms chinois. • Le système est mis en œuvre en tant que données l'architecture en streaming très similaire à un processeur de requête dans un système de gestion de base de données. Cette architecture bien comprise donne beaucoup de flexibilité pour ajouter des opérateurs tels que l'union, intersection, la matérialisation, le chargement des résultats plus anciens, sélection, etc. Le point de départ du nouveau logiciel a été le reimplementation Java de nos algorithmes éprouvés dans le nouveau cadre. L'étape suivante a été l'ajout de plusieurs fonc- tions à distance et les opérateurs de flux. Pour la liste des avertissements plus utiles, chaque bloc à l'intérieur d'un blocage a une étiquette résultant - par exemple le nom de la personne qui construit la connexion tween les deux BE- suspects pour le blocage ou la distance 2, le nom de la conférence / revue à la fois ont publié, ou le mot de titre à la fois utilisé dans certaines de leurs publications. Cette annotation se propage à travers le flux. Une sortie typique de nos regards système comme celui-ci: Brian T. Bennett (2) - (Peter A. Franaszek) et (journaux / ibmrd) - Brian T. Bennet (2) Il y a 2 occurrences du nom Brian T. Bennett et 2 autres avec un « t ». Ils partagent le co-auteur Peter A. Franaszek et ont tous deux publié au Journal IBM de la Recherche et Dev eloppement. Pour le mouvement des logiciels open source a produit une variété fascinante de systèmes qui sont souvent compétitifs aux logiciels commerciaux. Pour le champ étroit des métadonnées pour les publications de l'informatique une telle culture « base de données ouverte » est presque absente. La seule exception est le partage des fichiers BibTeX dans la collection des sciences informatiques bibliographies fondée par Achille Christian. Depuis quelques années, l'ensemble de données DBLP est disponible en XML (http: //dblp.uni- trier.de/xml). A notre grande surprise cela a eu un impact très intéressant: (1) Nous sommes conscients de> 100 publications qui utilisent les données de DBLP comme un ensemble de données de test pour une très large gamme d'expériences, la plupart dans le domaine du traitement XML. (2) Plusieurs groupes ont publié des articles sur le problème de nom homonymie et utilisé les données DBLP comme exemple principal (Lee et al., 2004) (Le et al., 2005) (Han et al., 2005) .... Notre prochaines étapes consisteront à comprendre les détails de ces articles, à réimplémenter les méthodes proposées dans notre cadre, et de les tester dans notre travail quotidien. Remerciements: Le type le plus encourageant du contrôle de la qualité est la rétroaction des utilisateurs. Nous AP- précier tous les e-mails par les utilisateurs, nous espérons qu'aucun courrier électronique ne deviennent graves victimes de nos filtres anti-spam rigides. Nous essayons de corriger toutes les erreurs que nous sont pointés immédiatement. Malheureusement, il est bien être- yond nos ressources pour inclure toutes les publications que nous sommes invités à considérer. À l'heure actuelle DBLP est pris en charge par la zone Microsoft Bay Research Center et par le Max-Planck-Institut für Informatik. Nous espérons trouver plus de sponsors ... - 9 - RNTI-E-6 Le maintien d'une base de données en ligne Références bibliographiques Bilenko, M., R. J. Mooney, W. W. Cohen, P. ravikumar et S. E. Fienberg (2003). correspondance des noms d'adaptation dans l'intégration de l'information. IEEE Intell. Syst. 18 (5), 16-23. Dasu, T. et T. Johnson (2003). Data Mining d'exploration et de nettoyage des données. John Wiley. Elmacioglu, E. et D. Lee (2005). Sur six degrés de séparation dans DBLP-DB et plus. SIGMOD de la fiche 34 (2), 33-40. Fankhauser, P. et al. (2005). Fachinformationssystem Informatik (FIS-I) und Semantische Technologien für Informationsportale (SemIPort). En Informatik 2005, Bd. 2, pp. 698-712. Han, H., W. Xu, H. Zha et C. L. Giles (2005). Un modèle de mélange hiérarchique de Bayes naïfs pour le nom homonymie dans les citations de l'auteur. Dans SAC 2005, p. 1065-1069. ACM. Hassan, A. E. et R. C. Holt (2004). Le petit monde de logiciels d'ingénierie inverse. En WCRE, pp. 278-283. Klink, S., M. Ley, E. Rabbidge, P. Reuther, B. Walter et A. Weber (2004). La navigation et la visualisation des données bibliographiques numériques. En VisSym 2004, pp. 237-242. Lee, M.-L., W. Hsu, et V. Kothari (2004). Nettoyage des liens parasites dans les données. IEEE intelli- gent Systems 19 (2), 28-33. Ley, M. (2002). La bibliographie scientifique informatique dblp: Evolution, la recherche, les questions perspec- tives. En 2002 SPIRE, Lisbonne, Portugal, 11-13 Septembre, 2002, p. 1-10. Springer. Liu, X., J. Bollen, M. L. Nelson, et H. V. de Sompel (2005). réseaux co-auteur dans la communauté de la recherche en bibliothèque numérique. CoRR cs.DL / 0502056. Sur, B.-W., D. Lee, J. Kang et P. Mitra (2005). Etude comparative du problème de nom homonymie en utilisant un cadre à base de blocage évolutive. En JCDL 2005, p. 344-353. Redman, T. C. (1996). Qualité des données pour l'ère de l'information. Artech House. Scannapieco, M., P. Missier et C. Batini (2005). la qualité des données à un coup d'oeil. Datenbank- Spektrum 14, 6-14. Staab, S. (2005). Les réseaux sociaux appliqués. IEEE Intell. Syst. 20 (1), 80-93. Watts, D. J. (2004). Six Degrees: la science d'un âge connecté. NY: W. W. Norton. CiteSeer et CV Google Scholar des bibliothèques Sont Électroniques ac- CÉS gigantesques Ë Donnant des publications scientifiques (en informatique). Deux collections CÉS Sont des machines gérées de COMME recherche Spécialisées Qui le web Avec parcourent d'interventions hu- peu Maines et les Documents pour analysent les et versez classer des Méta-Extraire des Données textes complets. D'une partie de autre, il y a des also Bases de données bibliog raphiques PEC en INS- Comme ingéniérie et PubMed en médecine. En informatique, le service de DBLP un evolue d'en Une petite bibliographie Une bibliothèque électronique la Plupart des Couvrant Domaines de l'informatique. Les collections du deuxième groupe Avec effort Sont gérées de un dérables humain consi-. À longue terme, un tel Ne est justifié Investissement Que Si la Qualité des Donnees RESTE Très une Supérieure de collections de Celle machines de type de recherche. Dans this article, nous dis- aspects cutons les et gestion Algorithmique de la qualité des Données. Nous nous concentrons sur le des NOMs Problème de Particulier personnes. - 10 -RNTI-E-6