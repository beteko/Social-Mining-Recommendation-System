 Apprendre les relations de préférence et de co occurrence entre les labels en classification multi labels Khalil Laghmari Christophe Marsala Mohammed Ramdani Laboratoire Informatique de Mohammedia FSTM Hassan II University of Casablanca BP 146 Mohammedia 20650 Maroc laghmari khalil gmail com ramdani fstm ac ma Sorbonne Universités UPMC Univ Paris 06 CNRS LIP6 UMR 7606 4 place Jussieu 75005 Paris France christophe marsala lip6 fr Résumé En classification multi labels chaque instance est associée à un ou plusieurs labels Par exemple un morceau de musique peut être associé aux labels ’heureux’ et ’relaxant’ Des relations de co occurrence peuvent exister entre les labels par exemple les labels ’heureux’ et ’tris te’ ne peuvent pas être associés au même morceau de musique Les labels peuvent aussi avoir des relations de préférence par exemple pour un mor ceau de musique contenant plusieurs piques le label ’heureux’ est préféré par rapport au label ’relaxant’ Les relations entre les labels peuvent aider à mieux prédire les labels associés aux instances Les approches existantes peuvent apprendre soit les relations de co occurrence soit les relations de préférence Ce travail introduit une approche permettant de combiner l’apprentissage des deux types de relations Les expérimentations menées montrent que la nouvelle approche introduite offre les meilleurs résultats de prédiction par rapports à cinq approches de l’état de l’art 1 Introduction La reconnaissance de formes pattern recognition constitue une compétence d’intel ligence fondamentale Par exemple en considérant un ensemble de labels disponibles {’heureux’ ’relaxant’ ’triste’ ’nerveux’} l’intelligence humaine est capable d’associer ces labels à des morceaux de musique selon les émotions qu’ils expriment Le défi de transférer la compétence de reconnaissance de formes aux ordinateurs fait partie du domaine de l’apprentissage artificiel L’apprentissage est dit supervisé 215 Apprendre les relations de préférence et de co occurrence entre les labels lorsqu’un ensemble d’instances dont les labels associés sont connus est disponible L’ap prentissage consiste à établir des liens entres les attributs descriptifs des instances et les labels associés L’objectif de l’apprentissage est de pouvoir prédire les labels asso ciés aux instances en se basant sur les attributs descriptifs L’ensemble d’instances est dit multi labels lorsque chaque instance est associée à un ou plusieurs labels parmi un ensemble de labels disponibles La classification multi labels Herrera et al 2016 est une tâche d’apprentissage supervisé sur des instances multi labels La classification floue Bouchon Meunier et al 1997 où l’association entre chaque instance et les labels disponibles possède un degré dans l’intervalle [0 1] est une généralisation de la classification multi labels où le degré d’association est binaire 0 ou 1 Dans cet article on s’intéresse à la classification multi labels et plus particulièrement au défi d’apprendre des relations entre les labels et les exploiter pour améliorer les prédictions Loza Mencía et Janssen 2014 Loza Mencía et Janssen 2016 Il existe deux types principaux de relations entre les labels — les relations de co occurrence par exemple les émotions ’heureux’ et ’triste’ sont rarement associées au même morceau de musique et les émotions ’heureux’ et ’relaxant’ peuvent être associées au même morceau de musique — les relations de préférence par exemple pour un morceau de musique contenant plusieurs piques le label à préférer entre ’relaxant’ et ’heureux’ pour l’associer à ce morceau de musique est le label ’heureux’ Les approches de classification multi labels existantes peuvent apprendre soit uni quement des relations de co occurrence soit uniquement des relations de préférence Gibaja et Ventura 2015 Dans cet article nous faisons l’hypothèse qu’une approche qui permet d’apprendre les deux types de relations entre les labels peut avoir une meilleure performance en prédiction que les approches existantes La suite de cet article est organisée comme suit l’état de l’art des approches de classification multi labels est discuté dans la Section 2 la nouvelle approche de classification multi labels permettant l’apprentissage des relations de co occurrence et de préférence entre les labels est présentée dans la Section 3 l’étude expérimentale comparant la nouvelle approche avec les approches existantes est présentée dans la Section 4 2 Classification multi labels 2 1 Description formelle de la classification multi labels Soit X = {xi}1≤i≤n un ensemble d’instances Soit A = {aj}1≤j≤p un ensemble d’attributs descriptifs Chaque instance xi est un vecteur de valeurs d’attributs des criptifs xi a1 xi ap = xi aj 1≤j≤p Soit C = {cl}1≤l≤k un ensemble de labels Chaque instance xi est associée à un sous ensemble de labels yi ⊆ C L’ensemble de sous ensembles de labels est noté P C Soit λ X → P C la fonc tion qui associe chaque instance xi ∈ X au sous ensemble de labels correspondant λ xi = yi La fonction λ est dite fonction de supervision de l’ensemble d’apprentis sage X Soit E P C × P C → [0 1] une fonction objectif à optimiser La classifica tion multi labels consiste à apprendre à partir de l’ensemble d’apprentissage supervisé 216 K Laghmari et al X λ un classifieur H a1 × × ap → P C qui prédit pour chaque instance x ∈ a1 × × ap l’ensemble de labels correspondants H x L’objectif du classi fieur multi labels est d’optimiser la fonction objectif E évaluant la prédiction H x par rapport au véritable sous ensemble de labels y ⊆ C associé à x 2 2 Approches de classification multi labels La classification multi labels est une généralisation de la classification mono label où chaque instance xi ∈ X ne peut être associée qu’à un seul label à la fois |yi| = 1 La classification multi labels peut être effectuée en adaptant les classifieurs mono label au cas des instances multi labels Sun et al 2016 Agrawal et al 2016 Wang et al 2015 L’inconvénient de cette catégorie d’approches est qu’il faut modifier l’algo rithme de classification pour modifier la stratégie d’apprentissage de relations entre les labels Une autre stratégie pour construire un classifieur multi labels consiste à appliquer des transformations sur les instances multi labels pour se ramener au cas mono label Tsoumakas et Katakis 2007 Cette catégorie d’approches possède deux principaux avantages — les classifieurs mono label existants peuvent être utilisés pour gérer les sous pro blèmes de classification mono label générés par la transformation des instances — il est possible de modifier la stratégie d’apprentissage de relations entre les labels en modifiant juste la méthode de transformation sans modifier l’algorithme de classification de base Les trois principales catégories d’approches de transformation du cas multi labels au cas mono label sont discutées dans la suite 2 2 1 Approches basées sur la prédiction directe de sous ensembles de labels La classification multi labels peut être transformée en classification mono label en considérant chaque sous ensemble de labels en tant qu’un nouveau label Read 2008 Soit C ′ l’ensemble de nouveaux labels et soit L X → C ′ la fonction qui associe à chaque instance de l’ensemble d’apprentissage xi ∈ X un nouveau label L xi ∈ C ′ Le nouveau label L xi correspond au sous ensemble de labels yi initialement asso cié à xi L’ensemble de nouveaux labels C ′ peut contenir au plus n labels différents C ′ = {c′l}1≤l≤n dans le cas où les sous ensembles de labels {yi}1≤i≤n dans l’ensemble d’apprentissage X sont tous différents Soit L−1 C ′ → X la fonction qui fournit pour un nouveau label c′l ∈ C ′ une instance xi ∈ X telle que L−1 c′l = xi et L xi = c′l Un classifieur mono label h a1 × × ap → C ′ peut être construit à partir de X muni de la fonction de supervision L Le classifieur multi labels H fournit une prédiction pour une instance donnée x ∈ a1 × × ap en faisant la conversion du nouveau label prédit h x en un sous ensemble de labels dans C Le classifieur H est donné par H x = λ L−1 h x L’inconvénient de cette catégorie d’approches de transformation est que deux sous ensembles de labels ayant des labels en commun sont considérés comme totalement 217 Apprendre les relations de préférence et de co occurrence entre les labels différents dans le problème transformé Par conséquent les relations entre les labels appartenant à deux sous ensembles de labels différents ne peuvent pas être apprises 2 2 2 Approches basées sur la prédiction intermédiaire de la présence de chaque label Soit λcl X → {0 1} la fonction qui associe à chaque instance xi ∈ X la valeur 1 si le label cl est associée à l’instance xi cl ∈ λ xi et la valeur 0 sinon L’approche ’Binary Relevance’ BR consiste à construire un classifieur multi labels H à partir d’un ensemble de k classifieurs mono labels {Hcl}1≤l≤k Tsoumakas et Katakis 2007 Chaque classifieurHcl a1 × × ap → {0 1} apprend de l’ensemble X muni de la fonction de supervision λcl à prédire pour une instance donnée x si elle est associée au label cl Hcl x = 1 ou non Hcl x = 0 Le classifieur multi labels H est donné par H x = {cl Hcl x = 1}1≤l≤k L’inconvénient de l’approche BR est que les classifieurs {Hcl}1≤l≤k sont tous indépendants L’approche BR ne permet donc pas d’apprendre des relations de co occurrence entre les labels L’approche ’Classifier Chains’ CC est une extension de l’approche BR permet tant l’apprentissage des relations entre les labels en introduisant un ensemble d’at tributs descriptifs supplémentaires B = {bl}1≤l≤k Chaque instance xi est étendue telle que xei = xi a1 xi ap λc1 xi λck xi L’ensemble d’apprentissage Xl de chaque classifieur Hcl est construit par une projection de l’ensemble d’appren tissage étendu Xe = {xei}1≤i≤n sur l’espace d’attributs descriptifs A ∪ {bl′}1≤l′<l Les attributs {bl′}l′≥l sont donc ignorés par le classifieur Hcl Le classifieur Hc2 a1 × × ap × b1 → {0 1} ne peut pas fournir directement une prédiction pour une instance x ∈ a1× × ap En effet la valeur de l’attribut b1 est inconnue pour les instances qui ne font pas partie de l’ensemble d’apprentissage L’instance x est donc d’abord étendue par la prédiction du classifieur Hc1 x = xa1 xap Hc1 xi avant d’être reçue par le classifieur Hc2 Chaque classifieur Hcl a donc la possibilité de fournir des prédictions en se basant sur les prédictions des autres classifieurs qui le précèdent {Hcl′}1≤l′<l≤k L’inconvénient de l’approche CC est que les relations de co occurrence qui peuvent être apprises dépendent de l’ordre initial des labels Par conséquent la prédiction d’un label cl ne peut pas dépendre d’une relation de co occurrence avec les labels cl′ l′ > l L’approche ’Aggregating Independent and Dependent classifiers’ AID permet d’apprendre les relations entre les labels sans dépendre de l’ordre initial des labels en se basant sur deux ensembles de classifieurs Montañés et al 2011 Le premier ensemble de classifieurs {hcl}1≤l≤k est construit par l’approche BR chaque classi fieur hl est indépendant des autres classifieurs Le deuxième ensemble de classifieurs {Hcl}1≤l≤k est construit de façon similaire à l’approche CC La différence est que l’ensemble d’apprentissage Xcl pour le classifieur Hcl est construit en projetant l’en semble étendu Xe sur tous les attributs initiaux et supplémentaires sauf l’attribut bl à prédire A ∪ B − {bl} Ceci permet au classifieur Hcl d’établir sa prédiction en se basant sur la présence ou l’absence des autres labels cl′ l′ 6= l Chaque instance donnée x ∈ a1 × × ap est étendue par les prédictions du premier ensemble de classifieurs xe = xa1 xap hc1 x hcl−1 x hcl+1 x hck x avant d’être passée en entrée au classifieur Hcl Chaque classifieur dépendant Hcl fournit sa prédiction en 218 K Laghmari et al se basant sur les prédictions initiales {hcl′ x }l′ 6=l et en ignorant les prédictions finales des autres classifieurs {Hcl′ x }l′ 6=l La prédiction du classifieur multi labels H est don née par H x = {cl Hcl x = 1}1≤l≤k L’approche AID possède deux inconvénients remarquables — elle nécessite l’apprentissage de 2k classifieurs — l’ensemble de labels prédit finalement n’est pas nécessairement en accord avec les relations apprises contrairement à l’approche CC En effet chaque label prédit finalement est en accord avec les relations apprises uniquement par rapport aux prédictions initiales {hcl′ x }l′ 6=l qui sont remplacées par les prédictions finales {Hcl′}1≤l′<l≤k L’approche ’Pre selection Selection and Interest of chaining based classifier’ PSI permet de combiner les avantages des approches CC et AID Laghmari et al 2016 Un ensemble de classifieurs initiaux {Hcl}1≤l≤k est construit de la même façon que les classifieurs dépendants dans l’approche AID Ceci permet d’apprendre initialement les relations entre les labels sans restriction Un ordre de prédiction est établi ensuite afin de fournir des prédictions cohérentes avec les relations apprises comme dans l’approche CC Le fait qu’un classifieur Hcl soit appris en considérant l’ensemble étendu d’attri buts A ∪ C − {cl} n’implique pas nécessairement que la prédiction de Hcl dépend de tous les attributs A ∪C − {cl} L’ordre des classifieurs {Hcl} est établi tel que chaque classifieur Hcl soit précédé par les classifieurs dont il dépend Le défi relevé par l’approche PSI est le cas d’une dépendance cyclique par exemple le cas où un classifieur Hcl dépend de l’attribut bl′ et le classifieur Hcl′ dépend de l’at tribut bl L’ordre de prédiction entre Hcl et Hcl′ ne peut pas être donné dans ce cas L’approche PSI est basée sur trois mesures appelées pré selection sélection et intérêt de chaînage qui permettent d’éliminer les dépendances cycliques La mesure de pré selection fournit l’ensemble de classifieurs impliqués dans une dépendance cyclique La mesure de sélection sélectionne un classifieur à remplacer par un nouveau classifieur La mesure d’intérêt de chaînage fournit l’ensemble d’attributs à considérer par le nouveau classifieur de façon à apprendre les relations entre les labels sans retomber dans une dé pendance cyclique Lorsqu’un classifieur est remplacé certaines dépendances cycliques disparaissent mais pas nécessairement toutes Les trois mesures PSI sont appliquées itérativement jusqu’à l’élimination de toutes les dépendances cycliques L’approche PSI possède deux principaux avantages — même si certains classifieurs peuvent être appris deux fois pour éliminer une dé pendance cyclique seulement les k classifieurs finaux sont gardés par l’approche PSI — l’ordre de prédiction est établi après l’apprentissage des classifieurs Ceci permet de ne pas empêcher l’apprentissage de certaines relations au préalable comme dans l’approche CC L’inconvénient de toutes les approches basées sur la prédiction intermédiaire de la présence de chaque label avant de fournir une prédiction multi labels BR CC AID et PSI est que les relations exprimant une préférence entre les labels ne sont pas apprises 219 Apprendre les relations de préférence et de co occurrence entre les labels 2 2 3 Approches basées sur la prédiction intermédiaire de la préférence entre chaque paire de labels L’approche ’Ranking by Pairwise Comparisons’ RPC est basée sur 12k k−1 clas sifieurs {Hcl cl′}1≤l<l′≤k permettant la prédiction d’une préférence entre chaque couple labels cl cl′ Hüllermeier et al 2008 L’ensemble d’apprentissageXcl cl′ du classifieurHcl cl′ est le sous ensemble deX conte nant uniquement les instances associées exclusivement à l’un des deux labels cl ou cl′ Xcl cl′ = {xi ∈ X cl ∈ yi et cl′ ∈ yi ou cl ∈ yi et cl′ ∈ yi } Soit λcl cl′ X → {cl cl′ ∅} la fonction donnée par — λcl cl′ xi = cl si cl ∈ yi et cl′ ∈ yi — λcl cl′ xi = cl′ si cl ∈ yi et cl′ ∈ yi — λcl cl′ xi = ∅ dans les autres cas La fonction λcl cl′ fournit le label préféré entre cl et cl′ pour les instances de l’ensemble d’apprentissage Le symbole ∅ indique que l’instance xi n’appartient pas à l’ensemble d’apprentissage du classifieur Hcl cl′ Chaque classifieur Hcl cl′ apprend à partir de l’ensemble Xcl cl′ muni de la fonction de supervision λcl cl′ à prédire le label préféré entre cl et cl′ pour une instance donnée x Soit Vcl a1 × × ap → [[0 k − 1]] la fonction qui fournit pour chaque label cl ∈ C le nombre de fois où il a été préféré pour une instance x le nombre de votes pour le label cl Vcl x = |{ cl′ cl′′ Hcl′ cl′′ x = cl}1≤l′<l′′≤k| L’approche RPC ne fixe pas une méthode de prédiction et permet juste d’ordonner les labels selon le nombre de fois qu’ils ont été préférés par les classifieurs {Hcl cl′}1≤l<l′≤k Il est possible par exemple de prédire les labels dont le nombre de votes est supérieur à un seuil fixé v Le classifieur multi labels H dans ce cas est donné par H x = {cl ∈ C Vcl x ≥ v} L’approche ’Calibrated Label Ranking’ CLR est une extension de l’approche RPC qui permet de sélectionner les labels à prédire en utilisant un label virtuel au lieu d’un paramètre seuil Fürnkranz et al 2008 L’approche CLR introduit un label virtuel c0 et apprend k classifieurs de plus {Hcl c0}1≤l≤k par rapport à l’approche RPC La fonction de supervision correspondant au classifieur Hcl c0 est donnée par λcl c0 xi = cl si cl ∈ yi et λcl c0 xi = c0 sinon Le classifieur multi labels H prédit tous les labels qui reçoivent plus de votes que le label virtuel H x = {cl ∈ C Vcl x ≥ Vc0 x } L’avantage des approches basées sur l’apprentissage de préférences RPC et CLR est que l’ensemble d’apprentissage est réduit pour chaque classifieur permettant de prédire une préférence Ceci est aussi un inconvénient car cela empêche d’apprendre les relations de co occurrence puisqu’il n’y a pas nécessairement assez d’instances en commun entres les ensembles d’apprentissage de deux classifieurs 3 Nouvelle approche de classification multi labels Soit X = {x1 x2 x3 x4 x5 x6} un ensemble d’apprentissage et C = {c1 c2 c3 c4} un ensemble de labels |C| = k = 4 La Table 1 représente les fonctions de super vision liant les instances aux labels correspondants Par exemple le classifieur Hc1 c3 220 K Laghmari et al permettant de prédire la préférence entre c1 et c3 dans l’approche RPC Section 2 2 3 est construit à partir du sous ensemble d’apprentissage Xc1 c3 = {x3 x6} muni de la fonction de supervision λc1 c3 Les instances associées au symbole ∅ dans la Table 1 sont ignorées à l’étape d’apprentissage du classifieur Hc1 c3 λc1 c2 λc1 c3 λc1 c4 λc2 c3 λc2 c4 λc3 c4 λc1 λc2 λc3 λc4 x1 c1 ∅ ∅ c3 c4 ∅ 1 0 1 1 x2 c1 ∅ ∅ c3 c4 ∅ 1 0 1 1 x3 c1 c1 c1 ∅ ∅ ∅ 1 0 0 0 x4 c2 ∅ ∅ c2 c2 ∅ 0 1 0 0 x5 ∅ ∅ ∅ ∅ ∅ ∅ 1 1 1 1 x6 ∅ c3 ∅ c3 ∅ c3 0 0 1 0 Tab 1 Exemple de données d’apprentissage Un exemple d’une règle de décision basée sur une combinaison des relations de dé pendance et de préférence est donné par ’si pour une instance x c1 est préféré au c2 et c3 est associé à x alors prédire que c4 est associé à x’ Afin d’apprendre cette règle de décision le classifieur Hc4 permettant de prédire l’ab sence ou la présence du label c4 doit considérer λc1 c2 et λc3 dans la Table 1 en tant qu’attributs descriptifs supplémentaires Cependant certaines instances n’ont pas une valeur définie pour les attributs de préférences supplémentaires symbole ∅ Pour remédier à ce problème des valeurs manquantes l’idée de notre approche est de les prédire en utilisant les classifieurs de préférences {Hcl cl′}1≤l<l′≤k décrits dans l’approche RPC Section 2 2 3 Ensuite pour apprendre à la fois les relations de pré férence et de dépendance chaque classifieur Hcl l ∈ [[1 k]] est construit en considérant {λcl′ cl′′ }1≤l′<l′′≤k et {λcl′}l′ 6=l en tant qu’attributs descriptifs supplémentaires Ceci risque de produire des dépendances cycliques qui peuvent être éliminées en utilisant l’approche PSI Section 2 2 2 Notre approche appelée Stacked_RPC_PSI est donc une combinaison des approches RPC et PSI permettant de tirer avantage à la fois des relations de préférence et de dépendance entre les labels et en utilisant le minimum nombre de classifieurs binaires 4 Expérimentation 4 1 Mesures de description des instances multi labels La performance des classifieurs multi labels peut dépendre de la répartition des labels par rapport aux instances Trois mesures sont souvent utilisées pour décrire la distribution des labels dans un jeu de données multi labels Tsoumakas et Katakis 2007 — la cardinalité label cardinality qui évalue la moyenne du nombre de label as sociés à une instance LC = 1 n n∑ i=1 |yi| 221 Apprendre les relations de préférence et de co occurrence entre les labels Données Domaine Instances Attribues Labels LC LD DLC emotions musique 593 72 6 1 869 0 311 27 scenes images 2407 294 6 1 074 0 179 15 yeast biologie 2417 103 14 4 237 0 303 198 Tab 2 Données multi labels — la densité label density qui évalue la moyenne du nombre de labels associés à une instance par rapport au nombre total de labels LD = 1 n n∑ i=1 |yi| k = LC k — le nombre de combinaisons distinctes de labels distinct label combinations qui évalue le nombre de sous ensembles de labels différents qui sont associés aux instances DLC = |{yi}1≤i≤n| 4 2 Données et procédure d’expérimentation Trois jeux de données multi labels provenant de domaines différents sont utilisés pour comparer la performance de prédiction des classifieurs multi labels Table 2 Le jeu de données des émotions Trohidis et al 2008 contient un ensemble de 594 instances Chaque instance représente un morceau de musique décrit par 72 attributs et associé à une ou plusieurs émotions parmi l’ensemble {amazed suprised happy pleased relaxing calm quiet still sad lonely angry aggresive} Le jeu de données des scènes Boutell et al 2004 contient 2407 instances Chaque instance représente une image décrite par 294 attributs et associée à un sous ensemble de labels dans {Beach Sunset FallFoliage Field Mountain Urban} Le jeu de données des protéines contient 2417 instances décrites par 103 attributs Elisseeff et Weston 2001 Chaque protéine est associée à une localisation dite composant cellulaire L’objectif est de prédire les localisations des protéines dans les cellules de levure La nouvelle approche introduite Stacked_RPC_PSI est comparée avec cinq autres approches existantes AID BR CC CLR et PSI Les arbres de décision Quinlan 1993 sont utilisés pour construire les classifieurs mono labels de base La méthode de validation croisée en 10 groupes est appliquée sur chaque jeu de données La moyenne par rapport aux 10 plis pour les mesures d’évaluation de la prédiction est calculée pour chacun des trois jeux de données ’emotions’ ’scenes’ et ’yeast’ Approche CRHS FMEASURE GMEAN EM HL PRECISION RECALL ACC− AID 0 46 0 55 0 60 0 19 0 24 0 58 0 58 0 84 BR 0 45 0 54 0 60 0 18 0 24 0 59 0 56 0 85 CC 0 46 0 55 0 60 0 21 0 25 0 59 0 56 0 85 CLR 0 45 0 54 0 59 0 17 0 24 0 55 0 60 0 83 PSI 0 48 0 56 0 61 0 25 0 24 0 59 0 58 0 84 Stacked_RPC_PSI 0 48 0 57 0 62 0 24 0 23 0 60 0 59 0 86 Tab 3 Évaluation de la prédiction sur les données ’emotions’ 222 K Laghmari et al Approche CRHS FMEASURE GMEAN EM HL PRECISION RECALL ACC− AID 0 55 0 58 0 62 0 46 0 15 0 57 0 63 0 91 BR 0 51 0 54 0 56 0 44 0 12 0 53 0 57 0 95 CC 0 57 0 59 0 60 0 54 0 13 0 60 0 59 0 93 CLR 0 50 0 53 0 58 0 40 0 13 0 51 0 59 0 94 PSI 0 57 0 59 0 60 0 54 0 13 0 59 0 59 0 93 Stacked_RPC_PSI 0 60 0 62 0 63 0 56 0 12 0 63 0 62 0 94 Tab 4 Évaluation de la prédiction sur les données ’scenes’ Approche CRHS FMEASURE GMEAN EM HL PRECISION RECALL ACC− AID 0 40 0 53 0 63 0 06 0 27 0 56 0 55 0 81 BR 0 42 0 54 0 63 0 06 0 25 0 60 0 55 0 85 CC 0 43 0 52 0 59 0 16 0 24 0 60 0 52 0 87 CLR 0 47 0 59 0 66 0 10 0 21 0 67 0 59 0 88 PSI 0 43 0 53 0 60 0 15 0 26 0 58 0 53 0 84 Stacked_RPC_PSI 0 44 0 54 0 61 0 13 0 23 0 62 0 53 0 88 Tab 5 Évaluation de la prédiction sur les données ’yeast’ 4 3 Mesures d’évaluation de la qualité de prédiction La qualité de prédiction peut être évaluée en se basant sur plusieurs mesures Her rera et al 2016 La mesure de l’erreur de hamming Hamming loss Destercke 2014 donnée par HL = |yi4H xi |k avec yi4H xi étant la différence symétrique entre l’ensemble correct de labels associés et l’ensemble de labels prédit donnée par yi4 H xi = {cl ∈ yi − H xi }1≤l≤k ⋃ {cl ∈ H xi − yi}1≤l≤k L’erreur de Hamming évalue la proportion des erreurs entre les labels effectivement associés à l’instance et les labels prédits par rapport au nombre total de labels dis ponibles Le nombre de labels disponibles représente le nombre maximal des erreurs possibles entre les labels effectivement associés à l’instance et les labels prédits L’erreur de Hamming est une mesure très optimiste pour les données ayant une cardinalité et une densité faibles Le classifieur multi labels dans ce cas apprend à prédire des sous ensembles de labels avec une cardinalité faible Ainsi même si aucun des labels prédits est effectivement associé à l’instance yi∩H xi = ∅ le nombre d’erreurs |yi4H xi | reste petit par rapport au nombre maximal d’erreurs k parce que la cardinalité de l’ensemble yi et de l’ensemble H xi est faible Le score de Hamming closely related Hamming score Godbole et Sarawagi 2004 n’est pas sensible à la cardinalité et à la densité des labels Il mesure le nombre de labels prédits correctement par rapport au nombre de l’union des labels prédits et des labels effectivement associés à l’instance CRHS = |yi ∩H xi ||yi ∪H xi | La précision precision mesure la probabilité qu’un label prédit soit effectivement associé à l’instance PRECISION = |yi ∩H xi ||H xi | Le rappel recall mesure la probabilité qu’un label associé à l’instance soit prédit RECALL = |yi ∩H xi ||yi| 223 Apprendre les relations de préférence et de co occurrence entre les labels La mesure Fβ van Rijsbergen 1974 combinant la précision et le rappel est donnée pour chaque β > 0 par Fβ = 1 + β2 PRECISION× RECALL β2 × PRECISION + RECALL Plus d’importance est donnée à la précision pour les valeurs β < 1 et plus d’importance est donnée pour le rappel pour les valeurs β > 1 La même importance est donnée pour la précision et le rappel pour la valeur β = 1 La moyenne géométrique GMEAN Kubat et al 1997 est une mesure d’évalua tion de la qualité de prédiction adaptée aux données avec un déséquilibre de labels pré sence de labels associés à presque toutes les instances et des labels associés à très peu d’instances En effet toutes les mesures précédentes favorisent un classifieur qui prédit le label majoritaire en cas de déséquilibre de labels La moyenne géométrique combine la précision positive donnée par acc+ = |{cl cl∈yi et cl∈H xi }1≤l≤k||yi| = RECALL et la précision négative donnée par acc− = |{cl cl ∈yi et cl ∈H xi }1≤l≤k||C−yi| en une seule mesure donnée par GMEAN = √ acc+ × acc− La correspondance exacte exact match est la mesure d’évaluation la plus stricte considérant la prédiction d’un ensemble de labels correcte seulement si l’ensemble pré dit correspond exactement à l’ensemble de labels effectivement associés à l’instance EM = 1 if yi = H xi 0 sinon 4 4 Résultats et discussion Toutes les approches exploitant les relations entre les labels fournissent générale ment des résultats meilleurs que l’approche BR qui ne permet pas l’apprentissage des relations entre les labels Tables 3 à 5 La nouvelle approche Stacked_RPC_PSI fournit les meilleurs résultats pour les données ’emotions’ et ’scenes’ mais pas pour les données ’yeast’ En effet les données ’yeast’ présentent un déséquilibre dans la distribution de labels certains labels sont très rares ou sont prédominants L’approche CLR fournit les meilleurs résultats pour les données ’yeast’ parce qu’elle est basée sur l’apprentissage de préférence utilisant juste un sous ensemble réduit de l’ensemble d’apprentissage L’effet du déséquilibre de la distribution de labels est donc réduit pour l’approche CLR Les approches CC AID et PSI sont basées sur les dépendances entre les labels qui peuvent propager les erreurs de prédiction Dans le cas où la prédiction d’un label dépend de la prédiction d’un label rare qui ne sera presque jamais prédit l’erreur de prédiction pour le label rare peut être propagée pour les labels dépendants La nouvelle approche Stacked_RPC_PSI fournit des résultats meilleurs que les approches CC AID et PSI parce qu’elle est basée aussi sur l’apprentissage de préférences Ceci confirme l’hypothèse que la combinaison des relations de co occurrence et des relations de préférence peut améliorer les prédictions 5 Conclusion Apprendre les relations entre les labels et les exploiter pour améliorer les prédic tions est un défi intéressant dans la classification multi labels L’approche RPC permet l’apprentissage des relations de préférences entre les labels et l’approche PSI per met l’apprentissage des relations de co occurrence entre les labels sans restriction au 224 K Laghmari et al préalable Ce travail introduit l’approche Stacked_RPC_PSI qui combine les deux approches RPC et PSI afin de bénéficier à la fois des relations de préférence et de co occurrence pour améliorer la prédiction L’expérimentation sur trois jeux de données montrent que l’approche Stacked_RPC_PSI est très compétitive avec les approches de l’état de l’art L’inconvénient de l’approche Stacked_RPC_PSI est qu’elle est sensible au problème du déséquilibre de la distribution de labels présence de labels rares ou de labels prédominants Une idée qui pourrait réduire l’impact du déséquilibre de la dis tribution de labels dans l’approche Stacked_RPC_PSI consiste à éviter d’apprendre des dépendances par rapport aux classifieurs de préférence triviaux qui prédisent le label majoritaire Références Agrawal S J Agrawal S Kaur et S Sharma 2016 A comparative study of fuzzy pso and fuzzy svd based rbf neural network for multi label classification Neural Computing and Applications 1–12 Bouchon Meunier B C Marsala et M Ramdani 1997 Learning from Imperfect Data John Wiley Sons Boutell M R J Luo X Shen et C M Brown 2004 Learning multi label scene classification Pattern Recognition 37 9 1757 – 1771 Destercke S 2014 Multilabel Prediction with Probability Sets The Hamming Loss Case pp 496 – 505 Cham Springer International Publishing Elisseeff A et J Weston 2001 A kernel method for multi labelled classification In In Advances in Neural Information Processing Systems 14 pp 681–687 MIT Press Fürnkranz J E Hüllermeier E Loza Mencía et K Brinker 2008 Multilabel clas sification via calibrated label ranking Machine Learning 73 2 133–153 Gibaja E et S Ventura 2015 A tutorial on multilabel learning ACM Comput Surv 47 3 52 1–52 38 Godbole S et S Sarawagi 2004 Advances in Knowledge Discovery and Data Mining 8th Pacific Asia Conference PAKDD 2004 Sydney Australia May 26 28 2004 Proceedings Chapter Discriminative Methods for Multi labeled Classification pp 22–30 Berlin Heidelberg Springer Berlin Heidelberg Herrera F F Charte A J Rivera et M J del Jesus 2016 Multilabel Classification Problem Analysis Metrics and Techniques Chapter Multilabel Classification pp 17–31 Hüllermeier E J Fürnkranz W Cheng et K Brinker 2008 Label ranking by learning pairwise preferences Artificial Intelligence 172 16–17 1897 – 1916 Kubat M R Holte et S Matwin 1997 Learning when negative examples abound pp 146–153 Berlin Heidelberg Springer Berlin Heidelberg Laghmari K C Marsala et M Ramdani 2016 Graded multi label classification Compromise between handling label relations and limiting error propagation In 11th Inter Conf on Intelligent Systems Theories and Applications SITA pp 1–6 225 Apprendre les relations de préférence et de co occurrence entre les labels Loza Mencía E et F Janssen 2014 Stacking label features for learning multilabel rules In S Džeroski P Panov D Kocev et L Todorovski Eds Discovery Science 17th Inter Conf DS 2014 Bled Slovenia October 8 10 2014 Proceedings Volume 8777 of Lecture Notes in Computer Science pp 192–203 Springer Loza Mencía E et F Janssen 2016 Learning rules for multi label classification a stacking and a separate and conquer approach Machine Learning 105 1 77–126 Montañés E J R Quevedo et J J del Coz 2011 Aggregating independent and dependent models to learn multi label classifiers In D Gunopulos T Hofmann D Malerba et M Vazirgiannis Eds ECML PKDD 2 Volume 6912 of Lecture Notes in Computer Science pp 484–500 Springer Quinlan J R 1993 C4 5 Programs for Machine Learning San Francisco CA USA Morgan Kaufmann Publishers Inc Read J 2008 A Pruned Problem Transformation Method for Multi label classifi cation In Proc 2008 New Zealand Computer Science Research Student Conference NZCSRS 2008 pp 143–150 Sun Z Z Guo M Jiang X Wang et C Liu 2016 Research and Application of Fast Multi label SVM Classification Algorithm Using Approximate Extreme Points pp 39–52 Cham Springer International Publishing Trohidis K G Tsoumakas G Kalliris et I P Vlahavas 2008 Multi label classifica tion of music into emotions In J P Bello E Chew et D Turnbull Eds ISMIR pp 325–330 Tsoumakas G et I Katakis 2007 Multi label classification An overview Int J Data Warehousing and Mining 2007 1–13 van Rijsbergen C J 1974 Foundations of evaluation Journal of Documentation 30 365–373 Wang X S An H Shi et Q Hu 2015 Fuzzy Rough Decision Trees for Multi label Classification pp 207–217 Cham Springer International Publishing Summary In multi label classification each instance can be associated to more than one label For example a music record can be associated to both labels ’happy’ and ’relaxing’ Labels can be related with co occurrence dependencies for example labels ’happy’ and ’sad’ can not be associated to the same music record Labels can also be related with preference relations for example the label ’happy’ is preferred over the label ’relaxing’ to be associated to a music record containing several pikes Label relations can help to better predict labels associated to instances Existing approaches can learn either co occurrence relations or preference relations This work introduces an approach allowing to learn the two types of relations in order to improve the predictive performance Experiments carried out show that the new introduced approach gives the best prediction results compared to five approaches from the state of the art 226 