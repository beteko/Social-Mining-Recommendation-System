 Interprétation spectrale de la classification relationnelle Lazhar Labiod Younès Bennani LIPN UMR 7030 Université Paris 13 99 avenue Jean Baptiste Clément 93430 Villetaneuse Prénom Nom lipn univ paris13 fr Résumé Ce papier présente une vue spectrale sur l’approche de l’analyse rela tionnelle pour la classification des données catégorielles Il établit d’abord le lien théorique entre l’approche de l’analyse relationnelle et le problème de classifica tion spectrale En particulier le problème de classification relationnelle est pré senté comme un problème de maximisation de trace ce problème est donc trans formé par la relaxation spectrale en un problème d’optimisation sous contraintes qui peut être résolu par des multiplicateurs de Lagrange la solution est donnée par un problème de valeurs propres 1 Introduction Le Clustering a reçu une attention accrue comme un problème important en apprentissage non supervisé avec de nombreuses applications un certain nombre de différents algorithmes et des méthodes ont émergé au fil des années La plupart des techniques utilisent une mesure de similarité par paire pour mesurer la distance entre deux points de données Récemment des recherches ont été élaborées sur les approches de clustering de données catégorielles Li et al 2004 Huang 1998 où les données catégorielles sont celles dont les valeurs d’attri buts sont nominales et non ordonnées par exemple la couleur et le sexe Il est à noter que les difficultés se posent en matière de clustering des données catégorielles en raison de l’ab sence de liens intrinsèquement ordonnés de données catégorielles La plupart des techniques de clustering basées sur les mesures métriques de distance ne sont donc pas applicables à la classification des données catégorielles D’autre part les méthodes spectrales ont été utilisées efficacement pour résoudre un certain nombre de problèmes de partitionnement de graphes les méthodes de coupure minimale Ratio cut et N cut ont été utiles dans de nombreux do maines tels que l’agencement du circuit et la segmentation d’image Shi et al 2000 Étant donné un ensemble de données la minimisation des fonctions objectives des méthodes N cut et Ratio cut est un problème d’optimisation NP difficile Ainsi en général ce problème est transformé par la relaxation spectrale en un problème d’optimisation avec une contrainte qui peut être résolu par des multiplicateurs de Lagrange et la solution est donnée par un problème de valeurs propres L’approche de l’analyse relationnelle a été utilisée pour la classification de données catégorielles Marcotorchino et al 1978 Marcotorchino 2006 Dans ce papier nous montrons que le problème de la classification relationnelle peut être formellement modé lisé comme un problème de maximisation de trace Nous avons également établi le lien entre la méthode de classification spectrale et l’Analyse relationnelle AR qui est fondée sur le critère Interprétation spectrale de la classification relationnelle de Condorcet Nous développons ensuite une procédure spectrale efficace inspirée de l’algo rithme proposé par Ng et al 2001 pour trouver la partition optimale maximisant le critère de l’AR Les résultats expérimentaux montrent l’efficacité de notre approche Le reste du papier est organisé comme suit La section 2 introduit l’approche de l’analyse re lationnelle La section 3 présente le critère de Condorcet normalisé et son équivalence avec les critères inertiels Des discussions sur la connexion spectrale de la classification relationnelle et la procédure d’optimisation proposée sont données dans la section 4 La section 5 montre nos résultats expérimentaux et enfin la section 6 présente des conclusions et certains travaux futurs 2 Analyse Relationnelle L’Analyse Relationnelle à été développée en 1977 par F Marcotorchino et P Michaud et s’inspire des travaux de Marquis de Condorcet qui s’est intéressé au 18ème siècle au résultat collectif d’un vote à partir de votes individuels Cette méthodologie est basée sur la représen tation relationnelle comparaison par paires des différentes variables et l’optimisation sous contraintes du critère de Condorcet 2 1 Notation et définitions Soit I un ensemble de données avec N objets I = {O1 O2 ON} décrit par l’en semble V de M attributs ou variables catégorielles {V 1 V 2 V m V M} chacun ayant p1 pm pM catégories respectivement et soit P = �M m=1 pm désigne le nombre total de catégories de toutes les variables Chaque variable catégorielle peut être décomposée en une collection de variables indicatrices Pour chaque variable V m les pm valeurs correspondent naturellement aux nombres de 1 à pm et V m1 V m2 V mpm sont des variables binaires tels que pour chaque j 1 ≤ j ≤ pm V mj = 1 si et seulement si V m prend la jieme valeur Ainsi la ma trice de données peut être exprimée comme une collection deM matricesKm m = 1 M de terme général kmij tel que kmij = 1 si l’objet i possède la categorie j de V m et 0 sinon ce qui donne la matrcie disjonctive K de dimensions N × P K = K1|K2| |Km| |KM La matrice disjonctive pondérée K̃ est obtenue par la multiplication de chaque entrée kij du K par la racine carrée du produit des sommes marginales de la ligne i ki et la colonne j k j Autrement dit chaque entrée k̃ij = kij√ ki k j En terme de notations matricielles on écrit K̃ = R− 12 KC− 12 où R = diag Ke et C = diag Kt e avec e = 1 est le vecteur de dimen sion appropriée dont toutes ses valeurs valent 1 et diag est la matrice diagonale La matrice S̃ est appelée la matrice de Condorcet de terme général s̃ii� représentant la mesure de simila rité globale entre les deux objets Oi et Oi� mesurée sur tous les M attributs La matrice S̃ de terme général ¯̃sii� représente la mesure de dissimilarité globale entre ces deux objets Pour ob tenir la matrice S̃ chaque attribut V m est transformé en une matrice carrée S̃m = K̃m K̃m t de tailleN ×N et de terme général s̃mii� représentant la mesure de similarité entre deux objets Oi et Oi� pour l’attribut variable V m Pour obtenir la matrice S̃ une mesure de dissimilarité ¯̃smii� entre les objets Oi et Oi� pour l’attribut V m est alors calculée comme le complément à la mesure de similarité maximale possible entre ces deux objets Comme la similarité entre deux objets différents est inférieure ou égale à leur auto similarité c a d s̃mii� ≤ min s̃mii s̃mi�i� alors Labiod et al il vient ¯̃smii� = 12 s̃ m ii + s̃mi�i� − s̃mii� Cela nous amène à une matrice de dissimilarité S̃ m Les matrices S̃ et S̃ sont alors obtenues en additionnant respectivement toutes les matrices S̃m et S̃ m soit S̃ = �M m=1 S̃ m = K̃K̃t et S̃ = �M m=1 S̃ m La similarité globale entre deux objets Oi et Oi� est donc s̃ii� = �M m=1 s̃ m ii� et leur dissimilarité globale est ¯̃sii� = �M m=1 ¯̃smii� 2 2 Maximisation du critère de Condorcet pondéré Mathématiquement le problème de la classification relationnelle de l’ensemble I en K classes disjointes se pose sous la forme d’un programme linéaire en variables bivalentes 0 1 maxX∈E X RAR S̃ X où RAR S̃ X = Tr S̃X + Tr S̃X = Tr[ S̃ − S̃ X] + β 1 où β = etS̃e est une constante que l’on peut ignorer car non pertinente d’un point de vue optimsation X est la solution recherchée elle modélise une partition dans un espace rela tionnel une relation d’équivalence et doit vérifier les propriétés suivantes xii = 1 ∀i réflexivité xii� − xi�i = 0 ∀ i i� symétrie xii� + xi�i�� − xii�� ≤ 1 ∀ i i� i�� transiti vité et xii� ∈ {0 1} ∀ i i� binarité E X est l’ensemble des matrices carrées satisfaisant les propriétés d’une relation d’équivalence X est la matrice complémentaire de X où chaque entrée x̄ii� = 1− xii� 3 Critère de Condorcet normalisé Le critère de Condorcet pondéré considère le nombre de catégories modalités partagées par chaque paire d’objets plus les modalités partagées par deux objets sont rares dans le jeu de données plus leur similarité est élevée Néanmoins ce critère n’est pas compensé par les cardinalités des classes Ce qui signifie qu’une classe peut se faire petite quand elle est touchée par des valeurs aberrantes Ainsi nous définissons le nouveau critère que nous appelons critère de Condorcet normalisé et est donnée comme suit R̃AR S̃ X = Tr[ S̃ − S̃ V −1X] 2 Où V est une matrice carrée diagonale de dimension N × N telle que V = diag Xe et vii = xi le nombre d’objets dans la même classe avec l’objet i Selon le principe de Huygens nous savons que l’inertie totale d’une partition X notée IT X est la somme de son inertie intra classe IW X et de son inertie inter classe IB X considérons ci dessous la formule de Huygens IT X � �� � InertieTotale = IB X � �� � InertieInterclasse + IW X � �� � InertieIntraclasse En terme de l’opérateur ma triciel Trace ces inerties s’expriment IT = 1N Tr S̃1N×N = P M − 1 avec 1N×N = ee t IB X = Tr S̃V −1X − 1 et IW X̃ = Tr S̃V −1X Nous pouvons observer que le critère de Condorcet normalisé s’exprime comme étant le critère de la différence inertielle R̃AR S̃ X = IB X − IW X + 1 Suivant la formule de Huygens on a les équivalences ci aprés max X R̃AR S̃ X ⇔ max X IB X ⇔ min X IW X ⇔ max X [IB X − IW X ] 3 Interprétation spectrale de la classification relationnelle Il s’agit d’un résultat bien connu pour maximiser maxX IB X ou de réduire au minimum minX IW X 4 Interprétation spectrale de la classification relationnelle Trouver une partition de l’ensemble I qui maximise le critère de Condorcet normalisé est NP difficile Nous appliquons donc une relaxation spectrale du problème pour maximiser le critère de Condorcet normalisé 4 1 Factorisation des relations X et V −1X Considérons la division des données en K classes disjointes où K est supérieur où égale à 2 Nous allons définir une matrice de partition Z de dimension N × K avec une colonne pour chaque classe Z = Z1 Z2 Zk ZK Chaque colonne est un vecteur d’indicatrices binaires tels que Zik = 1 si l’objet i appartient à la classe k 0 sinon Notez que la somme de chaque ligne est égale à l’unité et la matrice Z satisfait les propriétés suivantes de Tr ZT Z = N et ZT Z = N = diag n1 nl nK où nk représente la cardinalité de la classe k La relation d’équivalenceX et la relation d’équivalence pondérée V −1X peuvent être maintenant factorisées de la manière suivante X = ZZt et V −1X = Z ZtZ −1Zt La relationX étant une relation d’équivalence elle pourra être également décomposée en un produit de trois ma trices de la manière suivante X = Z̃N Z̃t La matrice Z̃ vérifie la propriété d’orthogonalité en utilisant la décomposition de X on pourra réécrire le programme de classificaton relation nelle comme suit maxZ̃tZ̃=IK Tr[N Z̃ t S̃ − S̃ Z̃] où IK est la matrice identité d’ordre K Le programme ci dessus est l’équivalent spectral du problème de maximisation du critère de Condorcet pondérémaxX RAR S̃ X cette dernière formulation spectrale impose la connais sance a priori de la matriceN c’est à dire le nombre de classes et la taille de chaque classe de la partition recherchée Nous donnons maintenant l’équivalent spectral du problème de maxi mization du critère de Condorcet normalisémaxX R̃AR S̃ X maxZ̃tZ̃=IK Tr[Z̃ t S̃− S̃ Z̃] Etant donné les équivalences présentées en 3 nous considérons dans la suite de ce papier le problème de maximisation de l’inertie inter classes IB X 4 2 Algorithme SpectCat Ci aprés la procédure spectrale proposée inspirée de l’algorithme proposé par Ng Jordan et Weiss Ng et al 2001 Algorithm2 SpectCat Algorithm 1 Construire la matrice de similarité S̃ 2 Definir la matrice diagonale D = diag S̃e 3 Trouver la matrice U contenant lesK premiers vecteur propres de la matrice Ŝ = D−1S̃ 4 Construire la matrice normalisée Û à partir de U Ûk = Uk||Uk|| ∀k = 1 K 5 Considérons chaque ligne de Û comme un point dansRK Appliquer les k means sur Û 6 Affecter chaque objet i à la classe Ck si et seulement si la ligne correspondante Ûi de Û à été affectée à la classe Ck Labiod et al 5 Expérimentation et validation Une étude de performance a été réalisée pour évaluer notre méthode dans cette section nous décrivons les expériences et les résultats Nous avons testé notre algorithme sur des don nées réelles obtenues à partir du référentiel UCI Machine Learning Repository et comparer ses performances avec d’autres algorithmes de clustering Nous avons utilisé la pureté pour me surer la qualité des résultats de clustering nous effectuons des comparaisons sur sept bases de données UCI voir tableau 1 Comme la méthode proposée est une approche spectrale adaptée TAB 1 – – Description des bases de données Bases de données d’objects d’attributes de classes Soybean small 47 21 4 Mushroom 8124 22 2 Congressional votes 435 16 2 Zoo 101 16 7 Hayes roth 132 4 3 Balance Scale 625 4 3 Car evaluation 1728 6 4 Audiology 200 69 24 aux données catégorielles nous avons comparé les performances de l’algorithme proposé avec d’autres algorithmes de classification de données catégorielles Nous avons étudié la cluste ring trouvé par quatre algorithmes notre algorithme SpectCat k modes standart l’algorithme K representative et l’algorithme Wk modes Aranganayagi et al 2009 Du tableau 2 il est clair que la performance de la méthode proposée qui repose sur le principe de la classification spectrale donne des résultats meilleurs ou semblables à ceux d’autres approches cela signifie que l’approche proposée améliore la pureté du clustering les disparités des performances de SpectCat par rapport aux différents algorithmes peut s’expliquer par la structure interne aux données à savoir le nombre de modalités par variable l’effectif de chaque modalité et la cavité de la matrice de données TAB 2 – – mesure de Pureté pour K modes K representatives weighted k modes et SpectCat Bases de données K Modes K Representatives WK Modes SpectCat Soybean small 66 89 89 100 Mushroom 59 61 61 61 Congressional votes 62 87 88 88 Zoo 88 89 90 90 Hayes roth 41 42 42 54 Balance Scale 50 52 52 56 Car evaluation 70 70 71 70 Audiology 62 61 62 61 6 Conclusions et perspectives Dans ce papier nous avons étudié l’interprétation spectrale de la classification relation nelle des données catégorielles Une procédure efficace pour l’optimisation est présentée qui combine l’algorithme spectrale et la représentation relationnelle des données Les résultats ex périmentaux montrent l’efficacité de la méthode proposée Nous avons l’intention de continuer notre travail par l’expérimentation d’un algorithme qui combine l’heuristique de l’AR avec celui de l’algorithme spectrale selon deux perspectives la première repose sur l’utilisation de Interprétation spectrale de la classification relationnelle l’AR comme une étape d’initialisation pour l’algorithme spectrale dans la seconde perspective nous allons proposer un criètre hybride pour la classification des données mixtes provenant de deux sources différentes Références Huang Z 1998 Extensions to the k means algorithm for clustering large data sets with categorical values Data Mining and Knowledge Discovery 2 283 304 Newman M and Girvan M 2004 Finding and evaluating community structure in networks Physical Review E 69 026113 Li T Ma S and Ogihara M 2004 Entropy based criterion in categorical clustering Pro ceedings of The 2004 IEEE International Conference on Machine Learning ICML 2004 536 543 Marcotorchino J F 2006 Relational analysis theory as a general approach to data analysis and data fusion In Cognitive Systems with interactive sensors 2006 Marcotorchino J F Michaud P 1978 Optimisation en analyse ordinale des données In Masson 1978 White S and Smyth P 2005 A spectral clustering approach to finding communities in graphs In SDM pages 76 84 Shi J and Malik J 2000 "Normalized cuts and image segmentation " IEEE Trans Pattern Analysis and Machine Intelligence vol 22 no 8 pp 888 905 August 2000 Ng A Y Jordan M and Weiss Y 2001 "On spectral clustering Analysis and an algorithm " in Proc of NIPS 14 2001 Aranganayagi S and Thangavel K 2009 "Improved K Modes for Categorical Clustering Using Weighted Dissimilarity Measure" International Journal of Engineering and Mathemati cal Sciences vol5 2 19 2009 Summary This paper introduces a spectral view on the Relational Analysis RA approach for cate gorical data clustering It first establishes the theoretical connection between the RA approach and classical spectral clustering technique In particular the RA problem is shown as a trace maximization problem Thus usually this problem is converted by spectral relaxation into an optimization problem with a constraint which can be solved by Lagrange multipliers and the solution is given by an eigenvalue problem 