articles assemblage pdfAnalyse globale du flux optique pour la détection d’évènements dans une scène de foule Yassine Benabbas Nacim Ihaddadene Thierry Urruty Chabane Djeraba Laboratoire d’Informatique Fondamentale de Lille LIFL UMR 8022 USTL CNRS Université des Sciences et Technologies de Lille 1 59650 Villeneuve d’Ascq France {yassine benabbas nacim ihaddadene thierry urruty chabane djeraba} lifl fr Résumé Les systèmes de vidéo surveillance sont de plus en plus autonomes dans la détection des événements anormaux Cet article présente une méthode de détection des flux majeurs et des évènements qui surviennent dans une scène de foule Ces détections sont effectuées en utilisant un modèle directionnel construit à partir d’un mélange de lois de von Mises appliqué à l’orientation des vecteurs de mouvement Les flux majeurs sont alors calculés en récupérant les orienta tions les plus importantes des mélanges Divers évènements se produisant dans une foule sont aussi détectés en utilisant en plus du modèle d’orientation un modèle probabiliste de magnitude des vecteurs de mouvement Les résultats de l’expérimentation sur un échantillon de vidéos d’événements sont présentés 1 Introduction La sécurité des personnes et des biens est un des problèmes majeurs dans les zones pu bliques telles que les aéroports les stations de métro les centres commerciaux ou les places publiques Le traitement automatique des vidéos provenant de caméras de surveillance est de plus en plus utilisé pour présenter une information pertinente aux opérateurs qui doivent agir dans les situations critiques dangereuses ou inhabituelles Ces dernières années ont vu l’in tégration dans les systèmes de vidéo surveillance d’algorithmes de détection de mouvements d’événements de bagages abandonnés ou de suivi de personnes Cependant vu la complexité du problème peu de systèmes se sont penchés sur les situations impliquant des foules de per sonnes L’analyse des flux de personnes consiste à détecter les tendances de mouvement dans les zones surveillées Elle devient nécessaire lorsque le suivi d’objets individuels échoue ce qui est souvent le cas dans une scène de foule Cette analyse est effectuée en traitant l’information de mouvement à travers des images successives La détection d’évènements est définie comme étant la détection des situations qui attirent l’attention d’une personne Shyu et al 2008 C’est un domaine vaste du à l’immense quantité d’évènements possibles En plus la définition d’un évènement change d’une personne à une autre et dépend fortement du contexte Beaucoup d’efforts ont été fournis pour la détection d’évènements atomiques qui représentent un élément de base pour la détection de situations plus complexes RNTI E 19 339 Détection d’évènements dans une scène de foule Dans cet article nous introduisons un modèle probabiliste pour représenter une scène Ce modèle gère efficacement la complexité des scénarios et l’imprévisibilité des comportements Notre approche a été appliquée sur une sélection d’évènements et expérimentée sur l’échan tillon de vidéos du workshop PETS’2009 1 Cet article est organisé comme suit Tout d’abord La section 2 présente quelques travaux antérieurs traitant du problème de l’analyse de foule La section 3 détaille la modélisation de la scène La section 4 décrit la méthodologie adoptée pour l’extraction des flux d’une scène et la détection d’évènements dans une scène de foule Les résultats de l’expérimentation sur l’échantillon de vidéos PETS’2009 sont présentés dans la section 5 La section 6 conclue cet article et décrit les travaux futurs potentiels 2 Travaux antérieurs Les approches traditionnelles pour l’analyse des événements dans une séquence vidéo sont composées des étapes suivantes Hu et al 2008 la détection de tous les sujets mobiles présents dans la scène à un instant 𝑡 le suivi des sujets détectés dans les instants suivants et l’analyse des allures et des trajectoires des sujets pour la détection d’évènements ou d’activités Cependant cette approche a beaucoup de faiblesses quand elle est appliquée à des scènes ou scénarios complexes impliquant une large foule Parallèlement Les approches globales traitent l’intégralité de la scène sans se focaliser sur les individus séparément Elles sont classées en deux catégories la première consiste à estimer la densité de la foule et la seconde à extraire des motifs de mouvement ou détecter des évènements dans une scène de foule Dans la première catégorie on distingue les méthodes basées sur l’extraction des textures et sur l’analyse des proportions des surfaces en mouvement Marana et al 1997 Rahmalan et al 2006 Lin et al 2001 Ma et al 2004 Ces méthodes fournissent une analyse statique intéressante pour la surveillance des foules mais ne détectent pas les évènements anormaux Il existe aussi quelques techniques basées sur le flux optique Boghossian et Velastin 1999 Davies et al 1995 qui détectent des foules stationnaires ou suivent des individus en utilisant plusieurs caméras Cupillard et al 2004 Dans la deuxième catégorie le but est de détecter les évènements anormaux dans une foule en se basant sur les motifs de mouvement Le principe d’extraction des motifs de mouvement est de modéliser les comportements les plus fréquents et de considérer les évènements anor maux comme des cas aberrants La déviation des comportements typiques est ainsi utilisée pour caractériser l’anormalité Plusieurs techniques ont été proposées pour cette catégorie Andrade et al 2006a b com binent les modèles de Markov cachés avec l’analyse en composantes principales des vecteurs du flux optique pour détecter des scénarios d’urgences Cependant les expérimentations ont été portées sur des données simulées Ali et Shah 2007 utilisent la dynamique des parti cules Lagrangiennes pour détecter les instabilités du flux Cette méthode est efficace pour la segmentation des grandes densités de foules marathons évènements politiques et religieux etc Ihaddadene et Djeraba 2008 detectent les situations d’écroulement en se basant sur une mesure qui décrit le degré d’organisation ou de désordre des vecturs de flux optique Cette approche fonctionne sur des zones unidirectionnelles e g escalators Mehran et al 2009 1 cvg rdg ac uk PETS2009 RNTI E 19 340 Y BENABBAS et al utilisent le flux optique pure pour détecter les comportements anormaux dans la foule en utili sant un modèle de force sociale Wright et Pless 2005 déterminent les motifs de mouvement persistants avec une distribution jointe globale des distributions indépendantes des gradients de luminosité locaux Cette variable aléatoire est modélisée avec un mélange Gaussien Cette approche assume que tous les mouvements sur une image sont cohérents e g voitures cette hypothèse est violée quand les piétons se déplacent indépendamment L’approche proposée contribue à la détection des orientations majeures dans une scène complexe dû au fait qu’elle construit en ligne un modèle probabiliste sur l’orientation du mouvement sur la scène qui opère en temps réel Elle contribue aussi dans la détection d’évè nements dans la foule en suivant des groupes de personne au lieu de suivre chaque personne individuellement ce qui facilite la détection d’évènements se produisant sur des foules 3 Détection et suivi de groupes L’approche proposée est composée de plusieurs étapes Figure 1 La première consiste à extraire un ensemble de points d’intérêt dans l’image courante Ces points sont par la suite traqués dans l’image suivante en utilisant des techniques de calcul du flux optique Les points statiques sont supprimés pour se focaliser sur les sujets en mouvement La scène est divisée en blocs et chaque vecteur de mouvement est attaché au bloc correspondant FIG 1 – Étapes de l’algorithme L’étape de classification des blocs regroupe les blocs voisins ayant une orientation et une vitesse similaires Enfin les évènements sont détectés en exploitant les informations du suivi de groupes le modèle de magnitudes et le modèle directionnel RNTI E 19 341 Détection d’évènements dans une scène de foule 3 1 Détection et suivi de points d’intérêt Ces étapes permettent d’extraire un ensemble de points d’intérêt à partir d’une image de la séquence vidéo en utilisant la méthode décrite dans Harris et Stephens 1988 Nous consi dérons que dans les scènes de vidéo surveillance les positions des caméras et les conditions de luminosité permettent d’extraire un nombre conséquent de points d’intérêt Tous les points d’intérêt de l’image sont traqués dans l’image suivante en utilisant l’algorithme de calcul de flux optique Lucas et Kanade 1981 Shi et Tomasi 1994 Le résultat de cette opération à l’instant 𝑡 est un ensemble 𝑉𝑡 de vecteurs à 4 dimensions 𝑉𝑡 = {𝑉1 𝑉𝑁 ∣𝑉𝑖 = 𝑋𝑖 𝑌𝑖 𝐴𝑖 𝑀𝑖 } où 𝑋𝑖 et 𝑌𝑖 sont les coordonnées du point 𝑖 par rapport au repère de l’image 𝐼𝑡 𝐴𝑖 est l’angle ou l’orientation de mouvement du point 𝑖 𝑀𝑖 est la magnitude de mouvement du point 𝑖 elle correspond à la distance entre la position du point 𝑖 dans l’image 𝐼𝑡 et sa nouvelle position dans l’image 𝐼𝑡+1 Cette étape permet d’enlever les points d’intérêts statiques qui ont une magnitude de mouvement inférieure à une magnitude minimale Finalement l’image est divisée en blocs de 𝐵𝑥 lignes et 𝐵𝑦 colonnes Chaque vecteur de mouvement est affecté au bloc adéquat selon son origine Nous considérons des blocs de dimension 16 × 16 pixels afin d’obtenir un bon équilibre entre le temps de traitement et la qualité les résultats 3 2 Le modèle de magnitude et le modèle de direction Dans cette étape on calcule la direction du flux optique dans chaque bloc Ces directions sont les entrés de la loi de probabilité du bloc La loi locale pour un bloc 𝐵𝑥 𝑦 est construite en utilisant un mélange de lois de von Mises aussi appelée loi normale circulaire La probabilité d’un variable angulaire 𝜃 est donnée par 𝑃𝑥 𝑦 𝜃 = 𝐾∑ 𝑖=1 𝜔𝑖 𝑥 𝑦 ⋅ 𝑉 𝜃 𝜇𝑖 𝑥 𝑦 𝑚𝑖 𝑥 𝑦 1 où𝐾 est le nombre de distributions Il représente le nombre maximum d’orientations prin cipales considéré 𝜔𝑖 𝑥 𝑦 𝜇𝑖 𝑥 𝑦 et 𝑚𝑖 𝑥 𝑦 sont respectivement le poids la direction modale et le paramètre de concentration de la 𝑖𝑚𝑒 loi du bloc 𝐵𝑥 𝑦 𝑉 𝜃 𝜇 𝑚 est la loi de von Mises de direction modale 𝜇 et paramètre de concentration 𝑚 Elle se caractérise par sa densité sur [0 2𝜋[ 𝑉 𝜃 𝜇 𝑚 = 1 2𝜋𝐼0 𝑚 exp [𝑚 cos 𝜃 − 𝜇 ] 2 où 𝐼0 𝑚 est la fonction de Bessel modifiée de première espèce et d’ordre 0 définie par 𝐼0 𝑚 = ∞∑ 𝑟=0 1 𝑟 2 1 2 𝑚 2𝑟 3 La figure 2 montre une représentation de la fonction densité d’un bloc on y distingue les deux tendances d’orientation gauche et droite RNTI E 19 342 Y BENABBAS et al FIG 2 – Représentation d’un mélange de 2 lois de von Mises Dans les espaces publiques les personnes se dirigent généralement dans des directions différentes Ainsi certaines zones ont des motifs de mouvement qui contiennent 2 orientations principales ou plus Par exemple il y a 4 orientations principales dans un passage piéton 2 orientations opposées pour les piétons et deux autres pour les voitures Il serait intéressant de savoir qui des piétons ou des voitures emprunte ce passage Ceci peut être fait en utilisant le modèle directionnel En effet le modèle de mélange de chaque bloc peut contenir jusqu’à 4 orientations principales Le poids nous informe de l’importance d’une orientation FIG 3 – Représentation des directions dominantes par bloc Pour chaque image les paramètres du mélange sont mis à jour en utilisant un algorithme en ligne d’approximation E M Kaewtrakulpong et Bowden 2001 qui est à l’origine utilisé pour estimer un mélange Gaussien L’algorithme a été adapté pour traiter des observations circulaires au lieu d’observations linéaires L’inverse de la variance 𝜎 de la loi normale est considéré comme étant le paramètre de concentration 𝑚 = 1 𝜎2 La figure 3 montre la repré sentation la loi de probabilité pour 2 blocs Les tendances de direction peuvent être perçues RNTI E 19 343 Détection d’évènements dans une scène de foule Dans ce papier on choisit𝐾 = 4 afin de représenter les 4 points cardinaux Le modèle de magnitude est un mélange Gaussien unidimensionnel sur la magnitude moyenne du mouvement entre deux images Elle est définie comme suit 𝑃 𝑥 = 4∑ 𝑘=1 𝜔𝑘 1 𝜎𝑘 √ 2𝜋 𝑒𝑥𝑝 − 𝑥− 𝜇𝑘 2 2𝜎2𝑘 4 où 𝜔𝑘 𝜇𝑘 et 𝜎𝑘 sont respectivement le poids la moyenne et la variance de la 𝑘𝑚𝑒 Gaussienne Les paramètres du mélange sont appris avec un algorithme d’apprentissage en ligne sur les données vidéo ’S0 normal flow’ appartenant à la base de vidéos de PETS’2009 Ces séquences contiennent des personne qui marchent a Image initiale b Tendences de direction FIG 4 – Représentation des flux multiples d’une image 3 3 Regroupement des blocs L’objectif de cette opération est de rassembler les blocs d’image entre eux pour obtenir des groupes représentant des entités ayant des directions similaires Ces groupes peuvent re présenter une ou plusieurs personnes Les critères d’affectation d’un bloc à un groupe sont la direction et la vitesse Ainsi les blocs voisins ayant une magnitude moyenne et une orientation principale similaires seront rattachés au même groupe Chaque bloc 𝐵𝑥 𝑦 est défini par sa position 𝑃𝑥 𝑦 = 𝑥 𝑦 𝑥 = 1 𝐵𝑥 𝑦 = 1 𝐵𝑦 et orientation Ω𝑥 𝑦 = 𝜇0 𝑥 𝑦 voir section 3 2 La figure 5 illustre le résultat de cette étape 3 4 Suivi de groupes Le suivi permet de retracer la trajectoire de la personne ou du groupe de personnes depuis son apparition dans le champ de la caméra jusqu’à sa disparition Cette opération est effectuée en mettant en correspondance les barycentres des groupes dans l’image 𝑓 avec les barycentres de l’image 𝑓+1 Chaque image 𝑓 est définie par ses groupes {𝐶1 𝑓 𝐶2 𝑓 𝐶𝑛𝑓 𝑓} où 𝑛𝑓 est le nombre de groupes détectés dans l’image 𝑓 Chaque groupe𝐶𝑖 𝑓 est décrit par son barycentre RNTI E 19 344 Y BENABBAS et al a Segmentation des blocs b Image d’origine avec les groupes résualtants FIG 5 – Regroupement des blocs 𝑂𝑖 𝑓 et son orientation moyenne 𝑋𝑖 𝑓 Le groupe 𝐶𝑚 𝑓+1 correspond au groupe 𝐶𝑖 𝑓 si son barycentre est le plus proche de 𝐶𝑖 𝑓 sans dépasser une distance minimale En d’autres termes elle doit satisfaire ces deux conditions ⎧⎨⎩ 𝑚 = argmin 𝑗 𝐷 𝑂𝑖 𝑓 𝑂𝑗 𝑓+1 𝑒𝑡 𝐷 𝑂𝑖 𝑓 𝑂𝑚 𝑓+1 < 𝜏 5 où 𝜏 est la distance minimale entre deux groupes on a choisi 𝜏 = 5 Si aucune correspondance n’a été trouvée aucun groupe 𝐶𝑚 𝑓+1 ne satisfait les deux conditions alors le groupe 𝐶𝑖 𝑓 a disparu et n’est plus suivi dans les prochaines images 4 Détection d’évènements dans une scène de foule Dans cette section nous décrivons les traitements nécessaires pour détecter certains événe ments liés aux foules de personnes Les scénarios retenus font partie des événements décrits dans le workshop PETS’2009 – Évènements liés à la vitesse de mouvement il s’agit de détecter si les personnes qui forment la foule marchent ou courent Ces événements peuvent être détectés en exploi tant la magnitude des vecteurs de flux optique à travers les images – Le rassemblement cet événement se produit quand deux ou plusieurs groupes se re joignent pour former un seul groupe – La division cet événement se produit lorsque les personnes qui forment un groupe se séparent pour des raisons telles que la dispersion ou l’évacuation Les évènements de la première catégorie sont détectés en comparant la magnitude moyenne du flux optique de chaque image au modèle de magnitude de la scène obtenu par apprentissage Les évènements de la deuxième et troisième catégorie sont détectés en analysant la position et la vitesse des groupes Un explication plus détaillée sera donnée dans ce qui suit RNTI E 19 345 Détection d’évènements dans une scène de foule 4 1 Évènements relatifs à l’allure Comme décrite précédemment l’idée principale est de comparer la magnitude moyenne des vecteurs de mouvement de chaque image au modèle de magnitude de la scène pour ob tenir les probabilité 𝑃𝑚𝑎𝑟𝑐ℎ 𝑃𝑐𝑜𝑢𝑟 des évènements marcher et courir respectivement Dans cet article puisque les vecteurs de mouvement sont considérés pour la détection bas niveau et 𝑃𝑐𝑜𝑢𝑟 = 1 − 𝑃𝑚𝑎𝑟𝑐ℎ Le calcul de 𝑃𝑐𝑜𝑢𝑟 permettra donc de déduire l’occurrence de l’évè nement courir et marcher Sous l’hypothèse qu’il y a plus de probabilité pour un groupe de rester dans son état courant que de passer subitement vers un état différent alors la probabilité finale des évènements courir et marcher est une somme pondérée des probabilités précédentes et de la probabilité courante Formellement une image 𝑓 avec une magnitude moyenne de flux optique𝑚𝑓 contient un événement courir si 𝑓∑ 𝑙=𝑓−ℎ 𝑤𝑓−𝑙 ⋅ 𝑃𝑐𝑜𝑢𝑟 𝑚𝑙 > 𝜗𝑐𝑜𝑢𝑟 6 où 𝜗𝑐𝑜𝑢𝑟 est le seuil de probabilité l’évènement courir ℎ est le nombre d’mages précédentes à considérer Chaque état précédent a un poids 𝑤𝑙 on a défini ℎ = 1 𝑤0 = 0 8 et 𝑤1 = 0 2 𝑃𝑐𝑜𝑢𝑟 𝑚𝑙 est la probabilité d’observer 𝑚𝑙 Elle est obtenue en comparant 𝑚𝑙 au modèle de magnitude obtenu à partir de personnes qui marchent voir section 3 2 en utilisant la formule 4 Cette probabilité est seuillée pour détecter l’évènement courir un seuil de 0 95 est choisi Ceci est justifié par le fait qu’il y a une probabilité de 0 95 pour une variable d’être entre 𝜇−2𝜎 et 𝜇+2𝜎 où 𝜇 et 𝜎 sont respectivement la moyenne et l’écart type de la loi Gaussienne Comme 𝑃𝑐𝑜𝑢𝑟 = 1 − 𝑃𝑚𝑎𝑟𝑐ℎ l’évènement marcher se produit quand il n’y a pas d’évènement courir et vice versa 4 2 Évènements de rassemblement ou de séparation Pour la détection des évènements rassemblement et séparation on calcule la variance cir culaire 𝑆0 𝑓 des orientations globales des groupes dans chaque image 𝑓 selon l’équation sui vante L Gaile et E Burt 1980 𝑆0 𝑓 = 1− 1 𝑛𝑓 𝑛𝑓∑ 𝑖=1 cos 𝑋𝑖 𝑓 −𝑋0 𝑓 7 La variance 𝑆0 𝑓 est comprise entre 0 et 1 inclus Si les angles sont identiques 𝑆0 𝑓 sera égal à 0 Un ensemble d’angles totalement opposés donnera une valeur de 𝑆0 𝑓 égale à 1 Si la variance circulaire dépasse un certain seuil 𝛽 on choisit 𝛽 = 0 3 dans notre implémentation on déduit la réalisation d’une séparation et ou d’un rassemblement On examine aussi la position et l’orientation de chaque groupe par apport aux autres groupes afin de décider précisément quel évènement s’est produit Si par exemple deux groupes proches sont orientés vers la même destination alors la probabilité de l’événement rassemblement sera grande Pour l’évènement séparation on distingue trois situations différentes 1 La division se produit dans un petit secteur et elle est temporaire c’est une dispersion locale RNTI E 19 346 Y BENABBAS et al a Un groupe avant séparation b Les groupes séparés FIG 6 – Détection d’une séparation 2 La division est plus longue dans le temps et les groupes s’éloignent c’est une séparation 3 Si la première situation se produit lorsque la foule court alors c’est une évacuation Les probabilités de fusion séparation dispersion locale et évacuation pour l’image 𝑓 notés respectivement 𝑃𝑓𝑢𝑠𝑓 𝑃𝑠𝑒𝑝𝑓 𝑃𝑑𝑖𝑠𝑝𝑓 𝑃𝑒𝑣𝑎𝑐𝑓 sont nuls si la variance circulaire est infé rieure à un seuil Dans le cas contraire les probabilités de fusion dispersion locale et séparation sont calculés en divisant le nombre d’occurrences de chaque évènement par leur nombre d’oc currences total dans l’image 𝑓 Soient 𝑁𝑓𝑢𝑠𝑓 𝑁𝑠𝑒𝑝𝑓 𝑁𝑑𝑖𝑠𝑝𝑓 le nombre d’occurrences des évènements fusion séparation dispersion locale respectivement dans l’image 𝑓 La probabilité de fusion 𝑃𝑓𝑢𝑠𝑓 à l’image 𝑓 est calculée comme suit 𝑃𝑓𝑢𝑠𝑓 = 𝑁𝑓𝑢𝑠𝑓 𝑁𝑓𝑢𝑠𝑓 +𝑁𝑠𝑒𝑝𝑓 +𝑁𝑑𝑖𝑠𝑝𝑓 8 Finalement la probabilité d’évacuation à l’image 𝑓 notée 𝑃𝑒𝑣𝑎𝑐𝑓 est un cas particulier puisqu’il est conditionné par l’évènement courir en plus de l’évènement dispersion locale Par conséquent s’il y a un évènement courir à l’image 𝑓 alors 𝑃𝑑𝑖𝑠𝑝𝑓 est remplacé par 𝑃𝑒𝑣𝑎𝑐𝑓 et 𝑁𝑑𝑖𝑠𝑝𝑓 est remplacé par 𝑁𝑒𝑣𝑎𝑐𝑓 5 Expérimentations L’approche décrite dans les sections précédentes a été évaluée sur la base de vidéos de PETS’2009 Ces vidéos incluent des séquences contenant différentes activités de foule Diffé rents scénarios impliquant le calcul de la densité de foule comptage du nombre de personnes suivi d’une seule personne dans une foule analyse de flux et détection d’évènements haut niveau Un ensemble de données d’apprentissage est aussi disponible il a été utilisé pour la création des modèles de magnitude et d’orientation de la scène Nous avons traité les séquences d’analyse de flux et de reconnaissance des évènements Ces séquences sont au format JPEG avec une résolution de 720× 576 pixels et une cadence de 8 ips RNTI E 19 347 Détection d’évènements dans une scène de foule Séquence Description Séq 1 7 personnes se déplacent en zigzag Séq 2 Une foule se déplace tout en évitant des obstacles hu mains Séq 3 3 des groupes se fusionnent en un seul groupe Séq 4 et 5 3 personnes circulent dans le sens inverse de la foule TAB 1 – Description des séquences utilisées pour la détection des flux multiples séquence Marcher Courir Dispersion locale Séparation Fusion Évacuation Séq 6 ∙ ∙ Séq 7 ∙ ∙ ∙ Séq 8 ∙ ∙ Séq 9 ∙ ∙ ∙ ∙ TAB 2 – Description des séquences utilisées pour la détection d’événéments Les séquences décrites dans le tableau 1 ont été utilisées pour la détection des flux mul tiples tandis que celles du tableau 2 contiennent les évènements expérimentés La majorité des évènements ont été détectés avec succès Quelques fausses détections surviennent principa lement dues à la mesure de profondeur qui donne des distances parfois imprécises entre les groupes et à l’ombre qui génère de faux groupes Le tableau 3 montre les mesures de précision et de rappel pour les divers événements expérimentés et qui montre que l’approche donne des résultats satisfaisants par comparaison à la vérité terrain Marcher Courir Evacuation Dispersion locale Fusion Séparation Précision 97 23% 75 86% 69 09% 67 40% 59 14% 47 36% Rappel 96 17% 81 48% 82 60% 45 04% 45 32% 47 36% TAB 3 – Performances du système pour chaque évènement 6 Conclusions Les approches traditionnelles pour l’analyse de comportement se focalisent généralement sur une seule personne La plupart de ces approches échouent sur les scènes de foule Dans ce papier une approche d’analyse globale pour la détection des flux multiples et la détection des évènements liés aux foules a été proposée Certains évènements sont aussi détectés en analysant la relation spatiotemporelle entre les groupes de personne pour chaque image Trois catégories d’évènements sont visées course rassemblement et séparation de personnes Les expérimentations sur l’échantillon de vidéos PETS’2009 ont montré que notre méthode est très prometteuse pour des scènes de foules et des scènes complexes Dans les travaux futurs RNTI E 19 348 Y BENABBAS et al nous appliquerons une méthode de suppression des ombres pour réduire l’effet des ombres En plus nous prendrons en compte de l’information de profondeur 2 5D ou 3D pour mesurer plus précisément les distances dans l’espace Remerciements Ce travail a été réalisé dans le cadre du projet ANR CAnADA 2007 2010 Analyse des comportements Anormaux Alerte Détection Action et le projet européen Miauce 2006 2009 FP6 Call 5 IST 2005 5 033715 Références Ali S et M Shah 17 22 June 2007 A Lagrangian particle dynamics approach for crowd flow segmentation and stability analysis IEEE Conference on Computer Vision and Pattern Recognition 2007 CVPR ’07 1–6 Andrade E L S Blunsden et R B Fisher 2006a Hidden Markov models for optical flow analysis in crowds 18th International Conference on Pattern Recognition ICPR’06 1 460–463 Andrade E L S Blunsden et R B Fisher 2006b Modelling crowd scenes for event detection 18th International Conference on Pattern Recognition ICPR’06 175–178 Boghossian B et S Velastin 1999 Motion based machine vision techniques for the mana gement of large crowds Proceedings of ICECS ’99 The 6th IEEE International Conference on Electronics Circuits and Systems 2 961–964 Cupillard F A Avanzi F Bremond et M Thonnat 2004 Video understanding for metro surveillance 2004 IEEE International Conference on Networking Sensing and Control 1 186–191 Davies A J H Yin et S Velastin 1995 Crowd monitoring using image processing Elec tronics Communication Engineering Journal 7 1 37–47 Harris C et M Stephens 1988 A combined corner and edge detector In Alvey Vision Conference pp 147–152 Hu M S Ali et M Shah 2008 Detecting global motion patterns in complex videos In ICPR’08 International Conference on Pattern Recognition Ihaddadene N et C Djeraba 2008 Real time crowd motion analysis ICPR International Conference on Pattern Recognition Tampa Florida USA Kaewtrakulpong P et R Bowden 2001 An improved adaptive background mixture model for realtime tracking with shadow detection 2nd European Workshop on Advanced Video Based Surveillance Systems AVBS01 VIDEO BASED SURVEILLANCE SYSTEMS L Gaile G et J E Burt 1980 Directional Statistics Concepts and techniques in modern geography no 25 Norwich England Geo Abstracts Lin S F J Y Chen et H X Chao 2001 Estimation of number of people in crowded scenes using perspective transformation IEEE Transactions on Systems Man and Cybernetics Part A 31 6 645–654 RNTI E 19 349 Détection d’évènements dans une scène de foule Lucas B et T Kanade 1981 An iterative image registration technique with an application to stereo vision Proceedings of the International Joint Conference on Artificial Intelli gence 1 674–679 Ma R L Li W Huang et Q Tian 2004 On pixel count based crowd density estimation for visual surveillance IEEE Conference Cybernetics and Intelligent Systems 1 170–173 Marana A S Velastin L Costa et R Lotufo 1997 Estimation of crowd density using image processing IEEE Colloquium Image Processing for Security Applications Digest No 1997 074 11 1–11 8 Mehran R A Oyama et M Shah 2009 Abnormal crowd behavior detection using social force model IEEE Computer Society Conference on Computer Vision and Pattern Recog nition Rahmalan H M S Nixon et J N Carter 2006 On crowd density estimation for sur veillance In International Conference on Crime Detection and Prevention Shi J et C Tomasi 1994 Good features to track In IEEE Conference on Computer Vision and Pattern Recognition pp 593–600 Shyu M L Z X abd Min Chen et S C Chen 2008 Video semantic event concept de tection using a subspace based multimedia datamining framework IEEE transactions on multimedia ISSN 1520 9210 10 252–259 Wright J et R Pless 2005 Analysis of persistent motion patterns using the 3d structure tensor In WACV MOTION ’05 Proceedings of the IEEE Workshop on Motion and Vi deo Computing WACV MOTION’05 Volume 2 Washington DC USA pp 14–19 IEEE Computer Society Summary Video surveillance systems are becoming more and more autonomous in the detection and the reporting of abnormal events This paper presents a method to detect major flows and events in crowd scenes These detections are performed using a Direction Model constructed from an online mixture of von Mises distributions applied to the orientation of the optical flow vectors Major flows are then detected by retrieving the most important orientations from the mixture Several crowd related events are also detected using a probabilistic model applied to the mean motion magnitude of the optical flow vectors on each frame of the scene In addition spatiotemporal relationship analysis of the crowd using the direction model according to the category of the event The results of processing on a video dataset are presented RNTI E 19 350 