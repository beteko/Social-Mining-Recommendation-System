intégration structure modèle probabiliste document mathias christine largeron franck thollard université monnet laboratoire hubert curien etienne prenom etienne résumé fouille textes comme recherche information différents dèles probabiliste vectoriel booléen révélés adaptés représenter documents textuels modèles présentent incon vénient tenir compte structure document plupart informations disponibles aujourd internet bases documen taires fortement structurées article1 proposons étendre modèle probabiliste représentation documents façon tenir compte poids certaine catégorie éléments structurels balises représentant structure logique structure forme modèle évalué collection campagne évaluation introduction fouille texte comme recherche information plusieurs modèles utili représenter document modèles probabiliste booléen vectoriel révélés adaptés représenter documents textuels cependant présentent inconvénient tenir compte structure document plupart infor mations disponibles aujourd internet bases documentaires fortement structurées raison laquelle travaux récents comme fouille intéressés structure documents notamment conduit émergence recherche information orientée contenu objectif justement exploi information structurelle contenue documents concevoir systèmes efficaces compétition inex2 initiative evaluation retrieval produit ailleurs depuis larges collections documents utilisables évaluation systèmes exploitation structure aussi étudiée tâches classement pervisé documents contexte plusieurs voies envisagées parmi lesquelles citera extension modèles usuels représentation documents textuels doucet ahonen exploitation structure arborescente documents sundaresan marteau vercoustre enfin contexte détection information nouvelle novelty detection autres travaux travail partiellement soutenu action collaborative intelligence région rhône alpes informatik duisburg intégration structure modèle probabiliste compte structure logique documents estimant poids accorder chacune parties composent jacquenet largeron article proposons étendre modèle probabiliste façon tenir compte éléments structure forme mettre évidence informations importantes notre approche nécessite phase apprentissage partie collection considérée cours apprentissage poids calculé chacune balises probabilité cette balise distingue termes pertinents seconde phase modèle avons développé permet estimer tenant compte poids probabilité document collection pertinent requête donnée modèle décrit prochaine section tandis résultats expérimentations obtenus collection présentés troisième section modèle probabiliste représentation documents structurés principe intégration structure modèle probabiliste documents recherche information modèle probabiliste documents robertson jones aspire estimer pertinence document requête partir babilités celle trouver information pertinente celle trouver information pertinente estimations basées probabilité chacun termes contenus document apparaître document pertinent document pertinent collection faire utilise collection composée documents requêtes connaissance documents pertinents chaque requête cette collection permet phase apprentissage estimer probabilité pertinence chaque terme fonction distributions respectivement documents pertinents documents pertinents notre objectif intégrer structure documents modèle parvenir recherche information structurée notre modèle seront considérés éléments structure logiques titre section paragraphe forme souligné centré intégration structure modèle probabiliste effectue ensuite niveaux premier structure logique utilisée identifier éléments seront susceptibles indexés notre système sections paragraphes tableaux second balises structure logique forme intégrées modèle probabiliste classique cette intégration nécessite étape préliminaire consiste estimer poids chacune balises poids probabilité balise distingue termes pertinents seconde étape intégration balises modèle avons développé permet déterminer probabilité document collection pertinent requête donnée tenant compte seulement pondération classique termes modèle probabiliste aussi pondération chacune balises englobent termes section suivante présente formellement modèle probabiliste représentation documents structurés notations dispose ensemble documents structurés pratique agira documents chaque élément logique section paragraphe représente ensemble termes délimité balise structurelle logique utilisée indexer élément ensemble éléments structurés considérés collection exemple sections paragraphes index termes construit ensemble balises logiques forme considé vecteur variables aléatoires valeur terme apparaît étiqueté balise sinon terme apparaît étiqueté balises évidence terme apparaît étiquette notera réalisation variable aléatoire partir cette représentation objectif maintenant étendre modèle probabiliste prendre compte structure forme documents probabilité pertinence élément basée balises fonction pondération introduite robertson jones auquel renvoyons lecteur précision largement utilisée systèmes recherche information probabilistes estimer poids terme élément notre modèle cette première pondération notée enrichie manière prendre compte structure logique forme documents contexte recherche information désire effet estimer pertinence élément relativement requête revient estimer respectivement probabilité trouver information pertinente respectivement pertinente quand observe élément requête donnée introduit fonction classement permettra comparant probabilités ordonner documents fonction pertinence rapport requête élevée pertinentes informations contenues bayes éliminant terme constant collection requête donnée interviendra classement documents obtient propor tionnelle intégration structure modèle probabiliste moyennant hypothèse indépendance termes binary independance model simplifier notations probabilité avoir sachant élément pertinent probabilité avoir étiqueté sachant élément pertinent probabilité avoir sachant élément pertinent probabilité avoir étiqueté sachant élément pertinent reportant fonction classement fonction logarithmique étant croissante prenant logarithme classe produit fonction celui produit terme constante relativement collection indépen considérer change classement produit fonction déduit fonction pertinence tirée fcbalises tiklog poids terme étiqueté balise ainsi modèle probabiliste tenant compte structure document pertinence élément rapport balises mesurée score fcbalises fcbalises pratique mesurer cette pertinence convient estimer probabilités partir échantillon apprentissage constitué ments jugés requête partir ensembles contenant respectivement éléments pertinents pertinents obtient nombre termes étiquetés parmi éléments pertinents nombre termes étiquetés parmi éléments nombre termes étiquetés parmi éléments pertinents somme occurrences termes figurant parmi éléments pertinents somme occurrences termes figurant parmi éléments pertinents déduit ayant construit estimateurs biais probabilités avoir terme étiqueté sachant élément respectivement pertinent pertinent déduit probabilité avoir balise sachant élément pertinent probabilité avoir balise sachant élément pertinent combinaison pertinences basées termes balises obtenir score global classement élément fonction termes balises permette estimer pertinence rapport requête avons proposé première approche consiste multiplier poids chaque terme moyenne poids correspondant toutes balises englobent terme ainsi calculons expérimentation collection présentation collection avons évalué notre modèle collection initiative evaluation retrieval composée articles anglais issus encyclopédie wikipedia modèle vectoriel fonction pondération utilisé comme modèle référence comparé modèle probabiliste structurel décrit précédemment utilise aussi fonction pondération intégrant balises résultats évalués utilisant précision rappel ainsi mesure performance globale interpolated average precision permettant combiner définie pehcevski requêtes collection indice référence utilisation balises quand toutes balises considérées cette tendance confirmée lorsqu considère rappel précision pendamment autre résultats préliminaires convaincants remettent nécessairement cause intérêt exploiter information structurelle information textuelle plutôt modalités combinaison poids termes éléments structurels intégration structure modèle probabiliste conclusion article avons proposé étendre modèle probabiliste représentation documents structurés façon tenir compte poids balises représentant structure logique structure forme poids estimés apprentissage calcul probabilité document collection pertinent requête donnée résultats préliminaires obtenus collection pagne évaluation soient convaincants pensons remettent cause intérêt exploiter information structurelle information textuelle combinaison poids termes balises étudiée manière approfondie références doucet ahonen naive clustering large document collection proceedings first workshop initiative evaluation retrieval schloss dagsuhl germany largeron thollard probabilistic document model integrating structure workshop initiative evaluation retrieval jacquenet largeron using structure documents improve discovery unexpected information marteau ménier ekamby apport prise compte contexte structurel modèles bayésiens classification documents structurés numéro spécial fouille données complexes pehcevski kamps kazai lalmas ogilvie piwowarski robertson evaluation measures proceedings robertson jones relevance weighting search terms journal american society information sciences vercoustre fegas lechevallier despeyroux classification ments partir representation lineaire arbres documents sundaresan classifier structured documents proceedings sixth sigkdd international conference knowledge discovery mining summary mining information retrieval differents models probabilistic boolean vectorial suited manage textuals documents document structure nevertheless documents available internet textual databases strongly strucured article propose extension probabilistic model order account structural elements present document model evaluated using evaluation campaign