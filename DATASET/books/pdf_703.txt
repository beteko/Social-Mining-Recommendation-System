articles assemblage pdfUn modèle d’extraction de masses de croyance à partir de probabilités a posteriori pour une amélioration des performances en classification supervisée Teh Amouh Monique Noirhomme Fraiture Benoît Macq Université de Namur Faculté d’informatique rue grandgagnage 21 5000 Namur Belgique {tam mno} info fundp ac be info fundp ac be Université catholique de Louvain Laboratoire de Télécommunications et Télédétection Place Stevin 2 1348 Louvain la neuve Belgique benoit macq uclouvain be tele ucl ac be Résumé L’objectif de cet article est de montrer que l’utilisation de la règle de décision du maximum de masse de croyance en lieu et place de celle du maximum de probabilité a posteriori peut permettre de réduire le taux d’erreur en classifi cation supervisée Nous proposons une technique efficace pour extraire à partir d’un vecteur de probabilités a posteriori un vecteur de masses de croyance sur lequel baser la décision par le maximum de masse de croyance L’application de notre méthode dans le domaine de la classification automatique en stades de sommeil montre une amélioration des performances pouvant atteindre 80% de réduction du taux d’erreur de classification 1 Introduction En classification supervisée l’information en sortie d’un classifieur se présente générale ment sous la forme d’un vecteur de probabilités a posteriori dont chacune des composantes se rapporte à l’une des classes connues La règle de décision par le maximum de probabilité a pos teriori semble la plus naturelle pour atteindre les meilleures performances Mais l’application d’une telle règle de décision suppose que l’on aie entièrement confiance dans les probabilités a posteriori produites par le classifieur Or dans la plupart des cas l’on ne peut raisonnablement pas avoir une confiance totale dans le classifieur Notre processus de décision devrait donc ju dicieusement tenir compte de la confiance ou croyance que nous mettons dans les résultats produits par le classifieur Cette croyance doit d’abord être mesurée de sorte que l’on puisse en avoir une valeur numérique utilisable dans les calculs La théorie de Dempster Shafer fournit un cadre puissant de mesure de la croyance en proposant des concepts permettant de modéliser l’information imparfaite RNTI E 19 513 Des probabilités a posteriori aux masses de croyance L’imperfection de l’information englobe l’imprécision l’incertitude et l’incomplétude A travers le concept de fonction de masses de croyance la théorie de Dempster Shafer nous permet de modéliser ces trois dimensions de l’information imparfaite reflétant ainsi notre confiance dans la source d’information Une fonction de masses de croyance ou fonction de masses tout court est une fonction tabulaire qui partage une quantité unitaire entre tous les sous ensembles de l’ensemble des classes connues contrairement à une fonction de pro babilités qui elle partage la quantité unitaire entre les classes sous ensembles singletons La valeur attribuée à un sous ensemble de classe correspond à la masse de croyance en ce sous ensemble La principale difficulté dans cette théorie réside dans la manière de distribuer les masses de croyance Les méthodes disponibles dans la littérature ont été dévoloppées dans un contexte de fusion de classifieurs ce qui suppose que leur application nécessite d’avoir au moins deux classifieurs Dans cet article nous proposons une méthode de calcul des valeurs de masse de croyance qui répond aux deux préoccupations suivantes – prendre en compte toute information disponible a priori succeptible d’influencer la confi ance que l’on pourrait avoir dans le classifieur – pouvoir appliquer la méthode pour améliorer les performances de n’importe quel classi fieur unique donné hors du contexte de fusion de classifieurs Notre approche est schématisée sur la figure 1 Le classifieur donné reçoit en entrée un vecteur de caractéristiques x et produit en sortie un vecteur de probabilités y Ce vecteur de probabilités est ensuite transformé par notre méthode en un vecteur de masses de croyance z sur lequel va se baser la décision d’assignation de l’objet S à l’une des classes connues ou éventuellement la décision de rejet FIG 1 – Schéma de la transformation d’un vecteur de probabilités a posteriori en un vecteur de masses de croyance pour une amélioration des performances en classification supervisée Outre la fonction de masses la théorie de Dempster Shafer propose également un certain nombre de règles de décision Seule la règle du maximum de masse est utilisée dans l’approche que nous développons ici Rappelons qu’avec la règle du maximum de probabilité à posteriori un rejet n’a lieu que s’il n’y a pas de maximum unique ou si le maximum n’atteint pas un certain seuil et l’on est dans l’impossibilité de quantifier la confiance que l’on a dans ce rejet Non seulement notre approche permet de réduire le taux d’erreur elle offre également l’opportunité de mesurer notre confiance en cas de rejet Cette confiance correspond à la valeur de croyance attribuée à l’ensemble complet des classes Après avoir rappelé dans la section 2 la définition de la notion de fonction de masses nous discutons dans la section 3 quelques méthodes proposées dans la littérature pour le calcul des valeurs de masse de croyance Dans la section 4 nous détaillons notre technique puis la testons RNTI E 19 514 T Amouh et al dans la section 5 avec six classifieurs différents dans le domaine de la classification en stades de sommeil Nous discutons nos résultats dans la section 6 et concluons dans la section 7 2 Fonction de masses de croyance La notion de fonction de masses est l’une des notions introduites par la théorie de l’évi dence de Dempster Shafer généralisant la théorie des probabilités dans le cas des variables dis crètes Dans cette section nous donnons la définition formelle de cette fonction avant d’intro duire la manière dont nous l’utilisons pour améliorer les performances d’un classifieur donné Le lecteur est invité à se référer aux travaux originaux de Shafer Shafer 1976 pour un dis cours détaillé sur la théorie de l’évidence Soit Θ = {θ1 θ2 · · · θN} un ensemble de N classes On note 2Θ l’ensemble des sous ensembles de Θ On définit sur 2Θ une fonction de masses m de la manière suivante { 0 ≤ m A ≤ 1 ∀A ∈ 2Θ ∅ et ∑ A∈2Θ m A = 1 0 = m ∅ 1 m A est une mesure de la confiance que l’on est disposé à accorder exactement au sous ensembleA étant donné l’information disponible Autrement dit m A correspond à la part de croyance qui soutient l’hypothèse compositeA sans soutenir aucun sous ensemble strict deA Contrairement à la théorie des probabilités où la quantité unitaire est divisée entre plusieurs hypothèses atomiques {θi} en théorie de l’évidence pour toute hypothèse composite A tel que m A > 0 m A reflète une certaine ignorance car elle représente une croyance qui ne peut être subdivisée en sous ensembles plus fins Ceci conduit à l’inégalité suivante m A + m A ≤ 1 où A est le complément de A dans Θ Cette inégalité contraste avec le postulat d’additivité dans la théorie des probabilités Si m A > 0 alors A est appelé élément focal de m Comme indiqué dans l’introduction les composantes du vecteur de sortie z dans notre méthode voir figure 1 sont considérées comme étant les valeurs d’une fonction de masses m Cette fonction de masses a N + 1 éléments focaux N étant le nombre total de classes dans l’application de classification supervisée { zi = m {θi} ∀i ∈ {1 · · · N + 1} {θ N+1 } = Θ par convention 2 où zi représente la ième composante du vecteur z Les éléments focaux de m sont {θ1} {θ2} · · · {θN} et Θ Chaque valeur zi est la masse de croyance accordée à la classe θi étant donné le vecteur de probabiltés y produit par le classificateur La règle de décision par le maximum de masse de croyance s’énonce affecter l’objet S à θi i ∈ {1 · · · N + 1} si zi > zj ∀j ∈ {1 · · · N + 1} et j �= i 3 S’il n’y a pas de composante zi de z telle que zi > zj ∀j ∈ {1 · · · N + 1} et j �= i par exemple lorsque deux composantes différentes atteignent une valeur maximale la décision est alors un rejet L’affectation de l’objet S à θ N+1 correspond également à un rejet puisque z N+1 représente la masse de croyance associée à l’ensemble complet Θ Avant de détailler notre approche nous allons discuter quelques méthodes de calcul de la fonction de masses que l’on rencontre dans la littérature RNTI E 19 515 Des probabilités a posteriori aux masses de croyance 3 Méthodes de calcul de la fonction de masses La stratégie que nous développons dans cet article pour le calcul des valeurs de masse de croyance peut s’appliquer dans deux contextes différents contexte 1 classifieur unique l’on souhaite améliorer les performances d’un classifieur quelconque donné dont la sortie est un vecteur de probabilités a posteriori contexte 2 fusion de classifieurs l’on dispose de K ≥ 2 classifieurs et l’on cherche à exploiter simultanément les K réponses différentes L’originalité de notre approche réside dans le fait que toutes les méthodes existantes pour le calcul des valeurs de masse de croyance dans des applications de classification ont été conçues pour la fusion de plusieurs classifieurs Elles ne s’appliquent donc pas telles quelles contraire ment à notre méthode dans le contexte d’un classifieur unique dont on voudrait améliorer les performances Dans la méthode de Xu Xu et al 1992 pour chacun des K classifieurs à fusionner les taux de reconnaissance d’erreur et de rejet respectivement �r �s et 1− �r− �s sont assimilés à des masses de croyance et la fonction de masses m est définie comme suit – si la décision par le maximum de probabilité a posteriori mène à un rejet alors m Θ =1 – si la décision par le maximum de probabilité a posteriori mène au choix de la classe θn alors m distribue la quantité unitaire sur trois élements focaux {θn} {θn} et Θ de la manière suivante m {θn} =�r m {θn} =�s et m Θ =1− �r − �s Cette méthode de calcul des valeurs de masse de croyance pourrait bien s’appliquer dans le contexte d’un classifieur unique mais elle n’est guère théoriquement satisfaisante Si les taux de reconnaissance d’erreur et de rejet peuvent sans difficulté être considérés comme des pro babilités ils ne peuvent être assimilés à des masses de croyance que sous certaines condi tions puisque la croyance dans les réponses d’un classifieur est nécessairement affectée par la confiance que l’on fait au classifieur Les masses de croyance et les probabilités ne coïncident que lorsque l’on est tout à fait confiant quant aux réponses du classifieur La méthode de Rogova Rogova 1994 inclut une étape d’apprentissage pour la fusion des classifieurs fk k ∈ {1 · · · K} Cet apprentissage consiste à calculer pour chaque paire fk θn un vecteur de référence Ekn comme étant la moyenne des vecteurs de sortie lorsque f k est appliqué sur les données d’apprentissage appartenant à la classe θn On considère ensuite une fonction de proximité φ qui varie entre 0 et 1 et n’atteint la valeur de 1 que lorsque ses deux arguments sont égaux Pour une donnée inconnue x quelconque l’ensemble des valeurs prises par φ Ekn f k x permet de générer un ensemble de fonctions de masses dont la combinaison à l’aide d’opérateurs proposés par la théorie de l’évidence résulte en une autre fonction de masses m La décision de classification est alors basée sur m La technique proposée par Denoeux Denoeux 2000 pour le calcul des valeurs de masse de croyance ne s’inscrit ni dans le contexte 1 ni dans le contexte 2 puisqu’elle ne part pas d’un ou plusieurs classifieur s existant s C’est une technique d’apprentissage qui permet de construire un classifieur en utilisant des notions dont celle de fonction de masses introduites par la théorie de l’évidence Denoeux propose d’extraire à partir de l’ensemble d’apprentis sage J vecteurs prototypes p1 · · · pJ un prototype pj étant un vecteur situé dans l’espace des caractéristiques et dont on connaît la probabilité ujn d’appartenir à la classe θn Pour une donnée inconnue chaque prototype pj génère une fonction de masses mj à N + 1 éléments focaux mj Θ =1− αj exp −γj‖x− pj‖2 mj {θn} =αjujn exp −γj‖x− pj‖2 ∀n RNTI E 19 516 T Amouh et al où x est le vecteur de caractéristiques extrait de la donnée inconnue et γj et αj sont des para mètres associés au prototype pj Le paramètre αj varie entre 0 et 1 et γj > 0 La combinaison des J fonctions mj résulte en une autre fonction de masses m sur laquelle se base la décision de classification La méthode d’Al Ani Al Ani et Deriche 2002 est similaire à celle de par Rogova La principale différence entre les deux méthodes réside dans la manière de déterminer les vecteurs de référence Al Ani propose de les contruire par apprentissage alors que Rogova les calculait par moyennage A l’instar de la méthode de Rogova la méthode d’Al Ani définit une approche de fusion de classifieurs et nécessite au moins deux classificateurs pour s’appliquer Dans un contexte de fusion de classifieurs fk à sorties nominales la méthode d’Appriou Appriou 2002 propose d’extraire d’abord sous la forme de fonctions de probabilités condi tionnelles p fk θn de la connaissance au sujet de chacun des K classifieurs Un facteur de confiance qkn ∈ [0 1] est associé à chaque fonction de probabilités conditionnelles et reflète notre confiance dans l’estimation Si p fk θn est parfaitement représentative de la population des données concernant la paire fk θn alors qkn = 1 Par la suite lorsque pour une donnée inconnue le classifieur fk produit le label θc N fonctions de masses mkn ayant chacune trois éléments focaux sont calculées mkn {θn} = q k n × [ Rk×p fk=θc θn ] [ 1 + Rk×p fk=θc θn ] mkn {θn} = q k n [ 1 + Rk×p fk=θc θn ] mkn Θ = 1− q k n où Rk ≥ 0 est un facteur de normalisation Notons qu’Appriou a également proposé un modèle de fonction de masses ayant seulement deux éléments focaux La combinaison grâce à la règle de la somme orthognonale de Dempster de toutes les fonctions de masses mkn ainsi calculées résulte en une autre fonction de s m La décision de classification est alors basée sur m 4 Détail de l’approche proposée 4 1 Une procédure en deux étapes Dans la suite de cet article nous désignerons par hypothèses les N + 1 éléments focaux dans 2 En considérant que chaque hypothèse est représentée par un vecteur de référence à N composantes le vecteur de sortie z dans notre méthode voir figure 1 peut être obtenu par un calcul en deux étapes étant donné un objet inconnu S Etape 1 Pour chaque hypothèse {θj} la dissimilarité aj entre son vecteur de référence rj et le vecteur y correspondant à S est mesurée grâce à une fonction de distance φ par exemple la distance euclidienne aj = φ y rj Une fonction monotone décroissante g telle que l’exponentielle décroissante permet de me surer la proximité g aj entre rj et y Etape 2 La normalisation des valeurs de proximité obtenues à l’étape 1 conduit au vec teur z interprété comme une fonction de masses de croyance se rapportant à l’information véhiculée par y zi = m {θi} = g ai ∑N+1 j=1 g aj RNTI E 19 517 Des probabilités a posteriori aux masses de croyance Notons que les composants de z satisfont à l’expression 1 4 2 Implémentation connexionniste Notre approche exposée ci dessus présente quelques similitudes avec les réseaux à fonc tions radiales de base Ghosh et Nag 2001 qui sont des réseaux de neurones composés d’une couche d’entrée une couche cachée et une couche de sortie Etant donné un vecteur d’entrée la réponse d’une unité cachée est définie comme étant une fonction décroissante de la distance entre le vecteur d’entrée et un vecteur relatif à l’unité considérée La réponse d’une unité de sortie est définie comme étant la somme pondérée des réponses des unités cachées A l’instar des réseaux à fonctions radiales de base la technique que nous proposons peut également être représentée dans le formalisme connexionniste avec une seule couche cachée voir la figure 2 La couche cachée couche numéro 1 et la couche de sortie couche numéro 2 correspondent respectivement aux étapes 1 et 2 de la procédure décrite ci dessus Il y a N + 1 unités dans chacune de ces couches yN y1 g g g I I I z N+1 zi z1 a 1 N+1 a 1 j a 1 1 z 1 N+1 z 1 j z 1 1 a 2 N+1 a 2 i a 2 1 w 1 N N+1 w 1 1 N+1 w 1 11 w 1 N1 FIG 2 – Schéma connexionniste de notre méthode avec N unités dans la couche d’entrée N + 1 unités dans la couche cachée et N + 1 unités dans la couche de sortie yn représente la nème composante n ∈ {1 · · · N} du vecteur d’entrée y produit par le classifieur dont nous voulons améliorer les performances Ce vecteur satisfait à la contrainte suivante puisqu’il s’agit d’un vecteur de probabilités 0 ≤ yn ≤ 1 ∀n ∈ {1 · · · N} et N∑ n=1 yn = 1 4 Dans les couches numéro 1 et 2 la nème unité est associée à l’hypothèse {θn} et l’unité N + 1 est associée à l’hypothèse Θ On note a l j j ∈ {1 · · · N + 1} et l ∈ {1 2} la RNTI E 19 518 T Amouh et al valeur d’activation de l’unité j dans la couche l Une même fonction d’activation g est utilisée dans toutes les unités cachées La fonction d’activation utilisée dans les unités de sortie est la fonction identité I La réponse de l’unité i dans la couche l est notée z l i Dans la couche numéro 1 le paramètre w 1 nj correspond à la n ème composante du vecteur de référence w 1 j de l’hypothèse {θj} La valeur d’activation a 1 j qui mesure la dissimilarité entre y et w 1 j est fournie par le carré de la distance euclidienne entre les deux vecteurs a 1 j = ‖y −w 1 j ‖ 2 = N∑ n=1 yn − w 1 nj 2 ∀j ∈ {1 · · · N + 1} 5 La réponse z 1 j à une activation a 1 j mesure la proximité entre les deux vecteurs y et w 1 j Cette proximité est supposée directement proportionnelle à la croyance qui supporte l’hypo thèse {θj} Elle est maximale lorsque y = w 1 j i e a 1 j = 0 et décroît lorsque y s’éloigne de w 1 j Un tel comportement peut être engendré par une fonction exponentielle décroissante de la dissimilarité entre les deux vecteurs z 1 j = g a 1 j = exp −a 1 j ∀j ∈ {1 · · · N + 1} 6 La couche numéro 2 permet de normaliser les valeurs de proximité z 1 j Ces valeurs nor malisées correspondent aux composantes zi du vecteur de sortie z zi = z 2 i = a 2 i = z 1 i∑N+1 j=1 z 1 j ∀i ∈ {1 · · · N + 1} 7 4 3 Apprentissage des vecteurs de référence Soit Err le critère d’erreur Err = P∑ p=1 Ep avec Ep = ‖zp − tp‖2 8 où P est le nombre total de données dans l’ensemble d’apprentissage zp le vecteur de masses de croyance produit par notre méthode pour la donnée d’apprentissage p et tp le vecteur de masses désiré pour p Les composantes de tp étant inconnues nous proposons le raisonnement suivant pour leur calcul nous considérons les sorties désirées comme étant les valeurs de masse de croyance que l’on devrait obtenir si l’on était dans un “monde parfait” i e un monde où le classifieur serait parfait et ne ferait aucune erreur Dans ce cas l’on ferait entièrement confiance au classifieur puisque pour tout objet appartenant à la classe θc c ∈ {1 · · · N} le classifieur produirait un vecteur y ayant la forme yc = 1 et yn = 0 ∀n �= c 9 et les composantes des vecteurs de référence auraient la forme⎧⎪⎨⎪⎩ w 1 nj = 1 si n = j w 1 nj = 0 si n �= j et j �= N + 1 w 1 n N+1 = α ∀n ∈ {1 · · · N} 10 RNTI E 19 519 Des probabilités a posteriori aux masses de croyance où α ∈ R Afin de déterminer les valeurs appropriées de α on observe que sous l’hypothèse du monde parfait le vecteur de référence du rejet w 1 N+1 dont toutes les composantes valent α est à égale distance euclidienne de tout autre vecteur de référence w 1 j En notant β le carré de cette distance on a β = ‖w 1 N+1 −w 1 j ‖ = yc − α 2 + N∑ n=1 n�=c yn − α 2 En remplaçant yn par ses valeurs indiquées dans 9 on obtient β = Nα2 − 2α + 1 Le paramètre β ainsi calculé se retrouvera dans les expressions des composantes des vecteurs tp d’où l’on pourra déduire les valeurs appropriées de α En phase d’apprentissage et sous l’hypothèse du monde parfait pendant que les paramètres w 1 nj gardent leurs formes indiquées dans 10 lorsque l’on propage un vecteur y voir 9 dans le réseau et que l’on calcule les valeurs d’activation et de sortie grâce aux équations 5 6 et 7 le vecteur de sortie z obtenu correspond au vecteur de masses désiré tp Ainsi pour une donnée d’apprentissage p appartenant à la classe θc on obtient en propageant le y fourni par le classifieur pour la donnée p ⎧⎨⎩ tc = zc = exp β + 2 den ti = zi = exp β den ∀i �= c et i �= N + 1 t N+1 = z N+1 = exp 2 den 11 où den = exp β + 2 + exp 2 + N − 1 exp β et tj représente la jème composante du vecteur de masses désiré tp L’on peut alors déduire les valeurs appropriées de α en considé rant que tp étant une fonction de masses sensée représenter une situation parfaite ses valeurs doivent satisfaire les inéquations suivantes t N+1 < ti < tc ∀c i ∈ {1 · · · N} i �= c 12 En résolvant les inéquations 12 on trouve α ∈]−∞ A[ ∪ ]B +∞[ où A = 1− √ 1 + N N et B = 1+ √ 1 + N N En observant que−1 < A ∀N > 0 on déduit que α = −1 est un choix approprié puisque N est nécessairement positif L’on pourra donc remplacer β par N + 3 dans 11 Afin de trouver les valeurs optimales de w 1 nj en minimisant le critère d’erreur nous opé rons une descente de gradient stochastique à partir de l’équation 8 Cela nous amène à évaluer la dérivée suivante ∂Ep ∂w 1 nj = 2× δ 1 j × w 1 nj − yn 13 avec δ 1 j = ⎛⎝δ 2 j f1 z 1 j + N+1∑ j �=i=1 δ 2 i f2 z 1 i ⎞⎠ f3 a 1 j RNTI E 19 520 T Amouh et al où δ 2 i = 2× a 2 i − ti et les fonctions f1 f2 et f3 définies comme suit f1 z 1 j = ∑N+1 l=1 z 1 l − z 1 j ∑N+1 l=1 z 1 l 2 f2 z 1 i = −z 1 i ∑N+1 l=1 z 1 l 2 f3 a 1 j = − exp −a 1 j 4 4 Généralisation Une fois que les vecteurs de référence w 1 j sont appris ∀j l’on peut calculer un vecteur de masses z pour chaque vecteur d’entrée y inconnu et prendre une décision de classification par la règle du maximum de masse de croyance voir 3 5 Tests de l’approche proposée 5 1 Cotation en stades de sommeil Dans les laboratoires d’analyse du sommeil humain la cotation en stades de sommeil est une activité de classification des pages successives d’un enregistrement polysomnogra phique Un enregistrement polysomnographique est constitué de signaux bio électriques tels que des électro encéphalogrammes EEG des électro occulogrammes EOG et des électro myogrammes EMG enregistrés tout au long de la nuit plus ou moins 8 heures à l’aide de capteurs positionnés sur le corps d’un patient Afin de procéder à la cotation en stades l’enre gistrement polysomnographique est logiquement segmenté en plusieurs pages successives de 30 secondes La figure 3 illustre une page où les deux premiers signaux sont des sections de signaux EEG les troisième et quatrième sont des sections de signaux EOG et le dernier est une section d’un signal EMG La cotation en stades de sommeil consiste à identifier pour chaque page le stade de som meil correspondant parmi les 5 stades prédéfinis l’éveil A le sommeil paradoxal REM le stade 1 S1 le stade 2 S2 et le stade 3 S3 L’exposé de l’application de notre approche au problème de la cotation en stades de sommeil ne nécessite pas d’expliquer en détail chacun de ces stades Il suffit de noter que ces stades correspondent aux classes donc N = 5 et que les pages successives correspondent aux objets à classer Afin de tester notre approche dans plusieurs cas différents six classifieurs ont été déve loppés indépendamment de notre technique d’amélioration de performance Chacun de ces six classifieurs produit en sortie un vecteur de probabilités a posteriori qui deviendra l’entrée de notre méthode 5 2 Ensembles de données d’apprentissage et de test Nous avons disposé d’un ensemble de données d’apprentissage E contenant 47 enregistre ments polysomnographiques fournissant un total de 48579 pages classées par un expert humain du domaine Ces 47 enregistrements ont été partagés en 3 sous ensembles RNTI E 19 521 Des probabilités a posteriori aux masses de croyance FIG 3 – Une page de 30 secondes – le sous ensemble E1 servait au développement des classifieurs indépendamment de notre méthode – le sous ensemble E2 servait à l’apprentissage de notre méthode – le sous ensemble E3 servait au test Les sous ensembles E1 E2 et E3 forment ainsi une partition de E Afin de vérifier l’efficacité de notre technique dans différents scénarios nous avons aléatoirement généré trois partitions P1 P2 et P3 chacune constituée des sous ensembles E1 E2 et E3 6 Résultats et discussion N = 5 dans le problème de la cotation en stades de sommeil Nous avons également déjà établi que α = −1 est un choix approprié ∀N > 0 Nous implémentons l’algorithme suivant pour générer des graphiques de comparaison de performances – pour chaque partition Pi i = 1 · · · 3 – fixer N = 5 et α = 1 et utiliser le sous ensemble E2 pour entraîner notre algorithme d’amélioration de performance – pour chaque classifieur préalablement entraîné sur le sous ensemble E1 – pour chaque page appartenant au sous ensemble test E3 – calculer le vecteur y prendre une décision sur base de la règle du maximum de probabilités a posteriori et comparer la classe obtenue à la vraie classe de la page – à partir de y calculer le vecteur z prendre une décision sur base de la règle du maximum de masse de croyance et comparer la classe obtenue à la vraie classe de la page – end – dessiner un graphe ayant en abscisse les patients de E3 et en ordonnées les perfor mances du classifieur avant et après application de notre méthode – end RNTI E 19 522 T Amouh et al – end Un total de 18 graphes de comparaison 3 partitions× 6 classifieurs ont ainsi été générés Ces 18 graphes sont tout à fait similaires à celui de la figure 4 Il y apparaît clairement qu’en ce qui concerne le problème de la classification en stades de sommeil l’application de notre technique permet systématiquement d’améliorer les performances en réduisant le taux d’erreur Cette amélioration des performances peut être étonnamment élevée Par exemple pour le patient 2 4 6 8 10 0 4 0 5 0 6 0 7 0 8 0 9 1 P er fo rm an ce Performance of RF1 Performance of our technique on RF1 FIG 4 – Graphe de comparaison des performances avant et après application de notre mé thode représenté par la valeur 7 en abscisse le taux de reconnaissance des pages est passé de moins de 50% avant application de notre méthode à plus de 90% après application de notre méthode Un mauvais résultat avant application de notre méthode ne nuit donc pas nécessairement au résultat final 7 Conclusion et perspectives En classification supervisée l’utilisation de la règle de décision du maximum de masse de croyance en lieu et place de celle du maximum de probabilité a posteriori permet de réduire le taux d’erreur de classification Dans cet article une technique permettant de transformer un vecteur de probabilités a posteriori en un vecteur de masses de croyance dans le cadre de la théorie de l’évidence de Dempster et Shafer à été proposée et testée dans le domaine de la co tation en stades de sommeil Nous avons pu observer une évolution du taux de reconnaissance pouvant aller de 50% à 90% soit une réduction du taux d’erreur de 80% Il est à noter que notre méthode ne fait usage d’aucune caractéristique propre au domaine d’application et est totalement indépendante des classifieurs utilisés Dans un prochain article nous en testerons l’efficacité dans d’autres problèmes de classification supervisée RNTI E 19 523 Des probabilités a posteriori aux masses de croyance Références Al Ani A et M Deriche 2002 A New Technique for Combining Multiple Classifiers Using the Dempster Shafer Theory of Evidence Journal of Artificial Intelligence Research 17 333–361 Appriou A 2002 Discrimination Multisignal par la Théorie de l’Evidence In Lavoisier Ed Décision et Reconnaissance de Formes en Signal pp 219–257 11 rue Lavoisier 75008 Paris Denoeux T 2000 A Neural Network Classifier Based on Dempster Shafer Theory IEEE Transaction on Systems Man and Cybernetics 30 2 131–150 Ghosh J et A Nag 2001 An Overview of Radial Basis Function Network In R Howlett et L Jain Eds Basis Function Network Physica Verlag Rogova G 1994 Combining the Results of Several Neural Network Classifiers Neural Networks 7 5 777–781 Shafer G 1976 A Mathematical Theory of Evidence Princeton Princeton University Press Xu L A Krzyzack et C Y Suen 1992 Methods of Combining Multiple Classifiers and Their Applications to Handwriting Recognition IEEE Trans Syst Man Cybern 22 3 418–435 Summary We want to show that the performance of any given measurement level classifier can be enhanced when maximum posterior probability decision rule is replaced by maximum belief mass decision rule in the framework of the Dempster Shafer theory of evidence This shift in decision rule raises the need on a method for extracting class belief mass values from output posterior probabilities The aim of this paper is to propose an effective method for calculating class belief mass values on which to base class assignment decision in order to improve the accuracy and reliability of any given measurement level classifier The method can allow 80% reduction of misclassification error when applied to given measurement level classifiers in the automatic sleep stages scoring application domain RNTI E 19 524 