 Construction de profils de préférences contextuelles basée sur l’extraction de motifs séquentiels Arnaud Giacometti Dominique H Li Arnaud Soulet Université de Tours Laboratoire d’Informatique 3 place Jean Jaurès 41000 Blois FRANCE {arnaud giacometti dominique li arnaud soulet} univ tours fr Résumé L’utilisation de préférences suscite un intérêt croissant pour person naliser des réponses et effectuer des recommandations En amont l’étape es sentielle est l’élicitation des préférences qui consiste à construire un profil de préférences en sollicitant le moins possible l’utilisateur Dans cet article nous présentons une méthode basée sur l’extraction de motifs séquentiels afin de gé nérer des règles de préférences contextuelles à partir d’une base de paires de transactions À partir de ces règles générées qui ont une expressivité plus riche que celle des approches existantes nous montrons comment construire et utili ser un profil modélisant les préférences de l’utilisateur De plus notre approche a l’avantage de bénéficier des nombreux algorithmes efficaces d’extraction de séquences fréquentes L’évaluation de notre méthode sur des données réelles montre que les modèles de préférences construits permettent d’effectuer des re commandations justes à un utilisateur 1 Introduction Le besoin d’incorporer les préférences aux requêtes dans les technologies de l’information est un verrou crucial pour une grande variété d’applications allant de l’e commerce aux mo teurs de recherche personnalisés Un utilisateur accédant à un système d’information peut avoir à reformuler plusieurs fois sa requête pour éliminer les résultats insatisfaisants et cheminer vers le résultat attendu En particulier cette expérience est très fréquente avec les recherches sur le Web en raison d’une abondance d’information et surtout de l’hétérogénéité des utilisateurs Une observation cruciale alors est que différents utilisateurs considèreront comme pertinent des résultats différents car leurs préférences divergent Cependant la construction manuelle de modèles de préférences par l’utilisateur reste à la fois complexe et consommatrice de temps De ce fait l’apprentissage automatique de ses préférences en s’appuyant sur les interactions entre lui et le système joue un rôle critique dans de nombreuses applications Ces interactions appelées feedbacks utilisateurs implicites ont une forme souvent rudimentaire indiquant si un utilisateur a réalisé une action particulière sur un objet par exemple le temps passé sur un objet Ces feedbacks implicites sont souvent ambigus et d’une granularité peu fine mais ils sont plus faciles à obtenir en abondance dans un système réel Dans cet article nous faisons l’hypothèse que nous disposons d’un ensemble 419 Construction de profils de préférences contextuelles d’objets et d’un ensemble de paires de préférences sur ces objets c à d tel objet est préféré à tel autre Notre objectif sera de construire un modèle de préférences à partir de ces données même si de telles préférences sont moins subtiles que des notes et peuvent parfois contenir des inconsistances Dans cet article nous présentons une approche de construction de profils de préférences contextuelles basée sur l’extraction de motifs séquentiels nommée Sprex Sequence pattern based preference rule extraction Cette approche se constitue de trois composants principaux un extracteur de motifs séquentiels pour l’extraction des règles de préférence contextuelle une fonction de modélisation qui permet de trier et de sélectionner un sous ensemble de règles de préférence contextuelle afin de créer un profil et une fonction de préférence qui permettent de prédire la préférence de l’utilisateur en utilisant le profil construit L’approche Sprex étend l’expressivité des règles de préférence contextuelle par rapport à Agrawal et al 2006 Au paravant de telles règles permettaient seulement de préférer un item par rapport à un autre Notre proposition permet de préférer un ensemble d’items par rapport à un autre Ce gain en expressivité des règles permet de construire des profils enrichis plus proches des préférences de l’utilisateur En outre la réutilisation des outils d’extraction de motifs séquentiels fréquents permet à l’approche Sprex de générer les profils de préférences avec une très grande efficacité L’étude expérimentale montre la rapidité de l’approche mais aussi son efficacité en terme de prédiction L’article est organisé de la manière suivante La section 2 définit les notions préliminaires La section 3 introduit les travaux antérieurs associés à notre problématique La section 4 pré sente l’approche Sprex Pour cela nous définissons formellement la notion de séquences de préférence et ensuite introduisons globalement notre approche enfin nous présentons égale ment les méthodes Sprex Build et Sprex Predict qui composent l’approche Sprex La section 5 rapporte les expérimentations que nous avons menées sur des jeux de données réels avant de conclure et de présenter les perspectives associées dans la section 6 2 Définitions préliminaires et problématique Nous définissons les notions préliminaires liées à notre problématique et à notre approche dans cette section Soit R = {R1 R2 Rn} un ensemble d’attributs Pour chaque attribut Ri ∈ R nous notons le domaine de valeurs de Ri par dom Ri Nous définissons dom R = dom R1 × dom R2 × × dom Rm et appelons transaction chaque élément de dom R Soit I =⋃ Ri∈R dom Ri l’ensemble de toutes les valeurs d’attributs chaque valeur i ∈ I est un item Soit T = {i1 i2 in} une transaction chaque sous ensemble I ⊆ T est un itemset Une base de transactions est un ensemble de transactions chacune associée à un identifiant unique Une paire de transactions notée 〈T1 T2〉 est un vecteur de deux transactions tel que 〈T1 T2〉 6= 〈T2 T1〉 Dans cet article nous modélisons les préférences de l’utilisateur comme un ordre partiel� sur les itemsets tel que X � Y indique que l’utilisateur préfère l’itemset X à l’itemset Y Définition 1 Règle de préférence contextuelle étendue Une préférence contextuelle est une règle de la forme C → X � Y décrivant que l’utilisateur préfère l’itemset X à l’itemset Y si le contexte représenté par l’itemset C est observé 420 A Giacometti et al Cette définition étend la notion de règle de préférence contextuelle utilisée par Agrawal et al 2006 et de Amo et al 2012 En effet la définition usuelle se limite à des itemsets de taille 1 pour X et Y En d’autres termes l’expressivité de nos règles de préférences contex tuelles est plus forte Exemple 1 La règle de préférence {viande} → {carotte} � {riz} exprime qu’un utili sateur préfère des carottes au riz pour accompagner de la viande et la règle de préférence {viande samedi} → {carotte vin} � {riz soda} précise que le samedi cet utilisateur préfère accompagner sa viande avec des carottes et du vin plutôt que du riz et du soda Intuitivement deux transactions sont comparables suivant la règle C → X � Y si les deux contiennent C et si une seule des deux contient X et l’autre Y De manière formelle étant données une règle de préférence contextuelle r = C → X � Y et une paire de transactions p = 〈T1 T2〉 si C ⊆ T1 ∩ T2 X ⊆ T1 \ T1 ∩ T2 et Y ⊆ T2 \ T1 ∩ T2 alors on dit que p supporte r noté r `+ p en revanche si C ⊆ T1 ∩ T2 X ⊆ T2 \ T1 ∩ T2 et Y ⊆ T1 \ T1∩T2 alors on dit que p contredit r noté r `− p Par exemple soient deux règles r1 = {a c} → {b} � {e f} et r1 = {a c} → {d} � {b} on a r1 `+ p et r2 `− p si la paire de transactions p = 〈{a b c} {a c d e f}〉 Une préférence de l’utilisateur est une paire de transactions 〈T U〉 ∈ P qui spécifie que l’utilisateur préfère T à U également noté T � U Soit D une base de transactions décri vant des objets p ex des films une base de préférences de l’utilisateur P ⊆ D × D est un ensemble de paires de transactions correspondant à un échantillon des préférences de l’utili sateur sur les objets de D À partir d’une base de préférences utilisateurs P nous définissons le support d’une règle de préférence contextuelle r noté suppP r comme le nombre de paires de transactions qui supportent r nous définissions également la confiance de la règle r notée confP r comme le ratio du nombre de paires de transactions qui supportent r sur le nombre total de paires de transactions qui supportent ou contredisent r On a alors suppP r = |{p ∈ P | r `+ p}| et confP r = |{p ∈ P | r `+ p}| |{p ∈ P | r `+ p ∨ r `− p }| Définition 2 Règle de préférence contextuelle minimale Une règle de préférence contex tuelle r = C → X � Y est minimale par rapport à une base de préférences utilisateurs P si et seulement s’il n’existe aucune règle r′ = C ′ → X ′ � Y ′ r 6= r′ telle que C ′ ⊆ C X ′ ⊆ X et Y ′ ⊆ Y avec suppP r = suppP r′ et confP r = confP r′ Un modèle de préférences sur une base de préférences utilisateursP est un ensemble trié de règles de préférences contextuelles minimales notéMP Étant donnée une base de préférences d’un utilisateur on dit qu’un modèle de préférence est un profil de préférences de cet utilisateur Le problème de la construction de profil d’un utilisateur est ainsi de construire un modèle de préférences à partir d’une base de préférences de l’utilisateur 3 Travaux antérieurs Étant donnée une paire d’objets ou de transactions dans notre formalisme l’objectif d’un modèle de préférence est de prédire lequel sera préféré par l’utilisateur Les méthodes d’ap prentissage de préférences se distinguent par la nature des préférences qualitative ou quan titative et le modèle sémantique sous jacent p ex les modèles de Pareto et les modèles de préférences conditionnelles contextuelles 421 Construction de profils de préférences contextuelles Les approches d’élicitation de préférences quantitatives visent à associer un score à chaque objet afin d’ordonner un ensemble d’objets comme dans l’approche d’Agrawal et Wimmers 2000 par exemple Pour cette raison ces méthodes quantitatives qui établissent un classe ment sont aussi appelées learning to rank Plusieurs méthodes efficaces pour apprendre un classement ont été proposées notamment dans le domaine de la recherche d’information Par exemple Joachims 2006 a proposé un cadre d’apprentissage de fonctions de score en exploi tant une approche type Support Vector Machine SVM ce qui a donné lieu à l’algorithme SVMRank Les algorithmes RankBoost proposé par Freund et al 2003 et AdaRank proposé par Xu et Li 2007 optimisent le classement en s’appuyant sur une technique de boosting lors de l’apprentissage automatique En effet les méthodes quantitatives type SVMRank pro duisent le plus souvent des vecteurs numériques peu compréhensibles pour un utilisateur final et l’utilisateur ne peut ni interpréter le profil construit ni le modifier De plus les prédictions effectuées ne peuvent être expliquées simplement Sprex peut fournir des règles intelligibles pour justifier la prédiction qu’il a effectuée Les approches qualitatives ont pour objectif de produire un profil qui permettra déterminer une préférence entre deux objets En se basant sur le modèle de préférences de Pareto Kieß ling 2002 Holland et al 2003 ont proposés des approches pour extraire les préférences utilisateurs Plus récemment introduit par Jiang et al 2008 les exemples de préférences sont catégorisés en deux classes les exemples supérieurs ceux préférés par l’utilisateur et les exemples inférieurs ceux non préférés par l’utilisateur A partir de ces informations un ordre sur toute paire de tuples est inféré et peut donc permettre de comparer deux nouveaux tuples Historiquement les premières approches d’élicitation de préférences contextuelles condi tionnelles ont été proposées dans le domaine de l’intelligence artificielle Par exemple les CP Nets réseaux de préférences conditionnelles proposés par Boutilier et al 2004 per mettent à l’utilisateur de modéliser ses préférences contextuelles sous la forme d’un réseau assez compact A l’inverse notre méthode cherche à traiter des grands volumes de données contenant des incohérences car issus de feedbacks implicites Notre travail exploitent clairement des préférences contextuelles proches de celles propo sées par Agrawal et al 2006 pour classer des tuples ou par Stefanidis et al 2007 où le contexte est modélisé comme un ensemble d’attributs multidimensionnels Toutefois Agrawal et al 2006 Stefanidis et al 2007 ne présentent pas de méthodes d’extraction de préférences à partir de données Enfin dans le travail récent présenté par de Amo et al 2012 les préfé rences contextuelles sont formalisées et extraites en adaptant le cadre des règles d’association afin de construire les profils utilisateurs Notre définition de règles de préférences contextuelle est plus générale et s’appuie sur l’extraction de motifs séquentiels 4 L’approche Sprex Dans cette section nous présentons notre approche Sprex Dans un premier temps nous dé finissons formellement la correspondance entre préférences et motifs séquentiels L’extraction de règles de préférences contextuelles dans ce contexte consiste alors à extraire les séquences de préférence fréquentes Nous présentons ensuite les deux principales phases de l’approche Sprex Sprex Build et Sprex Predict 422 A Giacometti et al 4 1 Représentation séquentielle des préférences Soit I l’ensemble de tous les items un item de préférence est une paireL i oùL ∈ {C P N} est un label parmi Contexte Préferé et Non préféré et i ∈ I est un item Étant données deux transactions T et U telles que T � U l’itemset contextuel est un ensemble d’items de pré férence {C c1 C c2 C ck} où {c1 c2 ck} ≡ T ∩ U l’itemset préféré est l’ensemble {P x1 P x2 P xm} où {x1 x2 xm} ≡ T \ T ∩ U l’itemset non préféré est l’en semble {N y1 N y2 N yn} où {y1 y2 yn} ≡ U \ T ∩ U Les itemsets contextuel préféré et non préféré sont appelés les itemsets de préférence Nous définissons trois fonctions de label {λC λP λN} Chacune génère un itemset de préférence à partir d’un itemset usuel par exemple si I = {i1 i2 in} alors λC I = {C i1 C i2 C in} etc De manière plus simple on note CC = λC C XP = λP X et YN = λN Y Nous appelons alors la séquence 〈CCPPNN 〉 une séquence de préférence il s’agit d’une liste or donnée des itemsets de préférence sur les itemsets C P et N qui indique la préférence de la transaction T = C∪P sur la transaction U = C∪N Étant donnée une base de préférences de l’utilisateur P il existe une base de séquences de préférence notée PS dont chaque séquence associée à un identificateur unique correspond à une préférence unique p ∈ P Exemple 2 Soient T1 = {a b c d e f} et T2 = {a g h f} deux transactions Selon la préférence de l’utilisateur T1 � T2 on a l’itemset contextuel {C a C f} l’itemset préféré {P b P c P d P e} et l’itemset non préféré {N g N h} La séquence de préférence construite à partir de cette préférence utilisateur est alors 〈{C a C f}{P b P c P d P e}{N g N h}〉 Selon le principe de l’extraction de motifs séquentiels proposée par Agrawal et Srikant 1995 nous définissons les relations suivantes sur les séquences de préférence Etant donnée deux séquences de préférence s = 〈ICIP IN 〉 où IC IP et IN sont respectivement les item sets contextuel préféré et non préféré et s′ = 〈I ′CI ′P I ′N 〉 si IC ⊆ I ′C IP ⊆ I ′P et IN ⊆ I ′N alors s est une sous séquence de s′ dénoté par s v s′ Etant donnée une base de séquences de préférence PS le support de la séquence de préférence s dénoté par suppPS s est le nombre de séquences de préférence dePS qui contiennent s suppPS s = |{s′ ∈ PS | s v s′}| Etant donné un seuil minimal de support σ une séquence s est alors dite fréquente si suppPS s ≥ σ on parle de séquence fréquente de préférence Soit r = C → X � Y une règle de préférence contextuelle où C = {c1 c2 ck} X = {x1 x2 xm} et Y = {y1 y2 yn} alors la règle r peut être réécrite en une séquence de préférence 〈CCXPYN 〉 Propriété 1 Avec la paire de transactions 〈T U〉 où T � U représentée sous la forme d’une séquence de préférence 〈ICIP IN 〉 on obtient les relations suivantes C → X � Y `+ 〈T U〉 ⇐⇒ 〈CCXPYN 〉 v 〈ICIP IN 〉 1 C → X � Y `− 〈T U〉 ⇐⇒ 〈CCYPXN 〉 v 〈ICIP IN 〉 2 � Ainsi étant donnée une base de séquences de préférence PS construite à partir des pré férences utilisateurs P alors le support de la règle r = C → X � Y par rapport à P est équivalent au support de la séquence de préférence 〈CCXPYN 〉 par rapport à PS De plus le nombre de paires de transactions de P qui contredisent la règle r est équivalent au nombre de séquences de préférence de PS qui contiennent la séquence 〈CCYPXN 〉 423 Construction de profils de préférences contextuelles 4 2 Phase de construction Sprex Build La construction du modèle de préférences Sprex Build est décrite par l’algorithme 1 où un modèle de préférenceMP c à d le profil de l’utilisateur est généré à partir d’une base de préférences utilisateurs P avec un seuil minimal de support σ un seuil minimal de confiance δ et une fonction de modélisation π Sprex Build génère d’abord une base de séquences de préférence PS à partir des préférences utilisateurs P en utilisant la correspondance vue dans la section précédente ligne 1 à 4 Ensuite à la ligne 5 la collection des séquences fréquentes de préférence F est extraite depuis PS selon un seuil σ en utilisant n’importe quel algorithme d’extraction de motifs séquentiels dans notre partie expérimentale nous utiliserons l’approche PatternGrowth Pour chaque séquence fréquente de préférence s de l’ensemble F Sprex Build calcule sa confiance confPS s et l’ajoute au modèleM si confPS s ≥ δ Enfin une fonction de modélisation π définie par l’utilisateur est utilisée pour construire le modèle de préférence final Algorithme 1 Sprex Build Entrées Les préférences de l’utilisateur P un seuil minimal de support σ un seuil de confiance minimal δ et une fonction de modélisation π Sorties Modèle de règles de préférences contextuellesMP PS = ∅ 1 pour chaque 〈T U〉 ∈ P faire2 CC = λC T ∩ U PP = λP T \ T ∩ U NN = λN U \ T ∩ U 3 PS = PS ∪ 〈CCPPNN 〉 4 F = FrequentSequenceMining PS σ 5 M = ∅ 6 pour chaque s ∈ F faire7 si confPS s ≥ δ alors8 M =M∪ s 9 MP = π sort M 10 retournerMP 11 Comme précédemment décrit étant donné une paire de transactions 〈T U〉 une séquence de préférence 〈ICIP IN 〉 doit contenir au moins 2 itemsets de préférence et un maximum de 3 itemsets de préférence Plus précisément selon la structure d’une séquence de préférence générée à partir d’une base de transactions il y a 7 cas sur les motifs séquentiels extraits et tous ces cas à l’exception de 1 permettent de construire une règle de préférence L’exemple suivant illsutre cette propriété Exemple 3 Considère des itemsets de préférence qui contiennent deux items {C i1 C i2} {P i3 P i4} et {N i5 N i6} on a les correspondances suivantes entre les motifs séquentiels et les règles de préférence 1 〈{C i1 C i2}{P i3 P i4}{N i5 N i6}〉 ⇐⇒ {C i1 C i2} → {P i3 P i4} � {N i5 N i6} 2 〈{C i1 C i2}{P i3 P i4}〉 ⇐⇒ {C i1 C i2} → {P i3 P i4} � {} 3 〈{C i1 C i2}{N i5 N i6}〉 ⇐⇒ {C i1 C i2} → {} � {N i5 N i6} 424 A Giacometti et al 4 〈{P i3 P i4}{N i5 N i6}〉 ⇐⇒ {} → {P i3 P i4} � {N i5 N i6} 5 〈{P i3 P i4}〉 ⇐⇒ {} → {P i3 P i4} � {} 6 〈{N i5 N i6}〉 ⇐⇒ {} → {} � {N i5 N i6} 7 par contre le motif séquentiel 〈{C i1 C i2}〉 sera systématiquement ignoré car il ne sert à aucune règle pertinente Pour cette raison l’extraction des séquences de préférence fréquentes est plus simple que l’extraction de tous les motifs séquentiels Agrawal et Srikant 1995 Pei et al 2001 De plus comme un modèle de préférence est constitué uniquement de règles de préférences mi nimales le problème de construction se réduit même à l’extraction des séquences génératrices fréquentes introduites par Lo et al 2008 La méthode Sprex Build utilise ensuite l’ensemble des motifs séquentiels extraits afin de générer un modèle ligne 10 via une fonction de modélisation Avant d’appliquer une fonction de modélisation nous conservons pour chaque paire de transactions la meilleure règle qui la supporte Cette notion de meilleure est modélisée par un ordre sur les règles déjà utilisé par Liu et al 1998 pour la construction de classifieur Ainsi une règle est d’autant meilleure que sa confiance est élevée en cas d’égalité on choisit alors celle dont le support est le plus grand La fonction de modélisation effectue ensuite deux opérations 1 sélection de règles de préférence contextuelle en respectant des contraintes définies par l’utilisateur p ex le filtrage basé sur la confiance le support la composition la structure ou la taille des règles et 2 nouveau tri des règles sélectionnées en respectant un ordre défini par l’utilisateur en cas de besoin Il s’agit donc de conserver des règles sûres et générales pour que le modèle final soit à la fois précis et concis 4 3 Phase de prédiction Sprex Predict L’utilisation par Sprex Predict du modèle construit lors de la phase précédente pour effec tuer une prédiction entre deux préférences est détaillée en dessous Étant donné un modèleM une fonction de préférence ρ retourne un score c entre 0 et 1 qui prédit entre les transactions T et U celle qui est préférée par l’utilisateur en se référant au modèleM Si c > 0 5 cela signifie que l’utilisateur préfère la transaction T à la transaction U et ainsi Sprex Predict retourne la préférence T �M U si c < 0 5 Sprex Predict retourne la préférence U �M T car l’utilisateur préfère la transaction U à la transaction T sinon Sprex Predict retourne T ∼M U qui signifie l’indécision de Sprex Predict quant à la préférence de l’utilisateur entre T et U La fonction de préférence utilise les règles du modèleM afin de déterminer quelle est la transaction préférée entre T et U Une fonction simple de préférence est d’utiliser la meilleure règle du profil rbest qui permet de préférer T à U ou vice et versa Si T est préférée à U selon rbest la fonction de préférence ρbest retournera confP rbest une valeur > 0 5 À l’inverse si U est préférée à T selon rbest la fonction de préférence ρbest retournera 1 − confP rb une valeur < 0 5 Si aucune règle du profil ne s’applique la fonction ρbest retournera 0 5 À nouveau nous utilisons un ordre défini sur la meilleure confiance puis sur le meilleur support comme lors de la construction du modèle afin de choisir la meilleure règle 425 Construction de profils de préférences contextuelles Malheureusement la fonction de préférence ρbest est souvent indécise car il est peu fré quent que deux transactions soient directement comparables par une règle du modèle selon l’étude expérimentale menée dans de Amo et al 2012 Au lieu de comparer directement les deux transactions avec ρbest nous organisons un vote par valeur pour prendre la décision qui est le meilleur candidat Notre vote par valeur est un système de vote pour une élection à un siège dans lequel les électeurs E évalue les deux candidats en leur attribuant une valeur entre 0 et 1 en utilisant ρbest Les valeurs de chaque candidat sont additionnées et celui ayant le plus haut score est le gagnant Formellement nous avons ρvote =    1 si ∑ V ∈E ρbest M 〈T V 〉 > ∑ V ∈E ρbest M 〈U V 〉 0 si ∑ V ∈E ρbest M 〈T V 〉 < ∑ V ∈E ρbest M 〈U V 〉 0 5 si ∑ V ∈E ρbest M 〈T V 〉 = ∑ V ∈E ρbest M 〈U V 〉 3 Dans les expérimentations nous utiliserons exclusivement ρvote dont le rappel est toujours supérieur à ρbest pour une précision comparable 5 Évaluations expérimentales Dans cette section nous rapportons les évaluations expérimentales de notre approche Sprex sur les jeux de données réels 1 construits à partir des données disponibles sur MovieLens 2 et IMDB 3 Nous comparons Sprex à l’approche SVMRank développée par Joachims 2006 car il s’agit d’une des méthodes les plus performantes et des plus reconnues De plus la méthode proposée par de Amo et al 2012 utilise la même référence Toutes nos expérimentations ont été effectuées sur un serveur de 16 Core 2 40GHz Intel Xeon avec 32 giga octets de mémoire vive et avec le noyau Linux 2 6 32 L’extraction de motifs séquentiels est réalisée en utilisant le principe PatternGrowth proposé par Pei et al 2001 Toutes les méthodes sont implémentées en C++ Template et compilées par LLVM Clang++ Le jeu de données concerné dans nos expérimentations est constitué des 800 156 notes attribuées par 6 040 utilisateurs sur 3 881 films Chaque film constitue un ensemble d’attributs incluant un identifiant unique l’année de sortie les genres multi valeurs les réalisateurs multi valeurs et les principaux acteurs actrices multi valeurs Chaque utilisateur a évalué un certain nombre de films de quelques uns à quelques milliers avec des notes comprises entre 1 et 5 4 Tous les films votés par un même utilisateur composent un jeu de données indépendant Alors soit D un jeu de films votés par un utilisateur pour toute paire de films m1 m2 ∈ D on a m1 rating > m2 rating impose m1 � m2 Ainsi chaque jeu de films correspond à une base de préférences de l’utilisateur La table 1 liste les 4 jeux de données testés dans nos expérimentations où chaque jeu est identifié par l’identifiant de l’utilisateur et contient plus de 500 films votés afin d’assurer une validation croisée en 5 blocs telle que chaque bloc de données contient du moins 100 films votés Dans une première étape les motifs séquentiels sont extraits avec le support minimal va riant entre 0 4% et 1 8% pour créer des profils bruts qui contiennent les règles de préférence 1 Disponible sur info univ tours fr ~li data pref html 2 movielens org 3 imdb com 4 Nous avons délibérément choisi un jeu de données avec des feedbacks explicites plutôt que implicites pour pouvoir nous comparer avec SVMRank 426 A Giacometti et al Base Films votés Séquences de préférence Items distincts U0048 541 93365 2514 U0533 565 122757 2602 U3884 571 124974 2797 U4867 552 97860 2674 TAB 1 – Jeux de données réels sur les films votés a U0048 b U0533 c U3884 d U4867 FIG 1 – Les temps moyens en seconde de construction de profils bruts par rapport à la variation du support minimal a U0048 b U0533 c U3884 d U4867 e U0048 f U0533 g U3884 h U4867 FIG 2 – Les tailles moyennes de profils par rapport à la variation du support minimal avec la confiance minimale fixée à 75% a–d et à la variation de la confiance minimale avec le support minimal fixé à 0 5% e–h 427 Construction de profils de préférences contextuelles a U0048 b U0533 c U3884 d U4867 e U0048 f U0533 g U3884 h U4867 FIG 3 – Les précisions moyennes a–d et les rappels moyens e–h de profils par rapport à la variation du support minimal avec la confiance minimale fixée à 75% a U0048 b U0533 c U3884 d U4867 e U0048 f U0533 g U3884 h U4867 FIG 4 – Les précisions moyennes a–d et les rappels moyens e–h de profils par rapport à la variation de la confiance minimale avec le support minimal fixé à 0 5% 428 A Giacometti et al contextuelle minimales avec la confiance minimale fixée à 50% afin de faciliter les tests sui vants Ensuite pour chaque profil brut deux fonctions de modélisation MaxRule et MinRule sont appliquées pour construire des profils finaux La fonction MaxRule permet de construire des profils en sélectionnant les règles les plus spécifiques parmi toutes les règles minimales gé nérées précédemment par contre la fonction MaxRule construit un profil en utilisant les règles moins expressives comme introduites dans les approches proposées par Agrawal et al 2006 et par de Amo et al 2012 Dans cette étape la confiance minimale a varié entre 70% et 90% Enfin les résultats obtenus par SVMRank sont utilisés comme référence La figure 1 montre les temps moyens de construction de profils bruts à partir des 4 jeux de films En effet avec le support minimal 0 4% les constructions se terminent en 700 secondes dont les nombres moyens de règles par profil sont respectivement 20 934 13 208 12 020 et 17 699 Après avoir appliqué la fonction de modélisation la taille des profils est significativement réduite comme le montre la figure 2 Nous avons testé la qualité de prédiction de chaque profil construit en mesurant la précision et le rappel de la prédiction Pour cet objectif deux séries de tests ont été effectuées en variant le support minimal la figure 3 et en variant la confiance minimale la figure 4 Les courbes montrent que la qualité de la prédiction augmente avec l’expressivité des règles qui composent les profils Par ailleurs les courbes montrent également qu’il y a une corrélation forte entre la qualité de prédiction et la diminution des seuils de support et de confiance La table 2 présente un exemple des règles de préférence contextuelle extraites à partir du jeu de films U0048 Contexte Préféré Non préféré Confiance Support {Action} {Fantasy Harrison_Ford} {1990s} 0 987578 11222 {Comedy} {Romance} {Family Sport} 0 968254 1487 {1990s} {Thriller Drama} {Comedy Adventure} 0 955490 1620 {1990s} {Thriller Tommy_Lee_Jones} {Comedy} 0 922667 1639 TAB 2 – Un exemple des règles de préférence contextuelle 6 Conclusions Dans cet article nous avons présenté Sprex une approche basée sur l’extraction de sé quences fréquentes pour la construction de modèles de préférences L’idée essentielle est de représenter les données d’apprentissage et les règles de préférence utilisateur sous la forme de triplets formant des séquences de préférence De cette manière nous avons pu tirer profits des travaux issus de l’extraction de motifs séquentiels fréquents et mettre en place une ap proche efficace Par ailleurs cette proposition a également l’avantage d’étendre l’expressivité des préférences extraites Nous avons évalué notre approche sur une base de données filmogra phique du monde réel et les résultats expérimentaux ont montré que les modèles de préférence construits sont relativement stables par rapport à la variation du seuil minimum de support Nos recherches futures vont s’orienter vers le développement de fonctions de modélisation et des fonctions de préférence afin d’améliorer la précision et le rappel de la prédiction des préférences de l’utilisateur Enfin nous pensons exploiter le potentiel des séquences au sein de l’approche Sprex pour introduire la notion de temps dans les règles de préférences 429 Construction de profils de préférences contextuelles Références Agrawal R R Rantzau et E Terzi 2006 Context sensitive ranking In SIGMOD pp 383–394 Agrawal R et R Srikant 1995 Mining sequential patterns In ICDE pp 3–14 Agrawal R et E L Wimmers 2000 A framework for expressing and combining preferences In SIGMOD pp 297–306 Boutilier C R I Brafman C Domshlak H H Hoos et D Poole 2004 Cp nets A tool for representing and reasoning with conditional ceteris paribus preference statements Journal of Artificial Intelligence Research 21 135–191 de Amo S M S Diallo C T Diop A Giacometti H D Li et A Soulet 2012 Mining contextual preference rules for building user profiles In DaWaK pp 229–242 Freund Y R D Iyer R E Schapire et Y Singer 2003 An efficient boosting algorithm for combining preferences Journal of Machine Learning Research 4 933–969 Holland S M Ester et W Kießling 2003 Preference mining A novel approach on mining user preferences for personalized applications In PKDD pp 204–216 Jiang B J Pei X Lin D W Cheung et J Han 2008 Mining preferences from superior and inferior examples In KDD pp 390–398 Joachims T 2006 Training linear SVMs in linear time In KDD pp 217–226 Kießling W 2002 Foundations of preferences in database systems In VLDB pp 311–322 Liu B W Hsu et Y Ma 1998 Integrating classification and association rule mining In KDD pp 80–86 Lo D S C Khoo et J Li 2008 Mining and ranking generators of sequential patterns In SDM pp 553–564 Pei J J Han B Mortazavi Asl et H Pinto 2001 PrefixSpan Mining sequential patterns efficiently by prefix projected pattern growth In ICDE pp 215–224 Stefanidis K E Pitoura et P Vassiliadis 2007 Adding context to preferences In ICDE pp 846–855 Xu J et H Li 2007 Adarank A boosting algorithm for information retrieval In SIGIR pp 391–398 Summary The use of preferences brings an increasing interest for personalizing the answers of queries and for performing recommendation where the essential step is to automatically build user preference profiles from data In this paper we present a sequential pattern mining based method for generating contextual preference rules in order to construct a profile that models user preferences Indeed our approach allows to use any frequent sequence mining algorithm to to generate preference rules that contain much rich information than existing methods The experimental results on real world datasets show the performance and effectiveness of our approach 430 