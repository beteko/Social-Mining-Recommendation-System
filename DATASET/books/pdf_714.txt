articles assemblage.pdf visuels Phrase Phrase-document basé sur la représentation efficace et pour la base de contenu efficace image de récupération Ismail Elsayad, Jean Martinet, Thierry Urruty, Chabane Djeraba LIFL / CNRS-UMR 8022-Université de Lille 1, France {ismail.elsayad, jean.martinet, thierry.urruty, chabane.djeraba}@lifl.fr Résumé. Avoir des méthodes efficaces et efficaces pour obtenir l'accès aux images souhaitées est aujourd'hui essentielle avec l'énorme quantité d'images numériques. Cet article présente une analogie entre la récupération et la récupération de texte images par le contenu. Nous faisons cette analogie de pixels aux lettres, patches à des mots, des ensembles de patches à des phrases et des groupes d'ensembles de correctifs à des phrases. Pour obtenir un taux correspondant plus accu- des documents, des fonctionnalités plus d'information, y compris des phrases et tences sen- sont nécessaires pour améliorer ces scénarios. L'approche proposée est basée d'abord sur la construction de différents mots visuels utilisant l'extraction locale des correctifs et des- cription. Après cela, nous étudions différentes règles d'association entre les mots visuels fréquents dans le contexte des régions locales dans l'image pour construire es de phras- visuels, qui seront regroupés à des peines différentes. 1 Introduction Dans les systèmes de recherche (CBIR) image en fonction du contenu typique, il est toujours important de sé- lect une représentation appropriée pour les documents (Baeza-Yates et Ribeiro-Neto, 1999). En effet, la qualité de la récupération dépend de la qualité de la représentation interne du contenu des documents. Une technique populaire qui a été utilisée consiste récemment à considérer les images comme sac de mots (Grauman et al., 2005, Jurie et al., 2005, 2003 Djeraba et Sivic et al., 2005). De même à la représentation des documents en termes de mots dans le domaine de texte, les mots sac-of-modèles approchent une image comme un sac de mots visuels, qui est formé par une quantification vectorielle de descripteurs de région locale. D'une part, le sac de mots approche permet d'atteindre de bons résultats en représentant les apparences d'objets variables causées par des changements dans la pose, l'échelle, la traduction, etc. D'autre part, la faible puissance de discrimination des mots visuels conduit à une faible corrélation entre les caractéristiques de l'image et sa sémantique. Nous développons une riche et la représentation de la structure globale corsés des documents visuels en tenant compte non seulement des mots visuels, mais aussi l'introduction de deux représentations de niveau supérieur à savoir: des phrases et des phrases visuelles. Dans notre approche, nous extrayons patches d'image échelle et invariantes d'orientation locale de chaque image en utilisant SURF (Bay et al., 2008). Les correctifs sont regroupés en différents groupes pour former un vocabulaire visuel. Les images sont divisées en bandes verticales et horizontales qui définissent les régions locales où les apprenants des règles d'association sont utilisés pour découvrir des modèles de mots visuels qui co-produisent fréquemment dans ces régions. Des mots visuels différences qui ont ents règles d'association fortes dans ces régions, des expressions visuelles sont construites. Enfin, des phrases voisines qui se trouvent dans la même bande sont regroupés en tences sen-. RNTI-E-19- 157 - (. Lew et al, 2006) visuelle Phrase Phrase-document basé sur la représentation pour efficace et efficiente image Basé tente Con- récupération par rapport à l'état des techniques de l'art, nous proposons une approche basée sur mots visuels, des phrases et des phrases qui maintiennent les différentes informa- tions structurelles entre les parcelles locales et dans un ensemble de correctifs locaux qui sont situés dans des zones d'image. Cela enrichit la présentation avec plus d'informations et donne une meilleure représentation structurelle globale pour l'ensemble de l'image. Le reste de l'article est structuré comme suit. Dans la section 2, nous décrivons notre méthode pour construire des mots visuels à partir d'images et de l'exploitation minière des expressions visuelles de mots visuels qui mène nous à construire les phrases visuelles. Dans la section 3, nous vous présentons notre similitude d'image moi- ThOD basée sur les mots visuels, des phrases et des phrases visuelles visuelles. L'article 4 conclut le document. 2 image représentation Dans cette section, nous décrivons trois composantes de la chaîne de processus dans la construction de la représentation phrase-expression visuelle (voir la figure 1). FIGUE. 1 - Flux d'informations dans la représentation du document visuel 2.1 construction visuelle des mots Nous utilisons la fonction de bas niveau SURF descripteur qui décrit comment les intensités de pixels sont distribués dans un quartier dépendant à l'échelle de chaque point d'intérêt détecté par le Fast- hessois. Cette approche est similaire à EIPD (Lowe, 2004), mais les images intégrales (Viola et Jones, 2001) est utilisé conjointement avec des filtres connus sous le nom vaguelettes Haar sont utilisés afin d'augmenter la robustesse et de diminuer le temps de calcul. vaguelettes Haar sont simples filtres qui peuvent être utilisés pour trouver des gradients dans les directions x et y. L'extraction du descripteur peut être divisé en deux tâches distinctes (voir Figure 2). Tout d'abord, chaque point d'intérêt est attribué une orientation reproductible. En second lieu, un E-RNTI-19 dépend de l'échelle gagnant - 158 - I. Elsayad et al. dow est construit, dans lequel un vecteur de dimension 64 est extrait. Il est important que tous les calculs pour le descripteur sont basées sur des mesures par rapport à l'échelle détectée afin d'obtenir des résultats invariants d'échelle. mots visuels sont créés en regroupant les caractéristiques observées afin de former un vocabulaire visuel. Nous quantifions l'espace caractéristique de vecteur par chaque caractéristique Assign- ing observée au mot visuel le plus proche. 2.2 Construction Phrase Visuelle En retournant aux documents texte, une phrase peut être définie comme un groupe de mots qui fonctionnent comme une seule unité dans la syntaxe d'une phrase et ayant un sens différent pris ensemble ou séparément. Ceci est également applicable dans une image, mais dans un espace 2D. Dans notre approche, nous seg- ment l'image en différentes bandes locales à travers des colonnes et des lignes couvrant l'ensemble de l'image (voir les lignes rouges et vertes de la figure 2). Avoir une image représentée par des mots visuels, nous examinons les règles d'association (Simovic et Djeraba 2008) entre les différents mots visuels fréquents qui se produisent dans les mêmes bandes locales. Considérant que l'ensemble des tous les mots visuels (vocabulaire visuel) est W = {w1, w2 ... wk}, D est la base de données (ensemble d'images I), et T = {t1, t2 ... tn} est l'ensemble de tous différents jeux de mots visuels situés dans une même bande. En revenant à la définition des règles d'association, W représente l'ensemble des éléments et T désigne l'ensemble des transactions. Une règle d'association est une relation d'un XVy d'expression, où X et Y sont des ensembles d'éléments. Les propriétés des règles d'association de caractériser sont les suivants: - La règle XVy tient dans l'ensemble de la transaction T avec le support s si s% des transactions par T contient X et Y; - La règle XVy tient dans l'ensemble des transactions T avec confiance c si c% des transac- tions en T qui contiennent X contient également Y. Après extraction l'ensemble des transactions et de trouver les règles d'association, les règles d'association sont appelés forte si elles ont soutien et la confiance ci-dessus et confiance minsupport minconfi- respectivement. Enfin, tous les mots visuels qui sont dans la même bande et impliqués dans les règles d'association fortes formeront une expression visuelle. FIGUE. 2 - Un exemple d'une image après taches locales (carrés bleus) extraction par SURF alors il est segmentée à différentes bandes verticales et horizontales (lignes verte et rouge). RNTI-E-19- 159 - Phrase visuelle Phrase-document basé sur la représentation efficace et pour l'image de base tente efficace Con- récupération 2.3 construction de la phrase visuelle Une fois des phrases visuelles ont été construites, nous pouvons traiter à l'étape suivante pour Construc l'ing phrases visuelles en regroupant des phrases voisines qui se trouvent dans la même bande. phrases visuelles Con- de a un avantage de construction définies intrinsèque depuis une phrase visuelle peut être partagée par différents objets dans une image, et cela donne une bonne représentation des rela- tions structurelles entre les différents objets qui ne sont pas représentés par le mot ou l'expression visuelle. 3 appariement de similarité et de recherche Compte tenu de la représentation d'image proposée dans la section 2, cette section décrit comment les images sont adaptées, en estimant une valeur de similarité de la représentation 3 facettes. Le modèle espace vectoriel tradi- tionnelle (Salton et al., 1975) de la recherche d'information est adapté à notre représentation, et utilisé pour la mise en correspondance de similarité et la récupération des images. Le triplet représente chaque image dans le modèle: ddd SPW d); ,,, (,, 2,1 dnddd ppppp) ,,, (,, 2,1 dnddd wwwww ) ,,, (,, 2,1 dsddd wsssS Où dW, dP et dS sont les vecteurs pour le mot, la phrase, et facette de phrase dans les représentations d'un document respectivement. Notez que les vecteurs pour chaque niveau de mensonge de représenta- tion dans un espace séparé. dans les vecteurs ci-dessus, chaque composante représente le poids de la Nous avons utilisé le système de pondération standard tf.idf dimension correspondante., où les valeurs tf et idf sont indépendamment des estimations des mots, des phrases et des phrases. Nous avons une simple mesure de similarité qui permet d'évaluer la contribution des mots, des phrases et des phrases. la mesure de similarité entre une requête q et un document d est estimé à 1), (), () () (SSR dqdqdq SVPPRSVWWRSVdqsimilarity la récupération Status Value (RSV) de 2 vecteurs est estimé avec le cosinus. Les 3 paramètres non-négatifs, et doivent être fixés suivant les pistes d'expérimentation afin d'évaluer la contribution de chaque niveau de représentation de manière indépendante, et une combinaison de tous les niveaux de représentation. 4 expériences Dans cette section, nous décrivons un ensemble d'expériences dédiées à tester l'approche proposée. L'ensemble de données d'image utilisé pour ces expériences est un sous-ensemble d'images à partir de 1000 Caltech 101 Dataset1 (Fei-Fei et al., 2004) également répartis en 10 catégories d'objets divers. Nous avons choisi au hasard 10 images de chacune de ces catégories et les ont utilisés comme requête im- RNTI-E-19 - 160 - I. Elsayad et al. âge. Toutes les expériences ont été effectuées sur une machine Intel Xeon 3 GHz avec 3 Go de mémoire fonctionnant sous Microsoft Windows XP. Les algorithmes sont implémentés en C ++ en utilisant la bibliothèque OpenCV ver1.0. (Bradski et Kaehler, 2008). Pour mesurer l'efficacité de notre approche, on calcule le temps utilisé pour récupérer les 10 plus proches voisins de chaque image de requête. Ce temps de traitement des requêtes comprend le temps utilisé pour récupérer des images candidats de la base de données et le temps de rang eux. Le temps de traitement des requêtes moyenne varie. Elle varie de moins de 10 millisecondes à environ 160 millisecondes, en fonction du nombre de mots visuels, des phrases et des phrases dans les images de la requête. Dans l'ensemble jeu moyen d'images de la requête, il faut environ 48 millisecondes pour chaque catégorie pour obtenir les résultats de récupération. Pour évaluer l'efficacité de notre représentation à base d'expression visuelle phrase, nous essayons de récupérer des images à l'aide (i) les mots visuels seulement (sur la base de mots visuels), (ii) des expressions visuelles que (syntagmatique visuelle) et (iii ) mots visuels, phrase phrases et en même temps (visuel basé phrase-tence sen-). L'efficacité de chaque paramètre est déterminé par la précision moyenne, qui est le pourcentage des images pertinentes à partir des 10 images extraites dans chaque catégorie (voir figure 3). FIGUE. 3 - Comparaison de l'efficacité de la recherche d'images entre des algorithmes basés phrase-expression basée mot-visuel, phrase- base et visuel Si l'on compare les approches basées sur des mots-visuels et syntagmatique, l'approche de la phrase ne surclasse pas pas le mot visuel basée dans une catégorie parce que certaines images ne sont pas assez patchs locaux pour créer un ensemble de phrases qui est à lui seul une bonne repré- sentation pour l'image. D'autre part, il est évident que l'approche fondée phrase-phrase surclasse les autres parce que le mot et les approches sont intégrées dans la phrase de cette approche. 5 Conclusion Nous avons présenté une nouvelle approche pour la recherche d'images basée sur le contenu qui a proposé une chaîne de processus pour la construction de mots visuels, des phrases et des phrases. Nous avons également présenté la méthodologie trieval re qui utilise une mesure de similarité basée sur les mots visuels, des phrases et des sen- 0 50 100 C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 visuelle moyenne précision mot: précision moyenne basée expression visuelle basée visuelle précision moyenne syntagmatique sentence- av er ag e pr ec est io n catégorie RNTI-e-19- 161 - visuelle phrase phrase-document basé sur la représentation pour efficace et efficace image en fonction de la tente con- récupération tences. Enfin, nos résultats expérimentaux ont montré que l'approche proposée pourrait récupérer des images de façon efficace. Dans nos travaux futurs, nous allons étudier comment mesurer la similarité d'image en appliquant différentes techniques par différents niveaux de représentation (mots, phrases et des phrases). Plus- plus, plus de travail doit être fait dans le choix et la combinaison de descripteur de fonction de bas niveau. Références Baeza-Yates, R. et B. Ribeiro-Neto (1999). Modern Information Retrieval. ACM Press. Bay, H., A. Ess, T. Tuytelaars et L. V. Gool (2008) .SURF: Accélérez fonction, vision par ordinateur et la compréhension de l'image (CVIU), Vol. 110, n ° 3, pp. 346-359. Bradski, G. et A. Kaehler (2008). Apprentissage OpenCV. Vision par ordinateur avec la bibliothèque OpenCV. Djeraba, C. (2003). Association et Content-Based récupération. IEEE Trans. Knowl. Les données Eng. 15 (1): 118-135. Fei-Fei, L., R. Fergus et P. Perona (2004). L'apprentissage des modèles visuels génératives de quelques exemples de formation: une approche bayésienne incrémentale testée sur 101 catégories d'objets. CVPR 2004, Atelier sur générative-Model Based Vision. IEEE Computer Society. Grauman, K. et T. Darrel (2005). Le noyau de match de pyramide: classement avec discriminante ensembles de caractéristiques d'image. Actes de la Conférence internationale sur l'ordinateur Vi- sion, pp.1458-1465. IEEE Computer Society, ICCV 239. Etats-Unis. Jurie, F. et B. Triggs (2005). Création d'codebooks efficaces pour la reconnaissance visuelle. Ings Proceed- de la Conférence internationale sur la vision par ordinateur. Washington, DC, États-Unis. Lowe, D.G. (2004). image distinctive comporte des points clés échelle invariant. International Journal of Computer Vision, 60 (2): 91-110. Lew, M. S., N. Sebe, C. Djeraba et R. Jain (2006). la recherche d'information multimédia basée sur le contenu: Etat de l'art et de défis. TOMCCAP 2 (1): 1-19. Burrus, C.S. R.A. Sivic, J., B. Russell, A. Efros, A. Zisserman et W. Freeman (2005). A la découverte des objets et leur emplacement dans les images. ICCV, volume 1, pages 370-377. Simovic, D., C. Djeraba (2008). outils mathématiques pour l'exploration de données. La théorie des ensembles, des ordres partiels, Combinatoire, série Advanced Information et traitement des connaissances. Springer, ISBN 978-1-84800-200-5. Salton, G., R. Wong, C. et S. Yang (1975). Un modèle vectoriel pour ING automatique Index-. Communications de l'ACM, vol. 18, n °. 11, pages 613-620. Viola, P. et M. Jones (2001). la détection d'objet rapide en utilisant une cascade boosté de fonctionnalités simples. Conférence internationale en vision par ordinateur et de reconnaissance de motif (CVPR 2001). RNTI-E-19 - 162 -