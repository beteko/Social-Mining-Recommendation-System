SSC: statistique subspatial Clustering Laurent Candillier1,2, Isabelle Tellier1, Fabien Torre1, Olivier Bousquet2 1 grappa - Université Charles de Gaulle - Lille 3 candillier@grappa.univ-lille3.fr http: //www.grappa.univ-lille3.fr 2 Pertinence - 32 rue des Jeûneurs -75002 Paris olivier.bousquet@pertinence.com http: //www.pertinence.com CV. Cet article se lieu le cadre du Dans subspatial clustering, la Do not is à double problématique: identifier les grappes et simultanément le Sous- espace Spécifique Dans each is defini Lequel, et each assorti- ment caractériser par un minimum de dimensions Nombre de postes, permettant AINSI Une présentation des experts par de compréhensible un de du domaine d'application d'. Les methods Jusqu'a présent répandrai proposées this le défaut Tâche de Ontario se cadre un à restreindre numérique. L'article Objectif de l'Est de CET pro- un poseur de sous-espace cluster algorithme capable de des Données Traiter à la Fois décrites par des attributes Continus et des attributes catégoriels. Nous Présentons Une sur l'méthode basée EM algorithme classique Opérant sur un Mais modèle des Données et simplifié D'une technique Suivi ori- Ginale de sélection d'attributes verser ne keep les dimensions Que perti- nentes de each cluster. Les Expérimentations ensuite présentées, sur des bases menées de bien also Données Que REELLES artificielles, Que notre montrent des Résultats Algorithme Présente en Annoter de robustes qualité de la classification et de compréhensibilité des grappes obtenus. Introduction Face aux informations d'Quantités Qui ne d'increase Dans cessent les Bases de données du monde entier, l'extraction de connaissances heuristiques à automatique partir de bureaux bases et les techniques de visualisation des Indispensables Résultats Sont devenues. C'est la raison d'être de la fouille de Données. Dans un cadre de CE, l'apprentissage non supervisez (clustering OU) is used Depuis longtemps les répandrai identifiant Groupes (ou groupes) d'éléments similaires (enquête de voir Berkhin 2002). Une problèmatique à visage Supplémentaire des apparait Bases de données de grande dimensionnalité: Dans CE CAS, les Groupes PEUVENT Être caractérisés sous UNIQUEMENT PAR-ensembles CERTAINS de dimensions et dimensions SCÉ pertinentes d'PEUVENT Être un groupe Différentes à l'Autre. Sur de tells Problèmes, les techniques de regroupement classiques mal voiture fonctionnent, sur la distance Une fondées Entre definie objets dans l'Espace globalement de description, ne PEUVENT pas ELLES le fait appréhender la notion de Qué Varie d'un similarité groupe à l'Autre . Une nouvelle une problématique Emerge Fait recemment, du sous-espace cluster Celle, l'ENJEU Do not is de les cibler d'objets et Groupes, verser each, le sous-RNTI-espace E Spécifique-3177 SSC: subspatial statistique Clustering il is Dans defini Lequel 1. Et s'accompagne d'Objectif this un second: de provide Description Celui Une des Groupes iDENTIFIE compréhensible. Les methods proposées se verser this Tâche sur le focalisées Sont premier et Objectif le deuxième déshabillé en Ontario. De plus, la partie Expérimentale de bureaux porte travaux sur des Exclusivement Données Numériques. L'de cet article Objectif de l'Est un proposeur algorithme de regroupement sous-espace CA- pable de des Données Traiter à la Fois décrites par des attributes Continus et des attributes catégoriels, à l'très demandé de regler le Utilisateur Moins de paramêtres possible, et sortie en juin fournissant simple représentation des groupes iDENTIFIE. Nous coupes sur ACDE Call for l'EM adapted au Algorithme en cluster (Ye et al., 2003). Nous en proposons la version en juin Simplifiée l'hypothèse Que ajoutant les Données des Sont générées distributions Indépendantes SELON sur each dimension. Nous Céci d'en Përmet Une théorie dériver sous forme de compréhensible rules PUISQUE each dimension is characterized indépendem ment des Autres. La suite de l'article is costume Comme Organisée: Dans la section 1, nous Présentons notre méthode de regroupement sous-espace; les Expérimentations Dans la salle de bains présentées section 2, des bases Sur menées de bien artificialisation also Données cielles Que REELLES, presentent les de notre algorithme Résultats; et nous terminons Dans la section 3 conclusions par les CE par Quelques perspectives Ouvertes et travail. Algorithme 1 Dans SSC (Parsons et al., 2004), les auteurs Ont Etudie et comparé les methods to vary de sous-espace clustering. Toutes Sont capables de Retrouver EFFICACEMENT les grappes et their sous-espace Spécifique, Mais ELLES nécessitent Souvent des paramêtres Difficiles à regler Par l'Utilisateur ET influant Sur performances their (seuil de densité, clusters, la distance MINIMALE clusters Entre Nombre de postes Moyen de dimensions characteristics des , etc.) de plus, tous les essais sur were des bases effectués de Données Exclusivement Numériques. Enfin, la proposition de aboutie Aucune simple présentation des Résultats n'à éffectuée Été. Ce point le plus POURTANT voiture cruciale si la same dimensionnalité des grappes was Réduite les sous-Dans espaces Qui their Propres Sont, ci-may Celle encore trop élévée Être expert verser du domaine d'Qu'un demande le puisse appréhender Résultat. Ou il possible d'EST Souvent de bureaux Ignorer les dimensions CERTAINES, tout en conservant le same des objets partitionnement. 1.1 Modèle de provide probabiliste en AFIN sortie de notre algorithme de sous-espace simple, des grappes en cluster Une description trouvés, de les NOUS REPRESENTER choisissons sous forme de rules (hy- percubes Dans des sous-espaces de l'espace d'origine), la représentation Comme association reconnue Facilement interprétable. Pour integrer this Dans l'algorithme contrainte EM classique, nous proposons d'ajouter l'hypothèse Que les Données des Sont générées distribu- tions SELON Indépendantes sur each dimension. This cav hypothèse d'effet le modèle classique affaiblir, en Prenant also les compte di- Entre corrélations possibles mensions, Mais AINSI, la modélisation à la is Adaptée sous forme de présentation rules 1la la différence Avec de la problématique d'attributes sélection ( ous sélection de fonction) is that the sous-espace à locale is cible pôle each, et non globale à tous (Parsons et al., 2004). EGC 2005 RNTI-E-3 178 Candillier et al. des grappes de voiture each dimension is found characterized indépendemment des Autres. De Plus, L'Est Algorithme, plus ALORS Que l'algorithme Rapide classique, voiture le nouveau modèle de paramêtres Nécessite Moins (O (M) Au Lieu du O (M 2) classique, le M répandrai de dimensions Nombre), et les opérations Matricielles Sont évitées. Dans notre modèle, nous supposons Que les Données were des distributions générées gaussiennes SELON sur les dimensions et continue des distributions mul- SELON tinomiales sur les dimensions discrètes. Le modèle des EST Fait paramêtres Suivants composé verser cluster Ck each: fils Wk poids; verser dimension d each continuer, sa moyenne et sa variance μkd σkd; et verser each dimension d discrète, les Fréquences de each modalité Freqskd. Il suppose La Donnee du Nombre K de REcherches clusters. 1.2 Nous l'utilisons Algorithme EM Algorithme sur notre modèle classique. Les paramêtres du modèle correspondant cachés aux Probabilités d'appartenance de each à each groupe objet. Dans Notre CAS, les dimensions being Indépendantes supposées, la P Probabilité d'appartenance (- → Xi | Ck) d'un objet - → Xi à un groupe Ck correspond au produit des Probabilités P (Xid | CKD) sur each dimension d: 1√ 2πσkd exp (- 12 (Xid-μkd σkd) 2) si d is continue, et Freqskd (Xid) si d is discrète. Et versez EVITER sur Qu'une Une Probabilité dimension nulle n'annule la Probabilité globale, nous utilisons très positif Une constante Qui Faible Constitué Une borne minimale sur les Probabilités P (Xid | CKD). L'EM is Algorithme verser convergeur Connu Dans Lentement CERTAINS CAS. Pour l'accelerer, nous proposons d'ajouter l'heuristique suivante: s'arrêter when les attributions de groupes aux objets ne pas changent. Ce critère d'Arret Au FORTEMENT ressemblent à celles critere ALORS d'Arret de K-means. À each iteration, il Faut EVALUER les also Fait at- tributions de groupes aux objets costume Comme: Cluster (- → Xi) = ArgMaxkP (- → Xi | Ck). Nalement Fi-, l'algorithme is RELANCE un certains Nombre de solutions des AVEC FOIS Initiales Aléatoires. PUI la partition la fonction E maximisant = Σ i log (P (- → Xi)) is conservée. 1.3 Présentation du Résultat Que Le Résultat AFIN Le plus Compréhensible Soit possible, nous nous souhaitons Don- ner Une vue sur each seconde grappe, à sa représentation correspondant Simplifiée sous forme de règle, par le décrite Chacune de dimensions possibles Moins. Dans mes premiers temps de l'ONU, each groupe Représenté par l'EST minimum intervalle l'en- Semble Contenant des facts des objets Inclus dans le groupe sur les dimensions continue, et par la probable ainsi que la modalité sur les dimensions discrètes. Salle de bains, le soutien de la Calculated is règle (l'ensemble des objets compris Dans la règle). Un Wkd Puis weight is Attribué à des dimensions d Chacune du groupe Ck, en fonction de la dispersion relative des objets sur la dimension. Pour les dimensions se poursuit, il s'agit du rapport Entre la variance locale et la variance par rapport à globale μkd (N correspond au d'objets de Nombre la base). Et versez les dimensions Discrets il s'agit de la frequency relatif de la probable ainsi que la modalité (correspondent Modalitesd à l'ensemble des sur la Modalités dimension possibles d, et Frequencesd à l'ensemble des Fréquences de bureaux de Chacune sur l Modalités « ensemble de la base). EGC 2005 RNTI-E-3179 SSC: Subspace Clustering statistique Wkd =        1- σ2 kd σ2 d, with σ2d = Σ i (Xid-μkd) 2 N si d continuer Freqskd (mod) -Frequencesd ( mod) 1-Frequencesd (mod) SI d mod = Discrete AVEC arg {} m∈Modalitesd Freqskd (m) la sélection des Puis dimensions s'effectue Comme costume pertinentes: pour les dimensions Toutes, Dans l'ordre présentées croissant de poids Leur , la dimension si supprimer sa suppression ne pas le soutien modifie de la règle. Enfin, de Visualiseur AFIN les Résultats obtenus graphiquement, nous proposons de l'ONU Calculer à each Associe poids Couple de dimensions PRESENTES Dans la description des groupes: Vij = Σ k max (wki, WKJ). Plus ce poids important de l'Est, ainsi que les rules sur SCÉ deux projetées dimensions Sont Spécifiques. 2 Expérimentations 2.1 Essais sur Données de nous artificielles comparateur AFIN aux methods to vary de sous-espace regroupement, nous pro- posons de MENER SCÉ des bases EXPÉRIENCES Sur UNIQUEMENT Numériques. Les plus parmi Récentes, LAC de (Domeniconi et al., 2004) is Une méthode Qui Efficace, est comme la Nôtre, Un seul parametre Nécessite: Le Utilisateur Nombre de grappes REcherches. Nous proposons de nous comparateur à et Algorithme this des bases artificielles utilisons EVALUER les verser d'Taux de notre algorithme Erreurs et de LAC en classification. À partition each is la Associée des grappes pureté moyenne Produits (la correspondent à au pureté maximale d'idée Pourcentage du groupe objets au same Qui appartiennent initial). K des points d'ancrage (- → O1, ..., - → OK) Tirés Sont dans l'Espace aléatoirement de la description à M dimensions, groupes et centroïdes Sont utilisés des Comme (C1, ..., CK) Ë Générer. À chacun de bureaux grappes is Une partie des Associée N objets, et un sous-ensemble des dimensions M dimensions constituant des ses characteristics. Les des coordonnées Puis objets à un groupe Appartenant Ck Une Sont générées SELON centre de loi normalien OKD et d'écart de type sur ek dimension d characteristic Toute de Ck; Elles genere Sont es Une loi uniforme SELON Dans l'espace de la description des dimensions non characteristics. Les expériences en menées Varier les paramêtres Faisant de des bases artificielles génération mis en avant Ontario la de notre méthode robustesse. En Particulier, verser faire Elle se revele Efficace visage au bruit existant Dans les Données (la pureté moyenne des grappes is for de 90% à 20% de bruit Dans la base contre 70% for BAC). Concerning le temps d'exécution de la méthode, l'heuristique nous Que d'Përmet proposed Avons obtain, verser des Résultats de qualité Similaire, des temps de calcul, plus de proches de K Ceux moyens (verser sa rapidité Connu) Que de Ceux considérer. Concerning le seul de l'algorithme Paramètre, le Nombre de grappes, si REcherches ci-is Celui au Inférieur de grappes Nombre réel, concepts de ALORS QUELQUES le Mais Sont fusionnés ne s'éloigne pas Résultat de la solution Complètement réelle. Is au upper Se il Nombre réel, les concepts se recouvrent ALORS. Enfin, les Que notons de notre algorithme Résultats tout also are si les robustes Données were des Lois générées SELON Dans les Intervalles uniformes de dimensions their de définition characteristics, au lieu de gaussiennes Loïs. EGC 2005 RNTI-E-3 180 Candillier et al. 2.2 Essais sur REELLES Des Données expériences also have sur des Été menées Bases de données REELLES. , La Parmi la base ELLES Automobile, des bases de question de l'UCI Données (Blake et Merz 1998), contains Description la (et catégorielle numérique) d'un ensemble de Voitures. Sur la base de this, les visualisations Graphiques correspondant à deux couples de dimensions maximales de poids SONT FOURNIES figure 1. L'algorithme se réunit en AINSI Avant que le prix des Voitures AUGMENTE FORTEMENT when their longueur DEPASSE les 170 (figure 1 (a)), Qc Les Voitures Ayant UNE traction arrière (RWD) Ont ONU poids à vide supérieur aux tractions avant et 4 roues motrices (figure 1 (b)), et that the majority des Voitures Les plus Chères Sont à traction arrière (figures correspondance Entre les deux concerning le groupe C2). Pour plus de détails sur les de Expérimentations, voir (Candillier et al., 2005). 5118 8111 11104 14097 17090 20083 23076 26069 29062 32055 35048 141 147 153 165 171 177 159 183 189 195 201 pr ic e longueur Objets C0 C1 C2 (a) des projections sur longueur et prix. 1488 1745 2002 2259 2516 2773 3030 3287 3544 3801 4058 rwd 4WD fwd cu rb -w t ei gh roues motrices Objets C0 C1 C2 (b) les projections Sur traction ET poids. Figure 1 -. De SSC sur Résultats la base de l'automobile, versez K = 3. 3 Conclusions et perspectives Nous presented Dans Avons cet article Une nouvelle méthode de sous-espace sur l'agrégation basée en EM Algorithme l'hypothèse Que ajoutant les Données were générées sé- des distributions Indépendantes LON sur each dimension. This une idée déjà-Été étudiée Dans (Pelleg et Moore 2000). Il exists several Entre notre méthode des différences et la their. La première Dans la modélisation apparait: au lieu de Supposer la répartition gaussienne Sur une dimension continue, les auteurs la à l'uniforme supposent d'un intérieur Donné intervalle, et de file d'attente Une utilisent la distribution aux bords de CET intervalle, d'un personne à charge Qui σ evolue Paramètre au cours de l'algorithme. This Variation entre Retrouvé Dans la salle de bains finale de regroupement méthode. En Particulier, their pas capable Ne est méthode de fils à jour Mettre Modèle de Façon incrémentale, la Nôtre Que Alors may s'adapter à la présentation de Nouveaux exemples. De plus, nous effi- tivement integrated Avons la catégorielle Qui ne etait problématique QU'A titre de évoquée perspectives Dans l'article et nous Avons Une méthode originale Proposé de sélection d'attributes per- mettant de provide en sortie un et Résultat compréhensible des grappes iDENTIFIE visuel. Nous defini Une also Avons originale heuristique verser accelerer l'algorithme. Pour la recherche Poursuivre Dans CE sens, il Semble de s'inspirer de Intéressant l'article EGC 2005 RNTI-E-3181 SSC: subspatial statistique Clustering de (. Bradley et al 1998) Qui Traité de l'accélération de l'EM Algorithme Dans le général CAS. Une piste possible Autre is d'EVITER de considerer les dimensions Toutes au cours de l'algorithme, en ne les dimensions Que sélectionnant de poids maximale. Notons enfin Que notre méthode la Nécessite d'un Donnée de la partie Paramètre de l'Utilisateur: K, le Nombre de grappes REcherches. Une improvement possible à identifier automatiquement consisterait CE Paramètre. Pour ACDE, il EST le classique d'UTILISER BIC critère (Ye et al., 2003). Dans Notre CAS, enchainee piste d'originale Serait le fait Qué UTILISER when K is au upper de groupes Nombre réel REcherches, les rules Associées Alors aux groupes se chevauchent. P. Enquête Berkhin Références du regroupement des techniques d'exploration de données. Rapport technique, logiciel Accrue, San Jose, Californie, 2002. Blake C.L. et Merz C. J. (1998). UCI référentiel de bases de données d'apprentissage de la machine [http: //www.ics.uci.edu/~mlearn/MLRepository.html]. Bradley P., U. Fayyad, et Reina C. Mise à l'échelle EM (Expectation-Maximisation) Clustering aux grandes bases de données. Microsoft Research Report, MSR-TR-98-35, août 1998. Candillier L., Tellier I., Torre F. Bousquet et O. SSC: statistique subspatial Clustering. Rapport technique grappa, 2005. [http: //grappa.univ-lille3.fr/~candillier/publis]. Domeniconi C, Papadopoulos D., D. et Gunopolos Ma S. Subspace Clustering de données de grande dimension. Dans SIAM Int. Conf. sur Data Mining, 2004. L. Parsons, E. Haque et Liu H. L'évaluation des algorithmes de regroupement de sous-espace. Dans l'atelier sur le clustering de haute dimension de données et ses applications, SIAM Int. Conf. sur Data Mining, pp 48-56, 2004. Pelleg D. et A. Moore Mélanges de rectangles: regroupement doux interprétable. Dans C. Brodley et A. éditeurs Danyluk, ICML 2001, pp 401-408. Ye L. et Spetsakis M.E. Clustering sur les données non observées en utilisant un mélange de gaussiennes. Rapport technique, Université York, octobre 2003. Résumé Dans cet article, nous nous concentrons sur la tâche de regroupement subspatiale, qui a deux objectifs: en même temps d'identifier les groupes et les sous-espaces où chacun d'eux est défini et décrire chaque groupe avec comme quelques dimensions que possible, de sorte que les résultats sont facilement interprétable par un utilisateur humain. Un défaut de méthodes existantes est qu'elles ne tiennent compte que des bases de données numériques. Le but de cet article est de proposer un nouvel algorithme de clustering subspatiale, capable d'aborder les bases de données qui peuvent contenir en continu ainsi que des attributs discrets. Nous présentons une méthode basée sur l'algorithme EM classique, mais appliqué à un modèle mod'ele simplifié et suivi par une technique originale de sélection de fonction qui ne conserve que les dimensions qui sont pertinentes pour chaque groupe. Des expériences, menées sur artifical ainsi que des bases de données réelles, montrent que notre algo- rithme donne des résultats robustes, en termes de classement et de l'intelligibilité de la sortie. EGC 2005 RNTI-E-3 182