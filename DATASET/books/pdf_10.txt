Sur les méthode ensembles basée répandrai l'apprentissage approximatifs en présence des incrémental déséquilibrées Sarra Bouzayane Données * ***, Saad * Inès ** * Université de Picardie Jules Verne, Amiens {sarra.bouzayane, ines.saad}@u-picardie. fr ** Ecole Supérieure de commerce, Amiens *** Institut Supérieur d'Informatique et de Multimédia, Sfax CV. Ce papier propose juin sur la méthode basée des ensembles AP- théorie proximatifs et à l'apprentissage dédiée supervisez Dans un incrémental de Données déséquilibrées Contexte. Consiste en THIS method phases: la Trois construc- tion d'Une Table de décision, L'Inference D'un Ensemble de rêgles de decisión et La classification de l'action each Potentielle Dans l'des cours de l'UNE de décision. Prédéfinies La MAI2P is Validée méthode in the des MOOCs (Contexte Massive Cours en ligne ouvert). 1 Introduction when les exemples d'Fournis de apprentissage Sont Manière séquentielle, l'apprentissage verser prix Une incrémental de décision s'avère Une obligation (Greco et al., 2004). ment GENERALE-, la phase de d'apprentissage par les traitee is techniques de l'ordinateur conventionnelles apprentissage. Cependant, les techniques CÉS au demeurent sensibles des Données DES- Problème Qui resulte de équilibrées la Entre les Répartition des cas inégalé des cours de décision. This la inégalité affecte considérablement la qualité de décision en il s'agit Particulier de Quand Don- Nées massifs. Ce may Problème, toutefois, par l'Être surmonté approach DRSA (base Dominance- rugueux approche Set) (Greco et al., 2001) sur les repos Qui Preferences et l'expertise des Décideurs la construction répandrai Humains d'un ensemble d » Apprenticeship de garantir La AFIN REPARTITION EGALE des instances Sur l'Ensemble de cours de décision. Ce travail propose Une méthode MAI2P (multicritère approche de la Per- incrémentale iodique prévision) sur l'approche basée DRSA la classification multicritère répandrai et periodic incrémentale. La Méthode MAI2P soi Compose de phases trois. La première à étau Construire une Table de décision et le repos sur trois étapes: l'identification d'un ensemble d'apprentis- sage; La construction d'Une Famille coherente de critères Pour la CARACTERISATION des actions; Et la classification de l'action Chaqué d'apprentissage des Dans l'UNE de cours de décision. La phase de deuxiéme is sur notre basée DRSA incrémentiel algorithme (Bouzayane et Saad, 2017) pour l'inférence et la mise à jour de l'ensemble de rules de décision. La third Consiste à la classification des « Actions PotentiELLES », en les rules Utilisant inférées précédemment. L'approach MAI2P is Validée sur le MOOCs (des Contexte Massive Cours en ligne ouvert). - 305 - sur DRSA Méthode basée la répandrai Le papier prédiction is incrémentale Comme costume structuré: La section 2 les notions de Définit la base de l'approche DRSA. La section 3 un état de present l'art. La section 4 Detaille la MAI2P méthode. La section 5 les Résultats de discute l'expérimentation. La section 6 le papier conclut. 2 Préliminaires: Set grossière basée Dominance- L'approche par approach DRSA developpee Greco et al. (2001) au EST dédiée de tri en Problème aide multicritère à la décision et de la Inspirée des ensembles théorie approximatifs. Elle Përmet de comparateur des actions Ë Une relation de Travers domination, des Preferences rendant compte d'un Décideur, d'inférer les AFIN rules de décision. This approche Définit Une table d'information par un 4-uplets S = <A, F, V, f> tells Que: Un ensemble d'un est fini des actions de référence; F is Une famille coherente de critères; V is a ensemble des facts des critères; possibles et f: A × F - → V is Une fonction d'information tel Que f (x, g) ∈ Vg, ∀ x ∈ A, ∀g ∈ F. l'action de each is référence à Une Seule affectée Clt classe; t ∈ {1, N}. Relation de dominance: La relation de domination DP is definie Comme suit: ∀ (x, y) ∈ A2, XDP y ⇔ f (x, gj) <f (y, gj) ∀gj ∈ P ⊆ F. ∀x ∈ A, es t associé un ensemble, P- dominant, les actions D'dominant x et un ensemble de P-Domine, D'actions dominées par x. Union Inférieure (supérieure): Cl≤n = ∪s≤nCls (Cl≥n = ∪s≥nCls); n = {1. . . N}: L'union Inférieure (supérieure) de Cln Que signifié « x Appartient au maximum de (minimum) à la classe Cln bien à ous Une classe au better (moins) also bonne Que CLN ». P Approximation Inférieure (Cl≥n) (ou P (Cl≤n)): les actions REGROUPE TOUTES l'en- Semble Do not P-dominante (P-Dominé) Est Certitude AVEC Ë affecté des MoiNs les classes (de) also Mieux bonnes Que Cln. En revanche, l'approximation REGROUPE Toutes les supérieure actions l'afféterie Do not is d'Une Manière réalisée possible. Règles de décision: L'ensemble de rules de décision de l'Est Appelé modèle Preferences. CES rules are générées à partir de l'approximation Inférieure et se presentent sous la forme: Si f (x, g1) ≥ r1 ∧ ... ∧ f (x, gn) ≥ rn Alors x ∈ Cl≥t tel QUE (r1 , ..., rn) ∈ (Vg1 × ... Vgn). 3 Travaux antérieurs approaches Dynamiques Quelques were Dans la littérature proposées répandrai la mise à jour des rules de incrémentale décision Suite à la variation de l'ensemble d'apprentissage. Les auteurs Dans (Greco et al., 2004) un de have Glance Proposé Algorithme Appelé. CeT al- gorithme Est basons des Négatives Sur les actions. En effet, each règle d'union Une IMPERATIVEMENT ne Doït Donnée pas x Satisfaire, si x n'appartient pas à l'union this, but also ne may Elle Satisfaire l'action x Aucune ET CE CAS la DANS sans supports ELLE Demeure. sans les supports de CÉS non Sont Dites et robustes l'algorithme Fait also dit non robuste. L'Glance Stocke Dans Algorithme la mémoire les rules de UNIQUEMENT et pas les décision d'exemples et apprentissage il is Fait par rapport à économe l'utilisation de l'espace mémoire. La Complexité de l'algo- rithme is si le linéaire le Considère d'actions et Nombre Elle Est en exponentielle le Nombre de Considérant critères. Les Les Dans mes (Li et al., 2013) un de have de mise Proposé à Algorithme jour des approximations incrémentale et inférieures de l'approach supérieures DRSA LORs de l'ajout (ou la suppression) D'une seule l'action Dans le Système D » information. La méthode - 306 - S. Bouzayane et I. Saad Nécessite: premièrement, la mise à jour des syndicats des Supérieures ET inférieures des classes de DE- Cision, Deuxiemement, la mise à jour des ensembles P-dominante et P-Dominé de l'action each Dans le Système d'information et la mise à enfin jour des approximations et inférieures des syndicats rieures supé- des cours de décision. L'algorithme le temps de réduire Proposé calculation l'action Entre OU lorsqu'une Quitte le Système d'information sans la AFFECTER Qualité des Règles de décision inférées. D'inférer des AFIN rules de décision robustes, nous choisissons de l'algorithme presented généraliser Dans Li et al. (2013) de considerer L'AFIN plats principaux Simultanée D'un d'ensemble des actions. D' 4 MAI2P: Méthode de classement section This Présente incrémentale la méthode MAI2P nous Qué proposed for the Avons prédiction et periodic de incrémentale la classe de décision Cli à l'action x Une Laquelle susceptible d'EST Appartenir. This method phases SE Compose de trois (cf. figure 1). FIGUE. 1 - Description générale de la méthode MAI2P (Pi = period i; T = Nombre de Périodes) 4,1 Phase 1: Construction de la Table de décision de la period Pi This is phases composée de trois étapes: 4.1.1 Etape 1: Construction d « ensemble un des « Actions de référence » Cette éTAPE Consiste à definir l'ONU d'ensemble d'apprentissage süffisant Nombre de postes ONU Contenant d'exemples représentatifs des cours répandrai de Chacune de décision. prédéfinies De la AFIN acception Dans l'terminologie Utilisée approach DRSA, nous les appelons d'exemples apprentissage, « Actions de référence ». La construction de s'effectue par ensemble CET un OU several deurs en fonction déci- de their expertise et their expérience. D'un point de vue de psychologique (Miller, 1956), un Décideur se caracterise par humain Une ca pacité cognitive representative la su- périeure à limite il may Laquelle des ses Réponses aux Associer des stimuli Qui lui Accordes are. AINSI, Pour la construction de l'ensemble d'apprentissage, Il Est süffisant Qué les actions Sélectionnées - 307 - sur DRSA Méthode basée la répandrai prédiction et incrémentale de représentants Soient qualité, quel Que their Soit effectif. L'intervention des experts Pour la construction de l'ensemble d'apprentissage d'Përmet obtain des sous-ensembles des « Actions équitables de référence » et de le Surmonter Problème de déséquilibrées Données. La MAI2P Doït Être méthode sur les Systèmes appliquée d'informations Qui Evoluent Dans le temps, l'ensemble des where « Actions de référence » d'Varie juin period à enchainee. AINSI, each period Pi, le Décideur ensemble Doït un nouvel Aï définir des « Actions de référence » qui se à l'ensemble rajouté des « Actions de référence », Ai-1, de les toutes ses Précédentes Périodes. 4.1.2 2 Etape: (. Mousseau et al, 1996) Construction d'Une famille coherente de Comparons un critères attribut, un critere de Doït permettre les Preferences des Mesurer Décideurs point un SELON de personnel Vue. Dans CE travail, l'approche nous Que is adoptons Consiste à Qui ascendante Construire une famille de criteria partir d'Une liste Indicators d'influenceur l'sujets sensibles opinion des Décideurs concerning La CARACTERISATION des actions. Salle de bains, des Réunions directes doivent Être le Décideur Avec menées d'obtain SES AFIN informations sur each préférentielles critère. D'appliquer les AFIN des points de vue préfé- tielles, nous adoptons qualitative Une échelle. 4.1.3 3 Etape: Classification de l'ensemble des « Actions de référence » Cette étape Consiste à la construction d'Une table de décision Di de la period Pi. C'est une matrice Do not les representent les colonnes « p » Critères d'évaluation et Fi Dans Contenus les Do not Forment ensemble un lignes de « m » « Actions de référence » Dans Aï contenues. Le contenu de la matrice is the d'évaluation fi fonction (Aj, i, gk) de l'action each Aj, i ∈ Aï sur each gk ∈ Fi critère tel i ∈ {Que 1..T}, j ∈ {1 ..M} et {k ∈ 1..p}. Les variables T, m et p le respectively Sont Nombre de considerer à pendentif Périodes le Processus de Prédiction, la taille | Aï | de l'ensemble des « Actions de référence » à la Définit et la period ième de l'ensemble taille | Fi | de la famille de critères. La derniére Colonne de la table de CONTAINS La AFFECTATION de en Décision D'each « Action de référence » Dans l'UNE des N cours de décision. 4.2 Phase 2: Mise à jour incrémentale des approximations de DRSA This Appliqué phase notre algorithme DRSA-incrémental (Bouzayane et Saad, 2017) sur la Table de décision Di Construite pendant la period Pi AFIN d'en inférer un modèle de la préférence, MPi, susceptible de classer action each Dans l'des cours de l'UNE de décision. prédéfinies la phase This is appliquée des que la Table de décision is complète. Elle l'ensemble des Considère « Actions de référence », Ai-1, de toutes ses les Précédentes et l'Périodes ensemble des « Actions de référence », Aï, de la period Pi. L'algorithme DRSA-incrémental EST l'insertion déclenché Dès de l'ensemble Aï Dans la Table de décision. Il est Couleur de composé: 1. Quatre ÉTAPES CALCULER les syndicats de Supérieures ET inférieures des cours de Chacune décision Cli-1. 2. les ensembles Calculer et Domines Dominantes Action pour each x + ∈ insérée Aï. 3. Mettre à jour les ensembles dominants et Domines Action pour each Aj, i-1 ∈ Ai-1. 4. Mettre à jour les approximations de syndicats de des Chacune des classes de décision. La sortie de la phase 2 is a Modele de de VIA Préférence permettant les « Actions Classer PotentiELLES » Pendentif la period Pi + 1. - 308 - S. Bouzayane et I. Saad 4.3 Phase 3: Classification des « Actions PotentiELLES » de la period Pi + 1 La phase third Exploité les rules de décision inférées précédemment d'attribuer AFIN des « Actions Chacune PotentiELLES » une L'Dans cours des N de décision Pré . définies Une « action potentielle » l'action is Une sensible d'être CLASSEE DANS L'UNE des cours de décision. Pendentif s'exécute phase de This la period Pi + 1 tout au long du Processus de tel Que i prédiction ∈ {2,. . . , T}. Elle commence par L'ÉValuatioN de « Actions Toutes Les PotentiELLES » sur l'ensemble de critères construits. Salle de bains, IL s'agit D'les rêgles de appliquer inférées pendentif en Décision La Periode Pi de les AFFECTER AFIN Dans Les cours de la décision prédéfinies. La MAI2P s'exécute méthode tout au long périodiquement du Processus de Prédiction: la première et la phases se déroulent Deuxième pendentif Pi toutes ses les tel Qué Périodes i ∈ {1,. . . , T -1} Alors that the third se deroule pendant la Période Pi; tel i ∈ {Que 2,. . . , T}. 5 Expérimentation et Evaluation de la MAI2P Nous Avons Méthode le Traité d'un MOOC CAS (formation en ligne et gratuite) Français Qui a Duré 5 et Accéde semaines nominale 2360 apprenants. L'Objectif is the de la prédiction hebdomadaire de classe à décision un apprenant Laquelle appartiendra: Cl1 des « Apprenants en osée d'abandonner »; Cl2 des « Apprenants en difficulté » mais Qui sont Actifs; et Cl3 des « dirigeants Apprenants ». - La phase 1. Nous Avons Construit, l'aide de Avec l'équipe pédagogique, des ensembles Quatre « Apprenants de référence » Aï tel i ∈ {Que 1, 2, 3, 4} et | Aï | = 30. Ensuite, Une famille coherente de 11 critères was definie Dont 8 are Statiques (exp. Niveau d'études) et 3 dynamiques d'are (exp. Le Nombre hebdomadaire de messages). Enfin, à la fin de each semaine Une Table de décision is Construite. - Phase 2. This étape was à la fin appliquée de each Si semaine Une Fois Que la Table de décision Di is i Que tel complète ∈ {1, 2, 3, 4} en l'appliquant DRSA incrémentiel Algorithme la mise à verser jour des incrémentale Règles de décision. - Phase3. This étape au Était appliquée Début de each Si du MOOC semaine en AP- pliquant le modèle de inféré à la Préférence fin de la semaine Si-1 pour la classification de l'ensemble d'Potentiels tel Que apprenants i ∈ {2, 3, 4, 5}. FIGUE. 2 - Qualité de la prédiction (F-mesure) les semaines du Durant MOOC La Figure 2 a rencontré l'accent sur-la variation de La F-des mesure de cours Trois décision Cl1, Cl2 et Cl3 D'une semaine à enchainee. - La F-Mesure de la classe CL1, des « Apprenants de risque », AUGMENTE au cours du temps. En effet, le MOOC par les EST rôdeurs Connu. CÉS RESTENT apprenants au bout de Actifs la première semaine en Mais l'intention Une Ayant d'abandonner la préalable la formation. - 309 - sur DRSA Méthode basée la répandrai Ce de type prédiction d'incrémentale dévalorise la prestation apprenants du modèle de prédiction Qui est basons sur le profil et le comportement de l'apprenant et non pas sur l'intention de fils. - La F-Mesure de la classe CL3, des « leaders Apprenants » AUGMENTE au cours du progressivement temps. En effet, D'une semaine à enchainee, les apprenants Ce Qui donne multiplient their forum au participation, plus d'informations Une ample sur Leur profils. Also, les EVALUATIONS par le MOOC proposées de plus de en Sont ainsi que des complexes d'Une semaine à enchainee Ce Qui d'Përmet Une vision, plus Précise sur les des Compétences apprenants. 6 Conclusion Dans papier CE, nous Avons Une méthode de Proposé classement multicritère et incrémentalement conte MAI2P sur l'approach basée DRSA Pour la periodic de la prédiction de décision à classe Une mesure is Laquelle susceptible d'Appartenir. La MAI2P is méthode de phases composée Trois: la construction d'Une table de décision; l'un d'inférence de modèle en Preferences l'appliquant DRSA incrémentiel Algorithme et la de la classe prédiction de décision à l'action each Laquelle appartiendra. Les Expérimentations de la MAI2P sur un méthode MOOC Fran- Cais Une qualité en Ontario de démontré prédiction Qui reached Une satisfaisante F = 0,66-mesure. Bouzayane Références, S. et I. Saad (2017). algorithme de mise à jour incrémentale des approximations dans DRSA pour traiter les sys d'information dynamique tèmes de moocs. Lors de la conférence internationale sur la gestion des connaissances, l'information et les systèmes de connaissances (KMIKS), 55-66. Greco, S., B. Matarazzo, et R. Slowinski (2001). La théorie des ensembles rugueux pour l'analyse de décision multicritère. EJOR 129 (1), 1-45. Greco, S., R. Slowinski, J. Stefanowski, et M. Zurawski (2004). Incrémentale par rapport à la règle mentale nonincre- induction pour la classification multicritère. Transaction Rough Sets II, 33-53. Li, S., T. Li, et D. Liu (2013). entretien dynamique des approximations dans l'approche définie grossière basée dominance dans la variation de l'ensemble d'objets. Int. J. Intell. Syst. 28, 729-751. Miller, G. A. (1956). Le nombre magique de sept, plus ou moins deux: certaines limites à notre capacité de traitement de l'information. Psychological Review 63 (2), 81. Mousseau, B. R., VINCENT, et B. Roy (1996). Un cadre théorique d'analyse de la notion d'importance relative des critères. J. multicritère Decis. Anal 5, 145-159. Roy, B. (1985). .. Methodology multicritère d » aide à la décision Economica Résumé Cet article propose une méthode basée sur la théorie des ensembles rugueux et dédié à l'apprentissage supervisé tal incrémentalement dans un contexte de données asymétriques Cette méthode consiste en trois phases:. La construction d'un . table de décision, la conclusion d'un ensemble de règles de décision, et la classification de chaque action potentielle dans l'une des classes de décision prédéfinis la méthode MAI2P est validée dans le cadre de MOOC (Massive cours en ligne ouvert) -. 310 -