bordures statistiques fouille incrémentale données streams emile symphor pierre alain grimaag scientifique interfacultaire université antilles guyane campus schoelcher 97275 schoelcher cedex martinique france symphor palaur martinique résumé récemment communauté extraction connaissances ressée nouveaux modèles données arrivent séquentiellement forme rapide continu streams particularités importantes flots seule quantité information partielle disponible cours temps ainsi après différentes mises successives devient indispensable considérer incertitude inhérente information tenue article introduisons nouvelle approche statistique biaisant valeurs supports motifs fréquents cette dernière maximiser paramètres précision rappel déterminés utilisateur limitant dégradation paramètre choisi définissons notions bordures statistiques celles constituent ensembles motifs candidats avèrent pertinents utiliser incrémentale streams différentes expérimentations effectuées cadre recherche motifs séquentiels montré intérêt approche potentiel techniques utilisées introduction dernières années grand nombre travaux proposés rechercher motifs fréquents grandes bases données fonction domaines applications motifs extraits itemsets srikant ayres séquences agrawal récemment travaux issus communauté chercheurs données fouille données considèrent streams acquisition données effectue façon régulière continue incrémentalement durée longue voire éventuellement illimitée compte grande quantité information streams problème extraction motifs fréquents toujours actualité demaine manku motwani golab contexte motif fréquent observé moins fraction appelée support motif stream paramètre theta utilisateur bordures statistiques fouille incrémentale streams streams sujets mises régulières fréquentes approches traditionnelles conviennent résultats obtenus ancienne partiellement valables nouvelle envisageable relancer algorithme données effet travaux développant approche incrémentale masseglia cheng problématique principale optimisation performance consiste construire maintenir mesure différentes mises successives ensemble motifs candidats celui utilisé mettre motifs fréquents éviter relancer algorithme depuis convient également souligner autre caractéristique intrinsèque streams découle connaissance stream partielle instant considéré conséquence nécessaire prendre compte incertitude engendrée connaissance toujours incomplète stream précisément traduit recherche motifs fréquents soulignant motifs fréquents obtenus motifs fréquents observés cause cette incertitude sources erreurs doivent considérées motifs observés comme fréquents fréquents longue période observation stream inversement motifs classés comme fréquents peuvent devenir longue période observation stream éviter erreurs nécessaire développer approche connaître motif fréquent partie examinée stream cette approche prédictive savoir quelle probabilité motif fréquent ensemble stream nombreuses applications exemple domaine prévision météorologique encore analyse tendance finance nécessitent approche disposant grande partie stream point statistique impossible affranchir sources erreur vapnik notre objectif essayer approcher mieux possible solution optimale article proposons approche permet considérant incertitude inhérente connaissance streams construire maintenir ensembles motifs candidats choisis constitue préalable fondamental nécessaire toute approche pertinente cadre incrémentale streams suite présentation organisée façon suivante paragraphe introduisons concepts permettent contrôler incertitude découlant sources reurs paragraphe montrons comment obtenir ensembles motifs pertinents effectuer incrémentale paragraphe présente expérimentation notre approche suivie analyse comparative travaux connexes paragraphe concluerons notre étude paragraphe supports statistiques définitions formaliser notre problématique définissons différents ensembles utilisés stream obtenu partir échantillonnage effectué domaine potentiellement grand contient motifs possibles figure chaque motif échantillonné symphor echantillonnage connue stream observe problème dépendemment partir distributiond laquelle formulons aucune hypothèse excepté celle biais renvoyons lecteur intéressé proches prenant compte biais fouilles données supervisées travaux partie stream observée représentée figure partir valeur fixée utilisateur paramètre support théorique voudrait connaître ensemble motifs vrais fréquents ensemble nommé représenté grisé figure hormis incertitude aspects estimation statistique approximation ensemble recouvre aspect combinatoire provient grande taille ensemble nommons semble motifs observés extraits stream réduisons cette différence algorithme permet obtenir super ensemble typiquement contient motifs supplémentaires obtenus partir généralisation éléments mannila toivonen propos ticle traiter aspect combinatoire essentiel jamais suffisamment grand englober regard façon construit figure ainsi importance problème estimation statistique demeure entier ensemble figures représente ensemble motifs vrais fréquents ensemble rappelons ensemble connu totalement compte seulement aussi sources erreurs précédemment indiquées découlent recherchons approcher mieux ensemble utilisant figure représente ensemble motifs observés fréquents stream estimation erreur apprécier approximation effectuée consécutivement sources erreurs ensembles permettent définir quatre paramètres suivants figure bordures statistiques fouille incrémentale streams vrais positifs représente ensemble motifs vrais fréquents égale observés fréquents positifs représente ensemble motifs vrais fréquents observés fréquents négatifs représente ensemble motifs vrais fréquents observés fréquents vrais négatifs représente ensemble motifs vrais fréquents stream également observés fréquents partir ensembles définis dessus indiquer formules précision rappel permettent estimer approximation effectuée précision permet quantifier proportion motifs fréquents estimés vrais fréquents dehors cherche maximiser revient minimiser première source erreurs symétriquement rappel permet quantifier proportion motifs vrais fréquents manquant cherche cette maximiser revient minimiser seconde source erreurs choix définition support statistique utilisé approcher motifs vrais fréquents stream approche naïve approcher mieux ensemble consisterait choisir autrement question pourrait poser savoir support statistique malheureusement principale seule propriété ensemble correspondre probabilité ensemble lorsque cardinal ensemble selon lemme borel cantelli devroye reviendrait connaître stream possible pratique théorème glivenko cantelli permet montrer borner erreur commise motifs vrais fréquents fonction divers paramètres parmi lesquels cardinal ensemble faire mieux souvent traitement information encore medecine plutôt simplement borner erreur beaucoup important estimer contrôler parties erreur conséquent développer approche consiste maximiser précision rappel choix valeurs limites pourraient convenir maximise précision rappel valeurs inintéressantes applications fouille données exemple choisit obtient ainsi avons également correspond valeur faible applications éléments considérés comme motifs vrais fréquents stream pourrait aussi choisir maximiser cette découle pourrait aucun élément motif fréquent exemples valeurs limites permettent cadrer principes notre approche générale choisir subtilement différent suffisamment symphor proche respectivement grand petit sorte possible contrôler maximisant précision rappel garantir forte babilité respectivement limitant dégradation paramètre contrôlé obtient ainsi ensemble petit contenant informations signi ficatives barrière statistique autour empêche proche éloigné conserver contrainte alors forte probabilité notre objectif maximiser précision rappel forte probabilité conséquent rechercher valeurs proches possibles cette barrière théorème dessous permet établir valeurs supports statistiques posons calculant valeur théorème choisit alors probabilité moins alors probabilité moins risque statistique streams valeurs supports statistiques définition supports obtenus statistiquement presque optimaux faute place renvoyons article démonstration complète celle repose utilisation inégalités concentration variables aléatoires préçis permettent obtenir résultats statistiquement presque optimaux optimalité tendons toute technique estimation obtenant meilleures bornes condamnée tromper critère maximiser quelque temps calcul bordures statistiques incrémentale cette section introduisons bordures statistiques supérieure inférieure pertinentes choix motifs fréquents conserver incrémentale objectif bordure statistique inférieure maximiser précision tandis bordure statistique supérieure maximiser rappel adoptons notation probabiliste définie mcallester partir théorème définissons ensemble suivant risque statistique utilisteur choisissant construit ensemble ainsi première source erreurs forte probabilité motifs motifs vrais fréquents figure grand ensemble possible contient uniquement motifs vrais fréquents après temps observation stream définissons ensemble comme étant bordure statistique inférieure partir échantillon motifs façon symétrique partir théorème définissons ensemble suivant lnsp_cikm05 2cette notation concise écrivant précise prédicat fraction ensemble obtenu partir distribution façon équivalente signifie prédicat probabilité ensemble obtenu partir distribution bordures statistiques fouille incrémentale streams bordure statistique inférieure bordure statistique supérieure risque statistique utilisteur choisissant construit ensemble ainsi deuxième source erreurs forte probabilité contient motifs vrais fréquents contient autres figure petit ensemble possible contient motifs vrais fréquents après temps observation stream définissons ensemble comme étant bordure statistique supérieure partir échantillon motifs stream stream motifs bordures statistiques incrémentale figure illustre utilisation bordures processus incrémentale recherchons motifs fréquents partir bordures statistiques notées figure bordures construites support choisi partir valeur calculée bordures permettent approcher mieux ensemble motifs vrais fréquents représente ajout section suivante expérimentations comparerons motifs fréquents obtenus grâce bordures statistiques rapport ensemble figure ensemble représente vrais motifs fréquents après incrémentale expérimentation comme avons précisé section précédente notre objectif expérimen tations consiste évaluer temps réponse associés bordures plutôt symphor database taille taille dragons valeurs paramètres forme valeur départ incrément valeur finale évaluer qualité utilisons mesures précision rappel précédemment équations indépendance notre méthode motifs recherchés avons utilisé algorithme traditionnel recherche motifs séquentiels fréquents spade cette évaluation avons utilisé données issus serveurs premier appelé dragons obtenu internet3 données représentent navigation utilisateurs taille fichier représente environ transactions deuxième données appelée obtenue partir transactions serveur bibliothèque université4 analyser qualité bordures stastiques évaluons différentes situations faisant varier ensemble paramètres exception faite variations paramètres décrites figure premier paramètre définit différentes valeurs support lesquelles allons réaliser expérimentation second paramètre définit taille rapport taille stream simulé taille dernier paramètre quant définit taille rapport celle notre représentera taille paramètre permet contrôler taille incrément rapport partie stockée initialement gérer organiser expériences générateur chargé coordonner tests effectuer utiliser stream aurait limiter qualité évaluation bordures statistiques avons choisi simuler connaissance domaine précisément simuler stream échantillonnons chaque données fragments exemple pouvons considérer données rivent successivement depuis données dragons pouvons stocker prenons transactions contenues cette conservons reste alors prendre incrément exemple taille cette construisons alors bordures statistiques bordure inférieure bordure supérieure définies section figures montrent résultats expériences obtenues respective bases dragons évaluer qualité bordures représentons leurs comportements rapport ainsi courbes représentent précision respectivement bordure statistique inférieure bordure statistique supérieure courbes représentent rappel courbes correspondent choix trivial constatons courbes comportement assez similaire précision approche plupart bases stockées quand elevezundragon bordures statistiques fouille incrémentale streams dragons taille taille taille taille dragons taille taille taille taille représente courbes gauche droite dragons trois valeurs valeurs tailles rapport rappel approche plupart bases stockées quand observations accords résultats théoriques section obser également autre phénomène rappel associé éloigné celui associé précision associée montre maximisation précision rappel obtenue réduit niveau dégradation autre paramètre notons aussi courbes précision meilleures performances celles rappel notamment figure surprenant section fourchette valeur précision beaucoup restreinte rappel variation taille possède également importance vient conforter résultat théorique auquel pouvait attendre effet intéresse rappel constate figures valeurs observées cette quantitée mentent taille traduit possédons données observées qualité prédiction augmente bases données autre phénomène semble apparaître premièrement cause faibles valeurs certains tests réalisés valeur était inférieure différences observées entre courbes semblent liées tailles bases données utilisées données petite celle dragons facteur pensons explique différence entre courbes phénomènes bases données petites tailles devraient présents bases données conséquentes vrais streams courbes figures choix donne meilleurs résultats concerne moyenne choix valeurs sachant proches forte probabilité notre approche efficacement optimiser processus incrémentale aurait symphor taille taille taille taille taille taille taille taille représente courbes gauche droite trois valeurs valeurs tailles rapport espace suffisant stockage choisirait bordure supérieure laquelle possède garanties importantes présence futurs fréquents nombre calculs supplémentaires faible contre devrait limiter raisons taille conserver bordure disons moins volumineuse bordure inférieure alors utilisée contient informations pertinentes ainsi bordures statistiques comme outils incrémentale indiquant limites desquelles inutile stocker informations valeur limite inférieure perte information serait importante valeur limite supérieure travaux connexes depuis nombreux travaux recherche focalisés maintenance ensembles motifs fréquents obtenus bases données statiques graphe regardons adéquation rapport notre problématique partition update cheung algorithmes partitionnement données effectué rechercher premier temps itemsets fréquents locaux relatifs chaque partition second temps déduire itemsets fréquents validation croisée repose hypothèse itemsets fréquents doivent moins partitions parthasarathy développé algorithme incrémentale incremental sequence mining maintenant treillis motifs construit partir motifs fréquents motifs bordure négative zheng développé algorithme incrementally updating sequence utilisant valeur support limiter taille espace candi bordures statistiques fouille incrémentale streams bordure négative différentes approches heurtent inconvénients inhérents utilisation bordure négative espace motifs candidats maintenir important nécessaire considérer relations structurelles existent entre motifs notamment motifs auraient faible valeur support différents algorithmes utilisant bordure négative coûteux temps consommateurs espace mémoire masseglia développé algorithme incrémentale utilisant approche génération candidats inconvénients espace candidats grand phase lente algorithme requiert plusieurs passages toute coûteux temps particulièrement motifs séquentiels séquences longues bordure statistique bordure statistique vrais quents rieure quents observe rieure comparaison algorithme incspan incremental mining sequential patterns large database développé cheng repose approche statistique construit ensemble motifs fréquents diminuant valeur support partir ratio partir ensemble motifs presque fréquents plusieurs motifs fréquents proviendraient alors seraient observés quents connue précédant autrement constituerait frontière entre motifs fréquents fréquents figure représentons exemple ensemble cette approche présente insuffisances majeures point statistique estimation incertitude intrinsèque streams construction ensemble motifs candidats permettant incrémen effet diminuer valeur support choix ratio simplement heuristique justification théorique ainsi cette approche offre aucune certitude indication erreur commise construction ensemble motifs fréquents quant motifs vrais fréquents stream identifiée symboles figure avons aucune garantie minimalité ensemble identifiée symboles figure fortement pénalisant réutilisation objectif optimisation méthode incrémentale conclusion article abordons problématique incrémentale motifs fréquents grandes bases données contexte streams symphor pertinent construire maintenir ensembles motifs vrais fréquents simplement observés comme plusieurs travaux kearns mansour nielsen vapnik montré intérêt approche statistique notamment détermination règles prévision optimisation algorithmes notre contribution majeure porte précisément point introduction supports statistiques complé supports classiques permettant obtenir bordures statistiques constituent ensembles statistiquement presque optimaux constante considérer cadre incrémentale expérimentations présentées montrent robustesse approche motifs séquentiels regard taille bases stockées différentes valeurs supports testées résultats encourageants points positifs quant applicabilité passage échelle méthode plusieurs extensions travaux possibles domaines recherche fouille données citera notamment travaux portent structures données cherche maintenir ensembles items observés fréquents rappel maximum préoc cupations actuelles concernent question suivante possible construire ensemble intermédiaire conserverait mieux propriétés chacune bordures celui représenterait compromis entre bordure statistique imposante stocker autre laquelle nombre accès données important références agrawal imielinski swami mining association rules between items large databases sigmod ayres flannick gehrke sequential pattern mining using bitmap representation cheng incspan incremental mining sequential patterns large database cheung maintenance discovered association rules large databases incremental updating technique demaine lopez ortizand munro frequency estimation internet streams limited space european symposium algorithms devroye györfi lugosi probabilistic theory pattern recognition huang active mining streams international conference mining golab issues stream management sigmod records mortazavi dayal freespan frequent pattern projected sequential pattern mining dynamically maintaining frequent items stream press shenker papadimitriou simple algorithm finding ments streams trans database systems bordures statistiques fouille incrémentale streams kearns mansour bottom decision pruning algorithm optimal generalization efficient algorithm mining frequent itemsets entire history streams workshop knowledge discovery streams manku motwani approximate frequency counts streams international conference large databases mannila toivonen levelwise search borders theories knowlede discovery mining knowledge discovery masseglia poncelet teisseire incremental mining sequential patterns large databases knowledge engineering mcallester bayesian theorems machine learning poncelet symphor estimation frequent itemsets streams theory experiments nielsen statistical region merging trans pattern analysis machine intelligence parthasarathy orihara dwarkadas incremental interactive sequence mining mortazavi pinto dayal prefixspan mining sequential patterns efficiently prefix projected pattern growth srikant mining sequential patterns conference vapnik statistical learning theory wiley mining concept drifting streams ensemble classifiers spade efficient algorithm mining frequent sequences machine learning journal zheng algorithms updating sequential patterns summary recently knowledge extraction community takes closer models where arrive timely manner continous streams important singularity inside streams relies available after following updates necessary uncertainty available paper introduce statiscal approach which biases initial support sequential patterns mining approach holds advantage maximize parameters cision recall chosen while limiting degradation other criterion define statistical borders which relevant frequent patterns incremental mining streams experiments performed sequential patterns demonstrate interest approach potential techniques