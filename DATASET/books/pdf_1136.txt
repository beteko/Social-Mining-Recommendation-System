forage distribué données comparaison entre agrégation échantillons agrégation règles aounallah quirion mineau département informatique génie logiciel département génie électrique génie informatique pavillon adrien pouliot université laval canada mohamed allah ulaval ulaval moaoa mineau ulaval ulaval personnel mineau squirion ulaval résumé attaquer problème forage grandes bases données distribuées proposons étudier approches première télécharger seulement échantillon chaque données effectuer forage deuxième approche miner distance chaque données indépendamment téléchar modèles résultants forme règles classification central agrégation derniers réalisée article présentons ensemble techniques échantillonnage communes présentons ensuite cette nouvelle technique distribué données mécanique agrégation basée coefficient confiance attribué chaque règle petits échantillons chaque données coefficient confiance règle calculé moyens statistiques utilisant théorème centrale conclusion présentons comparaison entre meilleures techniques échantillonnage avons trouvées littérature notre approche forage distribué données basée agrégation modèles introduction papier traite problème forage plusieurs bases données gigantesques géographiquement distribuées présentant comparant techniques forage données première technique avons examinée utilise échan tillon taille raisonnable chaque données auxquels agrégés appliquons technique forage données cette technique relève agrégation données cette perspective avons étudié techniques échantillonnage existantes description dernières ainsi comparaison empirique présentées article deuxième technique forage données introduisons basée agrégation modèles propose appliquer individuellement chaque comparaison entre agrégation échantillons agrégation règles données technique forage données modèles résultant techniques alors recueillis certain modèle agrégé produit technique décrite travail modèles soient produits individuellement chaque ensemble données produit technique agrégation proposons représentés forme ensemble règles classification comme expliqué papier technique agrégation proposons coefficient confiance associé chaque règle calculé utilisant théorème limite central autre petits échantillons chaque données échantillons employés valider coefficient statistiquement calculé article procède comme section ensemble niques échantillonnage communes présentée section présentons notre solution forage distribué données employant agrégation modèles section présentons résultats expérimen tations aident comparer approches présentons finalement conclusion travaux futurs échantillonnage échantillonnage consiste création échantillon représentatif large données hypothèse classificateur entraîné échantillon résultats significativement pires classificateur entraîné toute données notre contexte échantillonnage appliqué chaque répartie générant échantillons distincts chaque derniers regroupés entraîner classificateur littérature forage données riche plusieurs algorithmes échantillonnage langley provost lewis considérant comment échantillon formé algorithmes peuvent regroupés trois familles échantillonnage statique dynamique actif échantillonnage statique échantillonnage effectué ayant uniquement informations fournies données principalement échantillonner aléatoirement selon certains estimateurs distribution données moyenne écart algorithmes échantillonnage appel aucun autre algorithme gorithme classification automatique exemple produire échantillon comme présenté langley données échan tillon initial taille suite incréments abord créer ensemble initial taille éléments aléatoires ensuite distribu champs diffère significativement celle ajouter éléments aléatoires partir aounallah échantillonnage dynamique échantillonnage dynamique diffère échantillonnage statique uniquement processus validation échantillon effet chaque itération échan tillonnage dynamique classificateur partir échantillon celui évalué classificateur ainsi aboutit précision classification tisfaisante précision encore convergé précision satisfai sante algorithme échantillonnage réitère encore existe trois techniques permettant détection convergence détection locale arrêter quand cision cision langley estimation courbe apprentissage langley régression linéaire échan tillonnage local provost échantillonnage actif diffère échantillonnage dynamique façon algorithme sélectionne éléments chaque itération littérature échantillonnage actif utilisé contexte éléments données système apprentissage effet dernier choisir parmi éléments classés demande expert autre programme classer échantillonnage actif minimiser nombre éléments nécessaires prendre concept correctement réalisé choisissant éléments produisant grand informations matérialisé score efficacité contrairement échantillonnage dynamique choisit éléments aléatoirement général score efficacité calculé classificateur probabiliste classificateurs différentes méthodes échantillonnage actif peuvent résumées algorithme figure éléments aléatoires générer ensemble classificateurs partir encore convergé calculer score efficacité éléments choisis basant générer ensemble classificateurs partir algorithme échantillonnage actif généralement éléments ajoutés chaque itération éléments grandes valeurs efficiency score comme cette tâche sensible données bruitées alternative intéressante utiliser valeurs comme poids sélection aléatoire comme proposé uncertainty comparaison entre agrégation échantillons agrégation règles sampling tsechansky provost finalement ficacité pouvons remplacer ensemble classificateurs classificateur unique algorithme échantillonnage exige classificateur classificateur probabiliste restreint énormément choix cependant lewis propose approche hétérogène légère perte perfor mance échantillon utilisant simple classificateur probabiliste classificateur bayésien permettant ajout suppression éléments ligne durant entraînement ensuite second algorithme classification utilisé produire classificateur final basant échantillon produit forage distribué données utilisant agréga modèles construire notre modèle agrégé désormais appelé classificateur proposons architecture basée agents logiciels cette types agents œuvre agents mineurs minent chaque données répartie agent collecteur responsable regrouper informations produites agents mineurs tâche types agent détaillée aounallah mineau dessous donnons brève description tâches agent mineur tâche agent mineur décrite figure agent mineur travaillant données faire appliquer algorithme classification générant ensemble règles couvertures disjointes ensemble produit nombre règles calculer chaque coefficient confiance constante dépend degré confiance demandé écart erreur extraire échantillon aléatoire partir algorithme détaillant tâches agent mineur noter coefficient confiance règle calculé utilisant théorème limite centrale effet théorème stipule somme grand nombre variables aléatoires indépendantes identiquement distribuées distribution approximée normale ainsi comme classificateurs bâtis large volume données erreur règle calculé ensemble disjoint ensemble entraînement approximé normale erreur erreur aounallah appliqué toute population écart erreur écart associés règle pouvons calculer intervalle confiance lequel retrouvons erreur comme constante choisie fonction degré confiance désiré coefficient confiance chaque règle déduit intervalle confiance erreur choisi moins erreur calculé znσer autres termes moins erreur règle moins moitié largeur intervalle confiance erreur ainsi visons couvrir tâches agent collecteur tâche agent collecteur décrite figure globalement agent tâche filtrer règles statistiquement probablement avoir pouvoir prédictif basant coefficient confiance règles autre valider mesure statistique règles gardées après phase filtrage confrontant échantillons récoltés agents mineurs central faire agent collecteur création comme filtrage règles éliminer règles ayant coefficient confiance inférieur seuil déterminer empiriquement validation règles créer relation binaire définie chaque intersection écrivons couvre sinon écrivons couvre correctement autrement écrivons toute règle calculer erreur utilisant comme ensemble nombre chaque rangée relation divisé nombre valeurs nulles rangée construire ensemble règles formant classificateur utilisant seuil comme déterminer empiriquement algorithme détaillant tâches agent collecteur comparaison entre agrégation échantillons agrégation règles expérimentation comme proposé introduction papier présente comparaison entre techniques échantillonnage notre classificateur faire proposons effectuer tests suivants comparer différentes techniques échantillonnage entre elles précision prédiction déterminer meilleures seules dernières seront utilisées comparaison classificateur effectuer tests classificateur utilisant plusieurs valeurs seuils valeurs optimales seuils utilisées comparaison techniques échantillonnage faire comparaisons entre meilleures techniques échantillonnage classificateur précision prédiction taille requise échantillons temps exécution effectuer tests avons utilisé données tirés banque données blake taille varie 45222 objets bases adult chess versus house votes ionosphere mushroom indians diabetes wisconsin breast cancer mangasarian wolberg wisconsin diagnostic breast cancer tester méthodes échantillonnage ainsi impact préci apprentissage avons subdivisé chaque données ensemble entraînement ensemble exemple figure première subdivision simuler environnement distribué tests avons abord subdivisé chaque données bases ayant proportions deuxième subdivision premier ensemble utilisé comme ensemble classificateur modèle agrégé classificateur partir échantillons regroupés deuxième ensemble aléatoirement subdivisé trois quatre ensembles nombre données distribuées tailles aléatoires subdivisés ensembles ayant proportions fichier figure chaque fichier associé respectivement ensemble entraînement classificateur ensemble échantillons toires fichier associé extrait chaque ensemble entraînement taille taille données maximum objets1 comparaison techniques échantillonnage déterminer techniques performeront mieux avons comparé techniques échantillonnage dynamique actif utilisant chacun trois méthodes détection convergence cités méthodes testées suite incréments taille maximale nécessaire borner technique classification ensembles échantillons petits accord contraintes aounallah objects mush1 mush1 mush2 mush2 mush3 mush3 mush2 mush1 mush3 mushtest objects mushbestsampling objects mushroom mushbestsampling objects db32db deuxième subdivision première subdivision objects mushtest subdivision mushroom ensembles entraînement échantillons arithmétique arith géométrique avons aussi comparé méthodes échantillonnage aléatoire suite incréments arithmétique géométrique autre échantillon éléments tirés aléatoirement weighted uncertainty sampling totalisant ainsi méthodes échantillonnage meilleure technique deuxième troisième adult aléatoire dynamique aléatoire arith actif actif dynamique chess actif dynamique actif arith dynamique actif actif arith actif actif arith actif aléatoire arith aléatoire dynamique actif dynamique dynamique actif dynamique arith dynamique dynamique arith aléatoire arith dynamique actif trois meilleures techniques données tableau présente trois meilleures techniques échantillonnage parmi techniques testées basant précision prédiction moyenne précision essais obtenue chacun données utilisant algorithme apprentissage release quinlan tableau pouvons aisément observer techniques actif dynamique apparaissent presque toujours parmi trois meilleures techniques données techniques apparaît parmi trois meilleures techniques faisons appel tableau présente comparaison entre technique manquante meilleure technique trouvée basant tableaux pouvons remarquer erreur comparaison entre agrégation échantillons agrégation règles méthodes échantillonnage actif dynamique toujours fourchette rapport meilleure technique données résultats pouvons conclure dynamique représentent meilleurs techniques échantillonnage moins essais ressemblent nôtres conséquent elles seront seules techniques utilisées comparaison classificateur technique différence rapport meilleure technique adult actif dynamique actif actif différence entre meilleures techniques échantillonnage celles sentées expérimentation rappelons tests objectif déterminer valeurs optimales seuils faire avons choisi paramètres suivants construction classificateurs avons utilisé aussi algorithme lease permet production ensembles règles coefficient confiance chaque règle calculé rapport intervalle confiance seuil avons utilisé respectivement néanmoins valeurs donné exactement mêmes résultats concerne seuil avons utilisé toutes valeurs entre décrément valeur utilisé produire manière automatique calculer seuil basant moyenne confiance règles produites différents tests effectués classificateur utilisant valeurs seuil citées dessus montré donne meilleurs résultats résultat prévisible puisque seuil valeur plutôt valeur trouve consensus entre différents trouvant valeur moyenne proche ainsi pouvons conclure valeurs optimales seuils selon ensemble tests effectués respectivement comparaison entre apprentissage échan tillonnage basons notre comparaison résultats trouvés sections conséquent cette section limitons notre étude échantillonnage dynamique actif comparés classificateur comparaison conduite erreur prédiction temps exécution taille échantillons nécessaire chaque aounallah technique évaluer importance erreur obtenus classificateur techniques échantillonnage avons comparés erreur appliqué toute données utilisé seulement comme référence puisque selon hypothèses pouvons traiter entier cause contraintes temps traitement téléchargement référence juger pertinence erreur évalué techniques présentées article ailleurs avons choisi algorithme algorithme utilisé marché figure montre différents erreur obtenus algorithme repré senté histogrammes noirs échantillonnage dynamique représenté histogrammes clair échantillonnage actif représenté histogrammes blancs classificateur histogrammes foncé première conclusion tirée graphique erreur peuvent jugés acceptables puisque temps fourchette pires trois essais adult chess noter aucune tendance apparaît niers effet premier données échantillonnage actif donne résultat tandis échantillonnage dynamique classificateur donne erreur quant deuxième troisième données remarquons inverse échantillonnage actif performe correctement autres techniques performent moins adult chess mushroom dynamique classificateur actif comparaison erreur entre classificateur échantillonnage actif dynamique considérant erreur comme référence selon résultats pouvons ainsi conclure légère perte performance classification2 techniques échantillonnage testées classificateur présentent globalement performances classification acceptables rapport appliqué moyenne différences rapport techniques échantillonnage classificateur comparaison entre agrégation échantillons agrégation règles comparaison tailles tableau détaille taille bases données ainsi taille échantillons obtenus échantillonnage actif dynamique taille échantillons utilisés classificateur autre part3 fichiers entraînement dynamique actif classifier adult 20112 chess taille bases données échantillons tableau montre taille échantillons issus échantillonnage actif dynamique taille données explique figure égalité erreur techniques échantillonnage algorithme données ailleurs données notre classificateur donne mieux échantillons aussi petits objets moins autres classificateur erreur comparable techniques échantillon meilleur techniques mauvais technique échantillonnage cette performance intéressante puisque taille échantillons classificateur nettement petite celle cessaire techniques échantillonnage comparaison temps traitement finalement comparer techniques échantillonnage technique proposée temps exécution pouvons examiner figure notons programmes développés compilés compilateur exécutés machine raisons présentation avons figure temps exécution données adult valeurs échantillonnage dynamique actif classificateur respectivement tableau pouvons aisément conclure données technique toujours rapide parfois beaucoup rapide techniques échantillonnage outre analyse asympto tique illustrée partie figure temps exécution adult suggère lorsque taille bases données augmente technique restera beaucoup rapide techniques échantillonnage explique 3nous rappelons échantillons utilisés produire classificateur taille maximale objets inférieur taille inférieur aounallah chess dynamique classificateur actif comparaison temps exécution entre classifier techniques échantillonnage actif dynamique méthode détection convergence coûteuse temps exécution techniques échantillonnage dynamique actif bâtissent classificateur chaque itération comparativement classificateur chaque donnée distribuée parallèle classificateur ainsi pouvons extrapoler grandes bases données temps exécution techniques échan tillonnage efficaces supérieur temps exécution classificateur conclusion objectif papier faire comparaison entre techniques échan tillonnage existantes nouvelle technique forage distribué données agrégation modèles faire avons présenté survol techniques échantillonnage communes ainsi brève description nouvelle nique outre avons conduit quelques expériences déterminer meilleures techniques échantillonnage déterminer paramètres optimaux classificateur comparer meilleures techniques échantillonnage classificateur utilisant paramètres optimaux trouvés précédemment selon trois pects différents précision prédiction temps exécution taille échantillons comme résultats échantillonnage dynamique actif presque toujours meilleures techniques données utilisés compa raison dernières classificateur révélé conclusions suivantes toutes techniques échantillonnage classificateur globalement erreur comparables comparaison techniques algorithme agrégation toutes bases utilisé comme référence prouvé erreur techniques généralement acceptable légère perte performance moyenne comparaison entre agrégation échantillons agrégation règles classificateur rapide techniques échantillonnage classificateur nécessite échantillons beaucoup petite taille requis techniques échantillonnage conclusion exigence précision permet légère perte moins données apparaît classificateur représenter bonne solution forage bases données distribuées temps calcul requis considérablement moindre surcroît architecture multi agents utilisé parallélisation technique permettrait grâce hiérarchisation agents collecteur encore adaptabilité grandes bases données applications servent données transactionnelles telle commerce pourraient alors bénéficier expérimentations terrain venir résultats préliminaires présentés article encourageants références aounallah mineau confidence produced disjoint bases statistically sound regroup rules iadis international confe rence applied computing pages lisbon portugal blake repository machine learning databases mlearn mlrepository langley static versus dynamic sampling mining simoudis fayya editors proceedings second international conference knowledge discovery databases mining pages portland oregon press lewis sequential algorithm training classifiers proceedings sigir international conference research development information retrieval pages dublin springer verlag heidelberg mangasarian wolberg cancer diagnosis linear program provost jensen oates efficient progressive sampling chaud madigan editors proceedings fifth sigkdd inter national conference knowledge discovery mining pages press quinlan improved continuous attributes journal artificial intelligence research tsechansky provost active sampling class probability mation ranking