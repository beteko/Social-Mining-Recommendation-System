TOM: Bibliothèque A pour la modélisation de sujet et navigation Adrien Guille *, Edmundo-Pavel Soriano-Morales * * Laboratoire ERIC, Université Lumière Lyon 2 adrien.guille@univ-lyon2.fr, edmundo.soriano-morales@univ-lyon2.fr Résumé . Dans cet article, nous présentons TOM (Modélisation Topič), une bibliothèque Python pour la modélisation et la navigation sujet. Son objectif est de permettre une ana- lyse efficace d'un corpus de textes du début à la fin, par la découverte de sujets cachés. A cet effet, TOM propose des fonctions avancées pour la préparation et vectorisation un texte cor- pus. Il offre également une interface unifiée pour deux modèles de sujet (à savoir LDA à l'aide de l'inférence soit variationnelle ou échantillonnage de Gibbs, et NMF à l'aide de carrés moins avancés en alternance avec une projection de méthode gradient), et met en œuvre trois méthodes état de l'art pour estimer la valeur optimale nombre de sujets au modèle un corpus. Qui plus est, TOM construit un navigateur basé sur le Web interactif qui permet d'explorer un modèle de sujet et le corpus connexe facile. 1 modèles Présentation Sujet sont des outils utiles pour dévoiler la structure d'actualité latente des corpus de textes. Ils peuvent faire la recherche, la navigation et la synthèse de ces corpus plus facile. Plusieurs modèles et des algorithmes pour les rapproche ont été proposées ces dernières années. La qualité des sujets découverts dépend du modèle, l'algorithme d'approximation, la nature du corpus étudié, ainsi que le nombre de sujets (Stevens et al., 2012). Par conséquent, afin d'effectuer une analyse comparative thématique efficace d'un corpus de texte, il est important de comparer plusieurs approches pour identifier les sujets les plus pertinents. Toutefois, cela est une tâche difficile, car les implémentations existantes des algorithmes d'approximation sont indépendants, ce qui signifie que l'on doit apprendre comment les données sont structurées dans chaque mise en œuvre; ce que les fonctions de manipuler chaque modèle de sujet sont; comment adapter ces modèles de sujet sur l'ensemble exactement les mêmes caractéristiques, etc. D'autre part, plusieurs méthodes ont été proposées pour estimer le nombre optimal de sujets pour modéliser un corpus, mais - au meilleur de nos connaissances - leurs mises en œuvre sont pas accessible au public. Dans ce court article, nous présentons TOM (Modélisation Topič), une bibliothèque open source écrit en Python pour l'analyse d'un corpus de textes du début à la fin, par la découverte de sujets cachés. Outre les fonctions de préparation de corpus avancées, TOM offre une interface unifiée pour les implémentations existantes robustes d'algorithmes d'approximation, qui rend la manipulation et montage des modèles de sujet facile. Il met également en œuvre plusieurs fonctions pour estimer le nombre optimal de sujets pour modéliser un corpus. Qui plus est, TOM peut construire automatiquement une interface Web pour explorer un modèle de sujet et un corpus de manière interactive. - 451 - TOM: Bibliothèque A pour la modélisation de sujet et navigation 2 bibliothèque proposée Dans cette section, nous avons d'abord décrire les capacités de la bibliothèque proposée, TOM, nous illustrons comment l'utiliser avec l'aide de courts extraits de code. Les sources et la documentation sont disponibles en ligne à https://github.com/AdrienGuille/TOM. 2.1 Caractéristiques TOM fonctionne sur un corpus de texte, éventuellement complété par des méta-données telles que les auteurs ou les dates d'écriture / publication. préparation Corpus Préparation du corpus est fondamental, dans le sens où la pertinence de tout traitement ultérieur dépend de cette étape. fonctions de préparation avancées sont disponibles pour les français et en anglais. TOM peut lemmatiser français en utilisant Melt, un système de marquage partiel de synthèse vocale basée sur un modèle de Markov entropie maximale spécialement conçu pour le français (Denis et Sagot, 2012), et Lefff, un lexique morphologique et syntaxique pour le français (Sagot, 2010), à apparier avec lemmes {mot, une partie du discours}. Il peut également lemmatiser anglais d'une manière similaire, en utilisant un autre modèle d'entropie maximale formé pour l'anglais (Bird et al., 2009) et le lexique WordNet (Miller, 1995). Finalement, TOM construit la représentation d'espace vectoriel avec unigrammes ou n-grammes comme caractéristiques, en utilisant soit tf i · df ou simplement tf. L'espace vectoriel est une matrice n × m, avec n le nombre de textes et m le nombre de fonctions. modèles sujet donné la représentation d'espace de vecteur d'un corpus et un petit nombre de feuilles supérieure ics k (k m), un modèle de sujet se compose de deux matrices: W et H. W est une matrice n × k qui décrit les textes en fonction de thèmes, et H est une matrice k × m qui décrit les sujets en termes de caractéristiques (à savoir des mots ou des n-grammes de mots). Plus précisément, le wi coefficient, j définit l'importance du sujet j dans le texte i, et le coefficient salut, j définit l'importance de la fonction j dans le sujet i. Deux modèles sont disponibles dans le sujet TOM: (i) Latent Dirichlet Allocation (LDA), un modèle de sujet générative probable- abilistic proposé par Blei et al. (2003), et (ii) Méthode non négatif factorisation de la matrice (NMF), un espace vectoriel factorisation qui a récemment devenu populaire pour la modélisation sujet (Berry et Browne, 2005). En ce qui concerne LDA, la bibliothèque propose deux algorithmes: approximation de l'algorithme d'inférence variationnelle originale et la variante de Gibbs (Griffiths et Steyvers, 2004). En ce qui concerne NMF, elle repose sur un algorithme basé sur les moindres carrés alternant avec descente de gradient projeté (Lin, 2007). Estimation des paramètres Choix d'un nombre approprié de sujets est essentiel pour assurer une modélisation d'un per- tinent corpus de texte. TOM met en œuvre trois méthodes pour guider ce choix: (i) la méthode basée sur la stabilité proposée par Greene et al. (2014), (ii) la méthode basée sur le consensus pro- posé par Brunet et al. (2004), et (iii) la méthode de la divergence proposé par Arun et al. (2010). Chacune de ces méthodes est basée sur une hypothèse particulière et conduit à la computa- tion d'une mesure spécifique, dont la valeur est liée à la qualité d'un modèle de sujet pour un corpus et un certain nombre de sujets. TOM offre également des fonctions pour tracer ces mesures afin de faciliter leur inspection visuelle. - 452 - A. Guille et E.P. Soriano-Morales Sujet navigateur modèle Les offres du navigateur modèle sujet 3 aperçus: l'index des auteurs, le vocabulaire complet et le nuage de sujet, où chaque sujet est représenté par une bulle marquée avec les mots les plus importants et dont le diamètre est proportionnel à sa fréquence globale. Il offre également des vues détaillées interactives pour: chaque thème, chaque document, chaque auteur et chaque fonction (à savoir des mots ou n-gramme de mots) de l'espace vectoriel. Par exemple, la vue détaillée sur un sujet présente les traits les plus pertinents, l'évolution de la fréquence de sujet à travers le temps, la liste des textes connexes et le réseau de collaboration que les auteurs de liens. La présentation détaillée de texte présente un des plus importants des caractéristiques, la distribution de sujet et les textes plus similaires. Notez que certains éléments peuvent être absents, selon les méta-données disponibles avec le corpus d'entrée. 2.2 Utilisation Charger et préparer un corpus de texte L'entrefilet code suivant montre comment charger un corpus de documents en français, les lemmatiser et vectoriser les utiliser unigrammes et Tf · idf. corpus = Corpus (SOURCE_FILE_PATH = 'entrée / raw_corpus.csv', language = 'français', # langue stop-mots vectorisation = 'TFIDF', n_gram = 1, max_relative_frequency = 0,8, min_absolute_frequency = 4, préprocesseur = FrenchLemmatizer ()) print 'taille du corpus:', print corpus.size 'la taille du vocabulaire:', len (corpus.vocabulary) print 'vecteur pour le document 0: \ n', corpus.vector_for_document (0) instancier un modèle de sujet et d'estimer le nombre optimal de sujets ici, nous instancier un modèle thématique basé NMF et générer des tracés pour les trois paramètres pour estimer le nombre optimal de sujets pour modéliser le corpus chargé. topic_model = NonNegativeMatrixFactorization (corpus) à savoir = visualisation (topic_model) viz.plot_greene_metric (min_num_topics = 5, max_num_topics = 50, tao = 10, étape = 1, top_n_words = 10) viz.plot_arun_metric (min_num_topics = 5, max_num_topics = 50, = itérations 10) viz.plot_consens_metric (min_num_topics = 5, max_num_topics = 50, = 10 itérations) pour utiliser avec LDA Gibbs échantillonnage au lieu de NMF, il suffit de remplacer la première ligne avec les éléments suivants: topic_model = Allocation de Dirichlet latente (corpus, méthode = ») gibbs Déduire un modèle de sujet et enregistrer / charger Pour permettre la réutilisation des modèles de sujets déjà appris, TOM peut les enregistrer sur le disque, comme indiqué ci-dessous. topic_model.infer_topics (num_topics = 15) utils.save_topic_model (topic_model, 'sortie / NMF_15topics.tom') topic_model = utils.load_topic_model ( 'sortie / NMF_15topics.tom') - 453 - TOM: Une bibliothèque pour la modélisation de sujet et les informations de navigation Imprimer à propos d'un modèle sujet Cet extrait de code illustre comment on peut manipuler un modèle de sujet, par exemple obtenir la distribution de sujet pour un texte (un vecteur de longueur k) ou la distribution de mot pour un sujet (un vecteur de longueur m). imprimer « \ la distribution nTopic pour le document 0: », \ topic_model.topic_distribution_for_document (0) print « \ la distribution nword pour sujet 0: », \ topic_model.word_distribution_for_topic (0) Pour faciliter les interactions avec les modèles sujet, TOM offre des fonctions de niveau supérieur, par exemple d'identifier le sujet avec le poids le plus élevé pour un document donné, pour obtenir le plus de mots pertinents pour un sujet donné ou imprimer rapidement tous les sujets. imprimer '\ Nmost sujet probablement pour le document 0:', \ topic_model.most_likely_topic_for_document (0) imprimer '\ n10 mots les plus pertinents pour le sujet: 0', \ topic_model.top_words (0, 10) print '\ nTopics:' topic_model.print_topics (NUM_WORDS = 10) 3 démonstration Dans cette démo, le public sera invité à explorer l'anthologie EGC (817 articles publiés de 2004 à 2015) par le biais d'un navigateur modèle de sujet construit automatiquement par TOM. Voir Guille et al. (2016) pour plus de détails sur ce modèle de sujet. Fig. 1 et Fig. 2 (page 5) donnent un aperçu de ce que les partici- pants auront accès. Ils montrent respectivement la vue d'ensemble des nuages ​​de sujet de l'anthologie, et les queues dé- sur l'un des sujets. Ce navigateur modèle sujet peut être consulté en ligne à l'adresse http: //mediamining.univ- lyon2.fr/people/guille/egc2016. Les participants auront également l'occasion d'explorer un autre navigateur modèle de sujet basé sur les transcriptions des 900+ discours prononcés par François Hollande comme président de la France, entre mai 2012 et Janvier 2016. 4 Les travaux futurs travaux futurs comprend l'ajout de modèles plus sujet et approximation algorithmes. Plus particulièrement, il serait intéressant de mettre en œuvre un algorithme d'approximation qui optimise la Kullback-Leibler diver- fonction objectif gence, puisque Ding et al. (2008) ont montré que NMF est alors équivalente à probabilistes analyse sémantique latente (PLSA), un modèle de sujet séminal proposé par Hofmann (1999). Références Arun, R., V. Suresh, C. V. Madhavan, et M. N. Murthy (2010). En trouvant le nombre naturel de sujets avec l'allocation Dirichlet latente: Quelques observations. En PAKDD, pp. 391-402. Berry, M. W. et M. Browne (2005). surveillance de courriel en utilisant la matrice non négative factorisation. Journal of Computational et organisation mathématique Théorie 11 (3), 249-264. Oiseau, S., E. Klein et E. Loper (2009). Traitement du langage naturel avec Python. O'Reilly Media. Blei, D. M., A. Y. Ng, et M. I. Jordan (2003). Latent Dirichlet Allocation. Journal of Machine Learning Research 3, 993-1022. - 454 - A. Guille et E.P. Soriano-Morales figure. 1 - Vue d'ensemble du corpus avec le nuage de sujet. FIGUE. 2 - Vue détaillée sur l'un des sujets découverts. - 455 - TOM: Bibliothèque A pour la modélisation de sujet et navigation Brunet, J., P. Tamayo, et J. Golub, T.R.and Mesirov (2004). Metagenes découverte de motif moléculaire à l'aide de factorisation de la matrice. Actes de l'Académie nationale des sciences 101 (12), 4164 à -4169. Denis, P. et B. Sagot (2012). Le couplage d'un corpus annoté et un lexique pour l'état de l'art marquage pos. Ressources Linguistiques et évaluation 46 (4), 721-736. Ding, C., T. Lib et W. Peng (2008). Statistiques de calcul et d'analyse des données (52), 3913 à -3927. Greene, D., D. O'Callaghan et P. Cunningham (2014). Combien de sujets? analyse de la stabilité pour les modèles sujet. Dans ECML PKDD, pp. 498-513. Griffiths, T. L. et M. Steyvers (2004). Trouver des sujets scientifiques. Compte rendu de la Nati Académie des sciences onal 101, 5228-5235. Guille, A., E. P. Soriano Morales et C. O. Truica (2016). Modélisation du sujet et l'exploration de hypergraphe pour analyser l'histoire de la conférence EGC. En EGC. Hofmann, T. (1999). l'indexation sémantique latente probabilistes. En SIGIR, pp. 50-57. Lin, C. J. (2007). les méthodes de gradient projeté pour matrice non négative factorisation. tion neurale Computa- 19, 2756-2779. Miller, G. A. (1995). Wordnet: Une base de données lexicale pour l'anglais. Communications de l'ACM 38 (11), 39-41. Sagot, B. (2010). Le Lefff, un libre accès et grande couverture lexique morphologique et syntaxique pour le français. En LRGC. Stevens, K., P. Kegelmeyer, D. Andrzejewski et D. Buttler (2012). Explorer la cohérence des sujets sur de nombreux modèles et de nombreux sujets. Dans EMNLP-CoNLL, pp. 952-961. Article résumé This TOM present, Une bibliothèque Python Pour la modélisation et l'exploration de l'Objectif Dont thématiques is de de permettre d'analyser juin Mener Efficace, de bout en bout, d'un corpus Textuel par la découverte de Latentes thématiques. TOM des offres la préparation répandrai fonctions et la vectorisation de corpus interface Une Unifiée Pour Deux de Modèles thématiques (LDA et NMF), et methods verser trois implémente le Estimer optimal de Nombre thématiques. Par ailleurs, TOM CONSTRUIT ONU EXPLORATEUR automatiquement FACILEMENT D'Interactif etudier permettant Modele de l'ONU les documents THÉMATIQUES ET Liés. - 456 -