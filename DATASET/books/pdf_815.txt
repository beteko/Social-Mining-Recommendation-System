EGC2008 Data mining pour l'extraction de l'activité dans les données vidéo JoseLuis PATINO, Etienne CORVEE François BREMOND, Monique THONNAT INRIA 2004 route des Lucioles, 06902 Sophia Antipolis (FRANCE) {jlpatino, Etienne.Corvee, Francois.Bremond, Monique.Thonnat}@sophia. inria.fr http://www-sop.inria.fr/orion/ Résumé. L'exploration des grandes données vidéo est une tâche qui est désormais possible en raison des progrès réalisés sur la détection et le suivi objet. les techniques d'extraction des données telles que le regroupement sont généralement employés. Ces techniques ont principalement été appliquées pour la segmentation / indexation de la vidéo mais la traction de la connaissance de l'activité contenue dans la vidéo n'a été que partiellement pris en compte. Dans cet article, nous présentons comment l'information vidéo est traitée dans le but ultime de parvenir à la découverte de connaissances des personnes activité dans la vidéo. Tout d'abord, jects ob- d'intérêt sont détectés en temps réel. Puis, dans un processus hors ligne, nous visons à effectuer la découverte de connaissances à deux étapes: 1) trouver les principaux modèles de trajectoire des gens dans la vidéo. 2) trouver des modèles d'interaction entre les objets et per- PLE contextuels de la scène. Une ing cluster- ascendante hiérarchique est utilisé à chaque étape. Nous présentons les résultats obtenus sur des vidéos réelles du métro de Turin (Italie). 1 Introduction De nos jours, plus que jamais, les progrès techniques et scientifiques exige des opérateurs humains pour traiter de plus en plus grandes quantités de données. Pour traiter cette énorme quantité de données, la plupart des travaux peuvent maintenant être effectuées dans le domaine d'exploration de données pour synthétiser, analyser l'information et de mesure de l'extrait, qui est généralement caché dans les données brutes. Clustering est l'une des techniques les plus couramment utilisées dans les données minières pour effectuer des tâches de découverte de connaissances sur grande quantité de données sans connaissance préalable de ce qui pourrait être caché dans les données. Il existe de nombreuses techniques de regroupement dans la littérature, et l'objectif principal de toutes ces techniques est d'obtenir une partition des données en organisant automatiquement dans des groupes séparés où les objets à l'intérieur d'un groupe spécifique sont plus semblables les uns aux autres (en ce qui concerne leur caractéristiques extraites et mesurées, ou de variables) que pour les objets des autres groupes. Extraction de documents texte (Blatak 2005, Lemoine et al., 2005; Xing et Ah-Hwee 2005) et l'exploitation des données liées au Web pour l'extraction de l'activité dans l'information de données vidéo (Chia-hui et Kayed 2006, Facca et Lanzi 2005; McCurley et Tomkins 2004) sont deux champs d'application bien connus de l'exploration de données. L'application des techniques d'exploration dans les grandes données vidéo est désormais possible aussi en raison des progrès réalisés sur la détection d'objet et (ing Track- Fusier et al., 2007, Vu et al., 2003). Des recherches antérieures ont mis l'accent sur la classification vidéo sémantique pour l'indexation et la recherche (Oh et Bandi 2002. Ewerth et al 2007) (. Benini et al, 2006) ou la création de résumé vidéo, mais l'extraction de connaissances sur l'activité contenue dans la vidéo a été seulement partiellement pris en compte. Récemment, il a été démontré que l'analyse du mouvement des objets mobiles détectés dans la vidéo peut donner des informations sur la trajectoire normale et anormale (Porikli, 2004; Naftel et Khalid 2006, Anjum et Cavallaro 2007). Comment- a été fait jamais petite enquête pour trouver les modes d'interaction entre les objets mobiles détectés et les objets contextuels de la scène. Un premier travail a été présenté par (et al Patino. 2007) où les techniques de clustering ont été utilisées pour trouver des modèles de ries trajecto- et modèles d'activité. Dans cet article, nous présentons un ensemble de fonctionnalités plus riches et de définir de nouvelles distances entre les caractéristiques symboliques. Nous appliquons la classification ascendante hiérarchique 1) pour trouver les principaux modèles de trajectoire des gens dans la vidéo. 2) pour extraire les relations complexes entre les personnes et les objets contextuels de la scène. Cette recherche a été fait dans le cadre du GARDIEN proje ct, qui est une initiative européenne de fournir un outil efficace pour la gestion des grands multimédia de collec- tions. À l'heure actuelle, il est testé sur de grands enregistrements vidéo souterrains (métro GTT, Turin, Italie et métro ATAC, Rome, Italie). Dans ce travail, nous présentons les résultats obtenus sur des vidéos réelles de trois caméras du métro de Turin (Italie). La structure générale de notre système est présenté dans la section 2. détection d'objets et d'événements est expliqué dans la section 3. Trajectoire analy- sis des objets mobiles est expliqué à la section 4 alors que l'extraction des interactions significatives entre les personnes et les objets contextuels de la scène est décrite dans section cinq. Dans la sixième section, nous présentons les résultats obtenus. Notre conclusion est donnée est l'article 7. 2 Structure générale de l'approche proposée comporte trois éléments principaux qui définissent notre approche: l'acquisition de données, l'analyse ON- ligne de flux vidéo et l'analyse hors ligne. Une vue d'ensemble du système est illustré à la figure 1. Les flux vidéo sont directement introduits dans notre système d'analyse en ligne pour la détection en temps réel des objets et des événements de la scène. Cette procédure va sur une base image par image et les résultats sont stockés dans une base de données spécifique en ligne. A ce niveau, les événements détectés contiennent déjà des informations sémantiques décrivant l'interaction entre les objets et les informations contextuelles de la scène. Ceci est une première couche d'information sémantique dans notre sys- tème. L'analyse des objets détectés et événements récupérés à partir de la base de données en ligne fournira de nouvelles informations difficiles à voir directement sur les flux vidéo. Cela constitue une couche OND d'information sémantique sec-. Dans cette couche les trajectoires prises par les utilisateurs sont caractérisés. Ces informations sont mis en place dans un modèle approprié de représentation des connaissances à partir de laquelle les relations complexes peuvent être découvertes entre les objets mobiles et les objets contextuels de la scène. Les mesures statistiques telles que les chemins fréquents la plupart, le temps passé par les utilisateurs à interagir avec les objets contextuels de la scène peuvent être inférées. J. L. Patino et al. RNTI - X - page 3 Fig. 1 - Aperçu de l'approche proposée. 3 Objet et événement de détection La première tâche de notre démarche d'exploration de données est de détecter en temps réel des objets présents dans la vidéo et les événements d'intérêt. 3.1 suivi d'objets suivi plusieurs objets mobiles évoluant dans une scène est une tâche difficile à réaliser. Les détecteurs de mouvement ne parvient souvent à la détection d'objets en mouvement avec précision appelés « mobiles » qui induit mistracks des mobiles. De telles erreurs peuvent être causées par des ombres ou plus important en statique (si un objet mobile est masquée par un objet d'arrière-plan) ou dynamique (lorsque plusieurs projections mobiles sur le chevauchement de plan d'image) d'occlusion (Georis et al., 2003). En bref parler un algorithme de détection de mouvement permet la détection d'objets avant d'être classés et suivis au fil du temps. Les segments de détecteur de mouvement, de l'image de référence d'arrière-plan, les pixels d'avant-plan qui appartiennent à des objets en mouvement par une simple opération Threshold olding. Les pixels de premier plan sont alors regroupées en régions spatialement mobiles repré- ressentie par les boîtes englobantes. Ces régions sont ensuite classées en classes d'objets sémantiques en fonction de leur taille 3D. L'algorithme de suivi construit un graphique temporel des objets CONNECTE con- au fil du temps pour faire face aux problèmes rencontrés pendant le suivi. Les objets tégé de dé- sont connectés entre chaque paire d'images successives par un cadre de bâti (F2F) traqueur (Avanzi et al., 2005). Le graphique des objets liés est analysé par l'algorithme de suivi, aussi appelé Tracker à long terme, qui construit des chemins potentiels pour chaque mobile selon les liens établis par le tracker F2F. Le meilleur chemin est alors reconnu et les objets détectés liés par cette voie sont marquées avec le même identifiant. L'exploration de données pour l'extraction de l'activité dans les données vidéo 3.2 détection des événements Les événements d'intérêt sont définis en fonction de la langue sémantique introduite par Vu et al., (2003). Cela suppose une ontologie où les objets d'intérêt « o »; zone d'intérêt « z » et les objets contextuels d'intérêt « eq » (objets contextuels font partie du modèle de scène vide correspondant à l'environnement statique) sont définis. les relations spatio-temporelles sont ensuite construits pour former les événements d'intérêt: - inside_zone (o, z) »: quand un objet « o » est dans la zone « z ». - 'stays_inside_zone (o, z, T1)': lorsque l'événement 'INTÉRIEUR_ zone (o, z)' est détecté Suc-cessivement pendant au moins secondes T1 - 'close_to (o, eq, D)': lorsque le 3D distance d'un emplacement de l'objet sur le plan de masse est inférieure à la distance maximale autorisée, D, à partir d'un objet d'équipement « eq » - « stays_at »: lorsque l'événement « fermer (o, eq, Dmax, T2) » est détecté consécutivement pendant au moins T2 secondes. - « crowding_in_zone »: lorsque l'événement « stays_inside_zone (foule, z, T3) » est détectée pendant au moins secondes T3. Dans notre application particulière, nous avons utiliser les variables suivantes: - objet o = {p, g, c, l, t, u} avec p = personne, g = groupe, c = foule l = bagages, t = train, et u = inconnu. - zone z = {plate-forme, validating_zone, vending_zone} - eq équipement = {g1, ..., G10, VM1, VM2} où « gi » est la porte de la i-ième et vmi est le i-ième distributeur automatique. - T1 = 60 s, D = 1m50, T2 = 5 s, T3 = 120 s. 4 Trajectoire Analyse Pour la caractérisation du motif trajectoire de l'objet, nous avons sélectionné un dations détaillées, compact, et la représentation souple convient aussi pour une analyse plus poussée, par opposition à de nombreux systèmes vidéo qui stockent réellement la séquence d'emplacements d'objets pour chaque image de la vidéo , qui est une représentation lourde sans information sémantique. Si l'ensemble de données est composé d'objets m, la trajectoire pour l'objet i dans ce jeu de données est définie comme l'ensemble des points [xi (t), yi (t)]; x et y sont des vecteurs de séries chronologiques dont la longueur n'est pas égal pour tous les objets que le temps qu'ils passent dans la scène est variable. Deux points clés définissant ces séries temporelles sont le début et la fin, [xi (1), yi (1)] et [xi (fin), yi (fin)] comme ils définissent où l'objet vient et où il est aller à. Nous construisons un vecteur caractéristique de ces deux points. De plus, on inclut les informations de direction donnée en tant que [cos (θ), sin (θ)], où θ est l'angle qui définit le vecteur joignant [xi (1), yi (1)] et [xi (fin), yi (fin)]. Nous nourrissons le vecteur de caractéristique formé par ces six éléments dans un algorithme de classification ascendante hiérarchique (Kaufman et Rousseeuw, 1990). Pour un ensemble de données constitué d'objets m il y a m * (m-1) / 2 paires dans l'ensemble de données. Nous employons la distance euclidienne comme mesure de calculer similitude la distance entre toutes les caractéristiques de trajectoire. trajectoires d'objets avec la distance minimale sont regroupés ensemble. Lorsque deux ou plusieurs trajectoires sont définies ensemble leur barycentre global est pris en compte pour le regroupement plus. La fusion successive de J. L. Patino et al. RNTI - X - page 5 grappes est répertorié par le dendrogramme. L'évaluation du dendrogramme est généralement subjective par adjugeant qui seuil de distance semble créer le plus naturel regroupement des données. Pour cette raison, nous avons créé une interface qui permet à l'utilisateur d'explorer le gramme dendro-. Le nombre final de grappes est réglé manuellement et les valeurs typiques sont comprises entre 12 et 25 pour un ensemble de données de 1000 à 2500 objets mobiles. Comme les préformes d'acquisition dans un environnement multi-caméra les classes obtenues peuvent être généralisés à différentes vues de la caméra grâce à une matrice d'étalonnage 3D appliquée au cours du système d'analyse en ligne. Afin d'évaluer notre approche d'analyse de trajectoire, nous avons défini un ensemble de données contenant la vérité au sol de plus de 300 trajectoires. L'ensemble de données a été annotés manuellement. Les attributs sémantiques tels que « Du sud Portes des distributeurs automatiques » ont été enregistrées dans la base Data-. Il y a une centaine de ces annotée ETM attributs. antic En général, chaque description sémantique est associée à une trajectoire qui correspond le mieux à cette description. En outre, deux trajectoires définissent les limites de confiance au sein de laquelle on peut encore associer cette description tic seman-. La figure 2 montre quelques exemples des trajectoires de base de données et de leur asso- ATED sens sémantique. Nous calculons deux mesures de performance pour valider la qualité de l'approche de regroupement proposée, à savoir, de fusion et de rappel. Le premier donne une indication sur le nombre d'étiquettes sémantiques du rez-de-vérité (ou classes) sont mis ensemble dans un cluster unique résultant de la procédure agglomératif. Ces étiquettes sémantiques rez-de-vérité (contenant trois trajectoires par étiquette) sont: 'la vérité au sol associée au cluster. Idéalement, tous les jectoires de tradi- rez-de-vérité associés à la même étiquette sémantique doivent être inclus dans le même cluster. La dernière mesure de la performance (Rappel) indique le nombre de trajectoires vérité terrain match- ing un groupe donné par rapport au nombre de «vérité terrain associée au cluster. La figure 3 représente l'évolution de ces deux facteurs en fonction du nombre de grappes qui est sen cho- lors de l'exécution de l'algorithme de clustering. FIGUE. 2 - rez-de-vérité pour deux groupes sémantiques différents. Parce que toutes les trajectoires ne peuvent être également observés par la caméra (par exemple tous les tourniquets établir la distinction dans le coin supérieur gauche nécessiterait une résolution spatiale plus grande), il est en réalité très difficile à réaliser une bijection entre les étiquettes sémantiques et l'extraction de données résultant pour l'extraction de l'activité dans les groupes de données vidéo. Cependant, nous visons à avoir le niveau le plus bas possible et de fusion le plus élevé de rappel Percent- âge. A partir de la figure 3, on peut observer qu'un bon compromis est atteint pour un certain nombre de groupes d'environ 21. 3 - Evolution de la mesure de la qualité de groupement de fusion (fusion d'étiquettes sémantiques de réalité de terrain) et de rappel (récupération des trajectoires réalité de terrain avec la même étiquette sémantique) en fonction du nombre de grappes. 5 Interaction Analysis 5.1 Clustering de table d'objet mobile dans un deuxième étape de l'analyse hors ligne, on analyse la trajectoire de jects ob- mobiles détectés en même temps que d'autres caractéristiques utiles qui donnent des informations sur l'interaction entre les mobiles et les éléments contextuels de la scène. Les caractéristiques de l'objet mobile suivantes sont utilisées. - m_id: l'étiquette d'identification pour l'objet. - m_type: la classe l'objet appartient à: Personne, groupe, Foule ou bagages. - m_start: temps l'objet est d'abord vu. - m_duration: le temps dans lequel l'objet est observé. - m_significant_event: événement le plus important parmi tous les événements. Il est calculé comme événement le plus fréquent lié à l'objet mobile. - m_trajectory_type: le motif caractérisant la trajectoire de l'objet. J. L. Patino et al. RNTI - X - page 7 5.2 Clustering de la table d'objet mobile Une fois que toutes les mesures statistiques des activités de la scène ont été calculées et l'information a été mis dans le format modèle proposé correspondant, nous visons à découvrir- ing relations complexes qui peuvent exister entre mobiles eux-mêmes des objets et entre les objets mobiles et les objets contextuels de la scène. Pour cette tâche, nous courons une nouvelle procédure de regroupement où agglomératif l'ensemble de données est l'ensemble de la table d'objet mobile, il auto. Chaque enregistrement de la table est ainsi défini cinq caractéristiques comme l'étiquette d'identification ne sont pas prises en compte pour l'algorithme de clustering. Il faut remarquer que ce processus de regroupement, l'ensemble des Tures fea- contient numérique (par exemple le temps de début et de la durée d'un objet) et sym- valeurs Bolić (par exemple, le type d'objet et l'événement significatif) par opposition à le regroupement des trajectoires où toutes les fonctions sont numériques. Pour appliquer l'algorithme de classification agglomérante, nous avons défini une spécifi c métrique pour les valeurs symboliques: Pour le type d'objet () () () () () ()         ⊃⊃⇔ ⊃⊃⇔ = ⇔ = - sinon CrowdtypeobjopPersonGroutypeobjo PersontypeobjopPersonGroutypeobjo typeobjotypeobjo oo ji ji ji ji 1 '' _, '' _ 5,0 '' _, '' _ 5,0 __0 pour le type de trajectoire jiji tctcoo - = - où tci, TCJ sont les centres ou les prototypes des grappes de trajectoire respectivement corres- pondante à oi et oj et résultant de la dernière étape de regroupement trajectoire. Pour l'événement important, nous avons une comparaison logique () ()      = ⇔ = - sinon eventsigoeventsigo oo ji ji 1 __0 6 Résultats Nous présentons le résultat de notre approche sur une séquence vidéo de la durée de métro Torino 48 minutes. Au total notre algorithme détecté 2052 objets mobiles. La figure 4 montre par exemple une personne tracked étiquetés 1 et une foule Suivies des gens étiquetés 534. La figure 5 montre également une personne tracked, étiqueté 58 avec deux nouveaux objets: un groupe de personnes marqué 24 et une exploration de données pour l'extraction de l'activité dans les données vidéo non classés objet suivi marqué 68. en raison de la faible partie inférieure contraste du groupe de personnes, ce groupe a été segmenté en deux objets suivis (au lieu d'une) marquées 24 et 68. Fig. 4 - Une personne avec une étiquette « 1 » et une foule avec étiquette « 534 » sont suivis. a été détecté séjours « fils » à per- portes l'événement. La figure 5 montre la personne suivie étiquetée 1 qui sont restés assez longtemps devant les distributeurs automatiques de billets de validation portant la mention « Portes » pour que l'événement « stays_at » est détecté. Le groupe de personnes à chenilles marquée 24 sur la figure 3 est en interaction avec le numéro de distributeur automatique 2 assez longtemps pour que l'événement « stays_at » à détecter. Dans ces deux chiffres, n'a pas montré l'événement primitif « inside_zone », mais a également été détectée pour les autres objets présents dans la salle. FIGUE. 5 - Une personne avec une étiquette « 1 » et une foule avec étiquette « 534 » sont suivis. Les « séjours de groupe à un distributeur automatique » de l'événement a été détecté. Ensuite, nous avons regroupé les trajectoires des objets mobiles détectés 2052 en 21 grappes employant l'algorithme de clustering hiérarchique. Chaque groupe représente alors un type de trajectoire. La caractérisation des trajectoires donne des informations importantes sur le comportement et les flux de personnes. Par exemple, groupe trajectoire 21 montre que les gens qui viennent utilisé les machines distributrices et déplacer ensuite directement aux portes. 13 grappes Trajectoire montre que les gens qui viennent de portes / portails nord et sortant par les portes sud (voir figure 6). J. L. Patino et al. RNTI - X - page 9 Fig. 6 - groupe Trajectoire 21. Les gens se déplacent des distributeurs automatiques aux portes (à gauche);. groupe Trajectoire 13. Les gens qui viennent des portes va portes au sud (à droite) Quelques connaissances qui peuvent être déduites à partir du regroupement des trajectoires est la suivante: - 64% des gens vont directement aux portes sans s'arrêter à la machine de billets - 70% des personnes viennent de l'entrée nord - aux heures de pointe les gens sont 40% plus rapide pour acheter un billet - la plupart des gens passent 10 secondes dans la salle; FIGUE. 7 - Groupe 38 résultant de l'agrégation de la table d'objet mobile. Le panneau de droite indique les trajectoires des prototypes impliqués dans ce cluster. Une fois que les trajectoires d'objets mobiles a été caractérisée, toutes les informations sont ted formatage selon le tableau sémantique donnée dans la section 4.2. Il est alors possible d'exécuter à nouveau l'algorithme de clustering agglomératif cette fois sur la table d'objet mobile. Certains des groupes trouvés sont maintenant détaillées. Figure 7 (Cluster 38) représente le plus grand groupe trouvé; sa description détaillée est donnée dans le tableau 1. Cluster 38 est constitué de « objets inconnus » pour lesquels aucun cas aussi pu être détectés au cours de la phase de suivi (section 2). Ces objets sont principalement associés à des trajectoires de type 4 « sortie portes - aller à la n orth portes (ligne de trajectoire épais- est). En effet, il est aux portes que la reconnaissance d'objets est le plus difficile à réaliser que la plupart des activités a lieu là-bas. En fait, les deux plus grands groupes (non représentés) de l'extraction de données pour l'extraction de l'activité dans les données vidéo suivantes ont la description similaire, mais impliquent respectivement « personne » et « Groupe personne ». Nous avons donc les connaissances que les portes du Nord sont les plus utilisés par les utilisateurs. Cluster 38 Cluster 6 Nombre d'objets 385 15 types de types d'objets: { 'Unknown'} fréq: 385 types: { 'Personne'} fréq: 15 Heure de début (min) [0,1533, 48,4633] [28,09, 46,79] Durée (s) [0,04, 128,24] [2,04, 75,24] types trajectoire types: { '4' '3' '7'} freq: [381 1 3] types: { '13' '12' '19'} freq: [13 1 1] importants types d'événements: { 'vide '} Freq: 385 types: {' inside_zone_Platform'} Freq: 15 TAB. 1 - Propriétés groupe 38 et le groupe 6 après clusterisation de l'objet mobile ta- ble. La figure 8 présente un autre groupe (6) dont seulement 15 mobiles, mais ils comme étant à l'intérieur de la plate-forme tous en com- mon type d'objet étant la personne et tous ont été détectés. Inter- estingly Ceci nous montre en grappe que les trajectoires de type « 12 » et « 19 » peuvent être liés à tra- jectory « 13 » (représentée sur la figure 6). Dans les trois trajectoires prototypes du point de sortie sont des portes sud. FIGUE. 8 - Groupe 6 résultant de l'agrégation de la table d'objet mobile. Le panneau de droite indique les trajectoires des prototypes impliqués dans ce cluster. 7 Conclusion Dans cet article, il a été démontré comment les techniques de regroupement peuvent être appliquées sur des données vidéo pour l'extraction d'informations significatives. regroupement hiérarchique première a été appliquée afin d'obtenir les trajectoires des prototypes qui caractérisent les flux de personnes dans le sous-sol. Ensuite, nous appliquons dans une deuxième étape à nouveau la classification hiérarchique dans le but de réaliser la prise de découverte de connaissances en compte d'autres informations significatives en plus tion comme le mo- type de l'objet détecté et son événement important. Pour cette fin, nous J. L. Patino et al. RNTI - X - page 11 a créé un format de modélisation des connaissances spécifiques qui rassemble toutes les informations à partir d'objets suivis d'intérêt sur la scène. Ce type de représentation permet à l'utilisateur final d'explorer les interactions entre les personnes et les objets contextuels de la scène. De cette façon, il est effectivement possible d'obtenir des statistiques sur l'activité souterraine et ainsi optimiser res- sources disponibles. Nous avons défini des distances sémantiques qui nous permettent de relier différents types d'objets et types de trajectoires différentes. Ce faisant nous travaillons directement sur toutes les fonctions CHAR acterising objets mobiles et d'analyser les variables hétérogènes. Cela nous permettra de trouver des relations entre les gens, leurs trajectoires et leurs occurrences. Dans notre travail d'avenir, nous allons inclure une phase d'apprentissage pour mieux définir les modèles d'objet de la scène et de diminuer le nombre de détection « inconnu » des objets. Nous chercherons à ajouter des fonctionnalités plus significatives qui peuvent caracté- terise une trajectoire. Nous travaillerons aussi pour améliorer les distances sémantiques que nous avons implémentées par exemple que de meilleures relations peuvent être extraites. Références Anjum N., Cavallaro A. (2007). calibrage de la caméra à l'unité d'analyse de comportement sur la base trajectoire, Proceedings of IEEE conférence sur la base surveil- lance et le signal vidéo de pointe, AVSS'07, pp 6. Avanzi A., F. Bremond, Tornieri C, Thonnat M. (2005). Conception et évaluation d'une plate-forme de surveillance des activités ligent tuelle, EURASIP, 2359-2374. Benini, S .; Bianchetti, A .; Leonardi, R .; Migliorati, P. (2006). Extraction des importants résumés vidéo par Dendrogramme Analyse, IEEE Conférence internationale sur le traitement de l'image, 133-136. J. Blatak (2005). Premier ordre motifs fréquents dans Text Mining, Proceedings of EPIA, 344 -. 350. Chia-Hui CH, Kayed, M., Giri, M. R., Shaalan, K.F. (2006). A Surve y de l'information sur le Web Systèmes d'extraction, IEEE Transactions sur les connaissances et l'ingénierie des données, 18: 1411- 1428. Ewerth R., Freisleben B. (2007). Apprentissage semi-supervisé pour la recherche vidéo sémantique, ceedings Pro- de la 6e conférence internationale ACM sur la recherche d'images et de vidéo CIVR '07. Facca FM., Lanzi PL. (2005). Exploitation minière connaissances intéressantes de weblogs: une enquête, génie DataKnowledge, 53: 225-241. Fusier F., Valentin V., F. Brémond, M. Thonnat, Borg D., M. Thirde, Ferryman J. (2007) Comprendre la vidéo pour l'activité complexe de reconnaissance. Vision et machine de Applica- Journal, 18: 167-188. Georis B., F. Bremond, M. Thonnat, Macq B. (2003). Utilisation d'une méthode d'évaluation et de diagnostic pour améliorer le suivi Performances, Actes de la 3e Conférence Inter- IASTED tional sur la visualisation, l'imagerie et de traitement d'image (VIIP), 2. Kaufman L. et P. Rousseeuw J. (1990). Groupes de données dans la recherche. Introduction à l'analyse Cluster. New York: Wiley. L'exploration de données pour l'extraction de l'activité dans les données vidéo Lemoine J., H. Benhadda, Ah-Pine J. (2006). Classement non de documents supervisee Hétérogènes: Application au corpus '20 Newsgroups’, la 11e Conférence internationale IPMU, 3: 2538-2544. Marcotorchino F., P. Michaud (1981). Agrégation des en classification automa- similarités Que, Revue de Statistique Appliquée, 30. McCurley K.S., Tomkins, A. (2004). Mines et découverte de connaissances à partir du Web, ceedings Pro- du 7e Symposium international sur les Architectures parallèles, les algorithmes et les réseaux, 4-9. Naftel A., Khalid S. (2006). Objet le classement des trajectoires spatio-temporelles en utilisant l'apprentissage dans le VISED sans sur- coefficient caractéristique espace, tranactions. des systèmes multimédias, 12: 45-52. J. Oh, Bandi B. (2002). cadre d'exploration de données multimédia pour des séquences vidéo brutes, des données multimédia extraction MDM / KDD, 1-10. Patino J.L, Benhadda H., Corvee E., F. Bremond, Thonnat M. (2007) Modélisation vidéo-données et Discovery, Conférence internationale sur l'ingénierie de l'information visuelle VIE 2007, pp 9. Porikli, F. (2004). L'apprentissage des modèles de trajectoire de l'objet par le regroupement spectral, IEEE Interna- tional Conference sur Multimedia and Expo, ICME '04, 2: 1171-1174. Vu VT., Bremond F., Thonnat M. (2003). Interprétation automatique vidéo: Un nouvel algorithme de reconnaissance de scénario temporel, Actes du IJCAI'03, 1295-1302. J. Xing, Ah-Hwee T. (2005). Exploitation minière connaissance ontologique du texte spécifique à domaine docu- ments, cinquième IEEE Conférence internationale sur l'exploration de données, 4 pp. Résumé L'exploration de larges bases de Données techniques vidéo is une tache Qui DEVIENT possible Grâce aux Avancées Dans la détection et le Suivi d « objets. Les methods d'information de fouille le regroupement Comme Sont typiquement employés. Celles-ci were principa- la répandrai lement segmentation Appliquées / indexation vidéo l'extraction de Mais sur l'activité Connaissances Dans la vidéo Présente was only Partiellement adressee. Dans mes this article Présentons commentaire NOUS techniques SCÉ PEUVENT Être utilisées répandrai de l'informations Traiter vidéo répandrai l'extraction de connaissances heuristiques. Tout d'Abord, les objets d'en interest temps Sont détectés réel. Salle de bains, Dans un treatment Supplémentaire, nous recherchons à des nou- velles Extraire en deux etapes Connaissances: 1) l'extraction des motifs characteristics des Trajectoires des personnes Dans la vidéo. 2) l'extraction des motifs d'interaction Entre les personnes et les objets contextual Dans la scène. Dans les deux CAS, nous appliquons un regroupement hiérarchisée Que agglomératif. Nous Présentons des Résultats sur des vidéos obtenus du métro de Turin (Italie)