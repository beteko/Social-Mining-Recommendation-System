 Vers un cadre évolutif de classification non supervisée Mohamed Charouel Minyar Sassi Hidri Mohamed Ali Zoghlami Université Tunis El Manar Ecole Nationale d’Ingénieurs de Tunis BP 37 le Belvédère 1002 Tunis Tunisie { mohamed charouel minyar sassi} enit rnu tn ma zoghlami gmail com Résumé La classification non supervisée clustering évolutive surpasse géné ralement par celle statique en produisant des groupes de données clusters qui reflètent les tendances à long terme tout en étant robuste aux variations à court terme Dans ce travail nous présentons un cadre différent pour le clustering évo lutif d’une manière incrémentale par un suivi précis des variables de proximité temporelles entre les objets suivis par un clustering statique ordinaire 1 Introduction Dans de nombreuses applications pratiques de gestion de clusters résultat d’une opération de classification non supervisée clustering les objets à classifier évoluent dans le temps Le but est donc d’obtenir des clusters optimaux à chaque pas de temps Falkowski et al 2006 Tang et al 2008 et Zhang et al 2009 ont proposés des méthodes de clustering évolutif dans le but de produire des clusters optimaux qui reflètent les dérives à long terme dans les objets tout en étant robuste aux variations à court terme Chi et al 2009 ont développé cette idée en proposant deux cadres évolutifs pour le clustering spectral PCQ Preserving Clus ter Quality et PCM Preserving Cluster Membership Les deux cadres ont été proposés afin d’optimiser la modification de la fonction de coût proposée initialement par Chakrabarti et al 2006 Notre travail adapte le principe d’incrémentabilité afin de le généraliser à un ensemble d’algorithmes de clustering Le cadre proposé consiste à estimer les états de données à l’aide des proximités qui sont à la fois actuels et passés Puis il effectue un clustering statique sur les estimations de ces états Ce cadre de suivi de clustering évolutif d’une manière incrémen tale a été utilisé pour étendre une variété d’algorithmes de clustering statiques tels que les C Moyennes Floues CMF de Bezdek 1984 les k moyennes de Mac Queen 1967 et les approches spectrales de clustering présentées par Filippone et al 2008 Le reste de ce papier est organisé comme suit en section 2 nous présentons le cadre évolutif du clustering La section 3 présente les résultats d’expérimentation du cadre proposé sur une variété différente d’algorithmes de clustering statiques La section 4 conclue le papier et présente les travaux futures Vers un cadre évolutif de classification non supervisée 2 Cadre de clustering évolutif Nous traitons le clustering évolutif comme étant un problème de suivi par un regroupement statique ordinaire Pour ceci nous étudions des matrices de proximité notées W t comme la réalisation d’un processus aléatoire non stationnaire indexé par des mesures de temps discrètes Elles sont données par l’équation 1 W t = Ψt +N t t = 0 1 2 1 Où W t est une matrice déterministe inconnue des états non observés et N t est une matrice de bruit de moyenne nulle Ψt change au fil du temps pour réfléchir à long terme des dérives dans les proximités Nous présentons une approche plus simple qui implique une mise à jour recursive des estimations de ces états en utilisant un seul paramètre α nommé facteur d’oubli 2 1 Estimation de la matrice de proximité Une meilleure estimation peut être obtenue en utilisant un lissage de la matrice de proximité W t définie dans l’équation 2 W t = αtW t−1 + 1− αt W t pour t ≥ 1 et W 0 = W 0 2 Cette matrice lissée est un candidat dans l’estimation de Ψt Des méthodes d’estimation ont été proposées dans Ledoit et Wolf 2003 Schäfer et Strimmer 2005 et Chen et al 2010 D’une manière générale ils calculent la différence entre la matrice de proximité réelle et lissée donnée par l’équation 3 L αt =∥ W t−1 −Ψt ∥2F= n∑ i=1 n∑ j=1 W tij −Ψ t ij 2 3 Puisque N t N t−1 N0 sont mutuellement indépendants et ont une moyenne nulle et la va riance conditionnelle de W t−1 est nulle le risque de l’espérance conditionnelle de la fonction de perte peut être alors exprimé dans l’équation 4 R αt = n∑ i=1 n∑ j=1 { 1− αt 2V ar ntij + αt 2 W t−1 −Ψtij 2} 4 La dérivée première correspondante au facteur d’oubli est donnée par l’équation 5 αt = ∑n i=1 ∑n j=1 V ar n t ij ∑n i=1 ∑n j=1{ W t−1 −Ψtij 2 + V ar ntij } 5 Nous pouvons confirmer que αt minimise les risques parce que R” αt ≥ 0 pour tous les αt Le facteur d’oubli αt conduit à la meilleure estimation en terme de minimisation des risques Il nécessite la connaissance de la matrice de proximité réelle Ψt qui est ce que nous essayons d’estimer et la variance du bruit V ar N t Étant donné que nous traitons des adhésions des objets aux clusters nous proposons de faire les hypothèses suivantes sur la structure de Ψt et V ar N t M Charouel et M Sassi Hidri – Ψtii = Ψ t jj pour deux objets quelconques i et j qui appartiennent au même cluster – Ψtij = Ψ t lm pour deux objets distincts i j et deux objets quelconques distincts l m de telle sorte que i l appartiennent au même cluster et j m appartiennent au même cluster 2 2 Estimation adaptative du facteur d’oubli Nous pouvons échantillonner sur chaque bloc afin d’estimer les entrées de Ψt et de V ar N t et les remplacer pour obtenir une estimation α̂t de αt En effet pour estimer les entrées de Ψt = E[W t] nous procédons comme suit – Pour deux objets distincts i et j du même cluster c nous pouvons estimer W tij en utilisant la moyenne d’échantillon donnée par l’équation 6 Ê[W tij ] = 1 | c | | c | −1 ∑ l∈c ∑ m∈c m ̸=l W tlm 6 De même nous estimons Ψtii dans l’équation 7 Ê[Ψtii] = 1 | c | ∑ l∈c W tll 7 – Pour les objets distincts i dans les clusters c et d avec c ̸= d nous estimons Ψtij dans l’équation 8 Ê[W tij ] = 1 | c || d | ∑ l∈c ∑ m∈d W tlm 8 2 3 Fonction générique évolutive La fonction générique évolutive est donnée comme suit Algorithm 1 EvolClus Entrée Matrice de données Sortie Centres de clusters Ct au moment t 1 Ct ⇐ Ct−1 2 Pour chaque i = 1 2 Faire 3 Calculer Ê[W t] 4 Calculer V̂ ar W t 5 Calculer α̂t par substitution des estimations Ê[W t] et V̂ ar[W t] 6 Ŵ t ⇐ α̂t Ŵ t−1 + [1− α̂t ]W t 7 Fin Pour 8 Retourner Ct 3 Expérimentation Nous allons tester la capacité du cadre à s’adapter à un changement dans l’appartenance aux clusters Pour ceci nous allons varier les αt et voir le comportement de deux cadres Vers un cadre évolutif de classification non supervisée FIG 1 – Variation de l’indice de Rand en fonction des pas de temps selon les cadres statique et évolutif des k moyennes selon les cadres statique et évolutif avec αt fixe et estimé FIG 2 – Variation de l’indice de Rand en fonction des pas de temps selon les cadres statique et évolutif du CMF selon les cadres statique et évolutif avec αt fixe et estimé FIG 3 – Variation de l’indice de Rand en fonction des pas de temps selon les cadres statique et évolutif du clustering spectral avec αt fixe et estimé M Charouel et M Sassi Hidri Pour les k moyennes la figure 2 montre que si nous estimons αt la valeur de l’indice de Rand 1971 est plus grande pour cadre évolutif Par contre avec αt = 0 5 la figure 2 montre qu’il y a égalité entre l’algorithme des k moyennes dans les cadres statique et évolutif D’après la figure 3 nous remarquons que lorsque nous estimons αt la valeur de l’indice de Rand est plus grande dans le cadre évolutif que celui statique L’algorithme de CMF statique ne fonctionne pas bien dès que les clusters commencent à se chevaucher vers environ le 9ème pas de temps Avec αt = 0 5 les deux cadres fournissent les mêmes résultats Pour assurer le bon fonctionnement du cadre proposé nous allons étendre sa comparaison avec les résultats de deux cadres PCQ et PCM de Chi et al 2009 Le tableau 1 montre que le cadre proposé avec l’algorithme de CMF reste toujours plus efficace que les deux cadres PCQ et PCM puisque le résultat de la valeur de l’indice de Rand 1971 est toujours plus grand Méthode Paramètre Indice de Rand CMF statique 0 796 CMF incrémental estimation αt 0 963 PCQ at formés 0 910 at = 0 5 0 823 PCM at formés 0 842 at = 0 5 0 810 TAB 1 – Etude comparative des indices de Rand entre PCM PCQ et CMF incrémental De même nous comparons l’approche spectrale de clustering évolutif avec celle statique avec un αt estimé et fixe La figure 3 montre que l’algorithme fonctionne bien avec l’aspect incrémental et donne une valeur de l’indice de Rand 1971 plus grande que celle obtenue avec le cadre statique Ce qui implique le bon fonctionnement du cadre avec les approches spectrales Avec αt = 0 5 nous remarquons d’après 3 que le comportement est le même pour les deux cadres statique et évolutif 4 Conclusion Le cadre proposé dans ce travail surpasse généralement par celui statique en produisant des clusters qui reflètent les tendances à long terme tout en étant robuste aux variations à court terme Il est universel dans le sens qu’il permet à n’importe quel algorithme de clustering sta tique d’être étendu à un caractère évolutif qui fournit une méthode explicite pour la sélection du facteur d’oubli contrairement aux méthodes existantes L’objectif était de suivre avec pré cision la matrice réelle de proximité à chaque pas de temps Cela a été accompli en utilisant une mise à jour récursive avec un facteur d’adaptation d’oubli qui contrôle la quantité de poids à appliquer aux données historiques L’expérimentation a donné des résultats reflétant la performance du cadre adapté dans la performance de l’opération du clustering par rapport à celle statique Comme perspectives de travail nous proposons d’élargir les expérimentations sur d’autres jeux de données et la possibilité d’étendre ce cadre afin qu’il puisse supporter des larges BD par réduction de l’échelle et l’échantillonnage des données Vers un cadre évolutif de classification non supervisée Références Bezdek J 1984 Fcm The fuzzy c means clustering algorithm Computers et Geo sciences 10 2 3 191–203 Chakrabarti D R Kumar et A Tomkins 2006 Evolutionary clustering In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data mining 554–560 Chen A Y Wiesel C Eldar et A Hero 2010 Shrinkage algorithms for mmse covariance estimation IEEE Transactions on Signal Processing 58 10 5016–5029 Chi Y X Song D Zhou K Hino et B Tseng 2009 On evolutionary spectral clustering ACM Transactions on Knowledge Discovery from Data 3 4 603–621 Falkowski T J Bartelheimer et M Spiliopoulou 2006 Mining and visualizing the evo lution of subgroups in social networks In Proceedings of IEEE WIC ACM International Conference on Web Intelligence 52–58 Filippone M F Camastra F Masulli et S Rovetta 2008 A survey of kernel and spectral methods for clustering Pattern recognition 41 1 176–190 Ledoit O et M Wolf 2003 Improved estimation of the covariance matrix of stock returns with an application to portfolio selection Journal of Empirical Finance 10 5 603–621 Mac Queen J 1967 Some methods for classification and analysis of multivariate obser vations In Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability 281–297 Rand W 1971 Objective criteria for the evaluation of clustering methods Journal of the American Statistical Association 66 846–850 Schäfer J et K Strimmer 2005 A shrinkage approach to large scale covariance matrix estimation and implications for functional genomics Statist Applic Genetics Molec Biol ogy 4 32 Tang L H Liu J Zhang et Z Nazeri 2008 Community evolution in dynamicmulti mode networks In Proceedings of the 14th ACM SIGKDD International Conference on Knowl edge Discovery and Data Mining 677–685 Zhang J Y Song G Chen et C Zhang 2009 On line evolutionary exponential family mix ture In Proceedings 21st International Joint Conference on Artificial Intelligence 1610– 1615 Summary Evolutionary clustering surpasses generally the static one by producing clusters that reflect the long term trends while being robust to variations in the short term Several algorithms have been proposed while adopting these aspects They often operate by adding a fine temporal penalty cost function of a static clustering method In this work we adopt a different approach for evolutionary clustering by accurate monitoring of a proximity temporal variable between objects tracked by an ordinary static clustering 