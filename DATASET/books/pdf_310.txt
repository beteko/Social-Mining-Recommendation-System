 Clustering de séquences d’évènements temporels Romain Guigourès Dominique Gay Marc Boullé Fabrice Clérot Orange Labs prenom nom orange com Zalando prenom nom zalando de Résumé Nous proposons une nouvelle méthode de clustering et d’analyse de séquences temporelles basée sur les modèles en grille à trois dimensions Les séquences sont partitionnées en clusters la dimension temporelle est discrétisée en intervalles et la dimension évènement est partitionnée en groupes La grille de cellules 3D forme ainsi un estimateur non paramétrique constant par morceaux de densité jointe des séquences et des dimensions des évènements temporels Les séquences d’un cluster sont ainsi groupés car elles suivent une distribution similaire d’évènements au cours du temps Nous proposons aussi une méthode d’exploitation du clustering par simplification de la grille ainsi que des indica teurs permettant d’interpréter les clusters et de caractériser les séquences qui les composent Les expériences sur des données artificielles ainsi que sur des données réelles issues de DBLP démontrent le bien fondé de notre approche 1 Introduction Les données contenant une information temporelle constituent un défi pour le processus de découverte de connaissances Yang et Wu 2006 Les données temporelles sont complexes dans le sens où un objet de la base est décrit par une ou plusieurs séquences d’éléments or donnés dans le temps Selon la nature des éléments temporels catégoriels ou numériques ponctuels ou continus dans le temps il existe une grande diversité de méthodes d’extrac tion de connaissances Mörchen 2007 Ici nous nous intéressons aux données de séquences d’évènements catégoriels et ponctuels où chaque évènement d’une séquence est associé à un temps t et que nous appelons simplement séquences d’évènements temporels La fouille de séquences d’évènements temporels trouve des applications dans de nombreux domaines e g dans le domaine médical Patnaik et al 2011 explore des bases de dossiers médicaux électro niques de patients à la recherche de motifs d’évènements temporels fréquents dans le domaine du Web Masseglia et al 2008 et Saleh et Masseglia 2011 extraient des comportements fré quents d’utilisateurs par période de temps en sciences sociales Studer et al 2010 cherche à grouper des individus selon leur parcours de vie La majeure partie des efforts de recherche s’est focalisée sur l’extraction de motifs fréquents dans les données de séquences d’évène ments temporels ou TAS pour “Temporally Annotated Sequences” voir e g Giannotti et al 2006 Dans cet article nous nous intéressons au problème de clustering de séquences le but est de créer des groupes de séquences qui partagent des caractéristiques similaires Dans la 191 Clustering de séquences temporelles plupart des méthodes de l’état de l’art il est nécessaire de définir une mesure de dis similarité entre séquences ainsi que le nombre de clusters à trouver et d’autres paramètres e g Studer et al 2010 utilisent l’approche des k medoids couplée à une distance basée sur les opérations d’insertion suppression et de substitution dont les coûts sont à définir de transitions dans une séquence Le paramétrage de telle méthode est souvent complexe et peut dépendre du domaine d’application et de la quantité de données dont on dispose Le choix d’un clustering trop fin un grand nombre de clusters ne garantit pas que les clusters sont statistiquement valides et peut mener au sur apprentissage alors qu’un clustering grossier peu de clusters nous apporte une information peu précise sur la structure sous jacente des données et nous offre ainsi un ré sumé trop général des données De plus la dimension temporelle des séquences d’évènements temporels est primordiale et doit être prise en compte pour grouper des séquences similaires i e qui suivent la même distribution d’évènements au cours du temps Notre contribution est la suivante Nous proposons KHC une méthode de co clustering de séquences d’évènements temporels basée sur les modèles en grille Bondu et al 2013 le co clustering Dhillon et al 2003 Nadif et Govaert 2010 consiste à partitionner simultanément et de manière cohérente les trois dimensions de la base de séquences d’évènements tempo rels ici les séquences sont partitionnées en clusters ainsi que les évènements et le temps est discrétisé en intervalles Nous en déduisons une mesure de dissimilarité entre clusters nous permettant d’accéder par classification hiérarchique ascendante à la granularité nécessaire à l’analyse En section 3 nous validons expérimentalement la méthode sur des données synthé tiques et réelles et proposons des indicateurs utiles à l’interprétation des clusters révélés par la méthode 2 Séquences temporelles modèles en grilles et clustering Contexte et notations Une séquence s d’évènements temporels de taille k > 0 est un en semble d’observations ordonnées si = 〈 ti1 ei1 ti2 ei2 tiki eiki 〉 tel que ∀j 1 ≤ j ≤ iki tj ∈ R+ et ej ∈ E avec E un ensemble non ordonné d’évènements catégoriels Une base de données de séquences temporelles est simplement un ensemble de séquences temporelles ainsi définies D = {s1 sn} Nous proposons de représenter un ensemble de séquences temporelles par une base de données à trois variables ou dimensions S pour les identifiants de séquences T pour la variable temps et E pour la variable évènement Dans la suite un objet s t e de D sera appelé un point de la base Cette représentation tridimensionnelle des données se prête bien à l’usage des modèles en grilles Bondu et al 2013 pour le clustering – plus précisément nous utilisons le cadre de travail MODL Minimum Optimized Description Length et la méthode de coclustering KHC 1 déjà instanciée dans le cas des données fonctionnelles Boullé 2012 Le but est de partitionner les variables catégorielles identifiants de séquences et évènements et de discrétiser la variable numérique “temps” Le résultat est une grille tridimensionnelle dont les cellules sont définies par un groupe d’identifiants de séquence un groupe d’évènements et un intervalle de temps Le meilleur modèle M i e la grille optimale est la grille la plus probable connaissant les données Pour obtenir le modèle de grille optimalM nous utilisons une approche Bayesienne dite Maximum A Posteriori MAP et parcourons l’espace des modèles en optimisant un critère 1 Khiops Coclustering khiops com 192 R Guigourès et al Bayesien noté cost Le critère cost établit un compromis entre la précision et la robustesse du modèle en grille et est défini comme suit cost M = − log p M | D ︸ ︷︷ ︸ posterior = − log p M ︸ ︷︷ ︸ prior × p D |M ︸ ︷︷ ︸ vraisemblance 1 En utilisant un prior hiérarchique sur les paramètres de la grille uniforme 2 à chaque étage de la hiérarchie nous obtenons une expression analytique exacte du critère d’évaluation à optimi ser cost déduit de la même manière que Boullé 2012 Critère d’évaluation Un modèle de grille pour le coclustering de séquences temporelles est optimal s’il minimise le critère cost cost M = log n+ log a+ logN + logB n kS + logB a kE 2 + kS∑ iS=1 log NiS + niS − 1 niS − 1 + kE∑ iE=1 log NiE + niE − 1 niE − 1 + log N + k − 1 k − 1 + logN − kS∑ iS=1 kT∑ jT=1 kE∑ iE=1 logNiSjT iE + kS∑ iS=1 logNiS − n∑ i=1 log nSi + kE∑ iE=1 logNiE − a∑ i=1 log nEi + kT∑ jT=1 logNjT où n est le nombre de séquences a le nombre d’évènements de E N le nombre total d’évè nements temporels i e le nombre de points de la base kS resp kE kT le nombre de clusters de séquences resp le nombre de clusters d’évènements le nombre d’intervalles de temps k = kSkEkT le nombre de cellules de la grille NiS resp NjT NiE NiSjT iE est le nombre cumulé de points du cluster de séquences iS resp dans l’intervalle de temps jT du cluster d’évènements iE de la cellule iS jT iE de la grille niS resp niE le nombre de séquences dans le cluster iS resp le nombre de valeurs d’évènements dans le cluster iE et enfin nSi resp n E i le nombre de points de la séquence i resp le nombre de points ayant pour valeur d’évènement i Notons que B n kS est le nombre de divisions de n éléments en kS sous ensembles et B a kE est défini de manière similaire Les deux premières lignes correspondent à la probabilité a priori du modèle et constituent le terme de régularisation du modèle les modèles complexes beaucoup de clusters pour les va riables catégorielles et ou beaucoup d’intervalles pour la variable numérique seront pénalisés Les deux dernières lignes correspondent à la vraisemblance du modèle les modèles les plus proches des données seront préférés le cas extrême avec un point par cellule aura une vrai semblance maximale mais une probabilité a priori très faible et donc une valeur de cost très forte Une grille avec une faible valeur de cost indique une forte probabilité p M | D de la grille connaissant les données En termes de théorie de l’information le logarithme négatif de probabilités s’interprète comme une longueur de codage Ainsi selon le principe MDL Mini mum Description Length le critère cost peut s’interpréter comme la longueur de codage du 2 L’uniformité se situe à chaque étage de la hiérarchie le prior n’est donc pas uniforme dans ce cas l’approche MAP n’est pas une simple maximisation de la vraisemblance 193 Clustering de séquences temporelles modèle de grille plus la longueur de codage des données connaissant le modèle et une faible valeur de cost indique aussi une forte compression des données en utilisant le modèle M Le critère cost est optimisé en suivant une stratégie gloutonne ascendante i on part de la grille au grain le plus fin ii on considère toutes les fusions possibles entre groupes de valeurs ou intervalles et iii on réalise la meilleure fusion si le critère cost décroit après fusion Ce processus est réitéré tant qu’il y a amélioration du critère La grille obtenue constitue une es timation de la densité jointe des séquences et des dimensions des évènements temporels i e des trois variables S T et E Notons que KHC est libre de tout paramètre utilisateur i e nous n’avons pas à choisir le nombre de clusters de séquences ou d’évènements ni le nombre d’intervalles de temps de plus sa complexité en temps est sub quadratique Θ N √ N logN oùN est le nombre de points de la base – pour les détails complémentaires voir Boullé 2012 Mesure de dissimilarité et simplification de la structure de grille Bien qu’optimale la grille générée par KHC peut s’avérer trop fine pour une analyse directe par un utilisateur e g plusieurs dizaines de clusters de séquences peuvent être générés Nous proposons une méthode de simplification de la grille par fusions successives de clusters ou d’intervalles en choisissant la fusion qui dégrade le moins la qualité de la grille Pour ce faire nous introduisons une mesure de dissimilarité entre deux clusters ou intervalles qui caracté rise l’impact de la fusion sur le critère cost Soient c 1 et c 2 deux clusters d’une dimension de la grille M i e deux groupes de valeurs d’identifiants de séquences ou d’évènements ou deux intervalles contigus de temps Soit Mc 1∪c 2 le modèle de grille après avoir fusionné c 1 et c 2 La dissimilarité ∆ c 1 c 2 entre deux clusters est définie comme la différence du critère cost après et avant fusion ∆ c 1 c 2 = cost Mc 1∪c 2 − cost M 3 Ainsi si l’on fusionne les clusters qui minimisent ∆ nous obtenons la grille sub optimale M ′ avec un grain plus grossier i e simplifiée qui dégrade le moins le critère cost et donc avec une perte d’information minimale par rapport à la grille avant fusion Le taux d’information de la nouvelle grille M ′ est défini par τ M ′ = cost M ′ − cost M∅ cost M − cost M∅ 4 où M∅ est le modèle nul i e la grille dont aucune dimension n’est partitionnée En construi sant ainsi une hiérarchie ascendante des clusters en partant de M et au pire jusqu’à M∅ l’utilisateur pourra s’arrêter au niveau de grain voulu et nécessaire pour une analyse en contrô lant le nombre de clusters ou le pourcentage d’information gardée Notons que les fusions s’effectuent indistinctement sur toutes les dimensions en fonction de ∆ 3 Validation expérimentale Dans cette section nous proposons des expériences sur données simulées afin de démontrer l’efficacité de la méthode en termes de pertinence pour retrouver les motifs simulés dans les données ainsi qu’en terme de temps de calcul pour des données allant jusqu’au million de points Nous rapportons aussi les résultats de la méthode sur un jeu de données réelles Les expériences sont réalisées sur un PC de bureau cadencé à 3 8GHz avec 2Go de RAM 194 R Guigourès et al 3 1 Données simulées Exemple à 2 motifs Considérons deux motifs M1 et M2 définis sur le domaine de valeurs de temps T = [0 1000] ⊆ R+ et l’ensemble d’évènements E = {a b c d e f g h i j k l} tels que M1 M2 si t ∈ TM11 = [0 250] alors e ∈ E M1 1 = {a b c} si t ∈ T M2 1 = [0 100] alors e ∈ E M2 1 = {j k l} si t ∈ TM12 =]250 500] alors e ∈ E M1 2 = {d e f} si t ∈ T M2 2 =]100 400] alors e ∈ E M2 2 = {g h i} si t ∈ TM13 =]500 750] alors e ∈ E M1 3 = {g h i} si t ∈ T M2 3 =]400 600] alors e ∈ E M2 3 = {d e f} si t ∈ TM14 =]750 1000] alors e ∈ E M1 4 = {j k l} si t ∈ T M2 4 =]600 1000] alors e ∈ E M2 4 = {a b c} Considérons 10 séquences temporelles générées selon le motif M1 et 10 séquences tempo relles selon le motif M2 nous menons aussi les mêmes expériences pour 50 et 100 séquences générées par motif Nous générons une base de données D de 220 points soit en moyenne plus de 5 104 points par séquence Chaque point est un triplet de valeurs dont un identifiant de séquence choisi aléatoirement parmi 20 une valeur de temps aléatoire t sur T suivant la loi uniforme et une valeur d’évènement générée en fonction du motif Mi i e une valeur choisie aléatoirement dans l’ensemble Mi t Par ailleurs nous considérons des versions bruitées de cette base à différents niveaux de bruits η = {0 1 0 2 0 3 0 4 0 5} Lors de la génération d’un point la probabilité que la valeur d’évènement respecte le motif Mi est p e ∈Mi t = 1− η et p e ∈ {E \Mi t } = η 0 3 0 4 0 5 0 6 0 7 0 8 0 9 1 A d ju st e d R a n d I n d e x η=0% η=10% η=20% η=30% η=40% CM10 0 0 1 0 2 0 3 A d ju st e d R a n d I n d e x η=40% η=50% a 0 3 0 4 0 5 0 6 0 7 0 8 0 9 1 A d ju st e d R a n d I n d e x η=0% η=10% η=20% η=30% η=40% CM50 0 0 1 0 2 0 3 A d ju st e d R a n d I n d e x η=40% η=50% 0 3 0 4 0 5 0 6 0 7 0 8 0 9 1 A d ju st e d R a n d I n d e x η=0% η=10% η=20% η=30% η=40% CM100 0 0 1 0 2 0 3 A d ju st e d R a n d I n d e x η=40% η=50% b c FIG 1 – Evolution de l’ARI pour des bases de séquences suivant 2 motifs pour CM = 10 50 et 100 séquences par motif et à différents niveaux de bruit en fonction du nombre de points N Nous appliquons KHC à des sous ensembles de D de tailles croissantes faisant varier ainsi le nombre de points de 21 à 220 Nous calculons la valeur de l’indice de Rand ajusté ARI pour chaque grille générée pour évaluer la concordance entre les clusters de séquences trouvés par KHC et les deux motifs sous jacents Les résultats sont rapportés dans les figures 1 abc Nous observons que pour des petits sous ensembles de données de D il n’y a pas assez de points 195 Clustering de séquences temporelles pour que KHC découvre de motifs significatifs aucun cluster de séquences n’est découvert pour N ≤ 64 i e en moyenne 3 points par séquences Pour CM = 10 10 séquences par motifs en figure 1 a à partir de N = 128 points soit en moyenne seulement 6 points par séquence ARI = 1 et les deux motifs sous jacents sont découverts Nous remarquons aussi que pour un niveau de bruit η ≤ 0 1 N = 128 points suffisent encore à trouver les deux clusters de séquences puis plus le bruit augmente plus le nombre de points nécessaires à la découverte des deux motifs augmente Enfin augmenter le nombre de points jusqu’à 220 ne provoque pas de sur apprentissage la valeur de ARI est stable à 1 Les mêmes observations tiennent lorsque CM = 50 ou CM = 100 nous observons aussi que plus il y a de courbes par motifs i e plus CM est grand plus il faut de points pour découvrir les deux motifs Temps de calcul La figure 2 rapporte les temps de calcul des différentes versions de bases de données à 2 motifs pour CM = 10 50 100 en fonction du nombre de points D’une manière générale on observe que le temps de calcul augmente comme attendu avec le nombre de points d’apprentissage mais aussi avec CM et le niveau de bruit Retenons aussi que pour la base la plus difficile i e N = 220 CM = 100 soit en moyenne 5200 points par séquence et η = 0 5 KHC retrouve les motifs recherchés en moins de 1h30 Ici le temps de calcul dépend du nombre de valeurs de temps différentes prises dans T potentiellement 220 car lors de la discrétisation de T KHC explore toutes les coupures possibles entre deux valeurs de temps présentes dans les données nous avons réalisé les mêmes expériences avec des valeurs de temps entières prises dans T dans ce cas pour N = 220 CM = 100 et η = 0 5 KHC trouve les motifs recherchés en 13 minutes 2000 2500 3000 3500 4000 4500 5000 R u n ti m e s CM100 η=50% CM100 η=40% CM100 η=30% CM100 η=20% 0 500 1000 1500 2000 16384 32768 65536 131072 262144 524288 1048576 R u n ti m e s CM100 η=10% CM100 η=0% 2000 2500 3000 3500 4000 4500 5000 R u n ti m e s CM100 η=30% CM50 η=30% CM10 η=30% 0 500 1000 1500 2000 16384 32768 65536 131072 262144 524288 1048576 R u n ti m e s a b FIG 2 – Temps de calcul en fonction du nombre de points du nombre de séquences par motifs et donc dans la base et du niveau de bruit Visualisation et caractérisation des clusters Considérons la grille tridimensionnelle résul tant de KHC sur la base de données à 2 motifs telle que N = 220 points CM = 10 et η = 0 5 Nous proposons 3 visualisations différentes basées sur la fréquence des cellules l’informa tion mutuelle et le contraste des cellules – chacune d’entre elles apportant une information différente sur les clusters de séquences découverts Bien que KHC génère des grilles tridimen sionnelles la dimension S étant partitionnée en deux clusters de séquences nous proposons des visualisations sur les deux autres dimensions pour chaque cluster de séquences Nous pré sentons ces visualisations dans la figure 3 Visualisation de la fréquence En figures 3M1 a et 3M2 a la plus classique des visualisations consiste à représenter le nombre de points par cellule i e NiSjT iE pour la cellule iS jT iE Nous apercevons déjà les cellules les plus fréquentes qui correspondent à la définition des mo 196 R Guigourès et al tifs sous jacents malgré le niveau de bruit η = 0 5 Visualisation de l’information mutuelle Pour un cluster de séquences ciS l’information mu tuelle entre les variables TπM et EπM issues du partitionnement πM des variables temps et évènement généré par le modèle de grille M est défini comme suit MI TπM EπM = i1=kT∑ i1=1 i2=kE∑ i2=1 MIi1i2 où MIi1i2 = p ci1i2 log p ci1i2 p ci1 p c i2 5 Ainsi les MIi1i2 représentent la contribution de la cellule ci1i2 à l’information mutuelle Si MIi1i2 > 0 alors p ci1i2 > p ci1 p c i2 et on observe un excès d’interactions entre ci1 et c i2 localisé dans la cellule ci1i2 définie par l’intervalle Ti1 et le groupe d’évène ments Ei2 Inversement si MIi1i2 < 0 alors p ci1i2 < p ci1 p c i2 et on observe un déficit d’interactions dans la cellule ci1i2 Enfin si MIi1i2 = 0 alors soit p ci1i2 = 0 au quel cas la contribution à l’information mutuelle est nulle et il n’y a pas d’interactions soit p ci1i2 = p ci1 p c i2 et la quantité d’interactions dans ci1i2 est celle attendue en cas d’in dépendance des partitions En figures 3M1 b et 3M2 b nous rapportons les valeurs des MIi1i2 Les cellules des deux motifs sous jacents apparaissent clairement en rouge en raison d’une forte contribution à l’information mutuelle alors que les points issus du bruit sont mis en évidence par les cellules en bleu Fréquence Information mutuelle Contraste M1 a M1 b M1 c M2 a M2 b M2 c FIG 3 – Visualisation de la fréquence de l’information mutuelle conditionnelle à un cluster de séquences et du contraste pour les 2 clusters trouvés par KHC correspondant aux 2 motifs sous jacents M1 et M2 En abscisses la discrétisation du temps en 7 intervalles et en ordonnées la partition des évènements en 4 groupes E = {a b c} ∪ {d e f} ∪ {g h i} ∪ {j k l} 197 Clustering de séquences temporelles Visualisation du contraste Pour le couple de variables partitionnées à visualiser TπM EπM le contraste entre un contexte i e un cluster de séquences ciS et le reste des clusters de sé quences {ci}i 6=iS est défini comme suit Contraste ciS = MI T πM EπM ciS = i1=kT∑ i1=1 i2=kE∑ i2=1 MIi1i2 iS 6 où MIi1i2 iS = p ci1i2iS log p ci1i2iS p ci1i2 p c iS Comme précédemment le signe des MIi1i2 iS qualifiera le contraste entre ciS et le reste des données i e les clusters de séquences {ci}i 6=iS Les valeurs de MIi1i2 iS sont rapportées dans les figures 3M1 c et 3M2 c Prenons le cluster de séquences de cM1 Les cellules blanches indiquent qu’il n’y a pas de contraste à cet endroit entre cM1 et le reste des données ici cM2 par exemple la cellule [0 100] {g h i} malgré le bruit n’est pas caractéristique de cM1 en effet la probabilité du groupe d’évènements {g h i} dans l’intervalle de temps [0 100] n’est pas significativement différent selon qu’on se trouve dans cM1 ou cM2 De même la cellule [401 500] {d e f} présente un contraste nul puisqu’elle est commune aux deux motifs sous jacents Les cellules rouges indiquent ce qui caractérise cM1 par rapport à cM2 dans ces cellules la probabilité de points est bien supérieure pour cM1 que pour cM2 Les cellules bleues indiquent un contraste négatif la probabilité de points y est plus faible pour cM1 que pour cM2 3 2 Données réelles A partir de la base de données DBLP Ley 2009 nous considérons tous les auteurs qui ont publié des articles parus dans les actes de neuf conférences dont la thématique première est les bases de données et ou la fouille de données CIKM VLDB SIGMOD ICDE ICDM KDD SDM PAKDD PKDD Pour chaque auteur nous considérons l’année de publication et l’évènement lié à la publication i e le nom de la conférence Nous constituons ainsi une base de données de séquences d’évènements temporels à trois dimensions auteur année évè nement Les points de la base sont dupliqués lorsqu’un auteur a publié plusieurs fois dans la même conférence la même année La base D ainsi constituée est composée de plus Base de données Fouille de données VLDB SIGMOD ICDE CIKM KDD SDM PAKDD PKDD ICDM FIG 4 – Dendrogrammme des confé rences de 21000 auteurs qui ont publié de 1975 à 2012 dans neuf conférences distinctes – en tout 58547 points KHC calcule la grille optimale pour D en 215 se condes soit moins de 4 minutes La grille opti male est constituée de 9 groupes d’auteurs 15 in tervalles de temps et 9 groupes d’évènements une conférence par cluster En utilisant la mesure de dissimilarité ∆ pour les clusters d’évènements nous observons que les conférences orientées fouille de données FD sont plus similaires entre elles et il en est de même pour les conférences orientées Base de données BD aussi nous obtenons le den drogramme des conférences en figure 4 Comme attendu pour une résolution à 2 clusters on identifie bien les conférences orientées Base de données et Fouille de Données 198 R Guigourès et al La granularité de la grille optimale est acceptable pour une analyse sans simplification tou tefois pour des raisons de limitation de pages en figure 6 nous détaillons les résultats pour 4 des 9 neuf clusters d’auteurs que nous identifions comme des clusters d’auteurs spécialisés en fouille de données Bien que la grille soit constituée de 9 clusters d’auteurs ces clusters contiennent plusieurs centaines voire milliers d’auteurs De plus la plupart des auteurs ont très peu publié 1 ou 2 fois voir figure 5 dans les conférences de la base Pour analyser cha cun des clusters nous proposons une mesure pour identifier les auteurs les plus typiques d’un cluster 0 10 25 50 100 150 200 250 0 5 0 55 0 6 0 65 0 7 0 75 0 8 0 85 0 9 0 95 1 X P pu bl i A ≤ X FIG 5 – Distribution cumulée empirique du nombre d’auteurs ayant publié X fois soit p publiA ≤ X la probabilité qu’un auteur a publié moins de X fois Typicité d’une valeur d’un cluster Pour une valeur vi d’un cluster c de la partition XM de la variable X selon le modèle de grille M la typicité est définie par τ vi = 1 1− PXM c ∑ cj∈XM cj 6=c PXM cj cost M |c \ v cj ∪ v − cost M 7 où PXM c est la probabilité d’avoir un point avec une valeur du cluster c c \ v est le cluster c duquel on a retiré la valeur v cj ∪ v est le cluster cj auquel on a rajouté la valeur v et M |c \ v cj ∪ v le modèle de grille M qui a subi les modifications précitées Intuitivement une valeur vi est représentative d’un cluster c et dite typique si elle est proche de c et très différente en moyenne des autres clusters cj 6= c Aussi pour un cluster d’auteurs les auteurs qui ont peu publié 1 ou 2 fois voir figure 5 sont souvent moins typiques que ceux qui sont les plus prolifiques puisque si on les déplace vers un autre cluster la différence de cost dans la formule de la typicité sera faible Dans la figure 6 nous présentons pour chacun des quatre clusters d’auteurs un par ligne les auteurs les plus typiques colonne 1 ainsi que la fréquence de publications colonne 2 et le contraste colonne 3 par une grille à deux dimensions Année × Conférence Tout d’abord nous remarquons que les bornes de discrétisation du temps les années de 1975 à 2012 découvertes par KHC suit le lancement des conférences 1975 pour VLDB et SIGMOD 1984 pour ICDE 1993 pour CIKM 1995 pour KDD 1998 pour PAKDD 3 2001 pour ICDM et SDM puis à partir de 2002 on obtient un intervalle par année à l’exception de 2010 2011 3 PAKDD a été lancé en 1997 toutefois les publications de cette année ne sont pas référencées par DBLP 199 Clustering de séquences temporelles Auteurs typiques Fréquence Contraste FIG 6 – Visualisations des clusters d’auteurs des auteurs les plus typiques des clusters et du contraste entre clusters 200 R Guigourès et al En ce qui concerne les auteurs le premier cluster regroupe les auteurs très prolifiques avec un large spectre de publications et qui publient dans les neuf conférences depuis 1984 Sans surprise les plus typiques de ce cluster sont les chercheurs seniors et reconnus dans leur com munauté Ce qui caractérise ce groupe d’auteurs par rapport aux autres auteurs de la base le contraste c’est leur excès de publications à ICDM KDD SDM entre 2003 et 2011 Le deuxième cluster regroupe les auteurs “jeunes” spécialisés en FD qui ont publié entre 2006 et 2012 dans les conférences FD mais aussi CIKM qui contient une composante FD Ce qui caractérise ce cluster d’auteurs est leur densité de publications lors des six dernières années dans les conférences FD Le troisième cluster regroupe un autre type de chercheurs séniors en FD qui ont publié dans les conférences FD dans les premières années de leur lancement de 1995 à 2006 et moins récemment soit en raison de leur âge avancé soit en raison d’autres ac tivités de recherche e g S Tsumoto et T B Ho en bio informatique P Smyth et P Domingos en Machine Learning ou encore R Kohavi passé dans l’industrie Le dernier cluster regroupe un autre type de jeunes chercheurs en FD qui ont publié principalement à ICDM PAKDD et PKDD les dernières années – ce qui fait contraste par rapport aux autres auteurs Ce sont prin cipalement des auteurs d’origine Européenne ou de la zone Pacifique Asie qui publient dans les conférences régionales PAKDD et PKDD Les cinq autres clusters d’auteurs sont composés d’auteurs orientés BD De même différentes classes d’âge d’auteurs apparaissent e g un cluster de seniors qui ont publié dans les confé rences BD depuis leur lancement jusqu’en 2012 un cluster de jeunes auteurs qui ont beaucoup publié en BD à partir de 2003 2004 ou encore un cluster singulier d’auteurs dont la caracté ristique est un excès de publications à CIKM dans la dernière décennie Cette étude nous a permis de grouper les auteurs en fonction de leur séquence ou trajectoire de publications dans les neuf conférences de la base au cours du temps La grille ainsi que les indicateurs proposés nous ont permis d’analyser et de visualiser les résultats du clustering Ainsi nous sommes capables d’identifier facilement les conférences des communautés FD et BD et les auteurs qui y publient d’identifier les auteurs les plus typiques d’un cluster d’auteurs et de déterminer avec la mesure de contraste ce qui différencie un groupe d’auteurs du reste des auteurs de la base 4 Conclusion discussion Nous avons proposé une méthode de clustering et d’analyse de séquences temporelles ba sée sur les modèles en grille Les identifiants de séquence sont groupés en clusters ainsi que les évènements et la dimension temporelle est discrétisée en intervalles – le tout forme ainsi une grille tridimensionnelle ou tri clustering Obtenir la grille optimale au sens Bayésien ne nécessite aucun paramétrage utilisateur Pour exploiter la grille nous avons proposé i une mesure de dissimilarité entre clusters afin de sélectionner le grain de la grille tout en contrôlant la perte d’information ii un critère la typicité pour identifier les valeurs les plus représen tatives d’un cluster iii ainsi que deux critères basés sur l’information mutuelle pour caracté riser interpréter et visualiser les clusters trouvés Nos différentes propositions ont été validées sur des données simulées ainsi que sur des données réelles issues de DBLP Notons qu’une étude du comportement asymptotique des indicateurs proposés a été réalisée et qu’une étude complète des trajectoires antenne antenne d’utilisateurs du mobile – que l’on peut voir comme des séquences d’évènements – a été menée à l’échelle d’un pays voir Guigourès 2013 201 Clustering de séquences temporelles Références Bondu A M Boullé et D Gay 2013 Les modèles en grilles Principes évaluation algo rithmes et applications Tutorial given at EGC Boullé M 2012 Functional data clustering via piecewise constant nonparametric density estimation Pattern Recognition 45 12 4389–4401 Dhillon I S S Mallela et D S Modha 2003 Information theoretic co clustering In KDD’03 pp 89–98 ACM Press Giannotti F M Nanni et D Pedreschi 2006 Efficient mining of temporally annotated sequences In SDM Guigourès R 2013 Utilisation des modèles de co clustering pour l’analyse exploratoire des données Ph D thesis Université Paris 1 Panthéon Sorbonne Ley M 2009 DBLP some lessons learned PVLDB 2 2 1493–1500 Masseglia F P Poncelet M Teisseire et A Marascu 2008 Web usage mining extracting unexpected periods from web logs DMKD 16 1 39–65 Mörchen F 2007 Unsupervised pattern mining from symbolic temporal data SIGKDD Explorations 9 1 41–55 Nadif M et G Govaert 2010 Model based co clustering for continuous data In ICMLA pp 175–180 Patnaik D P Butler N Ramakrishnan L Parida B J Keller et D A Hanauer 2011 Experiences with mining temporal event sequences from electronic medical records initial successes and some challenges In KDD pp 360–368 Saleh B et F Masseglia 2011 Discovering frequent behaviors time is an essential element of the context KaIS 28 2 311–331 Studer M N S Müller G Ritschard et A Gabadinho 2010 Classer discriminer et visua liser des séquences d’événements In EGC pp 37–48 Yang Q et X Wu 2006 10 challenging problems in data mining research International Journal of Information Technology and Decision Making 5 4 597–604 Summary We suggest a novel way of clustering and analysing time annotated sequences by density estimation Our model is a tri dimensional data grid in which the sequences are partitioned into clusters the temporal dimension is discretized into intervals and the event dimension is partitioned into groups And the 3D cells of the grid form a nonparametric estimator of the joint density of the sequences and dimensions of the temporal events Thus the sequences of a cluster are similar in the sense that they follow the same density along the time dimension We also suggest a way for exploiting the clustering through the simplification of the grid together with new indicators useful for analyzing the learned clusters and characterizing their main components Experiments are lead on both synthetic and real data to demonstrate the efficiency and effectiveness of the approach 202 