contrôle risque multiple sélection règles association signi catives stéphane lallich prudhomme olivier teytaud laboratoire université lumière avenue pierre mendès france 69676 cedex france stephane lallich lyon2 prudhomme lyon2 artelys avenue jacques rousseau 92136 moulineaux olivier teytaud artelys résumé algorithmes extraction règles association parcourent cacement treillis itemsets constituer règles missibles seuils support donnent titude règles exploitables suggérons épurer telles bases éliminant règles statistiquement signi catives multitude tests pratiqués conduit mécaniquement multiplier règles sélection après avoir présenté procédures issues biostatistique contrôlent risque nombre fausses découvertes proposons bs_fd algorithme original fondé bootstrap sélectionne règles signi catives contrôlant nombre fausses découvertes expérimentations montrent cacité procédures clefs règle association qualité contrôle risque multiple admissibilité intérêt signi cation statistique recherche règles association intéressantes problème classique extraction connaissances partir données suite travaux agrawal cadre bases données transactionnelles telle enregistrement transaction champs correspondent articles disponibles nombre transactions nombre articles achat associé chaque article variable booléenne ensemble transactions matrice booléenne dimensions conjonction actes achat itemset associés ensemble articles comme variable booléenne partir matrice booléenne extraire règles client achète fromage alors probablement achète aussi règle association expression antécédent conséquent itemsets items communs nombres transactions réalisent respectivement items nombre celles réalisent proportions correspondantes désignées formalisme généralise toute données extrait table booléenne attributs contrôle risque sélection règles algorithmes extraction usuels reposent support particulier apriori algorithme fondateur agrawal srikant amélio rations proposées support règle proportion sactions réalisent alors proportion transactions réalisent parmi celles réalisent pabpa nabna algorithmes extraction support parcourent treillis itemsets rechercher itemsets fréquents support dépasse seuil minsupp cacité antimonotonie treillis déduit règles dépasse seuil minconf obtenant règles admissibles seuils choisis telles bases comportent grand nombre règles toujours intéressantes sélection règles intéressantes partir règles admissibles néces évaluer celles mesures ayant qualités requises compte nature règles association attentes utilisateur avons recensé telles mesures proposé critères évaluer lallich teytaud ainsi procédure décision choisir lenca chaque mesure choisie seuil minimal partir duquel règle sélectionnée retient nombre meilleures règles critère prise compte nombre observations oppose mesures statis tiques mesures descriptives logique priori souhaiter mesure statistique résultats observés étant autant ables grand cependant compte taille bases lesquelles recherche règles association telles mesures perdent pouvoir discriminant ainsi indice implication lerman intensité implication solutions intéressantes proposées indice probabiliste discriminant lerman centre réduit valeurs indice implication règles intensité impli cation entropique intensité implication facteur correctif tenant compte entropie expériences ensuit mélange notions signi cation intérêt perte intelligibilité mesure étudier paradoxalement nombre toutes règles milite abord tester signi cation statistique règles elles renforcent réellement probabilité conséquent testera hypothèse indépendance notée direction dépendance positive thèse alternative unilatérale notée ensuite utiliser mesures descriptives intelligibles discriminantes intérêt règles ltrée proposons ainsi nouvelle démarche dissocie signi cation statistique évaluation intérêt comporte trois étapes étape application algorithme support constituer règles admissibles seuils choisis étape ltrage règles indépendance chaque règle multitude tests pourrait tester pendance dépassement signi catif seuils support étape analyse règles gurant ltrée mesures descrip tives critères retenus utilisateur lenca lallich article approfondissons étape problème contrôler multiplicité tests éviter ation positifs chaque pratiqué risque espèce engendre mécaniquement positifs règles sélectionnées alors elles renforcent réellement probabilité conséquent avons proposé méthodes contrôle risque utilisant théorie apprentissage statistique dimension teytaud lallich bootstrap lallich teytaud pratique méthodes puissantes ignorant règles signi catives section détaille signi cation appliqué chaque règle contrôle positifs contrôler nombre fausses découvertes plutôt risque exposés section procédures contrôles récemment développées biostatistique présentées section méthode contrôle originale fondée bootstrap proposée section appliquons méthodes ltrer quelques bases règles section concluons section signi cation règle considérons règle mesure qualité croissante marges règle signi cative mesure valeur remet cause risque espèce décider signi cation calcule value probabilité obtenir valeur aussi grande sélectionne règle value cette démarche impose connaître cadre modélisation marges suppose répartis hasard indépendamment respectant marges démontre nombre exemples hypergéométrique convention variables aléatoires majuscules valeur observée marges value opérer approximation normale cette hypergéométrique conditions contraignantes savoir fonction répartition normale centrée réduite notant nabnanb valeur attendue cient corrélation entre vient value tabpb npapbpapb cient corrélation mesure privilégiée tester indépen dance dépendance positive risque erreurs espèce rechercher règles statistiquement signi catives parmi règles règles répète indépendance entre dépendance positive rencontre ainsi problème classique fouille données contrôle risque sélection règles réalité décision acceptation rejet total vraie vraie total synthèse résultats tests contrôle erreurs espèce positifs teste règles signi catives risque mécaniquement sélectionne règles règles 10000 correction bonferroni consiste pratiquer chaque risque risque rejeter moins suite bonne solution raisons contrôlé compris entre valant toutes règles indépendantes conservateur faveur augmente considérable risque espèce risque sélectionner règle pertinente régler problème évaluer erreurs espèce quantité moins sévère contrôler celle notamment lorsque tests indépendants règles indépendantes raison items elles partagent dépendances entre items érentes solutions développées récemment sélection gènes exprimant éremment suivant étiquette biopsie trouvera remarquable synthèse travaux fondamentale benjamini hochberg considérer risque erreur procédure lorsqu pratiquée nombre erreurs commises lorsque réitère procédure partir tableau quantités majuscules variables aléatoires observables celles minuscules étant inconnues concerne érents indicateurs erreurs commises présentons connus family error erreur famille complète false discovery fausses découvertes probabilité rejeter moins inconvénient sévère multiplicité tests suggéré variante exible originale autorise fausses découvertes appelons adjusted family error uafwer contrôle duquel proposons algorithme fondé bootstrap section remédier inconvénients diverses quantités reposant pérance nombre fausses découvertes éventuellement normalisée proposées connue benjamini hochberg proportion attendue règles sélectionnées parmi règles sélectionnées lorsque sinon ensuit storey proposé variante adaptée estimation erreur sachant hypothèse nulle refusée moins lallich quantités intérêt moins sévères résultat tests acceptation quelques sélections contrôle proportion augmente chaque probabilité règle pertinente sélectionnée puissance grand quand croît choisie nition risque multiple espèce problème contrôle allons examiner successivement celui procédures contrôle contrôle correction bonferroni correction bonferroni consiste calculer values ajustées prendre compte multiplicité tests etant données statistique relative règle value correspondante value ajustée notée sélectionne toutes règles ayant value ajustée inférieure risque montre condition indépendance règles vient défaut indépendance procédure procédures examinent values ordre croissant évoluer seuil procédure considère variable sélectionnée correspond situation fausse amène prendre compte nouveau seuil variables restant examiner values étant rangées ordre croissant désigne value refuse accepte toutes values suivent première acceptation cette procédure facile mettre oeuvre donne résultats lorsque nombre tests faible correction seuil ayant alors importance reste adaptée grand nombre tests procédure westfall young westfall young proposé procédure ajustement values contrôle oblige calculer calcul opéré randomi sation étiquettes variables règles indépendantes adapté recherche gènes exprimant éremment suivant étiquette biopsie procédé convient recherche règles association contrôle procédure benjamini benjamini méthode quentielle contrôler indépendance values prises ordre croissant rejette hypothèse nulle value examinée inférieure cette procédure assure indépendance compatible données positivement dépendantes contrôle risque sélection règles procédure storey cette procédure storey repose estimation celle celle nécessitant randomisation étiquettes adaptée règles estimer proportion fausses détec tions utilise approximation storey ˆpfdr nombre variables tester nombre règles rejet hypothèses correspondant value inférieures égales rejetées grande value proportion hypothèses nulles estimé cubic spline degrés liberté désigne acceptation valeurs comprises entre rapport rejet choisir avance global calculé variables contrôlées procédure grâce values chaque value value value erreur espèce value ajustée toute règle value value inférieure rejette sélectionne règle contrôle uafwer algorithme bs_fd notations ensemble transactions nombre items règles association valides critères prédé exemple support ensemble rassemblant règles valides signi catives critère désigne évaluation règle selon critère évaluation empirique règle selon critère ensemble nombre positifs risque procédure contrôle positifs nombre positifs souhaite dépasser risque sélectionner parmi règles celles statistiquement signi catives critère évaluation signi cativement élevée valeur attendue hypothèse indépendance avons suggéré lallich teytaud érents algorithmes utilisent outils apprentissage statistique garantir règles trouvées signi catives risque donné ainsi algorithme fondé bootstrap lallich expérimentations cette approche était prudente puissante prenant compte accepter façon contrôlée certain nombre fausses découvertes instar travaux benjamini section proposons bs_fd adapte algorithme contrôle nombre positifs algorithme bs_fd sélectionne règles candidates telle sorte contrôle uafwer assurant nombre règles sélectionnées positif dépasse risque précisément garantit converge limite grand échantillon transactions algorithme bs_fd garantir limiter perte généralité garantir remplaçant critère translaté suite opérateur cardinal associant ensemble cardinal cardinal ensemble évaluation empirique ensemble transactions grand nombre tirer remise liste éléments cardinal évaluation liste transactions calculer minimal obtient valeurs calculer quantile garder toutes règles telles réaliser dernière partie étape algorithme applique procédure calculerepsilon dessous procédure calculerepsilon tableauepsilon tableau taille variant tableauepsilon calculer grand élément tableauepsilon justi cation méthode méthodes bootstrap efron abord aspect intuitif approcher écart entre empirique réelle écart entre bootstrappée empirique outre elles profondes justi cations mathématiques nécessitent formalisation précise question posée formellement objectif fonction répartition nombre règles telles malgré valeur moins majoré théorèmes bootstrap appliqué famille fonctions hypothèses minimales waart wellner permettent approcher cette quantité contrôle risque sélection règles plusieurs critères pratique intéresse souvent plusieurs critères notre support critère indépendance extension algorithme bs_fd notée bs_fd_mc simplement utilisant comme critère unique érents critères ainsi travail critères considère utiliser bs_fd_mc risque fournit règles garanties critères risque optimiser risque seconde espèce gagnera travailler trans formations érentiables hadamard rendent critères mogènes exemple values réductions divisant écart empirique chaque critère valeur référence estimation écart issue complexité bs_fd complexité bs_fd proportionnelle considérant générateur nombres hasard fonctionne temps constant complexité recherche grand élément tableau proportionnelle taille tableau valeur assez grande imprécision nitude nuise globale dépend algorithme globalement linéaire forte constante bootstrap expérimentations description données méthodes ltrage présentées appliquées bases règles disponibles plateforme herbs vaillant celles extraites apriori suivant implémentation borgelt kruse bases mlearn mlsummary contraceptive method choice flags flags wisconsin breast cancer solar flare solar flare avons calculé chaque méthode réduction chaque après retrait règles signi catives caractéristiques résultats tableau dessous composé tableaux récapitulent carac téristiques chaque nombre règles sélectionnées suivant chaque méthode contrôle sélectionne règles ayant value bonferroni correction appliquée seuil procédure appliquée seuil bs_fd risque résultat appliqué cient corrélation comparé unilatéralement droite lallich caractéristiques flags règles couverture recouvrement seuil support seuil résultats flags contrôle bs_fd bonferroni filtrage quelques bases règles méthode décrite section utilisée seuil celui dernière value sélectionnée indiqué entre parenthèses comparer grossièrement nécessaire sélectionner règles degré contrôle voisin méthode utilisée rejet entre parenthèses indiqué nombre moyen rejets rejet choisie telle nombre acceptable possible bs_fd identique bs_fd trois critères comparé support comparés seuils utilisés extraction partir tableau opère érentes constatations bases ltrage totalement compris rection bonferroni raison seule règle départ value supérieure savoir autre autres values inférieures entre elles valent autres bases ltrage simple répétition indépendance réduit notablement ainsi ltrée reste encore beaucoup positifs rentes méthodes contrôle risque permettent encore éliminer comme prévu procédure contrôle risque sévère correction bonferroni donnant bases réduction sévérité cette procédure puissante limitant certes positifs augmentation négatifs procédure donne résultats voisins cacité venant grand nombre règles inutile correction seuil méthodes benjamini notre méthode bs_fd donnent sultats intermédiaires correspondant pouvait attendre méthode bs_fd apparaît comme sévère particulièrement solar contrôle risque sélection règles résultats cmc_app cmc_val croisement contrôle contrôle bs_fd bs_fd résultats validation flare raison paramétrage benjamini nombre moyen fausses découvertes alors bs_fd assure dépassé risque exigeant procédure ltrage autant nécessaire permet éliminer règles seraient sélectionnées nombre mesures qualité ainsi règles logiques conséquent fréquent solar flare elles valeur maximale toutes mesures donnent valeur maximale règles logiques alors elles aucune espèce intérêt value signi cative inverse calcul values préjuge classement ultérieur règles mesures descriptives favorisant règles intéressantes exemple mesures dissymétriques avantagent règles conséquent validation résultats alors découpage apprentissage validation courant apprentissage supervisé jamais pratiqué domaine règles association raison doute règles association ressortent apprentissage supervisé extraction suivant support tâche déterministe clairement comme souligne freitas mesure avons introduit signi cation logique distinguer apprentissage validation étudier pertinence règles sélectionnées apprentissage séparée hasard bases taille cmc_app avons extrait règles admissibles algorithme apriori avons règles érentes méthodes présentées ensuite tableau avons examiné comment comportaient règles admissibles issues cmc_app lorsqu elles étaient appliquées cmc_val avons calculé parmi règles sélectionnées chaque méthode cmc_app combien étaient encore sélectionnées méthode cmc_val constate ainsi règles admissibles cmc_val encore cmc_app alors descend lorsque règle garder règles signi catives quelle méthode revanche application bs_fd trois critères support permet revenir sérieuse diminution nombre règles lallich conclusion travaux futurs partons principe simple garder règles celles renforcent conclusion conséquent faire proposons stratégie ltrage bases règles conduit pratiquer multitude tests unilatéraux droite cient corrélation entre cette stratégie fondée contrôle nombre règles sélectionnées risque assurant grande puissance permettant utilisateur entre règles sélectionnées règles pertinentes sélectionnées proposons algorithme original bs_fd avantage contrôler directement nombre positifs moyenne tenant compte dépendance règles permettant tester plusieurs critères expérimenta tions montrent cacité stratégie proposée permet réduire sensiblement taille facilitant recours ultérieur mesures qualité descriptives apportent point complémentaire pertinence règles extension travail prévue fouille données génomiques chercher règles discriminantes procédures contrôle risque intéressent ensemble méthodes fouille données multiplie tests références agrawal srikant agrawal srikant algorithms mining ciation rules conference santiago chile agrawal agrawal imielinski swami mining associations between items large databases sigmod shington benjamini hochberg benjamini hochberg controlling false covery practical powerful approach multiple testing statisc benjamini benjamini multiple hypothesis procedure controls false discovery under independance planng borgelt kruse borgelt kruse induction association rules apriori implementation physika verlag germany efron efron bootstrap methods another jacknkife annals statistics freitas freitas understanding crucial erence between classi cation discovery association rules sigkdd explorations dudoit speed resampling based multiple testing microarray analysis california berkeley bootstrapping general empirical measures annals probability contribution étude expérimentale analyse certaines acquisitions cognitives certains objectifs didactiques mathematiques thèse contrôle risque sélection règles rennes kuntz couturier guillet version entropique intensité implication corpus volumineux revue extraction connaissances apprentissage hermès simple sequentially rejective multiple procedure scand statistic lallich teytaud lallich teytaud evaluation validation intérêt règles association paraître revue nouvelles technologies information cépaduès toulouse lenca lenca meyer picouet vaillant lallich tères évaluation mesures qualité règles association revue nouvelles technologies information cépaduès toulouse lerman lerman mesure contextuelle dicriminante qualité règles association lerman lerman rostam elaboration évalua indice implication données binaires mathématiques sciences humaines storey storey positive false discovery value écrit paraître annals statistics teytaud lallich teytaud lallich bornes uniformes extraction règles association actes colloque grenoble vaillant vaillant picouet lenca extensible platform quality measure benchmarking bisdor human centered processes vaart wellner vaart wellner convergence empirical processes springer series statistics vapnik vapnik nature statistical learning springer westfall young westfall young resampling based multiple testing examples methods values adjustment wiley summary association rules extraction algorithms allow ciently through lattice order constitute rules acceptable prede support dence levels however result multitude rules hardly exploitable suggest bases eliminating statistically signi rules titude performed tests mechanically leads multiplication false discoveries present procedures issued biostatistic which controlling number false discoveries propose bs_fd original algorithm based bootstrap which selects signi rules while controlling number false discoveries experimenting these procedures erent bases their ability rules bases keywords association quality multiple testing control